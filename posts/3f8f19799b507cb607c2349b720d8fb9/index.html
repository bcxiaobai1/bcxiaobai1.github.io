<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<title>毕业设计：深度学习卷积神经网络垃圾分类系统 - 深度学习 神经网络 图像识别 垃圾分类 算法 小程序 - 编程小白</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程小白" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程小白</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">毕业设计：深度学习卷积神经网络垃圾分类系统 - 深度学习 神经网络 图像识别 垃圾分类 算法 小程序</h1>
			
		</header>
		<div class="content post__content clearfix">
			


                <div id="content_views" class="markdown_views prism-atom-one-light">
                    
                        
                    
                    <p></p>
<div class="toc">
 <h3>文章目录</h3>
 <ul>
<li><a href="#0__1">0 简介</a></li>
<li><a href="#1__13">1 背景意义</a></li>
<li><a href="#2__20">2 数据集</a></li>
<li><a href="#3__32">3 数据探索</a></li>
<li><a href="#4__40">4 数据增广(数据集补充)</a></li>
<li><a href="#5__57">5 垃圾图像分类</a></li>
<li>
<ul>
<li><a href="#51__59">5.1 迁移学习</a></li>
<li>
<ul>
<li><a href="#511__61">5.1.1 什么是迁移学习？</a></li>
<li><a href="#512__65">5.1.2 为什么要迁移学习？</a></li>
</ul>
   </li>
<li><a href="#52__79">5.2 模型选择</a></li>
<li><a href="#53__96">5.3 训练环境</a></li>
<li>
<ul>
<li><a href="#531__98">5.3.1 硬件配置</a></li>
<li><a href="#532__102">5.3.2 软件配置</a></li>
</ul>
   </li>
<li><a href="#54__106">5.4 训练过程</a></li>
<li><a href="#55_PC_117">5.5 模型分类效果(PC端)</a></li>
</ul>
  </li>
<li><a href="#6__122">6 构建垃圾分类小程序</a></li>
<li>
<ul>
<li><a href="#61__132">6.1 小程序功能</a></li>
<li><a href="#62__143">6.2 分类测试</a></li>
<li><a href="#63__149">6.3 垃圾分类小提示</a></li>
<li><a href="#64__157">6.4 答题模块</a></li>
</ul>
  </li>
<li><a href="#7__416">7 关键代码</a></li>
<li><a href="#8__836">8 最后-毕设帮助</a></li>
</ul>
</div>
<p></p> 
<h1>
<a id="0__1"></a>0 简介</h1> 
<p>今天学长向大家介绍一个机器视觉项目</p> 
<p><strong>深度学习卷积神经网络垃圾分类系统</strong></p> 
<pre><code class="prism language-python">毕设帮助，开题指导，技术解答
?<span class="token number">746876041</span>
</code></pre> 
<h1>
<a id="1__13"></a>1 背景意义</h1> 
<p>近年来，随着我国经济的快速发展，国家各项建设都蒸蒸日上，成绩显著。但与此同时，也让资源与环境受到了严重破坏。这种现象与垃圾分类投放时的不合理直接相关，而人们对于环境污染问题反映强烈却束手无策，这两者间的矛盾日益尖锐。人们日常生活中的垃圾主要包括有害垃圾、厨余垃圾、可回收垃圾以及其他垃圾这四类，对不同类别的垃圾应采取不同分类方法，如果投放不当，可能会导致各种环境污染问题。合理地进行垃圾分类是有效进行垃圾处理、减少环境污染与资源再利用中的关键举措，也是目前最合适最有效的科学管理方式，利用现有的生产水平将日常垃圾按类别处理、利用有效物质和能量、填埋无用垃圾等。这样既能够提高垃圾资源处理效率，又能缓解环境污染问题。</p> 
<p>而对垃圾的分类首先是在图像识别的基础上的，因此本文想通过使用近几年来发展迅速的深度学习方法设计一个垃圾分类系统，从而实现对日常生活中常见垃圾进行智能识别分类，提高人们垃圾分类投放意识，同时避免人们错误投放而产生的环境污染。</p> 
<h1>
<a id="2__20"></a>2 数据集</h1> 
<p>数据集采用了中国发布的垃圾分类标准，该标准将人们日常生活中常见的垃圾分为了四大类。其中，将废弃的玻璃、织物、家具以及电器电子产品等适合回收同时可循环利用的废弃物归为可回收垃圾。将剩菜剩饭、果皮果壳、花卉绿植以及其他餐厨垃圾等容易腐烂的废弃物归为厨余垃圾。将废电池、废药品、废灯管等对人们身体健康和自然环境有害而且应当门处理的废弃物归为有害垃圾。除以上三类垃圾之外的废弃物都归为其他垃圾。</p> 
<p>该数据集是图片数据，分为训练集85%（Train）和测试集15%（Test）。其中O代表Organic（有机垃圾），R代表Recycle（可回收）</p> 
<p><img src="https://images2.imgbox.com/fa/79/y3Plcarf_o.png" alt="在这里插入图片描述"></p> 
<p><img src="https://images2.imgbox.com/2f/c1/VZuFg32j_o.png" alt="在这里插入图片描述"></p> 
<h1>
<a id="3__32"></a>3 数据探索</h1> 
<p>我们先简单的大致看看数据的情况</p> 
<p>所得的垃圾图片数据集中有40个二级类别，图片数量合计 14802张。由图3-1可以看出，各个垃圾类别的图像数据量不均衡，其中图片数据量较少的类别有：类别0(一次性快餐盒)、类别3(牙签)、类别20(快递纸袋)；数据量较多的类别是：类别11(菜叶根)、类别21(插头电线)、类别25(毛绒玩具)。</p> 
<p><img src="https://images2.imgbox.com/4c/fc/KH544I8D_o.png" alt="在这里插入图片描述"></p> 
<h1>
<a id="4__40"></a>4 数据增广(数据集补充)</h1> 
<p>数据增广就是对基础数据集进行扩充，避免因为数据集太少导致在模型训练过程可能出现的过拟合现象，以此来提高模型泛化能力，达到更好的效果。根据扩充数据集的来源可分为两类：内部数据增广是对基础数据集进行水平翻转、垂直翻转、高斯噪声以及高斯模糊等变换操作，来产生新的特征；而外部数据增广是引入新的高质量外部数据来扩充数据集，包括数据爬取与数据筛选两个步骤。</p> 
<p>数据爬取是通过网络爬虫技术来实现的，爬虫的流程是，首先向远程服务器端发送请求，获取目标网页的HTML文件；然后跟踪这个链接文件，获取文件数据。各种搜索引擎就是通过爬虫技术来实现网页数据更新，爬取的效率直接决定了搜索的效果。</p> 
<p><img src="https://images2.imgbox.com/80/a3/nYKCc9NK_o.png" alt="在这里插入图片描述"></p> 
<p>根据流程图可以看到，爬虫的流程与用户浏览网页的过程相似，首先输入目标URL地址，向服务器发送请求，接着服务器端会返回包含大量链接的HTML文件，然后提取这些链接将其组成URL列表，通过串行或并行方式从服务器端中下载数据。</p> 
<p>由于基础数据集中类别数量不均衡，所以本设计使用网络爬虫方式从百度图库对数量较少的类别进行数据扩充，首先输入想要爬取的图片名称关键字，然后输入想要爬取图片的数量以及存放的文件夹之后，进行图片爬取。</p> 
<p><img src="https://images2.imgbox.com/b0/da/2KoccwGJ_o.png" alt="在这里插入图片描述"></p> 
<p><img src="https://images2.imgbox.com/c2/6c/DSiA3VXQ_o.png" alt="在这里插入图片描述"></p> 
<h1>
<a id="5__57"></a>5 垃圾图像分类</h1> 
<h2>
<a id="51__59"></a>5.1 迁移学习</h2> 
<h3>
<a id="511__61"></a>5.1.1 什么是迁移学习？</h3> 
<p>迁移学习是指在一个数据集上，重新利用之前已经训练过的卷积神经网络，并将其迁移到另外的数据集上。</p> 
<h3>
<a id="512__65"></a>5.1.2 为什么要迁移学习？</h3> 
<p>卷积神经网络前面的层提取的是图像的纹理、色彩等特征，而越靠近网络后端，提取的特征就会越高级、抽象。所以常用的微调方法是，保持网络中其他参数不变，只修改预训练网络的最后几层，最后几层的参数在新数据集上重新训练得到。其他层的参数保持不变，作为特征提取器，之后再使用较小的学习率训练整个网络。因为从零开始训练整个卷积网络是非常困难的，而且要花费大量的时间以及计算资源，所以采取迁移学习的方式是一种有效策略。</p> 
<p>通常在非常大的数据集上对ConvNet进行预训练，然后将ConvNet用作初始化或者是固定特征提取器，以下是两个主要的迁移学习方法：</p> 
<p>1.微调卷积网络。使用预训练的网络来初始化网络而不使用随机初始化，比较常用的方法是使用在ImageNet数据集上训练好的模型参数进行初始化，然后训练自己的数据集。</p> 
<p>2.将卷积网络作为固定特征提取器。冻结除了全连接层外的所有其他层的权重，将最后的那个全连接层替换为具有随机权重的层，然后只对该层进行训练。</p> 
<p>要使用深度学习方法来解决垃圾图像识别分类问题，就需要大量的垃圾图片数据集，因为当数据集太小时，一旦加深模型结构，就很可能出现过拟合的情况，训练出的模型泛化能力不足，识别准确率不高。而基于迁移学习的方法，预训练模型已经具备了提取图像基本特征基的能力，这就能在一定程度上减缓过拟合发生的可能性，将预模型迁移到垃圾图像数据集上进行微调训练，提高识别准确率。</p> 
<h2>
<a id="52__79"></a>5.2 模型选择</h2> 
<p>采用迁移学习的方式导入预训练模型，冻结特征提取层，进行微调训练，选取了SeNet154、Se_ResNet50、Se_ResNext101、ResNext101_32x16d_WSL四种模型进行对比实验，选取结果较好的模型进行调优。其中，ResNext101_32x16d_WS预训练模型是由FaceBook在2019年开源的</p> 
<p><strong>SeNet154结构</strong></p> 
<p><img src="https://images2.imgbox.com/3b/a9/1BYLQbpe_o.png" alt="在这里插入图片描述"></p> 
<p><strong>学长采用的模型结构：</strong></p> 
<p><img src="https://images2.imgbox.com/4b/ef/IirdQ0Wp_o.png" alt="在这里插入图片描述"></p> 
<p>采用ResNext101_32x16d_WSL网络作为基本的网络结构进行迁移学习，将CBAM注意力机制模块添加在首层卷积层，来增强图像特征表征能力，关注图像的重要特征抑制不必要的特征，固定除全连接层之外的其他层的权重。为降低过拟合,在模型全连接层添加了Dropout层，损失函数采用交叉熵损失函数（CrossEntropyLoss）,优化函数对比了SGD和Adam,Adam在起始收敛速度快，但最终SGD精度高，所以采用了SGD。</p> 
<h2>
<a id="53__96"></a>5.3 训练环境</h2> 
<h3>
<a id="531__98"></a>5.3.1 硬件配置</h3> 
<p><img src="https://images2.imgbox.com/de/d9/4HCXEAE4_o.png" alt="在这里插入图片描述"></p> 
<h3>
<a id="532__102"></a>5.3.2 软件配置</h3> 
<p><img src="https://images2.imgbox.com/de/9c/JVnK13EM_o.png" alt="在这里插入图片描述"></p> 
<h2>
<a id="54__106"></a>5.4 训练过程</h2> 
<p>构建好模型结构后，设置数据集加载路径，在搭建好的环境中进行模型训练，将训练过程中每轮迭代的Train Loss、Valid Loss、Train Acc、Valid Acc等数据保存到log日志文件中，然后使用matplotlib库绘制在训练集和测试集上的Accuracy跟Loss的变化曲线。</p> 
<p>目前模型训练集准确度83.8%，测试集准确度67.5%，仍有待提高。。</p> 
<p><img src="https://images2.imgbox.com/60/dc/pBh1FZef_o.png" alt="在这里插入图片描述"></p> 
<h2>
<a id="55_PC_117"></a>5.5 模型分类效果(PC端)</h2> 
<p><img src="https://images2.imgbox.com/09/14/VwDk4XZz_o.png" alt="在这里插入图片描述"></p> 
<h1>
<a id="6__122"></a>6 构建垃圾分类小程序</h1> 
<p>学长设计的垃圾分类系统的核心功能是从本地相册上传照片或拍照上传照片进行识别分类，除此之外，还引入了语音识别功能、文字搜索功能、垃圾分类答题功能等满足用户的不同需求。系统的模块设计如下图所示。</p> 
<p>·<img src="https://images2.imgbox.com/cf/0c/ANmw1uwY_o.png" alt="在这里插入图片描述"></p> 
<p>其中识别模块是用户选择识别功能，包含拍照/相册识别，语音识别、文字搜索等功能，根据所选城市的不同展示相应的垃圾类别；指南功能模块是根据所选城市的不同介绍各种垃圾的种类以及投放要求；答题模块实现垃圾种类的选择答题功能。</p> 
<h2>
<a id="61__132"></a>6.1 小程序功能</h2> 
<p>识别模块的功能包括文字搜索、语音识别、拍照识别等，该模块界面设计如图所示：</p> 
<p><img src="https://images2.imgbox.com/ee/68/07aPImBS_o.png" alt="在这里插入图片描述"></p> 
<p>首先选择用户所在城市，然后选择使用的搜索方式，当通过三种搜索方式搜索不到相应垃圾类别时，可以通过反馈功能将未识别的垃圾名称向后台反馈信息，以便进一步完善系统。系统核心功能为拍照识别功能，拍照识别功能即调用在前面已经部署在华为云Model Arts平台上的垃圾分类识别模型，对用户从手机端提交的垃圾图片进行在线识别分类并返回识别结果，调用过程中用到了小程序的云函数功能。</p> 
<h2>
<a id="62__143"></a>6.2 分类测试</h2> 
<p><img src="https://images2.imgbox.com/75/d5/3vN9pp5z_o.png" alt="在这里插入图片描述"></p> 
<p><img src="https://images2.imgbox.com/7e/a9/O0SXfLl8_o.png" alt="在这里插入图片描述"></p> 
<h2>
<a id="63__149"></a>6.3 垃圾分类小提示</h2> 
<p>指南模块实现的功能是根据用户所选择的城市，将云数据库中的数据展示给用户，介绍目前不同城市发布的垃圾分类规则及投放的要求，如下图所示：</p> 
<p><img src="https://images2.imgbox.com/99/f8/BzhS6l3p_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/07/ee/bMvIxJJA_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/32/80/qGaGLDFq_o.png" alt="在这里插入图片描述"></p> 
<h2>
<a id="64__157"></a>6.4 答题模块</h2> 
<p>答题模块也是根据用户所选城市的不同，测评用户对其所在城市垃圾分类规则了解的程度，以此来科普垃圾分类知识以及增强人们垃圾分类的意识，该界面如下图所示，在答完题后显示分数以及正确答案。</p> 
<p><img src="https://images2.imgbox.com/9f/70/Ju3t7QIE_o.png" alt="在这里插入图片描述"></p> 
<p><img src="https://images2.imgbox.com/50/3a/VPycawNL_o.png" alt="在这里插入图片描述"></p> 
<p><strong>答题答案表</strong></p> 
<pre><code class="prism language-bash">├─ 其他垃圾_PE塑料袋
├─ 其他垃圾_U型回形针
├─ 其他垃圾_一次性杯子
├─ 其他垃圾_一次性棉签
├─ 其他垃圾_串串竹签
├─ 其他垃圾_便利贴
├─ 其他垃圾_创可贴
├─ 其他垃圾_卫生纸
├─ 其他垃圾_厨房手套
├─ 其他垃圾_厨房抹布
├─ 其他垃圾_口罩
├─ 其他垃圾_唱片
├─ 其他垃圾_图钉
├─ 其他垃圾_大龙虾头
├─ 其他垃圾_奶茶杯
├─ 其他垃圾_干燥剂
├─ 其他垃圾_彩票
├─ 其他垃圾_打泡网
├─ 其他垃圾_打火机
├─ 其他垃圾_搓澡巾
├─ 其他垃圾_果壳
├─ 其他垃圾_毛巾
├─ 其他垃圾_涂改带
├─ 其他垃圾_湿纸巾
├─ 其他垃圾_烟蒂
├─ 其他垃圾_牙刷
├─ 其他垃圾_电影票
├─ 其他垃圾_电蚊香
├─ 其他垃圾_百洁布
├─ 其他垃圾_眼镜
├─ 其他垃圾_眼镜布
├─ 其他垃圾_空调滤芯
├─ 其他垃圾_笔
├─ 其他垃圾_胶带
├─ 其他垃圾_胶水废包装
├─ 其他垃圾_苍蝇拍
├─ 其他垃圾_茶壶碎片
├─ 其他垃圾_草帽
├─ 其他垃圾_菜板
├─ 其他垃圾_车票
├─ 其他垃圾_酒精棉
├─ 其他垃圾_防霉防蛀片
├─ 其他垃圾_除湿袋
├─ 其他垃圾_餐巾纸
├─ 其他垃圾_餐盒
├─ 其他垃圾_验孕棒
├─ 其他垃圾_鸡毛掸
├─ 厨余垃圾_八宝粥
├─ 厨余垃圾_冰激凌
├─ 厨余垃圾_冰糖葫芦
├─ 厨余垃圾_咖啡
├─ 厨余垃圾_圣女果
├─ 厨余垃圾_地瓜
├─ 厨余垃圾_坚果
├─ 厨余垃圾_壳
├─ 厨余垃圾_巧克力
├─ 厨余垃圾_果冻
├─ 厨余垃圾_果皮
├─ 厨余垃圾_核桃
├─ 厨余垃圾_梨
├─ 厨余垃圾_橙子
├─ 厨余垃圾_残渣剩饭
├─ 厨余垃圾_水果
├─ 厨余垃圾_泡菜
├─ 厨余垃圾_火腿
├─ 厨余垃圾_火龙果
├─ 厨余垃圾_烤鸡
├─ 厨余垃圾_瓜子
├─ 厨余垃圾_甘蔗
├─ 厨余垃圾_番茄
├─ 厨余垃圾_秸秆杯
├─ 厨余垃圾_秸秆碗
├─ 厨余垃圾_粉条
├─ 厨余垃圾_肉类
├─ 厨余垃圾_肠
├─ 厨余垃圾_苹果
├─ 厨余垃圾_茶叶
├─ 厨余垃圾_草莓
├─ 厨余垃圾_菠萝
├─ 厨余垃圾_菠萝蜜
├─ 厨余垃圾_萝卜
├─ 厨余垃圾_蒜
├─ 厨余垃圾_蔬菜
├─ 厨余垃圾_薯条
├─ 厨余垃圾_薯片
├─ 厨余垃圾_蘑菇
├─ 厨余垃圾_蛋
├─ 厨余垃圾_蛋挞
├─ 厨余垃圾_蛋糕
├─ 厨余垃圾_豆
├─ 厨余垃圾_豆腐
├─ 厨余垃圾_辣椒
├─ 厨余垃圾_面包
├─ 厨余垃圾_饼干
├─ 厨余垃圾_鸡翅
├─ 可回收物_不锈钢制品
├─ 可回收物_乒乓球拍
├─ 可回收物_书
├─ 可回收物_体重秤
├─ 可回收物_保温杯
├─ 可回收物_保鲜膜内芯
├─ 可回收物_信封
├─ 可回收物_充电头
├─ 可回收物_充电宝
├─ 可回收物_充电牙刷
├─ 可回收物_充电线
├─ 可回收物_凳子
├─ 可回收物_刀
├─ 可回收物_包
├─ 可回收物_单车
├─ 可回收物_卡
├─ 可回收物_台灯
├─ 可回收物_吊牌
├─ 可回收物_吹风机
├─ 可回收物_呼啦圈
├─ 可回收物_地球仪
├─ 可回收物_地铁票
├─ 可回收物_垫子
├─ 可回收物_塑料制品
├─ 可回收物_太阳能热水器
├─ 可回收物_奶粉桶
├─ 可回收物_尺子
├─ 可回收物_尼龙绳
├─ 可回收物_布制品
├─ 可回收物_帽子
├─ 可回收物_手机
├─ 可回收物_手电筒
├─ 可回收物_手表
├─ 可回收物_手链
├─ 可回收物_打包绳
├─ 可回收物_打印机
├─ 可回收物_打气筒
├─ 可回收物_扫地机器人
├─ 可回收物_护肤品空瓶
├─ 可回收物_拉杆箱
├─ 可回收物_拖鞋
├─ 可回收物_插线板
├─ 可回收物_搓衣板
├─ 可回收物_收音机
├─ 可回收物_放大镜
├─ 可回收物_日历
├─ 可回收物_暖宝宝
├─ 可回收物_望远镜
├─ 可回收物_木制切菜板
├─ 可回收物_木桶
├─ 可回收物_木棍
├─ 可回收物_木质梳子
├─ 可回收物_木质锅铲
├─ 可回收物_木雕
├─ 可回收物_枕头
├─ 可回收物_果冻杯
├─ 可回收物_桌子
├─ 可回收物_棋子
├─ 可回收物_模具
├─ 可回收物_毯子
├─ 可回收物_水壶
├─ 可回收物_水杯
├─ 可回收物_沙发
├─ 可回收物_泡沫板
├─ 可回收物_灭火器
├─ 可回收物_灯罩
├─ 可回收物_烟灰缸
├─ 可回收物_热水瓶
├─ 可回收物_燃气灶
├─ 可回收物_燃气瓶
├─ 可回收物_玩具
├─ 可回收物_玻璃制品
├─ 可回收物_玻璃器皿
├─ 可回收物_玻璃壶
├─ 可回收物_玻璃球
├─ 可回收物_瑜伽球
├─ 可回收物_电动剃须刀
├─ 可回收物_电动卷发棒
├─ 可回收物_电子秤
├─ 可回收物_电熨斗
├─ 可回收物_电磁炉
├─ 可回收物_电脑屏幕
├─ 可回收物_电视机
├─ 可回收物_电话
├─ 可回收物_电路板
├─ 可回收物_电风扇
├─ 可回收物_电饭煲
├─ 可回收物_登机牌
├─ 可回收物_盒子
├─ 可回收物_盖子
├─ 可回收物_盘子
├─ 可回收物_碗
├─ 可回收物_磁铁
├─ 可回收物_空气净化器
├─ 可回收物_空气加湿器
├─ 可回收物_笼子
├─ 可回收物_箱子
├─ 可回收物_纸制品
├─ 可回收物_纸牌
├─ 可回收物_罐子
├─ 可回收物_网卡
├─ 可回收物_耳套
├─ 可回收物_耳机
├─ 可回收物_衣架
├─ 可回收物_袋子
├─ 可回收物_袜子
├─ 可回收物_裙子
├─ 可回收物_裤子
├─ 可回收物_计算器
├─ 可回收物_订书机
├─ 可回收物_话筒
├─ 可回收物_豆浆机
├─ 可回收物_路由器
├─ 可回收物_轮胎
├─ 可回收物_过滤网
├─ 可回收物_遥控器
├─ 可回收物_量杯
├─ 可回收物_金属制品
├─ 可回收物_钉子
├─ 可回收物_钥匙
├─ 可回收物_铁丝球
├─ 可回收物_铅球
├─ 可回收物_铝制用品
├─ 可回收物_锅
├─ 可回收物_锅盖
├─ 可回收物_键盘
├─ 可回收物_镊子
├─ 可回收物_闹铃
├─ 可回收物_雨伞
├─ 可回收物_鞋
├─ 可回收物_音响
├─ 可回收物_餐具
├─ 可回收物_餐垫
├─ 可回收物_饰品
├─ 可回收物_鱼缸
├─ 可回收物_鼠标
├─ 有害垃圾_指甲油
├─ 有害垃圾_杀虫剂
├─ 有害垃圾_温度计
├─ 有害垃圾_灯
├─ 有害垃圾_电池
├─ 有害垃圾_电池板
├─ 有害垃圾_纽扣电池
├─ 有害垃圾_胶水
├─ 有害垃圾_药品包装
├─ 有害垃圾_药片
├─ 有害垃圾_药瓶
├─ 有害垃圾_药膏
├─ 有害垃圾_蓄电池
└─ 有害垃圾_血压计
</code></pre> 
<h1>
<a id="7__416"></a>7 关键代码</h1> 
<pre><code class="prism language-python"><span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tf
<span class="token keyword">import</span> linecache
<span class="token keyword">import</span> cv2
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> os

<span class="token keyword">from</span> select_object <span class="token keyword">import</span> pretreatment_image

train_images_path <span class="token operator">=</span> <span class="token string">'D:/WorkSpace/Python/trash_classify_dataset/dataset/'</span>
train_labels_path <span class="token operator">=</span> <span class="token string">'D:/WorkSpace/Python/trash_classify_dataset/train_label.txt'</span>
test_images_path <span class="token operator">=</span> <span class="token string">'D:/WorkSpace/Python/trash_classify_dataset/dataset/'</span>
test_labels_path <span class="token operator">=</span> <span class="token string">'D:/WorkSpace/Python/trash_classify_dataset/test_label.txt'</span>

classify_num <span class="token operator">=</span> <span class="token number">50</span>
train_images_num <span class="token operator">=</span> <span class="token number">29081</span>
test_images_num <span class="token operator">=</span> <span class="token number">3232</span>


<span class="token keyword">def</span> <span class="token function">load_train_dataset</span><span class="token punctuation">(</span>index<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment"># 从1开始</span>
    <span class="token keyword">if</span> index <span class="token operator">&gt;</span> train_images_num<span class="token punctuation">:</span>
        <span class="token keyword">if</span> index <span class="token operator">%</span> train_images_num <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
            index <span class="token operator">=</span> train_images_num
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            index <span class="token operator">%=</span> train_images_num
    line_str <span class="token operator">=</span> linecache<span class="token punctuation">.</span>getline<span class="token punctuation">(</span>train_labels_path<span class="token punctuation">,</span> index<span class="token punctuation">)</span>
    image_name<span class="token punctuation">,</span> image_label <span class="token operator">=</span> line_str<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">' '</span><span class="token punctuation">)</span>
    image <span class="token operator">=</span> cv2<span class="token punctuation">.</span>imread<span class="token punctuation">(</span>train_images_path <span class="token operator">+</span> image_name<span class="token punctuation">)</span>
    <span class="token comment"># cv2.imshow('pic',image)</span>
    image <span class="token operator">=</span> cv2<span class="token punctuation">.</span>cvtColor<span class="token punctuation">(</span>image<span class="token punctuation">,</span> cv2<span class="token punctuation">.</span>COLOR_BGR2RGB<span class="token punctuation">)</span>
    image <span class="token operator">=</span> cv2<span class="token punctuation">.</span>resize<span class="token punctuation">(</span>image<span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">224</span><span class="token punctuation">,</span> <span class="token number">224</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> image<span class="token punctuation">,</span> image_label


<span class="token keyword">def</span> <span class="token function">combine_train_dataset</span><span class="token punctuation">(</span>count<span class="token punctuation">,</span> size<span class="token punctuation">)</span><span class="token punctuation">:</span>
    train_images_load <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>shape<span class="token operator">=</span><span class="token punctuation">(</span>size<span class="token punctuation">,</span> <span class="token number">224</span><span class="token punctuation">,</span> <span class="token number">224</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    train_labels_load <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>shape<span class="token operator">=</span><span class="token punctuation">(</span>size<span class="token punctuation">,</span> classify_num<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>size<span class="token punctuation">)</span><span class="token punctuation">:</span>
        train_images_load<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span> train_labels_index <span class="token operator">=</span> load_train_dataset<span class="token punctuation">(</span>count <span class="token operator">+</span> i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span>
        train_labels_load<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">(</span>train_labels_index<span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">1.0</span>
    count <span class="token operator">+=</span> size
    <span class="token keyword">return</span> train_images_load<span class="token punctuation">,</span> train_labels_load<span class="token punctuation">,</span> count


<span class="token keyword">def</span> <span class="token function">load_test_dataset</span><span class="token punctuation">(</span>index<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment"># 从1开始</span>
    <span class="token keyword">if</span> index <span class="token operator">&gt;</span> test_images_num<span class="token punctuation">:</span>
        <span class="token keyword">if</span> index <span class="token operator">%</span> test_images_num <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
            index <span class="token operator">=</span> test_images_num
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            index <span class="token operator">%=</span> test_images_num
    line_str <span class="token operator">=</span> linecache<span class="token punctuation">.</span>getline<span class="token punctuation">(</span>test_labels_path<span class="token punctuation">,</span> index<span class="token punctuation">)</span>
    image_name<span class="token punctuation">,</span> image_label <span class="token operator">=</span> line_str<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">' '</span><span class="token punctuation">)</span>
    image <span class="token operator">=</span> cv2<span class="token punctuation">.</span>imread<span class="token punctuation">(</span>test_images_path <span class="token operator">+</span> image_name<span class="token punctuation">)</span>
    image <span class="token operator">=</span> cv2<span class="token punctuation">.</span>cvtColor<span class="token punctuation">(</span>image<span class="token punctuation">,</span> cv2<span class="token punctuation">.</span>COLOR_BGR2RGB<span class="token punctuation">)</span>
    image <span class="token operator">=</span> cv2<span class="token punctuation">.</span>resize<span class="token punctuation">(</span>image<span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">224</span><span class="token punctuation">,</span> <span class="token number">224</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> image<span class="token punctuation">,</span> image_label


<span class="token keyword">def</span> <span class="token function">combine_test_dataset</span><span class="token punctuation">(</span>count<span class="token punctuation">,</span> size<span class="token punctuation">)</span><span class="token punctuation">:</span>
    test_images_load <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>shape<span class="token operator">=</span><span class="token punctuation">(</span>size<span class="token punctuation">,</span> <span class="token number">224</span><span class="token punctuation">,</span> <span class="token number">224</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    test_labels_load <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>shape<span class="token operator">=</span><span class="token punctuation">(</span>size<span class="token punctuation">,</span> classify_num<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>size<span class="token punctuation">)</span><span class="token punctuation">:</span>
        test_images_load<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span> test_labels_index <span class="token operator">=</span> load_test_dataset<span class="token punctuation">(</span>count <span class="token operator">+</span> i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span>
        test_labels_load<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">(</span>test_labels_index<span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">1.0</span>
    count <span class="token operator">+=</span> size
    <span class="token keyword">return</span> test_images_load<span class="token punctuation">,</span> test_labels_load<span class="token punctuation">,</span> count


<span class="token comment"># # 通过L2正则化防止过拟合</span>
<span class="token comment"># def weight_variable_with_loss(shape, stddev, lam):</span>
<span class="token comment">#     weight = tf.Variable(tf.truncated_normal(shape, stddev=stddev))</span>
<span class="token comment">#     if lam is not None:</span>
<span class="token comment">#         weight_loss = tf.multiply(tf.nn.l2_loss(weight), lam, name='weight_loss')</span>
<span class="token comment">#         tf.add_to_collection('losses', weight_loss)</span>
<span class="token comment">#     return weight</span>

<span class="token keyword">def</span> <span class="token function">weight_variable</span><span class="token punctuation">(</span>shape<span class="token punctuation">,</span> n<span class="token punctuation">,</span> use_l2<span class="token punctuation">,</span> lam<span class="token punctuation">)</span><span class="token punctuation">:</span>
    weight <span class="token operator">=</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>truncated_normal<span class="token punctuation">(</span>shape<span class="token punctuation">,</span> stddev<span class="token operator">=</span><span class="token number">1</span> <span class="token operator">/</span> n<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token comment"># L2正则化</span>
    <span class="token keyword">if</span> use_l2 <span class="token keyword">is</span> <span class="token boolean">True</span><span class="token punctuation">:</span>
        weight_loss <span class="token operator">=</span> tf<span class="token punctuation">.</span>multiply<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>l2_loss<span class="token punctuation">(</span>weight<span class="token punctuation">)</span><span class="token punctuation">,</span> lam<span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">'weight_loss'</span><span class="token punctuation">)</span>
        tf<span class="token punctuation">.</span>add_to_collection<span class="token punctuation">(</span><span class="token string">'losses'</span><span class="token punctuation">,</span> weight_loss<span class="token punctuation">)</span>
    <span class="token keyword">return</span> weight


<span class="token keyword">def</span> <span class="token function">bias_variable</span><span class="token punctuation">(</span>shape<span class="token punctuation">)</span><span class="token punctuation">:</span>
    bias <span class="token operator">=</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>constant<span class="token punctuation">(</span><span class="token number">0.1</span><span class="token punctuation">,</span> shape<span class="token operator">=</span>shape<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> bias


<span class="token keyword">def</span> <span class="token function">conv2d</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> w<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>conv2d<span class="token punctuation">(</span>x<span class="token punctuation">,</span> w<span class="token punctuation">,</span> strides<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">'SAME'</span><span class="token punctuation">)</span>


<span class="token keyword">def</span> <span class="token function">max_pool_2x2</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>max_pool<span class="token punctuation">(</span>x<span class="token punctuation">,</span> ksize<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                          strides<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">'SAME'</span><span class="token punctuation">)</span>


<span class="token comment"># 输入层</span>
<span class="token keyword">with</span> tf<span class="token punctuation">.</span>name_scope<span class="token punctuation">(</span><span class="token string">'input_layer'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    x_input <span class="token operator">=</span> tf<span class="token punctuation">.</span>placeholder<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>float32<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token number">224</span><span class="token punctuation">,</span> <span class="token number">224</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    y_input <span class="token operator">=</span> tf<span class="token punctuation">.</span>placeholder<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>float32<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token boolean">None</span><span class="token punctuation">,</span> classify_num<span class="token punctuation">]</span><span class="token punctuation">)</span>
    keep_prob <span class="token operator">=</span> tf<span class="token punctuation">.</span>placeholder<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
    is_training <span class="token operator">=</span> tf<span class="token punctuation">.</span>placeholder<span class="token punctuation">(</span>tf<span class="token punctuation">.</span><span class="token builtin">bool</span><span class="token punctuation">)</span>
    is_use_l2 <span class="token operator">=</span> tf<span class="token punctuation">.</span>placeholder<span class="token punctuation">(</span>tf<span class="token punctuation">.</span><span class="token builtin">bool</span><span class="token punctuation">)</span>
    lam <span class="token operator">=</span> tf<span class="token punctuation">.</span>placeholder<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
    learning_rate <span class="token operator">=</span> tf<span class="token punctuation">.</span>placeholder<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
    <span class="token comment"># 数据集平均RGB值</span>
    mean <span class="token operator">=</span> tf<span class="token punctuation">.</span>constant<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">159.780</span><span class="token punctuation">,</span> <span class="token number">139.802</span><span class="token punctuation">,</span> <span class="token number">119.047</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>tf<span class="token punctuation">.</span>float32<span class="token punctuation">,</span> shape<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    x_input <span class="token operator">=</span> x_input <span class="token operator">-</span> mean

<span class="token comment"># 第一个卷积层 size:224</span>
<span class="token comment"># 卷积核1[3, 3, 3, 64]</span>
<span class="token comment"># 卷积核2[3, 3, 64, 64]</span>
<span class="token keyword">with</span> tf<span class="token punctuation">.</span>name_scope<span class="token punctuation">(</span><span class="token string">'conv1_layer'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    w_conv1 <span class="token operator">=</span> weight_variable<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> use_l2<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> lam<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
    b_conv1 <span class="token operator">=</span> bias_variable<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">64</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    conv_kernel1 <span class="token operator">=</span> conv2d<span class="token punctuation">(</span>x_input<span class="token punctuation">,</span> w_conv1<span class="token punctuation">)</span>
    bn1 <span class="token operator">=</span> tf<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>batch_normalization<span class="token punctuation">(</span>conv_kernel1<span class="token punctuation">,</span> training<span class="token operator">=</span>is_training<span class="token punctuation">)</span>
    conv1 <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>bias_add<span class="token punctuation">(</span>bn1<span class="token punctuation">,</span> b_conv1<span class="token punctuation">)</span><span class="token punctuation">)</span>

    w_conv2 <span class="token operator">=</span> weight_variable<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> use_l2<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> lam<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
    b_conv2 <span class="token operator">=</span> bias_variable<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">64</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    conv_kernel2 <span class="token operator">=</span> conv2d<span class="token punctuation">(</span>conv1<span class="token punctuation">,</span> w_conv2<span class="token punctuation">)</span>
    bn2 <span class="token operator">=</span> tf<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>batch_normalization<span class="token punctuation">(</span>conv_kernel2<span class="token punctuation">,</span> training<span class="token operator">=</span>is_training<span class="token punctuation">)</span>
    conv2 <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>bias_add<span class="token punctuation">(</span>bn2<span class="token punctuation">,</span> b_conv2<span class="token punctuation">)</span><span class="token punctuation">)</span>

    pool1 <span class="token operator">=</span> max_pool_2x2<span class="token punctuation">(</span>conv2<span class="token punctuation">)</span>  <span class="token comment"># 224*224 -&gt; 112*112</span>
    result1 <span class="token operator">=</span> pool1

<span class="token comment"># 第二个卷积层 size:112</span>
<span class="token comment"># 卷积核3[3, 3, 64, 128]</span>
<span class="token comment"># 卷积核4[3, 3, 128, 128]</span>
<span class="token keyword">with</span> tf<span class="token punctuation">.</span>name_scope<span class="token punctuation">(</span><span class="token string">'conv2_layer'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    w_conv3 <span class="token operator">=</span> weight_variable<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> use_l2<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> lam<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
    b_conv3 <span class="token operator">=</span> bias_variable<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">128</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    conv_kernel3 <span class="token operator">=</span> conv2d<span class="token punctuation">(</span>result1<span class="token punctuation">,</span> w_conv3<span class="token punctuation">)</span>
    bn3 <span class="token operator">=</span> tf<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>batch_normalization<span class="token punctuation">(</span>conv_kernel3<span class="token punctuation">,</span> training<span class="token operator">=</span>is_training<span class="token punctuation">)</span>
    conv3 <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>bias_add<span class="token punctuation">(</span>bn3<span class="token punctuation">,</span> b_conv3<span class="token punctuation">)</span><span class="token punctuation">)</span>

    w_conv4 <span class="token operator">=</span> weight_variable<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> use_l2<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> lam<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
    b_conv4 <span class="token operator">=</span> bias_variable<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">128</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    conv_kernel4 <span class="token operator">=</span> conv2d<span class="token punctuation">(</span>conv3<span class="token punctuation">,</span> w_conv4<span class="token punctuation">)</span>
    bn4 <span class="token operator">=</span> tf<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>batch_normalization<span class="token punctuation">(</span>conv_kernel4<span class="token punctuation">,</span> training<span class="token operator">=</span>is_training<span class="token punctuation">)</span>
    conv4 <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>bias_add<span class="token punctuation">(</span>bn4<span class="token punctuation">,</span> b_conv4<span class="token punctuation">)</span><span class="token punctuation">)</span>

    pool2 <span class="token operator">=</span> max_pool_2x2<span class="token punctuation">(</span>conv4<span class="token punctuation">)</span>  <span class="token comment"># 112*112 -&gt; 56*56</span>
    result2 <span class="token operator">=</span> pool2

<span class="token comment"># 第三个卷积层 size:56</span>
<span class="token comment"># 卷积核5[3, 3, 128, 256]</span>
<span class="token comment"># 卷积核6[3, 3, 256, 256]</span>
<span class="token comment"># 卷积核7[3, 3, 256, 256]</span>
<span class="token keyword">with</span> tf<span class="token punctuation">.</span>name_scope<span class="token punctuation">(</span><span class="token string">'conv3_layer'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    w_conv5 <span class="token operator">=</span> weight_variable<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> use_l2<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> lam<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
    b_conv5 <span class="token operator">=</span> bias_variable<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">256</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    conv_kernel5 <span class="token operator">=</span> conv2d<span class="token punctuation">(</span>result2<span class="token punctuation">,</span> w_conv5<span class="token punctuation">)</span>
    bn5 <span class="token operator">=</span> tf<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>batch_normalization<span class="token punctuation">(</span>conv_kernel5<span class="token punctuation">,</span> training<span class="token operator">=</span>is_training<span class="token punctuation">)</span>
    conv5 <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>bias_add<span class="token punctuation">(</span>bn5<span class="token punctuation">,</span> b_conv5<span class="token punctuation">)</span><span class="token punctuation">)</span>

    w_conv6 <span class="token operator">=</span> weight_variable<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> use_l2<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> lam<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
    b_conv6 <span class="token operator">=</span> bias_variable<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">256</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    conv_kernel6 <span class="token operator">=</span> conv2d<span class="token punctuation">(</span>conv5<span class="token punctuation">,</span> w_conv6<span class="token punctuation">)</span>
    bn6 <span class="token operator">=</span> tf<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>batch_normalization<span class="token punctuation">(</span>conv_kernel6<span class="token punctuation">,</span> training<span class="token operator">=</span>is_training<span class="token punctuation">)</span>
    conv6 <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>bias_add<span class="token punctuation">(</span>bn6<span class="token punctuation">,</span> b_conv6<span class="token punctuation">)</span><span class="token punctuation">)</span>

    w_conv7 <span class="token operator">=</span> weight_variable<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> use_l2<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> lam<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
    b_conv7 <span class="token operator">=</span> bias_variable<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">256</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    conv_kernel7 <span class="token operator">=</span> conv2d<span class="token punctuation">(</span>conv6<span class="token punctuation">,</span> w_conv7<span class="token punctuation">)</span>
    bn7 <span class="token operator">=</span> tf<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>batch_normalization<span class="token punctuation">(</span>conv_kernel7<span class="token punctuation">,</span> training<span class="token operator">=</span>is_training<span class="token punctuation">)</span>
    conv7 <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>bias_add<span class="token punctuation">(</span>bn7<span class="token punctuation">,</span> b_conv7<span class="token punctuation">)</span><span class="token punctuation">)</span>

    pool3 <span class="token operator">=</span> max_pool_2x2<span class="token punctuation">(</span>conv7<span class="token punctuation">)</span>  <span class="token comment"># 56*56 -&gt; 28*28</span>
    result3 <span class="token operator">=</span> pool3

<span class="token comment"># 第四个卷积层 size:28</span>
<span class="token comment"># 卷积核8[3, 3, 256, 512]</span>
<span class="token comment"># 卷积核9[3, 3, 512, 512]</span>
<span class="token comment"># 卷积核10[3, 3, 512, 512]</span>
<span class="token keyword">with</span> tf<span class="token punctuation">.</span>name_scope<span class="token punctuation">(</span><span class="token string">'conv4_layer'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    w_conv8 <span class="token operator">=</span> weight_variable<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> use_l2<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> lam<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
    b_conv8 <span class="token operator">=</span> bias_variable<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">512</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    conv_kernel8 <span class="token operator">=</span> conv2d<span class="token punctuation">(</span>result3<span class="token punctuation">,</span> w_conv8<span class="token punctuation">)</span>
    bn8 <span class="token operator">=</span> tf<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>batch_normalization<span class="token punctuation">(</span>conv_kernel8<span class="token punctuation">,</span> training<span class="token operator">=</span>is_training<span class="token punctuation">)</span>
    conv8 <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>bias_add<span class="token punctuation">(</span>bn8<span class="token punctuation">,</span> b_conv8<span class="token punctuation">)</span><span class="token punctuation">)</span>

    w_conv9 <span class="token operator">=</span> weight_variable<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> use_l2<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> lam<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
    b_conv9 <span class="token operator">=</span> bias_variable<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">512</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    conv_kernel9 <span class="token operator">=</span> conv2d<span class="token punctuation">(</span>conv8<span class="token punctuation">,</span> w_conv9<span class="token punctuation">)</span>
    bn9 <span class="token operator">=</span> tf<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>batch_normalization<span class="token punctuation">(</span>conv_kernel9<span class="token punctuation">,</span> training<span class="token operator">=</span>is_training<span class="token punctuation">)</span>
    conv9 <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>bias_add<span class="token punctuation">(</span>bn9<span class="token punctuation">,</span> b_conv9<span class="token punctuation">)</span><span class="token punctuation">)</span>

    w_conv10 <span class="token operator">=</span> weight_variable<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> use_l2<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> lam<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
    b_conv10 <span class="token operator">=</span> bias_variable<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">512</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    conv_kernel10 <span class="token operator">=</span> conv2d<span class="token punctuation">(</span>conv9<span class="token punctuation">,</span> w_conv10<span class="token punctuation">)</span>
    bn10 <span class="token operator">=</span> tf<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>batch_normalization<span class="token punctuation">(</span>conv_kernel10<span class="token punctuation">,</span> training<span class="token operator">=</span>is_training<span class="token punctuation">)</span>
    conv10 <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>bias_add<span class="token punctuation">(</span>bn10<span class="token punctuation">,</span> b_conv10<span class="token punctuation">)</span><span class="token punctuation">)</span>

    pool4 <span class="token operator">=</span> max_pool_2x2<span class="token punctuation">(</span>conv10<span class="token punctuation">)</span>  <span class="token comment"># 28*28 -&gt; 14*14</span>
    result4 <span class="token operator">=</span> pool4

<span class="token comment"># 第五个卷积层 size:14</span>
<span class="token comment"># 卷积核11[3, 3, 512, 512]</span>
<span class="token comment"># 卷积核12[3, 3, 512, 512]</span>
<span class="token comment"># 卷积核13[3, 3, 512, 512]</span>
<span class="token keyword">with</span> tf<span class="token punctuation">.</span>name_scope<span class="token punctuation">(</span><span class="token string">'conv5_layer'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    w_conv11 <span class="token operator">=</span> weight_variable<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> use_l2<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> lam<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
    b_conv11 <span class="token operator">=</span> bias_variable<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">512</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    conv_kernel11 <span class="token operator">=</span> conv2d<span class="token punctuation">(</span>result4<span class="token punctuation">,</span> w_conv11<span class="token punctuation">)</span>
    bn11 <span class="token operator">=</span> tf<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>batch_normalization<span class="token punctuation">(</span>conv_kernel11<span class="token punctuation">,</span> training<span class="token operator">=</span>is_training<span class="token punctuation">)</span>
    conv11 <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>bias_add<span class="token punctuation">(</span>bn11<span class="token punctuation">,</span> b_conv11<span class="token punctuation">)</span><span class="token punctuation">)</span>

    w_conv12 <span class="token operator">=</span> weight_variable<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> use_l2<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> lam<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
    b_conv12 <span class="token operator">=</span> bias_variable<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">512</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    conv_kernel12 <span class="token operator">=</span> conv2d<span class="token punctuation">(</span>conv11<span class="token punctuation">,</span> w_conv12<span class="token punctuation">)</span>
    bn12 <span class="token operator">=</span> tf<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>batch_normalization<span class="token punctuation">(</span>conv_kernel12<span class="token punctuation">,</span> training<span class="token operator">=</span>is_training<span class="token punctuation">)</span>
    conv12 <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>bias_add<span class="token punctuation">(</span>bn12<span class="token punctuation">,</span> b_conv12<span class="token punctuation">)</span><span class="token punctuation">)</span>

    w_conv13 <span class="token operator">=</span> weight_variable<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> use_l2<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> lam<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
    b_conv13 <span class="token operator">=</span> bias_variable<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">512</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    conv_kernel13 <span class="token operator">=</span> conv2d<span class="token punctuation">(</span>conv12<span class="token punctuation">,</span> w_conv13<span class="token punctuation">)</span>
    bn13 <span class="token operator">=</span> tf<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>batch_normalization<span class="token punctuation">(</span>conv_kernel13<span class="token punctuation">,</span> training<span class="token operator">=</span>is_training<span class="token punctuation">)</span>
    conv13 <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>bias_add<span class="token punctuation">(</span>bn13<span class="token punctuation">,</span> b_conv13<span class="token punctuation">)</span><span class="token punctuation">)</span>

    pool5 <span class="token operator">=</span> max_pool_2x2<span class="token punctuation">(</span>conv13<span class="token punctuation">)</span>  <span class="token comment"># 14*14 -&gt; 7*7</span>
    result5 <span class="token operator">=</span> pool5

<span class="token comment"># 第一个全连接层 size:7</span>
<span class="token comment"># 隐藏层节点数 4096</span>
<span class="token keyword">with</span> tf<span class="token punctuation">.</span>name_scope<span class="token punctuation">(</span><span class="token string">'fc1_layer'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    w_fc14 <span class="token operator">=</span> weight_variable<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">7</span> <span class="token operator">*</span> <span class="token number">7</span> <span class="token operator">*</span> <span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">4096</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">4096</span><span class="token punctuation">,</span> use_l2<span class="token operator">=</span>is_use_l2<span class="token punctuation">,</span> lam<span class="token operator">=</span>lam<span class="token punctuation">)</span>
    b_fc14 <span class="token operator">=</span> bias_variable<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">4096</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    result5_flat <span class="token operator">=</span> tf<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>result5<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">7</span> <span class="token operator">*</span> <span class="token number">7</span> <span class="token operator">*</span> <span class="token number">512</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    fc14 <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>bias_add<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>result5_flat<span class="token punctuation">,</span> w_fc14<span class="token punctuation">)</span><span class="token punctuation">,</span> b_fc14<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token comment"># result6 = fc14</span>
    result6 <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>dropout<span class="token punctuation">(</span>fc14<span class="token punctuation">,</span> keep_prob<span class="token punctuation">)</span>

<span class="token comment"># 第二个全连接层</span>
<span class="token comment"># 隐藏层节点数 4096</span>
<span class="token keyword">with</span> tf<span class="token punctuation">.</span>name_scope<span class="token punctuation">(</span><span class="token string">'fc2_layer'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    w_fc15 <span class="token operator">=</span> weight_variable<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">4096</span><span class="token punctuation">,</span> <span class="token number">4096</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">4096</span><span class="token punctuation">,</span> use_l2<span class="token operator">=</span>is_use_l2<span class="token punctuation">,</span> lam<span class="token operator">=</span>lam<span class="token punctuation">)</span>
    b_fc15 <span class="token operator">=</span> bias_variable<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">4096</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    fc15 <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>bias_add<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>result6<span class="token punctuation">,</span> w_fc15<span class="token punctuation">)</span><span class="token punctuation">,</span> b_fc15<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token comment"># result7 = fc15</span>
    result7 <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>dropout<span class="token punctuation">(</span>fc15<span class="token punctuation">,</span> keep_prob<span class="token punctuation">)</span>

<span class="token comment"># 输出层</span>
<span class="token keyword">with</span> tf<span class="token punctuation">.</span>name_scope<span class="token punctuation">(</span><span class="token string">'output_layer'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    w_fc16 <span class="token operator">=</span> weight_variable<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">4096</span><span class="token punctuation">,</span> classify_num<span class="token punctuation">]</span><span class="token punctuation">,</span> classify_num<span class="token punctuation">,</span> use_l2<span class="token operator">=</span>is_use_l2<span class="token punctuation">,</span> lam<span class="token operator">=</span>lam<span class="token punctuation">)</span>
    b_fc16 <span class="token operator">=</span> bias_variable<span class="token punctuation">(</span><span class="token punctuation">[</span>classify_num<span class="token punctuation">]</span><span class="token punctuation">)</span>
    fc16 <span class="token operator">=</span> tf<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>result7<span class="token punctuation">,</span> w_fc16<span class="token punctuation">)</span> <span class="token operator">+</span> b_fc16
    logits <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>fc16<span class="token punctuation">)</span>

<span class="token comment"># 损失函数</span>
<span class="token keyword">with</span> tf<span class="token punctuation">.</span>name_scope<span class="token punctuation">(</span><span class="token string">'loss'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    cross_entropy <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>softmax_cross_entropy_with_logits_v2<span class="token punctuation">(</span>logits<span class="token operator">=</span>fc16<span class="token punctuation">,</span> labels<span class="token operator">=</span>y_input<span class="token punctuation">)</span>
    cross_entropy_mean <span class="token operator">=</span> tf<span class="token punctuation">.</span>reduce_mean<span class="token punctuation">(</span>cross_entropy<span class="token punctuation">)</span>
    tf<span class="token punctuation">.</span>add_to_collection<span class="token punctuation">(</span><span class="token string">'losses'</span><span class="token punctuation">,</span> cross_entropy_mean<span class="token punctuation">)</span>
    loss <span class="token operator">=</span> tf<span class="token punctuation">.</span>add_n<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>get_collection<span class="token punctuation">(</span><span class="token string">'losses'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    tf<span class="token punctuation">.</span>summary<span class="token punctuation">.</span>scalar<span class="token punctuation">(</span><span class="token string">'loss'</span><span class="token punctuation">,</span> loss<span class="token punctuation">)</span>

<span class="token comment"># 训练函数</span>
<span class="token keyword">with</span> tf<span class="token punctuation">.</span>name_scope<span class="token punctuation">(</span><span class="token string">'train'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    update_ops <span class="token operator">=</span> tf<span class="token punctuation">.</span>get_collection<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>GraphKeys<span class="token punctuation">.</span>UPDATE_OPS<span class="token punctuation">)</span>
    <span class="token keyword">with</span> tf<span class="token punctuation">.</span>control_dependencies<span class="token punctuation">(</span>update_ops<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment"># 保证train_op在update_ops执行之后再执行。</span>
        train_step <span class="token operator">=</span> tf<span class="token punctuation">.</span>train<span class="token punctuation">.</span>AdamOptimizer<span class="token punctuation">(</span>learning_rate<span class="token punctuation">)</span><span class="token punctuation">.</span>minimize<span class="token punctuation">(</span>loss<span class="token punctuation">)</span>

<span class="token comment"># 计算准确率</span>
<span class="token keyword">with</span> tf<span class="token punctuation">.</span>name_scope<span class="token punctuation">(</span><span class="token string">'accuracy'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    correct_prediction <span class="token operator">=</span> tf<span class="token punctuation">.</span>equal<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>logits<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> tf<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>y_input<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    accuracy <span class="token operator">=</span> tf<span class="token punctuation">.</span>reduce_mean<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>cast<span class="token punctuation">(</span>correct_prediction<span class="token punctuation">,</span> tf<span class="token punctuation">.</span>float32<span class="token punctuation">)</span><span class="token punctuation">)</span>
    tf<span class="token punctuation">.</span>summary<span class="token punctuation">.</span>scalar<span class="token punctuation">(</span><span class="token string">'accuracy'</span><span class="token punctuation">,</span> accuracy<span class="token punctuation">)</span>

<span class="token comment"># 会话初始化</span>
<span class="token comment"># sess = tf.InteractiveSession()</span>
<span class="token comment"># tf.global_variables_initializer().run()</span>
saver <span class="token operator">=</span> tf<span class="token punctuation">.</span>train<span class="token punctuation">.</span>Saver<span class="token punctuation">(</span><span class="token punctuation">)</span>
save_dir <span class="token operator">=</span> <span class="token string">"classify_modles"</span>
checkpoint_name <span class="token operator">=</span> <span class="token string">"train.ckpt"</span>
merged <span class="token operator">=</span> tf<span class="token punctuation">.</span>summary<span class="token punctuation">.</span>merge_all<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 将图形、训练过程等数据合并在一起</span>
<span class="token comment"># writer_train = tf.summary.FileWriter('logs/train', sess.graph)  # 将训练日志写入到logs文件夹下</span>
<span class="token comment"># writer_test = tf.summary.FileWriter('logs/test', sess.graph)  # 将训练日志写入到logs文件夹下</span>

<span class="token comment"># 变量初始化</span>
training_steps <span class="token operator">=</span> <span class="token number">25000</span>
display_step <span class="token operator">=</span> <span class="token number">10</span>
batch_size <span class="token operator">=</span> <span class="token number">20</span>
train_images_count <span class="token operator">=</span> <span class="token number">0</span>
test_images_count <span class="token operator">=</span> <span class="token number">0</span>
train_avg_accuracy <span class="token operator">=</span> <span class="token number">0</span>
test_avg_accuracy <span class="token operator">=</span> <span class="token number">0</span>

<span class="token comment"># # 训练</span>
<span class="token comment"># print("Training start...")</span>
<span class="token comment">#</span>
<span class="token comment"># # # 模型恢复</span>
<span class="token comment"># # sess = tf.InteractiveSession()</span>
<span class="token comment"># # saver.restore(sess, os.path.join(save_dir, checkpoint_name))</span>
<span class="token comment"># # print("Model restore success！")</span>
<span class="token comment">#</span>
<span class="token comment"># for step in range(training_steps):</span>
<span class="token comment">#     train_images, train_labels, train_images_count = combine_train_dataset(train_images_count, batch_size)</span>
<span class="token comment">#     test_images, test_labels, test_images_count = combine_test_dataset(test_images_count, batch_size)</span>
<span class="token comment">#</span>
<span class="token comment">#     # 训练</span>
<span class="token comment">#     if step &lt; 10000:</span>
<span class="token comment">#         train_step.run(</span>
<span class="token comment">#             feed_dict={x_input: train_images, y_input: train_labels, keep_prob: 0.8, is_training: True, is_use_l2: True,</span>
<span class="token comment">#                        learning_rate: 0.0001, lam: 0.004})</span>
<span class="token comment">#     elif step &lt; 20000:</span>
<span class="token comment">#         train_step.run(</span>
<span class="token comment">#             feed_dict={x_input: train_images, y_input: train_labels, keep_prob: 0.8, is_training: True, is_use_l2: True,</span>
<span class="token comment">#                        learning_rate: 0.0001, lam: 0.001})</span>
<span class="token comment">#     else:</span>
<span class="token comment">#         train_step.run(</span>
<span class="token comment">#             feed_dict={x_input: train_images, y_input: train_labels, keep_prob: 0.8, is_training: True, is_use_l2: True,</span>
<span class="token comment">#                        learning_rate: 0.00001, lam: 0.001})</span>
<span class="token comment">#</span>
<span class="token comment">#     # 每训练10步，输出显示训练过程</span>
<span class="token comment">#     if step % display_step == 0:</span>
<span class="token comment">#         train_accuracy = accuracy.eval(</span>
<span class="token comment">#             feed_dict={x_input: train_images, y_input: train_labels, keep_prob: 1.0, is_training: False,</span>
<span class="token comment">#                        is_use_l2: False})</span>
<span class="token comment">#         train_loss = sess.run(loss, feed_dict={x_input: train_images, y_input: train_labels, keep_prob: 1.0,</span>
<span class="token comment">#                                                is_training: False, is_use_l2: False})</span>
<span class="token comment">#         train_result = sess.run(tf.argmax(logits, 1),</span>
<span class="token comment">#                                 feed_dict={x_input: train_images, keep_prob: 1.0, is_training: False, is_use_l2: False})</span>
<span class="token comment">#         train_label = sess.run(tf.argmax(y_input, 1), feed_dict={y_input: train_labels})</span>
<span class="token comment">#</span>
<span class="token comment">#         test_accuracy = accuracy.eval(</span>
<span class="token comment">#             feed_dict={x_input: test_images, y_input: test_labels, keep_prob: 1.0, is_training: False,</span>
<span class="token comment">#                        is_use_l2: False})</span>
<span class="token comment">#         test_result = sess.run(tf.argmax(logits, 1),</span>
<span class="token comment">#                                feed_dict={x_input: test_images, keep_prob: 1.0, is_training: False, is_use_l2: False})</span>
<span class="token comment">#         test_label = sess.run(tf.argmax(y_input, 1), feed_dict={y_input: test_labels})</span>
<span class="token comment">#</span>
<span class="token comment">#         print("Training dataset:")</span>
<span class="token comment">#         print(train_result)</span>
<span class="token comment">#         print(train_label)</span>
<span class="token comment">#         print("Testing dataset:")</span>
<span class="token comment">#         print(test_result)</span>
<span class="token comment">#         print(test_label)</span>
<span class="token comment">#</span>
<span class="token comment">#         print("step {}n training accuracy {}n loss {}n testing accuracy {}n".format(step, train_accuracy, train_loss, test_accuracy))</span>
<span class="token comment">#         train_avg_accuracy += train_accuracy</span>
<span class="token comment">#         test_avg_accuracy += test_accuracy</span>
<span class="token comment">#         result_train = sess.run(merged, feed_dict={x_input: train_images, y_input: train_labels, keep_prob: 1.0,</span>
<span class="token comment">#                                                    is_training: False, is_use_l2: False})  # 计算需要写入的日志数据</span>
<span class="token comment">#         writer_train.add_summary(result_train, step)  # 将日志数据写入文件</span>
<span class="token comment">#</span>
<span class="token comment">#         result_test = sess.run(merged, feed_dict={x_input: test_images, y_input: test_labels, keep_prob: 1.0,</span>
<span class="token comment">#                                                is_training: False, is_use_l2: False})  # 计算需要写入的日志数据</span>
<span class="token comment">#         writer_test.add_summary(result_test, step)  # 将日志数据写入文件</span>
<span class="token comment">#</span>
<span class="token comment">#     # 每训练100步，显示输出训练平均准确度，保存模型</span>
<span class="token comment">#     if step % (display_step * 10) == 0 and step != 0:</span>
<span class="token comment">#         print("train_avg_accuracy {}".format(train_avg_accuracy / 10))</span>
<span class="token comment">#         train_avg_accuracy = 0</span>
<span class="token comment">#         print("test_avg_accuracy {}".format(test_avg_accuracy / 10))</span>
<span class="token comment">#         test_avg_accuracy = 0</span>
<span class="token comment">#</span>
<span class="token comment">#         saver.save(sess, os.path.join(save_dir, checkpoint_name))</span>
<span class="token comment">#         print("Model save success!n")</span>
<span class="token comment">#</span>
<span class="token comment"># print("Training finish...")</span>
<span class="token comment">#</span>
<span class="token comment"># # 模型保存</span>
<span class="token comment"># saver.save(sess, os.path.join(save_dir, checkpoint_name))</span>
<span class="token comment"># print("nModel save success!")</span>
<span class="token comment">#</span>
<span class="token comment"># # print("nTesting start...")</span>
<span class="token comment"># # avg_accuracy = 0</span>
<span class="token comment"># # for i in range(int(test_images_num / 30) + 1):</span>
<span class="token comment"># #     test_images, test_labels, test_images_count = combine_test_dataset(test_images_count, 30)</span>
<span class="token comment"># #     test_accuracy = accuracy.eval(</span>
<span class="token comment"># #         feed_dict={x_input: test_images, y_input: test_labels, keep_prob: 1.0, is_training: False, is_use_l2: False})</span>
<span class="token comment"># #     test_result = sess.run(tf.argmax(logits, 1),</span>
<span class="token comment"># #                            feed_dict={x_input: test_images, keep_prob: 1.0, is_training: False, is_use_l2: False})</span>
<span class="token comment"># #     test_label = sess.run(tf.argmax(y_input, 1), feed_dict={y_input: test_labels})</span>
<span class="token comment"># #     print(test_result)</span>
<span class="token comment"># #     print(test_label)</span>
<span class="token comment"># #     print("test accuracy {}".format(test_accuracy))</span>
<span class="token comment"># #     avg_accuracy += test_accuracy</span>
<span class="token comment"># #</span>
<span class="token comment"># # print("ntest_avg_accuracy {}".format(avg_accuracy / (int(test_images_num / 30) + 1)))</span>
<span class="token comment">#</span>
<span class="token comment"># sess.close()</span>


<span class="token comment"># 识别</span>
<span class="token comment"># 模型恢复</span>
sess <span class="token operator">=</span> tf<span class="token punctuation">.</span>InteractiveSession<span class="token punctuation">(</span><span class="token punctuation">)</span>
saver<span class="token punctuation">.</span>restore<span class="token punctuation">(</span>sess<span class="token punctuation">,</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>save_dir<span class="token punctuation">,</span> checkpoint_name<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Model restore success！"</span><span class="token punctuation">)</span>


<span class="token keyword">def</span> <span class="token function">predict_img</span><span class="token punctuation">(</span>img_path<span class="token punctuation">)</span><span class="token punctuation">:</span>
    img <span class="token operator">=</span> cv2<span class="token punctuation">.</span>imread<span class="token punctuation">(</span>img_path<span class="token punctuation">)</span>
    image <span class="token operator">=</span> np<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>img<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">224</span><span class="token punctuation">,</span> <span class="token number">224</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    classify_result <span class="token operator">=</span> sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>logits<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                               feed_dict<span class="token operator">=</span><span class="token punctuation">{<!-- --></span>x_input<span class="token punctuation">:</span> image<span class="token punctuation">,</span> keep_prob<span class="token punctuation">:</span> <span class="token number">1.0</span><span class="token punctuation">,</span> is_training<span class="token punctuation">:</span> <span class="token boolean">False</span><span class="token punctuation">,</span> is_use_l2<span class="token punctuation">:</span> <span class="token boolean">False</span><span class="token punctuation">}</span><span class="token punctuation">)</span>
    probability <span class="token operator">=</span> sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>logits<span class="token punctuation">,</span> feed_dict<span class="token operator">=</span><span class="token punctuation">{<!-- --></span>x_input<span class="token punctuation">:</span> image<span class="token punctuation">,</span> keep_prob<span class="token punctuation">:</span> <span class="token number">1.0</span><span class="token punctuation">,</span> is_training<span class="token punctuation">:</span> <span class="token boolean">False</span><span class="token punctuation">,</span>
                                              is_use_l2<span class="token punctuation">:</span> <span class="token boolean">False</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">.</span>flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>tolist<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span>
        classify_result<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
    <span class="token keyword">return</span> classify_result<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> probability


<span class="token keyword">def</span> <span class="token function">trash_classify</span><span class="token punctuation">(</span>img_path<span class="token punctuation">,</span> img_name<span class="token punctuation">,</span> upload_path<span class="token punctuation">)</span><span class="token punctuation">:</span>
    img_name <span class="token operator">=</span> img_name<span class="token punctuation">.</span>rsplit<span class="token punctuation">(</span><span class="token string">'.'</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
    <span class="token comment"># print(img_name)</span>
    pretrian_img_path<span class="token punctuation">,</span> selected_img_path <span class="token operator">=</span> pretreatment_image<span class="token punctuation">(</span>img_path<span class="token punctuation">,</span> img_name<span class="token punctuation">,</span> upload_path<span class="token punctuation">)</span>
    predict_result<span class="token punctuation">,</span> predict_probability <span class="token operator">=</span> predict_img<span class="token punctuation">(</span>pretrian_img_path<span class="token punctuation">)</span>
    <span class="token keyword">return</span> predict_result<span class="token punctuation">,</span> predict_probability

</code></pre> 
<h1>
<a id="8__836"></a>8 最后-毕设帮助</h1> 
<pre><code class="prism language-python">毕设帮助，开题指导，技术解答
?<span class="token number">746876041</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/01/d9/aKALl82w_o.png" alt="请添加图片描述"></p>
                </div>
                
                

		</div>
	</article>
</main>




			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程小白.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://www.w3counter.com/tracker.js?id=150625"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>
	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>