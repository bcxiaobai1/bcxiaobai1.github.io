<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<title>CNN-运动鞋品牌识别 - 编程小白</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程小白" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程小白</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">CNN-运动鞋品牌识别</h1>
			
		</header>
		<div class="content post__content clearfix">
			


                <div id="content_views" class="htmledit_views">
                    <ul>
<li><strong>? 本文为<a href="https://links.jianshu.com/go?to=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2Fk-vYaC8l7uxX51WoypLkTw" title="?365天深度学习训练营">?365天深度学习训练营</a> 中的学习记录博客</strong></li>
<li><strong>? 参考文章地址： 365天深度学习训练营-第5周：运动鞋品牌识别</strong></li>
<li><strong>? 作者：<a href="https://links.jianshu.com/go?to=https%3A%2F%2Fmp.weixin.qq.com%2Fs%2Fk-vYaC8l7uxX51WoypLkTw" title="K同学啊">K同学啊</a></strong></li>
</ul>
<p></p> 
<h1 id="b3e4e320">一、前期工作</h1> 
<h2>1. 设置GPU </h2> 
<div> 
 <pre><code class="hljs language-python"><span class="hljs-keyword">from</span> tensorflow       <span class="hljs-keyword">import</span> keras
<span class="hljs-keyword">from</span> tensorflow.keras <span class="hljs-keyword">import</span> layers,models
<span class="hljs-keyword">import</span> os, PIL, pathlib
<span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt
<span class="hljs-keyword">import</span> tensorflow        <span class="hljs-keyword">as</span> tf

gpus = tf.config.list_physical_devices(<span class="hljs-string">"GPU"</span>)

<span class="hljs-keyword">if</span> gpus:
    gpu0 = gpus[<span class="hljs-number">0</span>]                                        <span class="hljs-comment">#如果有多个GPU，仅使用第0个GPU</span>
    tf.config.experimental.set_memory_growth(gpu0, <span class="hljs-literal">True</span>)  <span class="hljs-comment">#设置GPU显存用量按需使用</span>
    tf.config.set_visible_devices([gpu0],<span class="hljs-string">"GPU"</span>)
gpus  </code></pre> 
</div> 
<pre>[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]</pre> 
<h2>2. 导入并查看数据</h2> 
<div> 
 <pre><code class="hljs language-python">data_dir = pathlib.Path(<span class="hljs-string">"./data/"</span>)
image_count = <span class="hljs-built_in">len</span>(<span class="hljs-built_in">list</span>(data_dir.glob(<span class="hljs-string">'*/*/*.jpg'</span>)))
<span class="hljs-built_in">print</span>(<span class="hljs-string">"图片总数为："</span>,image_count)</code></pre> 
</div> 
<pre>图片总数为： 578</pre> 
<div> 
 <pre><code class="hljs language-python">roses= <span class="hljs-built_in">list</span>(data_dir.glob(<span class="hljs-string">'train/nike/*.jpg'</span>))
PIL.Image.<span class="hljs-built_in">open</span>(<span class="hljs-built_in">str</span>(roses[<span class="hljs-number">0</span>]))</code></pre> 
</div> 
<div> 
 <p class="img-center"><img alt="" height="240" src="https://images2.imgbox.com/dd/ab/oeKISkgf_o.png" width="240"><span title="点击并拖拽以改变尺寸">​</span></p> 
</div> 
<p> </p> 
<h1 id="二、数据预处理">二、数据预处理</h1> 
<h2 id="1.加载数据">1. 加载数据</h2> 
<p>使用image_dataset_from_directory方法将磁盘中的数据加载到tf.data.Dataset中</p> 
<p>测试集与验证集的关系：</p> 
<ol>
<li>验证集并没有参与训练过程梯度下降过程的，狭义上来讲是没有参与模型的参数训练更新的。</li>
<li>但是广义上来讲，验证集存在的意义确实参与了一个“人工调参”的过程，我们根据每一个epoch训练之后模型在valid data上的表现来决定是否需要训练进行early stop，或者根据这个过程模型的性能变化来调整模型的超参数，如学习率，batch_size等等。</li>
<li>因此，我们也可以认为，验证集也参与了训练，但是并没有使得模型去overfit验证集</li>
</ol>
<div> 
 <pre><code class="hljs language-python">batch_size = 32
img_height = 224
img_width = 224</code></pre> 
</div> 
<div> 
 <pre><code class="hljs language-python">train_ds = tf.keras.preprocessing.image_dataset_from_directory(
    <span class="hljs-string">"./data/train/"</span>,
    seed=<span class="hljs-number">123</span>,
    image_size=(img_height, img_width),
    batch_size=batch_size)</code></pre> 
</div> 
<pre>Found 502 files belonging to 2 classes.
</pre> 
<div> 
 <pre><code class="hljs language-python">val_ds = tf.keras.preprocessing.image_dataset_from_directory(
    <span class="hljs-string">"./data/test/"</span>,
    seed=<span class="hljs-number">123</span>,
    image_size=(img_height, img_width),
    batch_size=batch_size)</code></pre> 
</div> 
<pre>Found 76 files belonging to 2 classes.</pre> 
<p>我们可以通过class_names输出数据集的标签。标签将按字母顺序对应于目录名称。 </p> 
<div> 
 <pre><code class="hljs language-python">class_names = train_ds.class_names
<span class="hljs-built_in">print</span>(class_names)</code></pre> 
</div> 
<pre>['adidas', 'nike']</pre> 
<p> </p> 
<h2 id="2.-可视化数据">2. 可视化数据</h2> 
<div> 
 <pre><code class="hljs language-python">plt.figure(figsize=(<span class="hljs-number">20</span>, <span class="hljs-number">10</span>))

<span class="hljs-keyword">for</span> images, labels <span class="hljs-keyword">in</span> train_ds.take(<span class="hljs-number">1</span>):
    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">20</span>):
        ax = plt.subplot(<span class="hljs-number">5</span>, <span class="hljs-number">10</span>, i + <span class="hljs-number">1</span>)
        plt.imshow(images[i].numpy().astype(<span class="hljs-string">"uint8"</span>))
        plt.title(class_names[labels[i]])
        plt.axis(<span class="hljs-string">"off"</span>)</code></pre> 
</div> 
<div> 
 <p class="img-center"><img alt="" height="236" src="https://images2.imgbox.com/bf/a4/REbJCfRE_o.png" width="1129"><span title="点击并拖拽以改变尺寸">​</span></p> 
</div> 
<p> </p> 
<h2 id="3.再次检查数据">3. 再次检查数据</h2> 
<div> 
 <pre><code class="hljs language-python"><span class="hljs-keyword">for</span> image_batch, labels_batch <span class="hljs-keyword">in</span> train_ds:
    <span class="hljs-built_in">print</span>(image_batch.shape)
    <span class="hljs-built_in">print</span>(labels_batch.shape)
    <span class="hljs-keyword">break</span></code></pre> 
</div> 
<pre>(32, 224, 224, 3)
(32,)</pre> 
<p> </p> 
<h2 id="4.-配置数据集">4. 配置数据集</h2> 
<ul><li id="u278a4345">
<strong>shuffle()</strong> ：打乱数据，关于此函数的详细介绍可以参考：<a href="https://zhuanlan.zhihu.com/p/42417456" title="数据集shuffle方法中buffer_size的理解 - 知乎">?365天深度学习训练营</a>
</li></ul>
<ul><li id="ub16fb8aa">
<strong>prefetch()</strong> ：预取数据，加速运行</li></ul>
<p id="u3abef3b2"><code>prefetch()</code>功能详细介绍：CPU 正在准备数据时，加速器处于空闲状态。相反，当加速器正在训练模型时，CPU 处于空闲状态。因此，训练所用的时间是 CPU 预处理时间和加速器训练时间的总和。<code>prefetch()</code>将训练步骤的预处理和模型执行过程重叠到一起。当加速器正在执行第 N 个训练步时，CPU 正在准备第 N+1 步的数据。这样做不仅可以最大限度地缩短训练的单步用时（而不是总用时），而且可以缩短提取和转换数据所需的时间。如果不使用<code>prefetch()</code>，CPU 和 GPU/TPU 在大部分时间都处于空闲状态：</p> 
<div> 
 <p class="img-center"><img alt="" height="158" src="https://images2.imgbox.com/78/86/GLEhpvWS_o.png" width="699"><span title="点击并拖拽以改变尺寸">​</span></p> 
</div> 
<p> 使用<code>prefetch()</code>可显著减少空闲时间：</p> 
<div> 
 <p class="img-center"><img alt="" height="157" src="https://images2.imgbox.com/e1/77/As6xvq66_o.png" width="698"><span title="点击并拖拽以改变尺寸">​</span></p> 
</div> 
<ul><li id="u84e0a021">
<strong>cache()</strong> ：将数据集缓存到内存当中，加速运行</li></ul>
<div> 
 <pre><code class="hljs language-python">AUTOTUNE = tf.data.AUTOTUNE

train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)
val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)</code></pre> 
</div> 
<p> </p> 
<h1 id="fab49ca5">三、构建CNN网络</h1> 
<p>卷积神经网络（CNN）的输入是张量 (Tensor) 形式的 (image_height, image_width, color_channels)，包含了图像高度、宽度及颜色信息。不需要输入batch size。color_channels 为 (R,G,B) 分别对应 RGB 的三个颜色通道（color channel）。在此示例中，我们的 CNN 输入的形状是 (224, 224, 3)即彩色图像。我们需要在声明第一层时将形状赋值给参数input_shape。</p> 
<div> 
 <pre><code class="hljs language-python">num_classes = <span class="hljs-number">2</span>

model = models.Sequential([
    layers.experimental.preprocessing.Rescaling(<span class="hljs-number">1.</span>/<span class="hljs-number">255</span>, input_shape=(img_height, img_width, <span class="hljs-number">3</span>)),
    
    layers.Conv2D(<span class="hljs-number">16</span>, (<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), activation=<span class="hljs-string">'relu'</span>, input_shape=(img_height, img_width, <span class="hljs-number">3</span>)), <span class="hljs-comment"># 卷积层1，卷积核3*3  </span>
    layers.AveragePooling2D((<span class="hljs-number">2</span>, <span class="hljs-number">2</span>)),               <span class="hljs-comment"># 池化层1，2*2采样</span>
    layers.Conv2D(<span class="hljs-number">32</span>, (<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), activation=<span class="hljs-string">'relu'</span>),  <span class="hljs-comment"># 卷积层2，卷积核3*3</span>
    layers.MaxPooling2D((<span class="hljs-number">2</span>, <span class="hljs-number">2</span>)),               <span class="hljs-comment"># 池化层2，2*2采样</span>
    layers.Dropout(<span class="hljs-number">0.3</span>),  
    layers.Conv2D(<span class="hljs-number">64</span>, (<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), activation=<span class="hljs-string">'relu'</span>),  <span class="hljs-comment"># 卷积层3，卷积核3*3</span>
    layers.Dropout(<span class="hljs-number">0.3</span>),
    
    layers.Flatten(),                       <span class="hljs-comment"># Flatten层，连接卷积层与全连接层</span>
    layers.Dense(<span class="hljs-number">128</span>, activation=<span class="hljs-string">'relu'</span>),   <span class="hljs-comment"># 全连接层，特征进一步提取</span>
    layers.Dense(num_classes)               <span class="hljs-comment"># 输出层，输出预期结果</span>
])

model.summary()  <span class="hljs-comment"># 打印网络结构</span>
</code></pre> 
</div> 
<blockquote> 
 <pre>Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
rescaling (Rescaling)        (None, 224, 224, 3)       0         
_________________________________________________________________
conv2d (Conv2D)              (None, 222, 222, 16)      448       
_________________________________________________________________
average_pooling2d (AveragePo (None, 111, 111, 16)      0         
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 109, 109, 32)      4640      
_________________________________________________________________
max_pooling2d (MaxPooling2D) (None, 54, 54, 32)        0         
_________________________________________________________________
dropout (Dropout)            (None, 54, 54, 32)        0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 52, 52, 64)        18496     
_________________________________________________________________
dropout_1 (Dropout)          (None, 52, 52, 64)        0         
_________________________________________________________________
flatten (Flatten)            (None, 173056)            0         
_________________________________________________________________
dense (Dense)                (None, 128)               22151296  
_________________________________________________________________
dense_1 (Dense)              (None, 2)                 258       
=================================================================
Total params: 22,175,138
Trainable params: 22,175,138
Non-trainable params: 0
_________________________________________________________________</pre> 
</blockquote> 
<p></p> 
<h2 id="四、训练模型">四、训练模型</h2> 
<p>在准备对模型进行训练之前，还需要再对其进行一些设置。以下内容是在模型的编译步骤中添加的：</p> 
<ul>
<li>损失函数（loss）：用于衡量模型在训练期间的准确率。</li>
<li>优化器（optimizer）：决定模型如何根据其看到的数据和自身的损失函数进行更新。</li>
<li>指标（metrics）：用于监控训练和测试步骤。以下示例使用了准确率，即被正确分类的图像的比率。</li>
</ul>
<h2 id="1.设置动态学习率">1. 设置动态学习率</h2> 
<div> 
 <pre><code class="hljs language-python"><span class="hljs-comment"># 设置初始学习率</span>
initial_learning_rate = <span class="hljs-number">0.0001</span>

lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(
        initial_learning_rate, 
        decay_steps=<span class="hljs-number">50</span>,      <span class="hljs-comment"># 敲黑板！！！这里是指 steps，不是指epochs</span>
        decay_rate=<span class="hljs-number">0.98</span>,     <span class="hljs-comment"># lr经过一次衰减就会变成 decay_rate*lr</span>
        staircase=<span class="hljs-literal">True</span>)

<span class="hljs-comment"># 将指数衰减学习率送入优化器</span>
optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)

model.<span class="hljs-built_in">compile</span>(optimizer=optimizer,
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=<span class="hljs-literal">True</span>),
              metrics=[<span class="hljs-string">'accuracy'</span>])</code></pre> 
</div> 
<p><strong>学习率大与学习率小的优缺点分析:</strong></p> 
<p><strong><span style="background-color:#4da8ee">学习率大</span></strong></p> 
<p>● 优点： ○ 1、加快学习速率。 ○ 2、有助于跳出局部最优值。 ● 缺点： ○ 1、导致模型训练不收敛。 ○ 2、单单使用大学习率容易导致模型不精确。</p> 
<p><strong><span style="background-color:#a2e043">学习率小</span></strong></p> 
<p>● 优点： ○ 1、有助于模型收敛、模型细化。 ○ 2、提高模型精度。 ● 缺点： ○ 1、很难跳出局部最优值。 ○ 2、收敛缓慢。</p> 
<p>注意：这里设置的动态学习率为：指数衰减型（ExponentialDecay）。在每一个epoch开始前，学习率（learning_rate）都将会重置为初始学习率（initial_learning_rate），然后再重新开始衰减。计算公式如下：</p> 
<p><span style="color:#956fe7"><strong>learning_rate = initial_learning_rate * decay_rate ^ (step / decay_steps)</strong></span></p> 
<p></p> 
<h2 id="2.早停与保存最佳模型参数">2. 早停与保存最佳模型参数</h2> 
<p>EarlyStopping()参数说明：</p> 
<ul>
<li>monitor: 被监测的数据。</li>
<li>min_delta: 在被监测的数据中被认为是提升的最小变化， 例如，小于 min_delta 的绝对变化会被认为没有提升。</li>
<li>patience: 没有进步的训练轮数，在这之后训练就会被停止。</li>
<li>verbose: 详细信息模式。</li>
<li>mode: {auto, min, max} 其中之一。 在 min 模式中， 当被监测的数据停止下降，训练就会停止；在 max 模式中，当被监测的数据停止上升，训练就会停止；在 auto 模式中，方向会自动从被监测的数据的名字中判断出来。</li>
<li>baseline: 要监控的数量的基准值。 如果模型没有显示基准的改善，训练将停止。</li>
<li>estore_best_weights: 是否从具有监测数量的最佳值的时期恢复模型权重。 如果为 False，则使用在训练的最后一步获得的模型权重。</li>
</ul>
<div> 
 <pre><code class="hljs language-python"><span class="hljs-keyword">from</span> tensorflow.keras.callbacks <span class="hljs-keyword">import</span> ModelCheckpoint, EarlyStopping

epochs = <span class="hljs-number">60</span>

<span class="hljs-comment"># 保存最佳模型参数</span>
checkpointer = ModelCheckpoint(<span class="hljs-string">'best_model.h5'</span>,
                                monitor=<span class="hljs-string">'val_accuracy'</span>,
                                verbose=<span class="hljs-number">1</span>,
                                save_best_only=<span class="hljs-literal">True</span>,
                                save_weights_only=<span class="hljs-literal">True</span>)

<span class="hljs-comment"># 设置早停</span>
earlystopper = EarlyStopping(monitor=<span class="hljs-string">'val_accuracy'</span>, 
                             min_delta=<span class="hljs-number">0.001</span>,
                             patience=<span class="hljs-number">20</span>, 
                             verbose=<span class="hljs-number">1</span>)</code></pre> 
</div> 
<p> </p> 
<h2 id="3.-模型训练">3.  模型训练</h2> 
<div> 
 <pre><code class="hljs language-python">history = model.fit(train_ds,
                    validation_data=val_ds,
                    epochs=epochs,
                    callbacks=[checkpointer, earlystopper])</code></pre> 
</div> 
<pre>Epoch 00057: val_accuracy did not improve from 0.88158
Epoch 00057: early stopping</pre> 
<p><span style="color:#511b78"><u>效果最好的一次，epoch走完了60次，val_accuracy为0.92，感觉选择一平均一最大池化比两平均效果好些。</u></span></p> 
<p></p> 
<h1 id="五、模型评估">五、模型评估</h1> 
<h2 id="1.-Loss与Accuracy图">1. Loss与Accuracy图</h2> 
<div> 
 <pre><code class="hljs language-python">acc = history.history[<span class="hljs-string">'accuracy'</span>]
val_acc = history.history[<span class="hljs-string">'val_accuracy'</span>]

loss = history.history[<span class="hljs-string">'loss'</span>]
val_loss = history.history[<span class="hljs-string">'val_loss'</span>]

epochs_range = <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(loss))

plt.figure(figsize=(<span class="hljs-number">12</span>, <span class="hljs-number">4</span>))
plt.subplot(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">1</span>)
plt.plot(epochs_range, acc, label=<span class="hljs-string">'Training Accuracy'</span>)
plt.plot(epochs_range, val_acc, label=<span class="hljs-string">'Validation Accuracy'</span>)
plt.legend(loc=<span class="hljs-string">'lower right'</span>)
plt.title(<span class="hljs-string">'Training and Validation Accuracy'</span>)

plt.subplot(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>)
plt.plot(epochs_range, loss, label=<span class="hljs-string">'Training Loss'</span>)
plt.plot(epochs_range, val_loss, label=<span class="hljs-string">'Validation Loss'</span>)
plt.legend(loc=<span class="hljs-string">'upper right'</span>)
plt.title(<span class="hljs-string">'Training and Validation Loss'</span>)
plt.show()</code></pre> 
</div> 
<div> 
 <p class="img-center"><img alt="" height="264" src="https://images2.imgbox.com/7f/c1/l2h5NQAl_o.png" width="706"><span title="点击并拖拽以改变尺寸">​</span></p> 
</div> 
<p></p> 
<div> 
 <pre><code class="hljs language-python"><span class="hljs-comment"># 加载效果最好的模型权重</span>
model.load_weights(<span class="hljs-string">'best_model.h5'</span>)

<span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> Image
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np

<span class="hljs-comment"># img = Image.open("./45-data/Monkeypox/M06_01_04.jpg")  #这里选择你需要预测的图片</span>
img = np.array(Image.<span class="hljs-built_in">open</span>(<span class="hljs-string">"./data/train/nike/1 (108).jpg"</span>))  <span class="hljs-comment">#这里选择你需要预测的图片</span>
image = tf.image.resize(img, [img_height, img_width])

img_array = tf.expand_dims(image, <span class="hljs-number">0</span>) 

predictions = model.predict(img_array) <span class="hljs-comment"># 这里选用你已经训练好的模型</span>
<span class="hljs-built_in">print</span>(<span class="hljs-string">"预测结果为："</span>,class_names[np.argmax(predictions)])</code></pre> 
</div> 
<pre>预测结果为： nike</pre> 
<p></p> 
<h1>一些收获与学习笔记：</h1> 
<h3><strong>1、对于卷积与池化</strong></h3> 
<p>池化时，如果更注重整体、背景，可以选择平均池化，但会使得图片“模糊”；如果更注重纹理、线条边缘，可以选择最大池化，如本次运动鞋识别，最大池化效果好些。</p> 
<p>一般而言，卷积层越多性能越好，但容易过拟合，池化层越多能回会降低模型预测的精准度。</p> 
<p>即大的方向上，欠拟合加卷积，过拟合加池化。</p> 
<p> </p> 
<h3><strong>2、对于学习率 </strong></h3> 
<p>并非学得越精细越好，有时可能会陷入"极大值"区域而非"最大值"。</p> 
<p><span style="background-color:#4da8ee">学习率大</span></p> 
<p>        ● 优点： ○ 1、加快学习速率。 ○ 2、有助于跳出局部最优值。 ● 缺点： ○ 1、导致模型训练不收敛。 ○ 2、单单使用大学习率容易导致模型不精确。</p> 
<p><span style="background-color:#a2e043">学习率小</span></p> 
<p>        ● 优点： ○ 1、有助于模型收敛、模型细化。 ○ 2、提高模型精度。 ● 缺点： ○ 1、很难跳出局部最优值。 ○ 2、收敛缓慢。</p> 
<p> </p> 
<h3><strong>3、batch_size </strong></h3> 
<p>Batch_size的作用：决定了下降的方向。</p> 
<p>在神经网络训练时，如果数据集足够小，可将数据一次性全部喂给神经网络</p> 
<p>但我们常常面临的是比较大的数据集，一次性喂给神经网络时，往往会出现内存/显存不足的现象。</p> 
<p>此时，我们会把比较大的数据集，分批次喂给神经网络。</p> 
<ul>
<li>batch_size：表示一次性喂给神经网络多少数据。</li>
<li>batches：该值等于dataset除以batch_size。总的数据集是dataset，我们每次喂给神经网络batch_size个数据，一共要喂dataset/batch_size次，才可以把数据集全部处理一遍。</li>
<li>steps：该值等于batches。steps表示在一个epoch内，要迭代多少次才可以把所有的数据都训练一遍；显然，迭代次数等于dataset/batch_size。</li>
</ul>
<p><strong>在合理范围内，增大Batch_size的好处：</strong></p> 
<ul>
<li>提高了内存利用率以及大矩阵乘法的并行化效率；</li>
<li>跑完一次epoch(全数据集）所需要的迭代次数减少，对相同的数据量，处理的速度比小的Batch_size要更快；</li>
<li>在一定范围内，一般来说 Batch_Size 越大，其确定的下降方向越准，引起训练震荡越小。</li>
</ul>
<p><br><strong>盲目增大Batch_size，Batch_size过大的坏处：</strong></p> 
<ul>
<li>提高了内存利用率，但是内存容量可能撑不住；</li>
<li>跑完一次epoch(全数据集)所需的迭代次数减少，要想达到相同的精度，其所花费的时间大大增加，从而对参数的修正也就显得更加缓慢；</li>
<li>Batch_Size 增大到一定程度，其确定的下降方向已经基本不再变化（会影响随机性的引入）。</li>
</ul>
<p> </p> 
<p><strong>一些经验之谈：</strong></p> 
<p>一般而言，根据GPU显存，设置为最大，而且一般要求是８的倍数（比如16，32，64），GPU内部的并行计算效率最高。<br> 或者选择一部分数据，设置几个８的倍数的Batch_Size，看看loss的下降情况，再选用效果更好的值。</p> 
<p><br><strong>总结：</strong></p> 
<p>batch_size设的大一些，收敛得快，也就是需要训练的次数少，准确率上升的也很稳定，但是实际使用起来精度不高；<br> batch_size设的小一些，收敛得慢，可能准确率来回震荡，因此需要把基础学习速率降低一些，但是实际使用起来精度较高。</p> 
<p> </p> 
<h3><strong>4、输入图片的大小</strong></h3> 
<p>输入网络的图片大小要根据网络结构来确定。</p> 
<p>主要看pool这个操作执行了几次，比如pool是2*2的，那么一次pool图像就缩小了一半。本实验执行了3次，就是2^3，那输入图片的尺寸就必须是2的3次方，8的倍数。</p> 
<p>输入图片大小变小之后，batchsize可以调大一些。在不超内存的情况下，batch越大越好</p> 
<p> </p> 
<h3><strong>5、others</strong></h3> 
<ul>
<li>有时模型准确率高但损失函数反而偏大，可能是受到了少数极端错误分类样本的影响。</li>
<li>对于训练集，在训练之前要进行shuffle操作，以确保模型的泛化能力。每一个epoch都需打乱数据的顺序，以使网络受到的调整更具有多样性。同时，我们会不断监督网络的训练效果。通常情况下，网络的性能提高速度会越来越慢，在几十到几百个epoch后网络的性能会趋于稳定，即性能基本不再提高.</li>
<li>通过Dataset对象的cache()方法和prefetch()通过缓存到内存中加速模型运行。</li>
</ul>
<p></p>
                </div>

		</div>
	</article>
</main>




			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程小白.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://www.w3counter.com/tracker.js?id=150625"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>
	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>