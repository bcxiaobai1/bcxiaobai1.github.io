<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<title>【自然语言处理】基于句子嵌入的文本摘要算法实现 - 编程小白</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程小白" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程小白</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">【自然语言处理】基于句子嵌入的文本摘要算法实现</h1>
			
		</header>
		<div class="content post__content clearfix">
			


        
                <div id="content_views" class="markdown_views prism-tomorrow-night-eighties">
                    
                        
                    
                    <h1>
<a id="centercenter_0"></a>
 
  基于句子嵌入的文本摘要算法实现
 
</h1> 
<p>人们在理解了文本的含义后，很容易用自己的话对文本进行总结。但在数据过多、缺乏人力和时间的情况下，自动文本摘要则显得至关重要。一般使用自动文本摘要的原因包括：</p> 
<ul>
<li>减少阅读时间</li>
<li>根据摘要，选择自己想研究的文档</li>
<li>提高索引的有效性</li>
<li>自动摘要算法比人工摘要算法的偏差更小</li>
<li>问答系统中的个性化摘要</li>
<li>能有效增加处理的文本数量</li>
</ul> 
<h2>
<a id="1_9"></a>1.方法分类</h2> 
<ul>
<li>基于输入 
  <ul>
<li>单个文档</li>
<li>多文档</li>
</ul> </li>
<li>基于目的 
  <ul>
<li>通用型。模型不对文本的所属领域或内容做出任何假设，所有输入被视为同质。目前，大部分研究的工作都是围绕这种方法展开的。</li>
<li>特定领域。模型使用特定领域的知识来形成更准确的摘要。例如，总结特定领域的研究论文、生物医学文献等。</li>
<li>基于查询。对相关问题的回答进行摘要。</li>
</ul> </li>
<li>基于输出 
  <ul>
<li>抽取。从输入文本中选择重要的句子形成摘要。目前，大多数摘要方法本质上都是抽取式的。</li>
<li>生成。模型生成短语和句子来提供更连贯的摘要。</li>
</ul> </li>
</ul> 
<p><img src="https://images2.imgbox.com/81/b6/gHsdLYbq_o.png" alt="在这里插入图片描述"></p> 
<h2>
<a id="2Pipeline_22"></a>2.Pipeline</h2> 
<p>本次任务是 <strong>对英语、丹麦语、法语等语言的电子邮件进行文本摘要</strong>。大多数公开可用的文本摘要数据集都是针对长文档的。由于长文档的结构与电子邮件的结构明显不同，因此使用监督方法训练的模型可能会出现领域适应性差的问题。因此，我们选择无监督方法来提取摘要。</p> 
<p>本文使用的方法主要来自论文《<code><a href="https://www.cs.utexas.edu/~asaran/reports/summarization.pdf">Unsupervised Text Summarization Using Sentence Embeddings</a></code>》。<img src="https://images2.imgbox.com/88/7c/b2vrdAub_o.png" alt="在这里插入图片描述"></p> 
<h3>
<a id="21_Email_Cleaning_26"></a>2.1 Email Cleaning</h3> 
<p>英文邮件示例：</p> 
<pre><code>Hi Jane,

Thank you for keeping me updated on this issue. I'm happy to hear that the issue got resolved after all and you can now use the app in its full functionality again. 
Also many thanks for your suggestions. We hope to improve this feature in the future. 

In case you experience any further problems with the app, please don't hesitate to contact me again.

Best regards,

John Doe
Customer Support

1600 Amphitheatre Parkway
Mountain View, CA
United States
</code></pre> 
<p>挪威语邮件示例：</p> 
<pre><code>Hei

Grunnet manglende dekning på deres kort for månedlig trekk, blir dere nå overført til årlig fakturering.
I morgen vil dere motta faktura for hosting og drift av nettbutikk for perioden 05.03.2018-05.03.2019.
Ta gjerne kontakt om dere har spørsmål.

Med vennlig hilsen
John Doe - SomeCompany.no
04756 | johndoe@somecompany.no

Husk å sjekk vårt hjelpesenter, kanskje du finner svar der: https://support.somecompany.no/
</code></pre> 
<p>意大利语邮件示例：</p> 
<pre><code>Ciao John, 

Grazie mille per averci contattato! Apprezziamo molto che abbiate trovato il tempo per inviarci i vostri commenti e siamo lieti che vi piaccia l'App. 

Sentitevi liberi di parlare di con i vostri amici o di sostenerci lasciando una recensione nell'App Store!

Cordiali saluti, 

Jane Doe
Customer Support

One Infinite Loop
Cupertino
CA 95014
</code></pre> 
<p>电子邮件开头和结尾的称呼和签名对摘要生成任务没有任何价值。为了使模型可以执行更简单的输入，可以从电子邮件中删除这些无意义的信息。</p> 
<p>称呼和签名因电子邮件以及语言而异，因此需要通过正则表达式进行删除。代码的简短版本如下所示（参考了 Mailgun Talon 在 <a href="https://github.com/mailgun/talon/blob/master/talon/signature/bruteforce.py">GitHub</a> 中的代码）：</p> 
<pre><code class="prism language-python"><span class="token comment"># clean() is a modified version of extract_signature() found in bruteforce.py in the GitHub repository linked above</span>
cleaned_email<span class="token punctuation">,</span> _ <span class="token operator">=</span> clean<span class="token punctuation">(</span>email<span class="token punctuation">)</span>

lines <span class="token operator">=</span> cleaned_email<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">'n'</span><span class="token punctuation">)</span>
lines <span class="token operator">=</span> <span class="token punctuation">[</span>line <span class="token keyword">for</span> line <span class="token keyword">in</span> lines <span class="token keyword">if</span> line <span class="token operator">!=</span> <span class="token string">''</span><span class="token punctuation">]</span>
cleaned_email <span class="token operator">=</span> <span class="token string">' '</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>lines<span class="token punctuation">)</span>
</code></pre> 
<p>还可以通过 <code>talon.signature.bruteforce</code> 实现：</p> 
<pre><code class="prism language-python"><span class="token keyword">from</span> talon<span class="token punctuation">.</span>signature<span class="token punctuation">.</span>bruteforce <span class="token keyword">import</span> extract_signature
cleaned_email<span class="token punctuation">,</span> _ <span class="token operator">=</span> extract_signature<span class="token punctuation">(</span>email<span class="token punctuation">)</span>
</code></pre> 
<p>清洗后的文本如下所示。</p> 
<p>英文电子邮件：</p> 
<blockquote> 
 <p>Thank you for keeping me updated on this issue. I’m happy to hear that the issue got resolved after all and you can now use the app in its full functionality again. Also many thanks for your suggestions. We hope to improve this feature in the future. In case you experience any further problems with the app, please don’t hesitate to contact me again.</p> 
</blockquote> 
<p>挪威语电子邮件：</p> 
<blockquote> 
 <p>Grunnet manglende dekning på deres kort for månedlig trekk, blir dere nå overført til årlig fakturering. I morgen vil dere motta faktura for hosting og drift av nettbutikk for perioden 05.03.2018-05.03.2019. Ta gjerne kontakt om dere har spørsmål.</p> 
</blockquote> 
<p>意大利语电子邮件：</p> 
<blockquote> 
 <p>Grazie mille per averci contattato! Apprezziamo molto che abbiate trovato il tempo per inviarci i vostri commenti e siamo lieti che vi piaccia l’App. Sentitevi liberi di parlare di con i vostri amici o di sostenerci lasciando una recensione nell’App Store.</p> 
</blockquote> 
<h3>
<a id="22_Language_Detection_110"></a>2.2 Language Detection</h3> 
<p>由于输入的电子邮件可以是任何语言，因此需要确定电子邮件使用的是哪种语言。许多 Python 库都提供的语言检测功能，例如 <code>polyglot</code>、<code>langdetect</code> 和 <code>textblob</code>。此处使用 <code>langdetect</code>，它支持 <span class="katex--inline"><span class="katex"><span class="katex-mathml">
    
     
      
       
        55
       
      
      
       55
      
     
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6444em"></span><span class="mord">55</span></span></span></span></span> 种不同语言的检测。</p> 
<pre><code class="prism language-python"><span class="token keyword">from</span> langdetect <span class="token keyword">import</span> detect
lang <span class="token operator">=</span> detect<span class="token punctuation">(</span>cleaned_email<span class="token punctuation">)</span> <span class="token comment"># lang = 'en' for an English email</span>
</code></pre> 
<h3>
<a id="23_Sentence_Tokenization_117"></a>2.3 Sentence Tokenization</h3> 
<p>不同语言的文本有不同的分割规则，在识别了每封电子邮件使用的语言后，我们可以利用 NLTK 将不同语言的文本分割成句子。</p> 
<pre><code class="prism language-python"><span class="token keyword">from</span> nltk<span class="token punctuation">.</span>tokenize <span class="token keyword">import</span> sent_tokenize
sentences <span class="token operator">=</span> sent_tokenize<span class="token punctuation">(</span>email<span class="token punctuation">,</span> language <span class="token operator">=</span> lang<span class="token punctuation">)</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/51/c2/8FJYZyCl_o.png" alt="在这里插入图片描述"></p> 
<h3>
<a id="24__SkipThought_Encoder_126"></a>2.4 Skip-Thought Encoder</h3> 
<p>接下来需要为电子邮件中的每个句子生成固定长度的向量表示。例如 <code>Word2Vec</code> 方法可以为模型词汇表中的每个词提供词嵌入（一些更高级的方法还可以使用子词信息为不在模型词汇表中的词生成嵌入）。下图是 <code>Word2Vec</code> 模型的 <code>Skip-Gram</code> 训练模式。</p> 
<p><img src="https://images2.imgbox.com/d4/63/GjBDSSq4_o.png" alt="在这里插入图片描述"><br> 对于句子嵌入，一种简单的方法是 <strong>对句子所包含的单词的词向量进行加权和</strong>。采用加权和是因为频繁出现的词，如 <code>and</code>、<code>to</code> 和 <code>the</code> 等单词所提供的关于句子的信息几乎非常少甚至没有。一些词虽然出现的次数较少，但它们是少数句子所特有的，具有更强的代表性。因此，我们假设权重与单词出现的频率成反比。</p> 
<p>然而无监督方法并没有考虑句子中单词的顺序，这可能会影响模型精度。此处，我们选择使用维基百科转储（<code>Wikipedia dumps</code>）作为训练数据，以监督的方式训练一个 <code>Skip-Thought</code> 句子编码器。 该模型主要由两部分组成：</p> 
<ul>
<li>编码器网络（<code>Encoder Network</code>）：编码器通常是 <code>GRU-RNN</code>，它为输入中的每个句子 <span class="katex--inline"><span class="katex"><span class="katex-mathml">
     
      
       
        
         S
        
        
         (
        
        
         i
        
        
         )
        
       
       
        S(i)
       
      
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em;vertical-align: -0.25em"></span><span class="mord mathnormal" style="margin-right: 0.0576em">S</span><span class="mopen">(</span><span class="mord mathnormal">i</span><span class="mclose">)</span></span></span></span></span> 生成固定长度的向量表示 <span class="katex--inline"><span class="katex"><span class="katex-mathml">
     
      
       
        
         h
        
        
         (
        
        
         i
        
        
         )
        
       
       
        h(i)
       
      
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em;vertical-align: -0.25em"></span><span class="mord mathnormal">h</span><span class="mopen">(</span><span class="mord mathnormal">i</span><span class="mclose">)</span></span></span></span></span>。<span class="katex--inline"><span class="katex"><span class="katex-mathml">
     
      
       
        
         h
        
        
         (
        
        
         i
        
        
         )
        
       
       
        h(i)
       
      
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em;vertical-align: -0.25em"></span><span class="mord mathnormal">h</span><span class="mopen">(</span><span class="mord mathnormal">i</span><span class="mclose">)</span></span></span></span></span> 是通过将 GRU 单元的最终隐藏状态传递给多个密集层来获得的。</li>
<li>解码器网络（<code>Decoder Network</code>）：解码器网络将 <span class="katex--inline"><span class="katex"><span class="katex-mathml">
     
      
       
        
         h
        
        
         (
        
        
         i
        
        
         )
        
       
       
        h(i)
       
      
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em;vertical-align: -0.25em"></span><span class="mord mathnormal">h</span><span class="mopen">(</span><span class="mord mathnormal">i</span><span class="mclose">)</span></span></span></span></span> 作为输入，并尝试生成两个句子：<span class="katex--inline"><span class="katex"><span class="katex-mathml">
     
      
       
        
         S
        
        
         (
        
        
         i
        
        
         −
        
        
         1
        
        
         )
        
       
       
        S(i-1)
       
      
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em;vertical-align: -0.25em"></span><span class="mord mathnormal" style="margin-right: 0.0576em">S</span><span class="mopen">(</span><span class="mord mathnormal">i</span><span class="mspace" style="margin-right: 0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right: 0.2222em"></span></span><span class="base"><span class="strut" style="height: 1em;vertical-align: -0.25em"></span><span class="mord">1</span><span class="mclose">)</span></span></span></span></span> 和 <span class="katex--inline"><span class="katex"><span class="katex-mathml">
     
      
       
        
         S
        
        
         (
        
        
         i
        
        
         +
        
        
         1
        
        
         )
        
       
       
        S(i+1)
       
      
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em;vertical-align: -0.25em"></span><span class="mord mathnormal" style="margin-right: 0.0576em">S</span><span class="mopen">(</span><span class="mord mathnormal">i</span><span class="mspace" style="margin-right: 0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.2222em"></span></span><span class="base"><span class="strut" style="height: 1em;vertical-align: -0.25em"></span><span class="mord">1</span><span class="mclose">)</span></span></span></span></span>，这两个句子可能分别出现在输入句子之前和之后。每个都实施单独的解码器来生成上一句和下一句，两者都是 <code>GRU-RNN</code>。<span class="katex--inline"><span class="katex"><span class="katex-mathml">
     
      
       
        
         h
        
        
         (
        
        
         i
        
        
         )
        
       
       
        h(i)
       
      
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em;vertical-align: -0.25em"></span><span class="mord mathnormal">h</span><span class="mopen">(</span><span class="mord mathnormal">i</span><span class="mclose">)</span></span></span></span></span> 作为解码器网络的 GRU 的初始隐藏状态。</li>
</ul> 
<p><img src="https://images2.imgbox.com/c9/95/THPCsZgw_o.png" alt="在这里插入图片描述"><br> 给定一个包含句子序列的数据集，解码器应该逐字生成上一句和下一句。编码器-解码器（<code>encoder-decoder</code>）网络通过训练使句子重建损失（<code>sentence reconstruction loss</code>）最小化。在此过程中，编码器学习生成向量表示，编码足够的信息供解码器使用，以便它可以生成相邻的句子。这些学习到的表示使得 <strong>语义相似的句子的嵌入在向量空间中彼此更接近</strong>，因此适用于聚类。我们把电子邮件中的句子作为编码器网络的输入，以获得所需的向量表示。</p> 
<p><img src="https://images2.imgbox.com/29/29/LrhIF6bE_o.png" alt="在这里插入图片描述"></p> 
<p>此处，我们可以使用 <code>Skip-Thoughts</code> 论文作者 <a href="https://github.com/ryankiros/skip-thoughts">开源的代码</a>。仅需几行代码就可以完成：</p> 
<pre><code class="prism language-python"><span class="token comment"># The 'skipthoughts' module can be found at the root of the GitHub  repository linked above</span>
<span class="token keyword">import</span> skipthoughts

<span class="token comment"># You would need to download pre-trained models first</span>
model <span class="token operator">=</span> skipthoughts<span class="token punctuation">.</span>load_model<span class="token punctuation">(</span><span class="token punctuation">)</span>

encoder <span class="token operator">=</span> skipthoughts<span class="token punctuation">.</span>Encoder<span class="token punctuation">(</span>model<span class="token punctuation">)</span>
encoded <span class="token operator">=</span>  encoder<span class="token punctuation">.</span>encode<span class="token punctuation">(</span>sentences<span class="token punctuation">)</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/4b/9a/25sVdRTJ_o.png" alt="在这里插入图片描述"></p> 
<h3>
<a id="25_Clustering_154"></a>2.5 Clustering</h3> 
<p>在为电子邮件中的每个句子生成句子嵌入后，可以对这些在高维向量空间中的嵌入进行聚类。聚类的数量将等于摘要中所需的句子数量。可以将摘要中的句子数定义为电子邮件中句子总数的平方根，也可以认为它等于句子总数的 <span class="katex--inline"><span class="katex"><span class="katex-mathml">
    
     
      
       
        30
       
       
        %
       
      
      
       30%
      
     
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8056em;vertical-align: -0.0556em"></span><span class="mord">30%</span></span></span></span></span>。</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>cluster <span class="token keyword">import</span> KMeans

n_clusters <span class="token operator">=</span> np<span class="token punctuation">.</span>ceil<span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>encoded<span class="token punctuation">)</span><span class="token operator">**</span><span class="token number">0.5</span><span class="token punctuation">)</span>
kmeans <span class="token operator">=</span> KMeans<span class="token punctuation">(</span>n_clusters<span class="token operator">=</span>n_clusters<span class="token punctuation">)</span>
kmeans <span class="token operator">=</span> kmeans<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>encoded<span class="token punctuation">)</span>
</code></pre> 
<h3>
<a id="26_Summarization_165"></a>2.6 Summarization</h3> 
<p>每个聚类都可以被理解为一组语义相似的句子，其含义可以由摘要中的一个候选句子表达。候选句子是向量表示最接近聚类中心的句子。然后对每个集群对应的候选句子进行排序，以形成电子邮件的摘要。摘要中候选句子的顺序由句子在原始电子邮件中的位置决定。</p> 
<pre><code class="prism language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>metrics <span class="token keyword">import</span> pairwise_distances_argmin_min

avg <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
<span class="token keyword">for</span> j <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>n_clusters<span class="token punctuation">)</span><span class="token punctuation">:</span>
    idx <span class="token operator">=</span> np<span class="token punctuation">.</span>where<span class="token punctuation">(</span>kmeans<span class="token punctuation">.</span>labels_ <span class="token operator">==</span> j<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
    avg<span class="token punctuation">.</span>append<span class="token punctuation">(</span>np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>idx<span class="token punctuation">)</span><span class="token punctuation">)</span>
closest<span class="token punctuation">,</span> _ <span class="token operator">=</span> pairwise_distances_argmin_min<span class="token punctuation">(</span>kmeans<span class="token punctuation">.</span>cluster_centers_<span class="token punctuation">,</span> encoded<span class="token punctuation">)</span>
ordering <span class="token operator">=</span> <span class="token builtin">sorted</span><span class="token punctuation">(</span><span class="token builtin">range</span><span class="token punctuation">(</span>n_clusters<span class="token punctuation">)</span><span class="token punctuation">,</span> key<span class="token operator">=</span><span class="token keyword">lambda</span> k<span class="token punctuation">:</span> avg<span class="token punctuation">[</span>k<span class="token punctuation">]</span><span class="token punctuation">)</span>
summary <span class="token operator">=</span> <span class="token string">' '</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token punctuation">[</span>email<span class="token punctuation">[</span>closest<span class="token punctuation">[</span>idx<span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token keyword">for</span> idx <span class="token keyword">in</span> ordering<span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre> 
<p>最终生成的摘要结果如下所示：</p> 
<p>英文电子邮件：</p> 
<blockquote> 
 <p>I’m happy to hear that the issue got resolved after all and you can now use the app in its full functionality again. Also many thanks for your suggestions. In case you experience any further problems with the app, please don’t hesitate to contact me again.</p> 
</blockquote> 
<p>丹麦语电子邮件：</p> 
<blockquote> 
 <p>Grunnet manglende dekning på deres kort for månedlig trekk, blir dere nå overført til årlig fakturering. I morgen vil dere motta faktura for hosting og drift av nettbutikk for perioden 05.03.2018-05.03.2019. Ta gjerne kontakt om dere har spørsmål.</p> 
</blockquote> 
<p>意大利语电子邮件：</p> 
<blockquote> 
 <p>Apprezziamo molto che abbiate trovato il tempo per inviarci i vostri commenti e siamo lieti che vi piaccia l’App. Sentitevi liberi di parlare di con i vostri amici o di sostenerci lasciando una recensione nell’App Store.</p> 
</blockquote> 
<h2>
<a id="3_190"></a>3.训练过程</h2> 
<p>预训练模型可用于编码英语句子。对于丹麦语句子，必须自己训练 <code>Skip-Thought</code> 模型。数据取自丹麦语维基百科转储（<code><a href="https://dumps.wikimedia.org/dawiki/latest/dawiki-latest-pages-articles.xml.bz2">Danish Wikipedia dumps</a></code>）。此处使用 <code><a href="https://github.com/attardi/wikiextractor">WikiExtractor</a></code> 解析维基百科转储，虽然它不是最好的工具，但它是免费的，并且可以在合理的时间内完成这项工作。</p> 
<p>由此生成的训练数据包括来自维基百科文章的 <span class="katex--inline"><span class="katex"><span class="katex-mathml">
    
     
      
       
        2
       
       
        ,
       
       
        712
       
       
        ,
       
       
        935
       
      
      
       2,712,935
      
     
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8389em;vertical-align: -0.1944em"></span><span class="mord">2</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em"></span><span class="mord">712</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em"></span><span class="mord">935</span></span></span></span></span> 个丹麦语句子。训练过程还需要预先训练好的 <code>Word2Vec</code> 词向量。此处使用的是 <span class="katex--inline"><span class="katex"><span class="katex-mathml">
    
     
      
       
        F
       
       
        a
       
       
        c
       
       
        e
       
       
        b
       
       
        o
       
       
        o
       
       
        k
       
      
      
       Facebook
      
     
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6944em"></span><span class="mord mathnormal" style="margin-right: 0.1389em">F</span><span class="mord mathnormal">a</span><span class="mord mathnormal">ce</span><span class="mord mathnormal">b</span><span class="mord mathnormal">oo</span><span class="mord mathnormal" style="margin-right: 0.0315em">k</span></span></span></span></span> 的 <span class="katex--inline"><span class="katex"><span class="katex-mathml">
    
     
      
       
        F
       
       
        a
       
       
        s
       
       
        t
       
       
        T
       
       
        e
       
       
        x
       
       
        t
       
      
      
       FastText
      
     
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6833em"></span><span class="mord mathnormal" style="margin-right: 0.1389em">F</span><span class="mord mathnormal">a</span><span class="mord mathnormal">s</span><span class="mord mathnormal" style="margin-right: 0.1389em">tT</span><span class="mord mathnormal">e</span><span class="mord mathnormal">x</span><span class="mord mathnormal">t</span></span></span></span></span> 的预训练词向量。预训练模型的词汇量为 <span class="katex--inline"><span class="katex"><span class="katex-mathml">
    
     
      
       
        312
       
       
        ,
       
       
        956
       
      
      
       312,956
      
     
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8389em;vertical-align: -0.1944em"></span><span class="mord">312</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em"></span><span class="mord">956</span></span></span></span></span> 个单词。这些词向量也是在丹麦语维基百科上进行训练的，因此词汇外的词非常少见。</p> 
<p>下面是该模块的简化版本，它仅支持英文电子邮件，但实现了上述所有步骤，效果非常好。</p> 
<pre><code class="prism language-python"><span class="token comment">#!/usr/bin/env python</span>
<span class="token comment"># -*- coding: utf-8 -*-</span>
<span class="token triple-quoted-string string">"""
Module for E-mail Summarization
*****************************************************************************
Input Parameters:
    emails: A list of strings containing the emails
Returns:
    summary: A list of strings containing the summaries.
*****************************************************************************
"""</span>


<span class="token comment"># ***************************************************************************</span>
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">from</span> talon<span class="token punctuation">.</span>signature<span class="token punctuation">.</span>bruteforce <span class="token keyword">import</span> extract_signature
<span class="token keyword">from</span> langdetect <span class="token keyword">import</span> detect
<span class="token keyword">from</span> nltk<span class="token punctuation">.</span>tokenize <span class="token keyword">import</span> sent_tokenize
<span class="token keyword">import</span> skipthoughts
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>cluster <span class="token keyword">import</span> KMeans
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>metrics <span class="token keyword">import</span> pairwise_distances_argmin_min
<span class="token comment"># ***************************************************************************</span>


<span class="token keyword">def</span> <span class="token function">preprocess</span><span class="token punctuation">(</span>emails<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    Performs preprocessing operations such as:
        1. Removing signature lines (only English emails are supported)
        2. Removing new line characters.
    """</span>
    n_emails <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>emails<span class="token punctuation">)</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>n_emails<span class="token punctuation">)</span><span class="token punctuation">:</span>
        email <span class="token operator">=</span> emails<span class="token punctuation">[</span>i<span class="token punctuation">]</span>
        email<span class="token punctuation">,</span> _ <span class="token operator">=</span> extract_signature<span class="token punctuation">(</span>email<span class="token punctuation">)</span>
        lines <span class="token operator">=</span> email<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">'n'</span><span class="token punctuation">)</span>
        <span class="token keyword">for</span> j <span class="token keyword">in</span> <span class="token builtin">reversed</span><span class="token punctuation">(</span><span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>lines<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            lines<span class="token punctuation">[</span>j<span class="token punctuation">]</span> <span class="token operator">=</span> lines<span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span>
            <span class="token keyword">if</span> lines<span class="token punctuation">[</span>j<span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token string">''</span><span class="token punctuation">:</span>
                lines<span class="token punctuation">.</span>pop<span class="token punctuation">(</span>j<span class="token punctuation">)</span>
        emails<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">' '</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>lines<span class="token punctuation">)</span>
        
        
<span class="token keyword">def</span> <span class="token function">split_sentences</span><span class="token punctuation">(</span>emails<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    Splits the emails into individual sentences
    """</span>
    n_emails <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>emails<span class="token punctuation">)</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>n_emails<span class="token punctuation">)</span><span class="token punctuation">:</span>
        email <span class="token operator">=</span> emails<span class="token punctuation">[</span>i<span class="token punctuation">]</span>
        sentences <span class="token operator">=</span> sent_tokenize<span class="token punctuation">(</span>email<span class="token punctuation">)</span>
        <span class="token keyword">for</span> j <span class="token keyword">in</span> <span class="token builtin">reversed</span><span class="token punctuation">(</span><span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>sentences<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            sent <span class="token operator">=</span> sentences<span class="token punctuation">[</span>j<span class="token punctuation">]</span>
            sentences<span class="token punctuation">[</span>j<span class="token punctuation">]</span> <span class="token operator">=</span> sent<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span>
            <span class="token keyword">if</span> sent <span class="token operator">==</span> <span class="token string">''</span><span class="token punctuation">:</span>
                sentences<span class="token punctuation">.</span>pop<span class="token punctuation">(</span>j<span class="token punctuation">)</span>
        emails<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> sentences
        
        
<span class="token keyword">def</span> <span class="token function">skipthought_encode</span><span class="token punctuation">(</span>emails<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    Obtains sentence embeddings for each sentence in the emails
    """</span>
    enc_emails <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token boolean">None</span><span class="token punctuation">]</span><span class="token operator">*</span><span class="token builtin">len</span><span class="token punctuation">(</span>emails<span class="token punctuation">)</span>
    cum_sum_sentences <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
    sent_count <span class="token operator">=</span> <span class="token number">0</span>
    <span class="token keyword">for</span> email <span class="token keyword">in</span> emails<span class="token punctuation">:</span>
        sent_count <span class="token operator">+=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>email<span class="token punctuation">)</span>
        cum_sum_sentences<span class="token punctuation">.</span>append<span class="token punctuation">(</span>sent_count<span class="token punctuation">)</span>

    all_sentences <span class="token operator">=</span> <span class="token punctuation">[</span>sent <span class="token keyword">for</span> email <span class="token keyword">in</span> emails <span class="token keyword">for</span> sent <span class="token keyword">in</span> email<span class="token punctuation">]</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Loading pre-trained models...'</span><span class="token punctuation">)</span>
    model <span class="token operator">=</span> skipthoughts<span class="token punctuation">.</span>load_model<span class="token punctuation">(</span><span class="token punctuation">)</span>
    encoder <span class="token operator">=</span> skipthoughts<span class="token punctuation">.</span>Encoder<span class="token punctuation">(</span>model<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Encoding sentences...'</span><span class="token punctuation">)</span>
    enc_sentences <span class="token operator">=</span> encoder<span class="token punctuation">.</span>encode<span class="token punctuation">(</span>all_sentences<span class="token punctuation">,</span> verbose<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>

    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>emails<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        begin <span class="token operator">=</span> cum_sum_sentences<span class="token punctuation">[</span>i<span class="token punctuation">]</span>
        end <span class="token operator">=</span> cum_sum_sentences<span class="token punctuation">[</span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">]</span>
        enc_emails<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> enc_sentences<span class="token punctuation">[</span>begin<span class="token punctuation">:</span>end<span class="token punctuation">]</span>
    <span class="token keyword">return</span> enc_emails
        
    
<span class="token keyword">def</span> <span class="token function">summarize</span><span class="token punctuation">(</span>emails<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    Performs summarization of emails
    """</span>
    n_emails <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>emails<span class="token punctuation">)</span>
    summary <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token boolean">None</span><span class="token punctuation">]</span><span class="token operator">*</span>n_emails
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Preprecesing...'</span><span class="token punctuation">)</span>
    preprocess<span class="token punctuation">(</span>emails<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Splitting into sentences...'</span><span class="token punctuation">)</span>
    split_sentences<span class="token punctuation">(</span>emails<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Starting to encode...'</span><span class="token punctuation">)</span>
    enc_emails <span class="token operator">=</span> skipthought_encode<span class="token punctuation">(</span>emails<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Encoding Finished'</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>n_emails<span class="token punctuation">)</span><span class="token punctuation">:</span>
        enc_email <span class="token operator">=</span> enc_emails<span class="token punctuation">[</span>i<span class="token punctuation">]</span>
        n_clusters <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>ceil<span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>enc_email<span class="token punctuation">)</span><span class="token operator">**</span><span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        kmeans <span class="token operator">=</span> KMeans<span class="token punctuation">(</span>n_clusters<span class="token operator">=</span>n_clusters<span class="token punctuation">,</span> random_state<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
        kmeans <span class="token operator">=</span> kmeans<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>enc_email<span class="token punctuation">)</span>
        avg <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        closest <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        <span class="token keyword">for</span> j <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>n_clusters<span class="token punctuation">)</span><span class="token punctuation">:</span>
            idx <span class="token operator">=</span> np<span class="token punctuation">.</span>where<span class="token punctuation">(</span>kmeans<span class="token punctuation">.</span>labels_ <span class="token operator">==</span> j<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
            avg<span class="token punctuation">.</span>append<span class="token punctuation">(</span>np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>idx<span class="token punctuation">)</span><span class="token punctuation">)</span>
        closest<span class="token punctuation">,</span> _ <span class="token operator">=</span> pairwise_distances_argmin_min<span class="token punctuation">(</span>kmeans<span class="token punctuation">.</span>cluster_centers_<span class="token punctuation">,</span>
                                                   enc_email<span class="token punctuation">)</span>
        ordering <span class="token operator">=</span> <span class="token builtin">sorted</span><span class="token punctuation">(</span><span class="token builtin">range</span><span class="token punctuation">(</span>n_clusters<span class="token punctuation">)</span><span class="token punctuation">,</span> key<span class="token operator">=</span><span class="token keyword">lambda</span> k<span class="token punctuation">:</span> avg<span class="token punctuation">[</span>k<span class="token punctuation">]</span><span class="token punctuation">)</span>
        summary<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">' '</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token punctuation">[</span>emails<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>closest<span class="token punctuation">[</span>idx<span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token keyword">for</span> idx <span class="token keyword">in</span> ordering<span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Clustering Finished'</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> summary
</code></pre> 
<h2>
<a id="4_310"></a>4.结果</h2> 
<p>当邮件中包含多个句子时，此种摘要方法效果较好。对于三句话的邮件，摘要可能是由两句话组成，但三个句子传达的意义可能完全不同，省略掉任何一个句子的信息都是不合适的。基于此，提取法通常并不适合短文本摘要。监督式 <code>Seq2Seq</code> 模型更适合这项任务。</p> 
<p>使用 <code>Skip-Thought</code> 方法进行向量化的一个缺点是模型可能需要训练很长时间。尽管在训练 <span class="katex--inline"><span class="katex"><span class="katex-mathml">
    
     
      
       
        2
       
       
        −
       
       
        3
       
      
      
       2-3
      
     
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.7278em;vertical-align: -0.0833em"></span><span class="mord">2</span><span class="mspace" style="margin-right: 0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right: 0.2222em"></span></span><span class="base"><span class="strut" style="height: 0.6444em"></span><span class="mord">3</span></span></span></span></span> 天后获得了可接受的结果，但 <code>Skip-Thought</code> 模型在丹麦语语料上训练了大约一周。该模型是按句子长度归一化的，所以成本在迭代期间波动很大。</p> 
<p><img src="https://images2.imgbox.com/49/68/6j47NEIJ_o.png" alt="在这里插入图片描述"><br> 可以查看数据集中最相似的句子，了解 Skip-Thoughts 模型的效果。</p> 
<p>例 <span class="katex--inline"><span class="katex"><span class="katex-mathml">
    
     
      
       
        1
       
      
      
       1
      
     
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6444em"></span><span class="mord">1</span></span></span></span></span>：</p> 
<ul>
<li><code>I can assure you that our developers are already aware of the issue and are trying to solve it as soon as possible.</code></li>
<li><code>I have already forwarded your problem report to our developers and they will now investigate this issue with the login page in further detail in order to detect the source of this problem.</code></li>
</ul> 
<p>例 <span class="katex--inline"><span class="katex"><span class="katex-mathml">
    
     
      
       
        2
       
      
      
       2
      
     
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6444em"></span><span class="mord">2</span></span></span></span></span>：</p> 
<ul>
<li><code>I am very sorry to hear that.</code></li>
<li><code>We sincerely apologize for the inconvenience caused.</code></li>
</ul> 
<p>例 <span class="katex--inline"><span class="katex"><span class="katex-mathml">
    
     
      
       
        3
       
      
      
       3
      
     
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6444em"></span><span class="mord">3</span></span></span></span></span>：</p> 
<ul>
<li><code>Therefore, I would kindly ask you to tell me which operating system you are using the app on.</code></li>
<li><code>Can you specify which device you are using as well as the Android or iOS version it currently has installed?</code></li>
</ul> 
<h2>
<a id="5_331"></a>5.优化</h2> 
<p>通过增加模型的复杂性可以进行一些相关的改进：</p> 
<ul>
<li>
<code>Quick-Thought Vectors</code> 是 <code>Skip-Thoughts</code> 方法的最新进展，可以显著减少训练时间并提高性能。</li>
<li>
<code>Skip-Thought</code> 编码表示的维数为 <span class="katex--inline"><span class="katex"><span class="katex-mathml">
     
      
       
        
         4800
        
       
       
        4800
       
      
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6444em"></span><span class="mord">4800</span></span></span></span></span>。由于维数灾难，这些高维向量不适合聚类。在使用 <code>Autoencoder</code> 或 <code>LSTM-Autoencoder</code> 进行聚类之前，可以进行降维。</li>
<li>可以通过训练解码器网络来实现 <strong>生成摘要</strong>，而不是提取摘要。解码器网络可以将聚类中心的编码表示转换回自然语言表示的句子。这样的解码器可以通过 <code>Skip-Thoughts</code> 编码器生成的数据进行训练。但是，如果我们希望解码器生成合理且语法正确的句子，则需要对解码器进行非常仔细的超参调整和架构决策。</li>
</ul>
                </div>
                
                

		</div>
	</article>
</main>




			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程小白.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://www.w3counter.com/tracker.js?id=150625"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>
	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>