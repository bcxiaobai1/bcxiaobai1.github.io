<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<title>openCV实战项目--人脸考勤 - 编程小白</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程小白" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程小白</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">openCV实战项目--人脸考勤</h1>
			
		</header>
		<div class="content post__content clearfix">
			


                <div id="content_views" class="htmledit_views">
                    <p>人脸任务在计算机视觉领域中十分重要，本项目主要使用了两类技术：<span style="color:#38d8f0">人脸检测</span>+<span style="color:#ed7976">人脸识别</span>。</p> 
<p>代码分为两部分内容：<strong>人脸注册</strong> 和 <strong>人脸识别</strong></p> 
<ul>
<li>
<strong>人脸注册</strong>：将人脸特征存储进数据库，这里用feature.csv代替</li>
<li>
<strong>人脸识别</strong>：将人脸特征与CSV文件中人脸特征进行比较，如果成功匹配则写入考勤文件attendance.csv</li>
</ul>
<p></p> 
<p>文章前半部分为一步步实现流程介绍，最后会有整理过后的完整项目代码。</p> 
<p></p> 
<h1>一、项目实现</h1> 
<h2>A. 注册： </h2> 
<h3>导入相关包</h3> 
<pre><code class="language-python">import cv2
import numpy as np
import dlib
import time
import csv
# from argparse import ArgumentParser
from PIL import Image, ImageDraw, ImageFont</code></pre> 
<h3>设计注册功能</h3> 
<p>注册过程我们需要完成的事：</p> 
<ul>
<li>打开摄像头获取画面图片</li>
<li>在图片中检测并获取人脸位置</li>
<li>根据人脸位置获取68个关键点</li>
<li>根据68个关键点生成特征描述符</li>
<li>保存</li>
<li>(优化)展示界面，加入注册时成功提示等</li>
</ul>
<p></p> 
<h3>1、基本步骤</h3> 
<p>我们首先进行<span style="color:#fe2c24"><strong>前三步</strong></span>：</p> 
<pre><code class="language-python"># 检测人脸，获取68个关键点，获取特征描述符
def faceRegister(faceId=1, userName='default', interval=3, faceCount=3, resize_w=700, resize_h=400):
    '''
    faceId:人脸ID
    userName: 人脸姓名
    faceCount: 采集该人脸图片的数量
    interval: 采集间隔
    '''

    cap = cv2.VideoCapture(0)
    # 人脸检测模型
    hog_face_detector = dlib.get_frontal_face_detector()
    # 关键点 检测模型
    shape_detector = dlib.shape_predictor('./weights/shape_predictor_68_face_landmarks.dat')
    # resnet模型
    face_descriptor_extractor = dlib.face_recognition_model_v1('./weights/dlib_face_recognition_resnet_model_v1.dat')
    
    while True:
        ret, frame = cap.read()

        # 镜像
        frame = cv2.flip(frame,1)

        # 转为灰度图
        frame_gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)
        
        # 检测人脸
        detections = hog_face_detector(frame,1)

        for face in detections:
            # 人脸框坐标 左上和右下
            l, t, r, b = face.left(), face.top(), face.right(), face.bottom()

            # 获取68个关键点
            points = shape_detector(frame,face)
            
            # 绘制关键点
            for point in points.parts():
                cv2.circle(frame,(point.x,point.y),2,(0,255,0),1)

            # 绘制矩形框
            cv2.rectangle(frame,(l,t),(r,b),(0,255,0),2)
                   
        cv2.imshow("face",frame)
        if cv2.waitKey(10) &amp; 0xFF == ord('q'):
            break
                 
    cap.release()
    cv2.destroyAllWindows
                    
            
faceRegister()      </code></pre> 
<p>此时一张帅脸如下：</p> 
<p class="img-center"><img alt="" height="308" src="https://images2.imgbox.com/af/34/OkLmW6Fa_o.png" width="548"></p> 
<p></p> 
<h3>2、描述符的采集</h3> 
<p>之后，我们根据参数，即faceCount 和 Interval 进行<span style="color:#fe2c24"><strong>描述符的生成和采集</strong></span>。</p> 
<p>(这里我默认是faceCount=3，Interval=3，即每3秒采集一次，共3次）</p> 
<pre><code class="language-python">def faceRegister(faceId=1, userName='default', interval=3, faceCount=3, resize_w=700, resize_h=400):
    '''
    faceId:人脸ID
    userName: 人脸姓名
    faceCount: 采集该人脸图片的数量
    interval: 采集间隔
    '''

    cap = cv2.VideoCapture(0)
    # 人脸检测模型
    hog_face_detector = dlib.get_frontal_face_detector()
    # 关键点 检测模型
    shape_detector = dlib.shape_predictor('./weights/shape_predictor_68_face_landmarks.dat')
    # resnet模型
    face_descriptor_extractor = dlib.face_recognition_model_v1('./weights/dlib_face_recognition_resnet_model_v1.dat')
    
    
    # 开始时间
    start_time = time.time()
    # 执行次数
    collect_times = 0
    

    while True:
        ret, frame = cap.read()
        
        # 镜像
        frame = cv2.flip(frame,1)

        # 转为灰度图
        frame_gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)
        
        # 检测人脸
        detections = hog_face_detector(frame,1)

        for face in detections:
            # 人脸框坐标 左上和右下
            l, t, r, b = face.left(), face.top(), face.right(), face.bottom()

            # 获取68个关键点
            points = shape_detector(frame,face)

            # 绘制人脸关键点
            for point in points.parts():
                cv2.circle(frame, (point.x, point.y), 2, (0, 255, 0), 1)
            # 绘制矩形框
            cv2.rectangle(frame, (l, t), (r, b), (0, 255, 0), 2)
            
            # 采集：
            if collect_times &lt; faceCount:
                # 获取当前时间
                now = time.time()
                # 时间限制
                if now - start_time &gt; interval:
                    # 获取特征描述符
                    face_descriptor = face_descriptor_extractor.compute_face_descriptor(frame,points)
                    # dlib格式转为数组
                    face_descriptor = [f for f in face_descriptor]

                    collect_times += 1
                    start_time = now
                    print("成功采集{}次".format(collect_times))
                else:
                    # 时间间隔不到interval
                    print("等待进行下一次采集")
                    pass
            else:
                # 已经成功采集完3次了
                print("采集完毕")
                cap.release()
                cv2.destroyAllWindows()
                return
              
        cv2.imshow("face",frame)
        if cv2.waitKey(10) &amp; 0xFF == ord('q'):
            break
                  
    cap.release()
    cv2.destroyAllWindows()
                    
            
faceRegister()  </code></pre> 
<pre>等待进行下一次采集
...
成功采集1次
等待进行下一次采集
...
成功采集2次
等待进行下一次采集
...
成功采集3次
采集完毕</pre> 
<p></p> 
<h3>3、完整的注册</h3> 
<p>最后就是<span style="color:#fe2c24"><strong>写入csv文件</strong></span></p> 
<p>这里加入了注册成功等的提示，且把一些变量放到了全局，因为后面人脸识别打卡时也会用到。</p> 
<pre><code class="language-python"># 加载人脸检测器
hog_face_detector = dlib.get_frontal_face_detector()
cnn_detector = dlib.cnn_face_detection_model_v1('./weights/mmod_human_face_detector.dat')
haar_face_detector = cv2.CascadeClassifier('./weights/haarcascade_frontalface_default.xml')

# 加载关键点检测器
points_detector = dlib.shape_predictor('./weights/shape_predictor_68_face_landmarks.dat')
# 加载resnet模型
face_descriptor_extractor = dlib.face_recognition_model_v1('./weights/dlib_face_recognition_resnet_model_v1.dat')</code></pre> 
<pre><code class="language-python"># 绘制中文
def cv2AddChineseText(img, text, position, textColor=(0, 255, 0), textSize=30):
    if (isinstance(img, np.ndarray)):  # 判断是否OpenCV图片类型
        img = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
    # 创建一个可以在给定图像上绘图的对象
    draw = ImageDraw.Draw(img)
    # 字体的格式
    fontStyle = ImageFont.truetype(
        "./fonts/songti.ttc", textSize, encoding="utf-8")
    # 绘制文本
    draw.text(position, text, textColor, font=fontStyle)
    # 转换回OpenCV格式
    return cv2.cvtColor(np.asarray(img), cv2.COLOR_RGB2BGR)
</code></pre> 
<pre><code class="language-python"># 绘制左侧信息
def drawLeftInfo(frame, fpsText, mode="Reg", detector='haar', person=1, count=1):
    # 帧率
    cv2.putText(frame, "FPS:  " + str(round(fpsText, 2)), (30, 50), cv2.FONT_ITALIC, 0.8, (0, 255, 0), 2)

    # 模式：注册、识别
    cv2.putText(frame, "Mode:  " + str(mode), (30, 80), cv2.FONT_ITALIC, 0.8, (0, 255, 0), 2)

    if mode == 'Recog':
        # 检测器
        cv2.putText(frame, "Detector:  " + detector, (30, 110), cv2.FONT_ITALIC, 0.8, (0, 255, 0), 2)

        # 人数
        cv2.putText(frame, "Person:  " + str(person), (30, 140), cv2.FONT_ITALIC, 0.8, (0, 255, 0), 2)

        # 总人数
        cv2.putText(frame, "Count:  " + str(count), (30, 170), cv2.FONT_ITALIC, 0.8, (0, 255, 0), 2)</code></pre> 
<pre><code class="language-python"># 注册人脸
def faceRegiser(faceId=1, userName='default', interval=3, faceCount=3, resize_w=700, resize_h=400):
    # 计数
    count = 0
    # 开始注册时间
    startTime = time.time()

    # 视频时间
    frameTime = startTime

    # 控制显示打卡成功的时长
    show_time = (startTime - 10)

    # 打开文件
    f = open('./data/feature.csv', 'a', newline='')
    csv_writer = csv.writer(f)

    cap = cv2.VideoCapture(0)

    while True:
        ret, frame = cap.read()
        frame = cv2.resize(frame, (resize_w, resize_h))
        frame = cv2.flip(frame, 1)

        # 检测
        face_detetion = hog_face_detector(frame, 1)

        for face in face_detetion:
            # 识别68个关键点
            points = points_detector(frame, face)
            # 绘制人脸关键点
            for point in points.parts():
                cv2.circle(frame, (point.x, point.y), 2, (0, 255, 0), 1)
            # 绘制框框
            l, t, r, b = face.left(), face.top(), face.right(), face.bottom()
            cv2.rectangle(frame, (l, t), (r, b), (0, 255, 0), 2)

            now = time.time()

            if (now - show_time) &lt; 0.5:
                frame = cv2AddChineseText(frame,
                                          "注册成功 {count}/{faceCount}".format(count=(count + 1), faceCount=faceCount),
                                          (l, b + 30), textColor=(255, 0, 255), textSize=30)

            # 检查次数

            if count &lt; faceCount:

                # 检查时间
                if now - startTime &gt; interval:
                    # 特征描述符
                    face_descriptor = face_descriptor_extractor.compute_face_descriptor(frame, points)

                    face_descriptor = [f for f in face_descriptor]

                    # 描述符增加进data文件
                    line = [faceId, userName, face_descriptor]
                    # 写入
                    csv_writer.writerow(line)

                    # 保存照片样本

                    print('人脸注册成功 {count}/{faceCount}，faceId:{faceId}，userName:{userName}'.format(count=(count + 1),
                                                                                                  faceCount=faceCount,
                                                                                                  faceId=faceId,
                                                                                                  userName=userName))

                    frame = cv2AddChineseText(frame,
                                              "注册成功 {count}/{faceCount}".format(count=(count + 1), faceCount=faceCount),
                                              (l, b + 30), textColor=(255, 0, 255), textSize=30)
                    show_time = time.time()

                    # 时间重置
                    startTime = now
                    # 次数加一
                    count += 1


            else:
                print('人脸注册完毕')
                f.close()
                cap.release()
                cv2.destroyAllWindows()
                return

        now = time.time()
        fpsText = 1 / (now - frameTime)
        frameTime = now
        # 绘制
        drawLeftInfo(frame, fpsText, 'Register')

        cv2.imshow('Face Attendance Demo: Register', frame)
        if cv2.waitKey(10) &amp; 0xFF == ord('q'):
            break
    f.close()
    cap.release()
    cv2.destroyAllWindows()</code></pre> 
<p>此时执行：</p> 
<pre><code class="language-python">faceRegiser(3,"用户B")</code></pre> 
<p class="img-center"><img alt="" height="319" src="https://images2.imgbox.com/12/35/7zsrReut_o.png" width="558"></p> 
<pre>人脸注册成功 1/3，faceId:3，userName:用户B
人脸注册成功 2/3，faceId:3，userName:用户B
人脸注册成功 3/3，faceId:3，userName:用户B
人脸注册完毕</pre> 
<p>其features文件：</p> 
<p class="img-center"><img alt="" height="55" src="https://images2.imgbox.com/1e/6a/tvQyiUaa_o.png" width="1200"></p> 
<p></p> 
<h2>B. 识别、打卡</h2> 
<p>识别步骤如下：</p> 
<ul>
<li>打开摄像头获取画面</li>
<li>根据画面中的图片获取里面的人脸特征描述符</li>
<li>根据特征描述符将其与feature.csv文件里特征做距离判断</li>
<li>获取ID、NAME</li>
<li>考勤记录写入attendance.csv里</li>
</ul>
<p>这里与上面流程相似，不过是加了一个对比功能，距离小于阈值，则表示匹配成功。就加快速度不一步步来了，代码如下：</p> 
<pre><code class="language-python"># 刷新右侧考勤信息
def updateRightInfo(frame, face_info_list, face_img_list):
    # 重新绘制逻辑：从列表中每隔3个取一批显示，新增人脸放在最前面

    # 如果有更新，重新绘制

    # 如果没有，定时往后移动

    left_x = 30
    left_y = 20
    resize_w = 80

    offset_y = 120
    index = 0

    frame_h = frame.shape[0]
    frame_w = frame.shape[1]

    for face in face_info_list[:3]:
        name = face[0]
        time = face[1]
        face_img = face_img_list[index]

        # print(face_img.shape)

        face_img = cv2.resize(face_img, (resize_w, resize_w))

        offset_y_value = offset_y * index
        frame[(left_y + offset_y_value):(left_y + resize_w + offset_y_value), -(left_x + resize_w):-left_x] = face_img

        cv2.putText(frame, name, ((frame_w - (left_x + resize_w)), (left_y + resize_w) + 15 + offset_y_value),
                    cv2.FONT_ITALIC, 0.5, (0, 255, 0), 1)
        cv2.putText(frame, time, ((frame_w - (left_x + resize_w)), (left_y + resize_w) + 30 + offset_y_value),
                    cv2.FONT_ITALIC, 0.5, (0, 255, 0), 1)

        index += 1

    return frame</code></pre> 
<pre><code class="language-python"># 返回DLIB格式的face
def getDlibRect(detector='hog', face=None):
    l, t, r, b = None, None, None, None

    if detector == 'hog':
        l, t, r, b = face.left(), face.top(), face.right(), face.bottom()

    if detector == 'cnn':
        l = face.rect.left()
        t = face.rect.top()
        r = face.rect.right()
        b = face.rect.bottom()

    if detector == 'haar':
        l = face[0]
        t = face[1]
        r = face[0] + face[2]
        b = face[1] + face[3]

    nonnegative = lambda x: x if x &gt;= 0 else 0
    return map(nonnegative, (l, t, r, b))</code></pre> 
<pre><code class="language-python"># 获取CSV中信息
def getFeatList():
    print('加载注册的人脸特征')

    feature_list = None
    label_list = []
    name_list = []

    # 加载保存的特征样本
    with open('./data/feature.csv', 'r') as f:
        csv_reader = csv.reader(f)
        for line in csv_reader:
            # 重新加载数据
            faceId = line[0]
            userName = line[1]
            face_descriptor = eval(line[2])

            label_list.append(faceId)
            name_list.append(userName)

            # 转为numpy格式
            face_descriptor = np.asarray(face_descriptor, dtype=np.float64)
            # 转为二维矩阵，拼接
            face_descriptor = np.reshape(face_descriptor, (1, -1))
            # 初始化
            if feature_list is None:
                feature_list = face_descriptor
            else:
                # 拼接
                feature_list = np.concatenate((feature_list, face_descriptor), axis=0)
    print("特征加载完毕")
    return feature_list, label_list, name_list</code></pre> 
<pre><code class="language-python"># 人脸识别
def faceRecognize(detector='haar', threshold=0.5, write_video=False, resize_w=700, resize_h=400):
    # 视频时间
    frameTime = time.time()

    # 加载特征
    feature_list, label_list, name_list = getFeatList()

    face_time_dict = {}
    # 保存name,time人脸信息
    face_info_list = []
    # numpy格式人脸图像数据
    face_img_list = []

    # 侦测人数
    person_detect = 0

    # 统计人脸数
    face_count = 0

    # 控制显示打卡成功的时长
    show_time = (frameTime - 10)

    # 考勤记录
    f = open('./data/attendance.csv', 'a')
    csv_writer = csv.writer(f)

    cap = cv2.VideoCapture(0)
    # resize_w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))//2
    # resize_h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)) //2

    videoWriter = cv2.VideoWriter('./record_video/out' + str(time.time()) + '.mp4', cv2.VideoWriter_fourcc(*'MP4V'), 15,
                                  (resize_w, resize_h))

    while True:
        ret, frame = cap.read()
        frame = cv2.resize(frame, (resize_w, resize_h))
        frame = cv2.flip(frame, 1)

        # 切换人脸检测器
        if detector == 'hog':
            face_detetion = hog_face_detector(frame, 1)
        if detector == 'cnn':
            face_detetion = cnn_detector(frame, 1)
        if detector == 'haar':
            frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            face_detetion = haar_face_detector.detectMultiScale(frame_gray, minNeighbors=7, minSize=(100, 100))

        person_detect = len(face_detetion)

        for face in face_detetion:

            l, t, r, b = getDlibRect(detector, face)

            face = dlib.rectangle(l, t, r, b)

            # 识别68个关键点
            points = points_detector(frame, face)

            cv2.rectangle(frame, (l, t), (r, b), (0, 255, 0), 2)

            # 人脸区域
            face_crop = frame[t:b, l:r]

            # 特征
            face_descriptor = face_descriptor_extractor.compute_face_descriptor(frame, points)
            face_descriptor = [f for f in face_descriptor]
            face_descriptor = np.asarray(face_descriptor, dtype=np.float64)

            # 计算距离
            distance = np.linalg.norm((face_descriptor - feature_list), axis=1)
            # 最小距离索引
            min_index = np.argmin(distance)
            # 最小距离
            min_distance = distance[min_index]

            predict_name = "Not recog"

            if min_distance &lt; threshold:
                # 距离小于阈值，表示匹配
                predict_id = label_list[min_index]
                predict_name = name_list[min_index]

                # 判断是否新增记录：如果一个人距上次检测时间&gt;3秒，或者换了一个人，将这条记录插入
                need_insert = False
                now = time.time()
                if predict_name in face_time_dict:
                    if (now - face_time_dict[predict_name]) &gt; 3:
                        # 刷新时间
                        face_time_dict[predict_name] = now
                        need_insert = True
                    else:
                        # 还是上次人脸
                        need_insert = False

                else:
                    # 新增数据记录
                    face_time_dict[predict_name] = now
                    need_insert = True

                if (now - show_time) &lt; 1:
                    frame = cv2AddChineseText(frame, "打卡成功", (l, b + 30), textColor=(0, 255, 0), textSize=40)

                if need_insert:
                    # 连续显示打卡成功1s
                    frame = cv2AddChineseText(frame, "打卡成功", (l, b + 30), textColor=(0, 255, 0), textSize=40)
                    show_time = time.time()

                    time_local = time.localtime(face_time_dict[predict_name])
                    # 转换成新的时间格式(2016-05-05 20:28:54)
                    face_time = time.strftime("%H:%M:%S", time_local)
                    face_time_full = time.strftime("%Y-%m-%d %H:%M:%S", time_local)

                    # 开始位置增加

                    face_info_list.insert(0, [predict_name, face_time])
                    face_img_list.insert(0, face_crop)

                    # 写入考勤表
                    line = [predict_id, predict_name, min_distance, face_time_full]
                    csv_writer.writerow(line)

                    face_count += 1

            # 绘制人脸点
            cv2.putText(frame, predict_name + " " + str(round(min_distance, 2)), (l, b + 30), cv2.FONT_ITALIC, 0.8,
                        (0, 255, 0), 2)

            # 处理下一张脸

        now = time.time()
        fpsText = 1 / (now - frameTime)
        frameTime = now
        # 绘制
        drawLeftInfo(frame, fpsText, 'Recog', detector=detector, person=person_detect, count=face_count)

        # 舍弃face_img_list、face_info_list后部分，节约内存
        if len(face_info_list) &gt; 10:
            face_info_list = face_info_list[:9]
            face_img_list = face_img_list[:9]

        frame = updateRightInfo(frame, face_info_list, face_img_list)

        if write_video:
            videoWriter.write(frame)

        cv2.imshow('Face Attendance Demo: Recognition', frame)
        if cv2.waitKey(10) &amp; 0xFF == ord('q'):
            break

    f.close()
    videoWriter.release()
    cap.release()
    cv2.destroyAllWindows()</code></pre> 
<p>然后效果就和我们宿舍楼下差不多了~ </p> 
<p><img alt="" height="400" src="https://images2.imgbox.com/90/b6/b9ZAxHxT_o.jpg" width="700"></p> 
<p>我年轻的时候，我大概比现在帅个几百倍吧，哎。</p> 
<p></p> 
<h1>二、总代码</h1> 
<p>上文其实把登录和注册最后一部分代码放在一起就是了，这里就不再复制粘贴了，相关权重文件下载链接：<a href="https://github.com/opencv/opencv/tree/master/data" title="opencv/data at master · opencv/opencv · GitHub">opencv/data at master · opencv/opencv · GitHub</a></p> 
<p>懒得下载或者懒得找也可以私信我发你，看见或有时间回。</p> 
<p></p> 
<p>当然本项目还有很多需要优化的地方，比如设置用户不能重复、考勤打卡每天只能一次、把csv改为链接成数据库等等，后续代码优化完成后就可以部署然后和室友**了。</p> 
<p></p>
                </div>

		</div>
	</article>
</main>




			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程小白.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://www.w3counter.com/tracker.js?id=150625"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>
	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>