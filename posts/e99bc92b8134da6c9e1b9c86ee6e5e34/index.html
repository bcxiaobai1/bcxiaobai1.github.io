<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<title>前沿科技探究DeepSQL：库内AI算法 - 编程小白</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程小白" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程小白</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">前沿科技探究DeepSQL：库内AI算法</h1>
			
		</header>
		<div class="content post__content clearfix">
			


                <div id="content_views" class="htmledit_views">
                    <p>数据库DeepSQL特性实现DB4AI功能，即在数据库内实现AI算法，以更好的支撑大数据的快速分析和计算。这里提供了一整套基于SQL的机器学习、数据挖掘以及统计学的算法，用户可以直接使用SQL进行机器学习工作。Deep SQL能够抽象出端到端从数据到模型的研发过程，配合底层的引擎及自动优化，具备基础SQL知识的技术人员即可完成大部分的机器学习模型训练及预测任务。整个分析和处理都运行在数据库引擎中，用户可以直接分析和处理数据库内的数据，不需要在数据库和其它平台之间进行数据传递，避免在多个环境之间进行不必要地数据移动。</p> 
<ul>
<li> <p><strong>概述</strong></p> </li>
<li> <p><strong>环境部署</strong></p> </li>
<li> <p><strong>使用指导</strong></p> </li>
<li> <p><strong>最佳实践</strong></p> </li>
<li> <p><strong>常见问题处理</strong></p> </li>
</ul>
<h1 id="概述-a-name-zh-cn-topic-0300593882-a">一、概述<a name="ZH-CN_TOPIC_0300593882"></a>
</h1> 
<p>DeepSQL是对openGauss DB4AI能力的增强，让对MADLib比较熟悉的数据分析师或开发者可以轻松迁移到openGauss上进行工作。DeepSQL将常用的机器学习算法封装为SQL语句，支持60多个常用算法。其中包括回归算法（例如线性回归，逻辑回归，随机森林等）、分类算法（比如KNN等）、聚类算法（比如K-means）等。除了基础的机器学习算法之外，还包括图相关的算法，比如最短路径，图形直径等等算法；此外还支持数据处理（比如PCA），稀疏向量，统计学常用算法（比如协方差，Pearson系数计算等），训练集测试集分割方法，交叉验证方法等。</p> 
<p><strong>表 1</strong> 支持的机器学习算法 - 回归类算法</p> 
<p><a name="table1794330112214"></a></p> 
<table>
<thead><tr id="row1494103011222">
<th id="mcps1.2.4.1.1"> <p id="p169553092218"><a name="p169553092218"></a>算法中文名称</p> </th>
<th id="mcps1.2.4.1.2"> <p id="p39583014222"><a name="p39583014222"></a>算法英文名称</p> </th>
<th id="mcps1.2.4.1.3"> <p id="p795143042218"><a name="p795143042218"></a>应用场景</p> </th>
</tr></thead>
<tbody>
<tr id="row129512301228">
<td style="vertical-align:top"> <p id="p169593017220"><a name="p169593017220"></a>逻辑回归</p> </td>
<td style="vertical-align:top"> <p id="p1295123062219"><a name="p1295123062219"></a>Logistic Regression</p> </td>
<td style="vertical-align:top"> <p id="p12106913288"><a name="p12106913288"></a>例如寻找某疾病的危险因素，金融商业机构需要对企业进行评估等。</p> <p id="p1471750153017"><a name="p1471750153017"></a>预测：根据模型预测不同的自变量情况下某病或某情况的发生概率。</p> <p id="p11101797280"><a name="p11101797280"></a>判别：实际上跟预测类似，也是根据模型判断某人属于某病或属于某种情况的概率有多大，即判断某人有多大可能是属于某病。</p> </td>
</tr>
<tr id="row19954304220">
<td style="vertical-align:top"> <p id="p199517305227"><a name="p199517305227"></a>Cox比例风险回归</p> </td>
<td style="vertical-align:top"> <p id="p5959307228"><a name="p5959307228"></a>Cox Proportional Hazards Regression</p> </td>
<td style="vertical-align:top"> <p id="p1395143015227"><a name="p1395143015227"></a>该模型以生存结局和生存时间为因变量，可同时分析众多因素对生存期的影响，能分析带有截尾生存时间的资料，且不要求估计资料的生存分布类型。由于上述优良性质，该模型自问世以来，在医学类研究中得到广泛的应用，是迄今生存分析中应用最多的多因素分析方法。</p> </td>
</tr>
<tr id="row19950302221">
<td style="vertical-align:top"> <p id="p49543032219"><a name="p49543032219"></a>弹性网络回归</p> </td>
<td style="vertical-align:top"> <p id="p595163022218"><a name="p595163022218"></a>Elastic Net Regularization</p> </td>
<td style="vertical-align:top"> <p id="p49520308229"><a name="p49520308229"></a>弹性回归是岭回归和套索回归的混合技术，它同时使用 L2 和 L1 正则化。当有多个相关的特征时，套索回归很可能随机选择其中一个，而弹性回归很可能都会选择。</p> </td>
</tr>
<tr id="row99643082210">
<td style="vertical-align:top"> <p id="p2964306229"><a name="p2964306229"></a>广义线性模型</p> </td>
<td style="vertical-align:top"> <p id="p189633042214"><a name="p189633042214"></a>Generalized Linear Models</p> </td>
<td style="vertical-align:top"> <p id="p14961730122210"><a name="p14961730122210"></a>在一些实际问题中，变量间的关系并不都是线性的，这种情况就应该用曲线去进行拟合。</p> </td>
</tr>
<tr id="row696630162212">
<td style="vertical-align:top"> <p id="p2962306221"><a name="p2962306221"></a>边际效应</p> </td>
<td style="vertical-align:top"> <p id="p296143022217"><a name="p296143022217"></a>Marginal Effects</p> </td>
<td style="vertical-align:top"> <p id="p1496153019227"><a name="p1496153019227"></a>提供边际效应的计算。</p> </td>
</tr>
<tr id="row209683011222">
<td style="vertical-align:top"> <p id="p9961130152214"><a name="p9961130152214"></a>多类回归</p> </td>
<td style="vertical-align:top"> <p id="p1896730102219"><a name="p1896730102219"></a>Multinomial Regression</p> </td>
<td style="vertical-align:top"> <p id="p296133011221"><a name="p296133011221"></a>如果目标类别数超过两个，这时就需要使用多类回归，如疗效可能是“无效”，“显效”，“痊愈”三类。</p> </td>
</tr>
<tr id="row1296193022217">
<td style="vertical-align:top"> <p id="p1296113022217"><a name="p1296113022217"></a>序数回归</p> </td>
<td style="vertical-align:top"> <p id="p7969307224"><a name="p7969307224"></a>Ordinal Regression</p> </td>
<td style="vertical-align:top"> <p id="p59743019228"><a name="p59743019228"></a>在统计学中，序数回归是一种用于预测序数变量的回归分析，即其值存在于任意范围内的变量，不同值之间的度量距离也不同。它可以被认为是介于回归和分类之间的一类问题。例如，病情的分级（1、2、3、4级），症状的感觉分级（不痛、微痛、较痛和剧痛），对药物剂量反应的分级（无效、微效、中效和高效）等等。不同级别之间的差异不一定相等，如不痛与微痛的差值不一定等于较痛与剧痛的差值。</p> </td>
</tr>
<tr id="row1175543110251">
<td style="vertical-align:top"> <p id="p197565312259"><a name="p197565312259"></a>聚类方差</p> </td>
<td style="vertical-align:top"> <p id="p475618318256"><a name="p475618318256"></a>Clustered Variance</p> </td>
<td style="vertical-align:top"> <p id="p1175673162515"><a name="p1175673162515"></a>Clustered Variance模块调整聚类的标准误差。例如，将一个数据集合复制100次，不应该增加参数估计的精度，但是在符合独立同分布假设（Independent Identically Distributed，IID）下执行这个过程实际上会提高精度。</p> </td>
</tr>
<tr id="row184031335122518">
<td style="vertical-align:top"> <p id="p1540483514253"><a name="p1540483514253"></a>稳健方差</p> </td>
<td style="vertical-align:top"> <p id="p194046356251"><a name="p194046356251"></a>Robust Variance</p> </td>
<td style="vertical-align:top"> <p id="p24041635122515"><a name="p24041635122515"></a>Robust Variance模块中的函数用于计算线性回归、逻辑回归、多类逻辑回归和Cox比例风险回归的稳健方差（Huber-White估计）。它们可用于计算具有潜在噪声异常值的数据集中数据的差异。</p> </td>
</tr>
<tr id="row1293444012256">
<td style="vertical-align:top"> <p id="p1993516408256"><a name="p1993516408256"></a>支持向量机</p> </td>
<td style="vertical-align:top"> <p id="p8935540142519"><a name="p8935540142519"></a>Support Vector Machines(SVM)</p> </td>
<td style="vertical-align:top"> <p id="p29631481307"><a name="p29631481307"></a>用于文本和超文本的分类、图像分类，比起传统的查询优化方案，支持向量机能够获取明显更高的搜索准确度。这同样也适用于图像分割系统。</p> </td>
</tr>
<tr id="row13892174622516">
<td style="vertical-align:top"> <p id="p889284610252"><a name="p889284610252"></a>线性回归</p> </td>
<td style="vertical-align:top"> <p id="p889215469259"><a name="p889215469259"></a>Linear Regression</p> </td>
<td style="vertical-align:top"> <p id="p1889294692517"><a name="p1889294692517"></a>应用广泛，例如经济学、金融学等。</p> </td>
</tr>
</tbody>
</table>
<p></p> 
<p><strong>表 2</strong> 支持的机器学习算法 - 其他监督学习</p> 
<p><a name="table185531692118"></a></p> 
<table>
<thead><tr id="row8553560216">
<th> <p id="p364762072111"><a name="p364762072111"></a>算法名称（中文）</p> </th>
<th> <p id="p764772052117"><a name="p764772052117"></a>算法名称（英文）</p> </th>
<th> <p id="p1664702092111"><a name="p1664702092111"></a>应用场景</p> </th>
</tr></thead>
<tbody>
<tr id="row145532692113">
<td style="vertical-align:top"> <p id="p7553664212"><a name="p7553664212"></a>决策树</p> </td>
<td style="vertical-align:top"> <p id="p2055318652113"><a name="p2055318652113"></a>Decision Tree</p> </td>
<td style="vertical-align:top"> <p id="p0553126132113"><a name="p0553126132113"></a>最为广泛的归纳推理算法之一，处理类别型或连续型变量的分类预测问题，可以用图形和if-then的规则表示模型，可读性较高。</p> </td>
</tr>
<tr id="row185532612214">
<td style="vertical-align:top"> <p id="p65531469212"><a name="p65531469212"></a>随机森林</p> </td>
<td style="vertical-align:top"> <p id="p35531363219"><a name="p35531363219"></a>Random Forest</p> </td>
<td style="vertical-align:top"> <p id="p45531766218"><a name="p45531766218"></a>随机森林是一类专门为决策树分类器设计的组合方法。它组合多棵决策树作出的预测。</p> </td>
</tr>
<tr id="row115546662119">
<td style="vertical-align:top"> <p id="p55541682116"><a name="p55541682116"></a>条件随机场</p> </td>
<td style="vertical-align:top"> <p id="p1655416112114"><a name="p1655416112114"></a>Conditional Random Field (CRF)</p> </td>
<td style="vertical-align:top"> <p id="p1555416617212"><a name="p1555416617212"></a>条件随机场（CRF）是一种判别的，无向概率的图形模型。线性链CRF是一种特殊类型的CRF，它假定当前状态仅取决于先前的状态。在分词、词性标注和命名实体识别等序列标注任务中取得了很好的效果。</p> </td>
</tr>
<tr id="row7554166102116">
<td style="vertical-align:top"> <p id="p125541769218"><a name="p125541769218"></a>朴素贝叶斯</p> </td>
<td style="vertical-align:top"> <p id="p1055486132118"><a name="p1055486132118"></a>Naive Bayes</p> </td>
<td style="vertical-align:top"> <p id="p55547617215"><a name="p55547617215"></a>通过计算概率来进行分类，可以用来处理多分类问题，比如：垃圾邮件过滤器。</p> </td>
</tr>
<tr id="row1554561212">
<td style="vertical-align:top"> <p id="p2554136142117"><a name="p2554136142117"></a>神经网络</p> </td>
<td style="vertical-align:top"> <p id="p195549692118"><a name="p195549692118"></a>Neural Networks</p> </td>
<td style="vertical-align:top"> <p id="p1855419632112"><a name="p1855419632112"></a>拥有广泛的应用场景，譬如语音识别、图像识别、机器翻译等等。在模式识别的领域中算是标准监督学习算法，并在计算神经学中，持续成为被研究的课题。MLP已被证明是一种通用的函数近似方法，可以被用来拟合复杂的函数或解决分类问题。</p> </td>
</tr>
<tr id="row10554186202111">
<td style="vertical-align:top"> <p id="p185546682110"><a name="p185546682110"></a>k临近算法</p> </td>
<td style="vertical-align:top"> <p id="p955411672118"><a name="p955411672118"></a>k-Nearest Neighbors</p> </td>
<td style="vertical-align:top"> <p id="p16649165416515"><a name="p16649165416515"></a>K近邻分类方法通过计算每个训练样例到待分类样品的距离，取和待分类样品距离最近的K个训练样例，K个样品中哪个类别的训练样例占多数，则待分类元组就属于哪个类别。</p> <p id="p1655476152119"><a name="p1655476152119"></a>可用于：文字识别，面部识别，基因模式识别，客户流失预测、欺诈侦测。</p> </td>
</tr>
</tbody>
</table>
<p></p> 
<p><strong>表 3</strong> 支持的机器学习算法 - 数据处理类算法</p> 
<p><a name="table89836408312"></a></p> 
<table>
<thead><tr id="row14983174033118">
<th> <p id="p1528823212322"><a name="p1528823212322"></a>算法名称（中文）</p> </th>
<th> <p id="p8288183233219"><a name="p8288183233219"></a>算法名称（英文）</p> </th>
<th> <p id="p1528833233211"><a name="p1528833233211"></a>应用场景</p> </th>
</tr></thead>
<tbody>
<tr id="row15983144033117">
<td style="vertical-align:top"> <p id="p14984164013110"><a name="p14984164013110"></a>数组操作</p> </td>
<td style="vertical-align:top"> <p id="p1498412404315"><a name="p1498412404315"></a>Array Operations</p> </td>
<td style="vertical-align:top"> <p id="p3156332123714"><a name="p3156332123714"></a>数组、向量操作运算，包括基础的加减乘除、幂运算、开方、cos、sin、绝对值、方差等。</p> </td>
</tr>
<tr id="row1698419401319">
<td style="vertical-align:top"> <p id="p1760602703311"><a name="p1760602703311"></a>主成成分分析</p> </td>
<td style="vertical-align:top"> <p id="p132357253332"><a name="p132357253332"></a>Dimensionality Reduction (PCA)</p> </td>
<td style="vertical-align:top"> <p id="p2098413406315"><a name="p2098413406315"></a>降维，计算主成分。</p> </td>
</tr>
<tr id="row1998424015319">
<td style="vertical-align:top"> <p id="p8984114043118"><a name="p8984114043118"></a>变量编码</p> </td>
<td style="vertical-align:top"> <p id="p79841740183110"><a name="p79841740183110"></a>Encoding Categorical Variables</p> </td>
<td style="vertical-align:top"> <p id="p64018265314"><a name="p64018265314"></a>当前支持one-hot和dummy编码技术。</p> <p id="p815911224375"><a name="p815911224375"></a>当需要用一组特定的预测变量与其它预测变量组作比较时，通常使用哑编码（dummy coding），与之比较的变量组称为参照组。One-hot编码与哑编码类似，两者的区别是前者为每种分类值建立数字类型的0/1指示列。在每行数据中（对应一个数据点），只有一个分类编码列的值可以为1。</p> </td>
</tr>
<tr id="row8984124012314">
<td style="vertical-align:top"> <p id="p1698434014311"><a name="p1698434014311"></a>矩阵操作</p> </td>
<td style="vertical-align:top"> <p id="p498414403313"><a name="p498414403313"></a>Matrix Operations</p> </td>
<td style="vertical-align:top"> <p id="p117551051388"><a name="p117551051388"></a>运用矩阵分解，将大型矩阵分解成简单矩阵的乘积形式，则可大大降低计算的难度以及计算量。</p> <p id="p8984194016313"><a name="p8984194016313"></a>矩阵加减乘除、最值、均值、求秩、求逆、矩阵分解(QR，LU，Cholesky)，特征提取。</p> </td>
</tr>
<tr id="row169845404312">
<td style="vertical-align:top"> <p id="p8984154012311"><a name="p8984154012311"></a>规范化和距离函数</p> </td>
<td style="vertical-align:top"> <p id="p7984104011317"><a name="p7984104011317"></a>Norms and Distance Functions</p> </td>
<td style="vertical-align:top"> <p id="p898434083114"><a name="p898434083114"></a>求范数，余弦相似度，向量间距离。</p> </td>
</tr>
<tr id="row798484016316">
<td style="vertical-align:top"> <p id="p29841540163116"><a name="p29841540163116"></a>稀疏向量</p> </td>
<td style="vertical-align:top"> <p id="p998417403315"><a name="p998417403315"></a>Sparse Vectors</p> </td>
<td style="vertical-align:top"> <p id="p2984740173113"><a name="p2984740173113"></a>实现稀疏向量类型，如果向量中重复值较多，可以用来压缩储存节省空间。</p> </td>
</tr>
<tr id="row10608101717341">
<td style="vertical-align:top"> <p id="p16609517123412"><a name="p16609517123412"></a>透视图</p> </td>
<td style="vertical-align:top"> <p id="p11609161763412"><a name="p11609161763412"></a>Pivot</p> </td>
<td style="vertical-align:top"> <p id="p360912171342"><a name="p360912171342"></a>透视表或枢轴表，通常用来实现OLAP或报表系统中一类常见的行列转置需求。pivot函数能够对一个表中存储的数据执行基本行转列操作，并将汇总后的结果输出到另一个表中。使行列转置操作变得更为简单与灵活。</p> </td>
</tr>
<tr id="row1329632115341">
<td style="vertical-align:top"> <p id="p12296821193415"><a name="p12296821193415"></a>模式匹配</p> </td>
<td style="vertical-align:top"> <p id="p18296192123413"><a name="p18296192123413"></a>Path</p> </td>
<td style="vertical-align:top"> <p id="p14296152120348"><a name="p14296152120348"></a>是在一系列行上执行常规模式匹配，并提取有关模式匹配的有用信息。有用的信息可以是简单的匹配计数或更多涉及的内容，如聚合或窗口函数。</p> </td>
</tr>
<tr id="row151090259343">
<td style="vertical-align:top"> <p id="p131102025113418"><a name="p131102025113418"></a>会话</p> </td>
<td style="vertical-align:top"> <p id="p1111052583410"><a name="p1111052583410"></a>Sessionize</p> </td>
<td style="vertical-align:top"> <p id="p18110172514343"><a name="p18110172514343"></a>会话化功能对包括事件序列的数据集执行面向时间的会话重建。定义的不活动时段表示一个会话的结束和下一个会话的开始。</p> <p id="p515116125361"><a name="p515116125361"></a>可以用于：网络分析，网络安全，制造，财务和运营分析。</p> </td>
</tr>
<tr id="row2093316281346">
<td style="vertical-align:top"> <p id="p1493382812344"><a name="p1493382812344"></a>共轭梯度法</p> </td>
<td style="vertical-align:top"> <p id="p17933128143417"><a name="p17933128143417"></a>Conjugate gradient</p> </td>
<td style="vertical-align:top"> <p id="p1693316288345"><a name="p1693316288345"></a>求解系数矩阵为对称正定矩阵的线性方程组的数值解的方法。</p> </td>
</tr>
<tr id="row1729361183519">
<td style="vertical-align:top"> <p id="p1429371115353"><a name="p1429371115353"></a>词干提取</p> </td>
<td style="vertical-align:top"> <p id="p1129311115354"><a name="p1129311115354"></a>Stemming</p> </td>
<td style="vertical-align:top"> <p id="p19162185615359"><a name="p19162185615359"></a>词干提取简单说就是找出单词中的词干部分，场景比如：搜索引擎建立网页主题概念。</p> <p id="p71621256143516"><a name="p71621256143516"></a>在英文网站优化作用明显，对其他语言有借鉴意义。</p> </td>
</tr>
<tr id="row1682012617407">
<td style="vertical-align:top"> <p id="p14820726134013"><a name="p14820726134013"></a>训练集测试集分割</p> </td>
<td style="vertical-align:top"> <p id="p17820182694013"><a name="p17820182694013"></a>Train-Test Split</p> </td>
<td style="vertical-align:top"> <p id="p4820626184014"><a name="p4820626184014"></a>分割数据集，把一份数据集划分成训练集和测试集，train的部分用于训练，test部分用于验证。</p> </td>
</tr>
<tr id="row234813317406">
<td style="vertical-align:top"> <p id="p123485338405"><a name="p123485338405"></a>交叉验证</p> </td>
<td style="vertical-align:top"> <p id="p63481336407"><a name="p63481336407"></a>Cross Validation</p> </td>
<td style="vertical-align:top"> <p id="p53485334407"><a name="p53485334407"></a>交叉验证。</p> </td>
</tr>
<tr id="row33451640204013">
<td style="vertical-align:top"> <p id="p19345124024014"><a name="p19345124024014"></a>预测指标</p> </td>
<td style="vertical-align:top"> <p id="p93456402401"><a name="p93456402401"></a>Prediction Metrics</p> </td>
<td style="vertical-align:top"> <p id="p53451240114016"><a name="p53451240114016"></a>用于评估模型预测的质量，包括均方误差，AUC值、混淆矩阵、修正R方等用于评价模型的函数。</p> </td>
</tr>
<tr id="row161046303404">
<td style="vertical-align:top"> <p id="p51051930144010"><a name="p51051930144010"></a>小批量预处理</p> </td>
<td style="vertical-align:top"> <p id="p310512304406"><a name="p310512304406"></a>Mini-Batch Preprocessor</p> </td>
<td style="vertical-align:top"> <p id="p81054304400"><a name="p81054304400"></a>把数据打包成小份进行训练，优点是它可以比随机梯度下降（默认MADlib优化器）表现更好，会更快更平滑的收敛。</p> </td>
</tr>
</tbody>
</table>
<p></p> 
<p><strong>表 4</strong> 支持的机器学习算法 - 图类</p> 
<p><a name="table153361051113913"></a></p> 
<table>
<thead><tr id="row12336195118399">
<th> <p id="p1393095814413"><a name="p1393095814413"></a>算法名称（中文）</p> </th>
<th> <p id="p993095816416"><a name="p993095816416"></a>算法名称（英文）</p> </th>
<th> <p id="p49301758104113"><a name="p49301758104113"></a>应用场景</p> </th>
</tr></thead>
<tbody>
<tr id="row433795114393">
<td style="vertical-align:top"> <p id="p14337185113910"><a name="p14337185113910"></a>所有对间最短路径</p> </td>
<td style="vertical-align:top"> <p id="p43377511396"><a name="p43377511396"></a>All Pairs Shortest Path (APSP)</p> </td>
<td style="vertical-align:top"> <p id="p233710512394"><a name="p233710512394"></a>所有对最短路径（APSP）算法找到所有顶点对之间的最短路径的长度（总和权重），使得路径边缘的权重之和最小化。</p> </td>
</tr>
<tr id="row43378512398">
<td style="vertical-align:top"> <p id="p1333711516395"><a name="p1333711516395"></a>广度优先算法</p> </td>
<td style="vertical-align:top"> <p id="p163371951143912"><a name="p163371951143912"></a>Breadth-First Search</p> </td>
<td style="vertical-align:top"> <p id="p9337165113399"><a name="p9337165113399"></a>广度优先算法遍历路径。</p> </td>
</tr>
<tr id="row1733745163920">
<td style="vertical-align:top"> <p id="p3337351193911"><a name="p3337351193911"></a>超链接诱导主题搜索</p> </td>
<td style="vertical-align:top"> <p id="p10337651203911"><a name="p10337651203911"></a>Hyperlink-Induced Topic Search (HITS)</p> </td>
<td style="vertical-align:top"> <p id="p8337951133920"><a name="p8337951133920"></a>HITS算法输出每个节点的authority评分和hub评分，其中authority评分给出页面内容的分数，hub评估出连接到其他页面的分数。</p> </td>
</tr>
<tr id="row233795111392">
<td style="vertical-align:top"> <p id="p63371519398"><a name="p63371519398"></a>平均路径长度</p> </td>
<td style="vertical-align:top"> <p id="p193372051143919"><a name="p193372051143919"></a>Average Path Length</p> </td>
<td style="vertical-align:top"> <p id="p153379516399"><a name="p153379516399"></a>此函数计算每对顶点之间的最短路径的平均值。平均路径长度基于“可到达的目标顶点”，因此它忽略了未连接的顶点之间的无限长度路径。</p> </td>
</tr>
<tr id="row33377515395">
<td style="vertical-align:top"> <p id="p1033745193918"><a name="p1033745193918"></a>中心性</p> </td>
<td style="vertical-align:top"> <p id="p033795133914"><a name="p033795133914"></a>Closeness Centrality</p> </td>
<td style="vertical-align:top"> <p id="p4337125119393"><a name="p4337125119393"></a>接近度度量是和的倒数，平均值的倒数，以及到所有可到达目标顶点（不包括源顶点）的最短距离的倒数之和。</p> </td>
</tr>
<tr id="row1434018144313">
<td style="vertical-align:top"> <p id="p934011113439"><a name="p934011113439"></a>图表直径</p> </td>
<td style="vertical-align:top"> <p id="p16340517432"><a name="p16340517432"></a>Graph Diameter</p> </td>
<td style="vertical-align:top"> <p id="p234051174318"><a name="p234051174318"></a>直径被定义为图中所有最短路径中最长的。</p> </td>
</tr>
<tr id="row431674134313">
<td style="vertical-align:top"> <p id="p13164414431"><a name="p13164414431"></a>入度出度</p> </td>
<td style="vertical-align:top"> <p id="p13316443433"><a name="p13316443433"></a>In-Out Degree</p> </td>
<td style="vertical-align:top"> <p id="p531684154317"><a name="p531684154317"></a>计算图中每个点的入度出度，入度指指向此点的边的数量，出度指此点指向其他点的边的数量。</p> </td>
</tr>
<tr id="row177383615431">
<td style="vertical-align:top"> <p id="p127383684315"><a name="p127383684315"></a>网页排名</p> </td>
<td style="vertical-align:top"> <p id="p1673846154317"><a name="p1673846154317"></a>PageRank</p> </td>
<td style="vertical-align:top"> <p id="p37386624320"><a name="p37386624320"></a>给定图形，给定图形，PageRank算法输出概率分布，该概率分布表示随机遍历图形的人将到达任何特定顶点的可能性。</p> </td>
</tr>
<tr id="row18338199184312">
<td style="vertical-align:top"> <p id="p153383934313"><a name="p153383934313"></a>单源最短路径</p> </td>
<td style="vertical-align:top"> <p id="p133386924310"><a name="p133386924310"></a>Single Source Shortest Path (SSSP)</p> </td>
<td style="vertical-align:top"> <p id="p14392818165112"><a name="p14392818165112"></a>给定图形和源顶点，单源最短路径（SSSP）算法找到从源顶点到图中的每个其他顶点的路径，使得路径边缘的权重之和最小化（每条边权值非负）。</p> </td>
</tr>
<tr id="row1412412204314">
<td style="vertical-align:top"> <p id="p5126126438"><a name="p5126126438"></a>弱连通分量</p> </td>
<td style="vertical-align:top"> <p id="p18121412114313"><a name="p18121412114313"></a>Weakly Connected Component</p> </td>
<td style="vertical-align:top"> <p id="p1712161234314"><a name="p1712161234314"></a>给定有向图，弱连通分量（WCC）是原始图的子图，其中所有顶点通过某个路径彼此连接，忽略边的方向。在无向图的情况下，弱连通分量也是强连通分量。该模块还包括许多在WCC输出上运行的辅助函数。</p> </td>
</tr>
</tbody>
</table>
<p></p> 
<p><strong>表 5</strong> 支持的机器学习算法 - 时间序列</p> 
<p><a name="table10752114512562"></a></p> 
<table>
<thead><tr id="row9752114535615">
<th> <p id="p4752204515617"><a name="p4752204515617"></a>算法名称（中文）</p> </th>
<th> <p id="p1675274512569"><a name="p1675274512569"></a>算法名称（英文）</p> </th>
<th> <p id="p18752174515617"><a name="p18752174515617"></a>应用场景</p> </th>
</tr></thead>
<tbody><tr id="row15752045115610">
<td style="vertical-align:top"> <p id="p187521845145611"><a name="p187521845145611"></a>差分整合移动平均自回归模型</p> </td>
<td style="vertical-align:top"> <p id="p187521845175611"><a name="p187521845175611"></a>Autoregressive Integrated Moving Average model(ARIMA)</p> </td>
<td style="vertical-align:top"> <p id="p18752114512568"><a name="p18752114512568"></a>时间序列预测，用于理解和预测一系列数据的未来值。</p> <p id="p4810153919572"><a name="p4810153919572"></a>比如：国际航空旅客数据，预测旅客人数。</p> </td>
</tr></tbody>
</table>
<p></p> 
<p><strong>表 6</strong> 支持的机器学习算法 - 采样</p> 
<p><a name="table4800126141316"></a></p> 
<table>
<thead><tr id="row780092601311">
<th> <p id="p270284991312"><a name="p270284991312"></a>算法名称（中文）</p> </th>
<th> <p id="p970204991315"><a name="p970204991315"></a>算法名称（英文）</p> </th>
<th> <p id="p1870220498133"><a name="p1870220498133"></a>应用场景</p> </th>
</tr></thead>
<tbody>
<tr id="row58001226111315">
<td style="vertical-align:top"> <p id="p4800426101312"><a name="p4800426101312"></a>采样函数</p> </td>
<td style="vertical-align:top"> <p id="p380042671315"><a name="p380042671315"></a>sample</p> </td>
<td style="vertical-align:top"> <p id="p1780012264134"><a name="p1780012264134"></a>抽样。</p> </td>
</tr>
<tr id="row1480019264138">
<td style="vertical-align:top"> <p id="p1480062616135"><a name="p1480062616135"></a>分层抽样</p> </td>
<td style="vertical-align:top"> <p id="p98001026101316"><a name="p98001026101316"></a>Stratified Sampling</p> </td>
<td style="vertical-align:top"> <p id="p17323133614159"><a name="p17323133614159"></a>分层随机抽样，又称类型随机抽样，它是先将总体各单位按一定标准分成各种类型（或层）；然后根据各类型单位数与总体单位数的比例，确定从各类型中抽取样本单位的数量；最后，按照随机原则从各类型中抽取样本。</p> </td>
</tr>
<tr id="row1080142613137">
<td style="vertical-align:top"> <p id="p1580113262134"><a name="p1580113262134"></a>对称抽样</p> </td>
<td style="vertical-align:top"> <p id="p880162661316"><a name="p880162661316"></a>Balanced Sampling</p> </td>
<td style="vertical-align:top"> <p id="p680112601318"><a name="p680112601318"></a>一些分类算法仅在每个类中的样本数大致相同时才最佳地执行。高度偏斜的数据集在许多领域中是常见的（例如，欺诈检测），因此重新采样以抵消这种不平衡可以产生更好的决策边界。</p> </td>
</tr>
</tbody>
</table>
<p></p> 
<p><strong>表 7</strong> 支持的机器学习算法 - 统计学</p> 
<p><a name="table1560264413152"></a></p> 
<table>
<thead><tr id="row2603154410159">
<th> <p id="p17335719121813"><a name="p17335719121813"></a>算法名称（中文）</p> </th>
<th> <p id="p73351019111812"><a name="p73351019111812"></a>算法名称（英文）</p> </th>
<th> <p id="p15335131913186"><a name="p15335131913186"></a>应用场景</p> </th>
</tr></thead>
<tbody>
<tr id="row66033448158">
<td style="vertical-align:top"> <p id="p46039440152"><a name="p46039440152"></a>汇总统计函数</p> </td>
<td style="vertical-align:top"> <p id="p3603174441512"><a name="p3603174441512"></a>Summary</p> </td>
<td style="vertical-align:top"> <p id="p8603184414157"><a name="p8603184414157"></a>生成任何数据表的摘要统计信息。</p> </td>
</tr>
<tr id="row460324491519">
<td style="vertical-align:top"> <p id="p760310444157"><a name="p760310444157"></a>协方差和相关系数</p> </td>
<td style="vertical-align:top"> <p id="p186031544171516"><a name="p186031544171516"></a>Correlation and Covariance</p> </td>
<td style="vertical-align:top"> <p id="p5603244161512"><a name="p5603244161512"></a>描述性统计，求Pearson系数，相关系数，另一个输出协方差。了解数据从统计学上反映的量的特征，以便我们更好地认识这些将要被挖掘的数据。</p> </td>
</tr>
<tr id="row760364412158">
<td style="vertical-align:top"> <p id="p460312442152"><a name="p460312442152"></a>统计频率算法</p> </td>
<td style="vertical-align:top"> <p id="p12603154411156"><a name="p12603154411156"></a>CountMin (Cormode-Muthukrishnan)</p> </td>
<td style="vertical-align:top"> <p id="p15603114491515"><a name="p15603114491515"></a>统计一个实时的数据流中元素出现的频率，并且准备随时回答某个元素出现的频率，不需要的精确的计数。</p> </td>
</tr>
<tr id="row7603344191510">
<td style="vertical-align:top"> <p id="p14603134491511"><a name="p14603134491511"></a>基数估计算法</p> </td>
<td style="vertical-align:top"> <p id="p166031244171517"><a name="p166031244171517"></a>FM (Flajolet-Martin)</p> </td>
<td style="vertical-align:top"> <p id="p1760344461511"><a name="p1760344461511"></a>获取指定列中的不同值的数量。 找出这个数字集合中不重复的数字的个数。</p> </td>
</tr>
<tr id="row2603174413154">
<td style="vertical-align:top"> <p id="p26039443156"><a name="p26039443156"></a>最频繁值</p> </td>
<td style="vertical-align:top"> <p id="p1603194431510"><a name="p1603194431510"></a>MFV (Most Frequent Values)</p> </td>
<td style="vertical-align:top"> <p id="p46039446153"><a name="p46039446153"></a>计算频繁值的场景。</p> </td>
</tr>
<tr id="row5603174416151">
<td style="vertical-align:top"> <p id="p12603154431512"><a name="p12603154431512"></a>假设检验</p> </td>
<td style="vertical-align:top"> <p id="p1860434412155"><a name="p1860434412155"></a>Hypothesis Tests</p> </td>
<td style="vertical-align:top"> <p id="p46042445154"><a name="p46042445154"></a>包含F-test，chi2-test等。</p> </td>
</tr>
<tr id="row16194141361910">
<td style="vertical-align:top"> <p id="p9195613111915"><a name="p9195613111915"></a>概率函数</p> </td>
<td style="vertical-align:top"> <p id="p191951313111920"><a name="p191951313111920"></a>Probability Functions</p> </td>
<td style="vertical-align:top"> <p id="p16195171313199"><a name="p16195171313199"></a>概率函数模块为各种概率分布提供累积分布，密度、质量和分位数函数。</p> </td>
</tr>
</tbody>
</table>
<p></p> 
<p><strong>表 8</strong> 支持的机器学习算法 - 其他算法</p> 
<p><a name="table910801142712"></a></p> 
<table>
<thead><tr id="row01086112717">
<th> <p id="p6196614275"><a name="p6196614275"></a>算法名称（中文）</p> </th>
<th> <p id="p14195616278"><a name="p14195616278"></a>算法名称（英文）</p> </th>
<th> <p id="p8191569273"><a name="p8191569273"></a>应用场景</p> </th>
</tr></thead>
<tbody>
<tr id="row181081710279">
<td style="vertical-align:top"> <p id="p101084117276"><a name="p101084117276"></a>k-聚类算法</p> </td>
<td style="vertical-align:top"> <p id="p71081811279"><a name="p71081811279"></a>K-means</p> </td>
<td style="vertical-align:top"> <p id="p110831182710"><a name="p110831182710"></a>聚类场景。</p> </td>
</tr>
<tr id="row1610820182713">
<td style="vertical-align:top"> <p id="p410917118277"><a name="p410917118277"></a>隐含狄利克雷分布</p> </td>
<td style="vertical-align:top"> <p id="p15109171192711"><a name="p15109171192711"></a>Latent Dirichlet Allocation (LDA)</p> </td>
<td style="vertical-align:top"> <p id="p1310915110276"><a name="p1310915110276"></a>LDA 在主题模型中占有非常重要的地位，常用来文本分类。</p> </td>
</tr>
<tr id="row7109411278">
<td style="vertical-align:top"> <p id="p910919132719"><a name="p910919132719"></a>关联规则算法</p> </td>
<td style="vertical-align:top"> <p id="p1510918116272"><a name="p1510918116272"></a>Apriori Algorithm</p> </td>
<td style="vertical-align:top"> <p id="p10109514274"><a name="p10109514274"></a>关联规则算法，关联规则挖掘的目标是发现数据项集之间的关联关系。比如经典的“啤酒和尿布”。</p> </td>
</tr>
</tbody>
</table>
<p> </p> 
<h1 id="环境部署-a-name-zh-cn-topic-0300593883-a">二、环境部署<a name="ZH-CN_TOPIC_0300593883"></a>
</h1> 
<p>DeepSQL环境包括编译数据库和安装算法库两个部分。</p> 
<h2 id="前提条件-a-name-section9205152617372-a">前提条件<a name="section9205152617372"></a>
</h2> 
<ul>
<li>环境中安装python2.7.12以上版本Python。</li>
<li>数据库需要开启对PL/Python存储过程的支持。</li>
<li>安装算法库需要拥有管理员权限的用户。</li>
</ul>
<h2 id="操作步骤-a-name-section1262314198407-a">操作步骤<a name="section1262314198407"></a>
</h2> 
<ol>
<li> <p>检查部署Python环境。</p> <p>安装前，请查看系统安装的python版本，当前DeepSQL需要python2.7.12以上版本的环境。</p> 
  <ul>
<li>如果当前系统python2版本高于2.7.12，可以直接安装python-devel包。</li>
<li>如果版本过低，或者无法安装python-devel包，可以下载最新python2源码，手动配置编译python2，并配置环境变量。</li>
</ul>
<p>算法库中，部分算法调用了python包，如numpy，pandas等。用户可以安装以下python库：</p> <pre>
<code>pip install numpy
pip install pandas
pip install scipy
</code></pre> 
  <blockquote> 
   <p><img alt="" src="https://images2.imgbox.com/d1/94/3xahL6CZ_o.gif"> <strong>须知：</strong>  </p> 
   <ul>
<li> <p>如果自行编译python，需要在<strong>configure</strong>脚本执行时加入<strong>–enable-shared</strong>参数。</p> </li>
<li> <p>如果系统中的python2使用的是UCS4编码，自行编译python2时，还需要加入<strong>–enable-unicode=ucs4</strong>参数。</p> </li>
<li> <p>可以在系统中自带的python2下执行：“import sys；print sys.maxunicode”并查看结果，如果结果是65535，说明系统默认的是ucs2；如果结果是1114111，说明用的ucs4编码。</p> </li>
<li> <p>如果系统中内置的python2使用的ucs4，说明系统中的gdb，gstack等也会依赖ucs4。因此自行编译的python2在configure时，需要添加–enable-unicode=ucs4，否则后续使用gdb，gstack时，会遇到报错。</p> </li>
</ul>
  </blockquote> </li>
<li> <p>编译部署数据库。</p> <p>数据库需要开启对PL/Python存储过程的支持。默认编译数据库，不包含此模块。因此需要编译数据库时，在configure阶段，加入--with-python参数；</p> <p>其他编译保持步骤不变；</p> <p>编译完成后，需要重新gs_initdb；</p> <p>默认PL/Python存储过程模块不被加载，请执行“CREATE EXTENSION plpythonu”来加载模块。</p> </li>
<li> <p>算法库编译和安装。</p> <p>算法库使用开源的MADlib机器学习框架。源码包和相应patch可以从第三方库的代码仓库里获取。安装命令如下：</p> <pre>
<code>tar -zxf apache-madlib-1.17.0-src.tar.gz
cp madlib.patch apache-madlib-1.17.0-src           
cd apache-madlib-1.17.0-src/
patch -p1 &lt; madlib.patch
</code></pre> <p>编译命令如下：<br><code>./configure -DCMAKE_INSTALL_PREFIX={YOUR_MADLIB_INSTALL_FOLDER} -DPOSTGRESQL_EXECUTABLE=$GAUSSHOME/bin/ -DPOSTGRESQL_9_2_EXECUTABLE=$GAUSSHOME/bin/ -DPOSTGRESQL_9_2_CLIENT_INCLUDE_DIR=$GAUSSHOME/bin/ -DPOSTGRESQL_9_2_SERVER_INCLUDE_DIR=$GAUSSHOME/bin/ # 以上均为configure命令。 make make install </code></p> <p>其中， {YOUR_MADLIB_INSTALL_FOLDER}需要改为用户的实际安装路径。</p> 
  <blockquote> 
   <p style="text-align:center"><strong><img alt="" src="https://images2.imgbox.com/65/9e/k4b1TV6T_o.gif">须知：</strong> 编译MADlib时，会联网下载依赖软件。无法联网时，需要手动下载依赖包“PyXB-1.2.6.tar.gz”，“eigen-branches-3.2.tar.gz”和“boost_1_61_0.tar.gz”放在本地。使用的configure命令如下： </p> 
   <pre>复制代码<code>./configure -DCMAKE_INSTALL_PREFIX={YOUR_MADLIB_INSTALL_FOLDER}                  # your install folder
-DPYXB_TAR_SOURCE={YOUR_DEPENDENCY_FOLDER}/PyXB-1.2.6.tar.gz                     # change to your local folder
-DEIGEN_TAR_SOURCE={YOUR_DEPENDENCY_FOLDER}/eigen-branches-3.2.tar.gz      # change to your local folder
-DBOOST_TAR_SOURCE={YOUR_DEPENDENCY_FOLDER}/boost_1_61_0.tar.gz              # change to your local folder
-DPOSTGRESQL_EXECUTABLE=$GAUSSHOME/bin/
-DPOSTGRESQL_9_2_EXECUTABLE=$GAUSSHOME/bin/
-DPOSTGRESQL_9_2_CLIENT_INCLUDE_DIR=$GAUSSHOME/bin/
-DPOSTGRESQL_9_2_SERVER_INCLUDE_DIR=$GAUSSHOME/bin/
</code></pre> 
  </blockquote> </li>
<li> <p>将算法库安装到数据库中。</p> </li>
</ol>
<p>a.进入{YOUR_MADLIB_INSTALL_FOLDER}路径。</p> 
<p>b.进入bin文件夹。</p> 
<p>c.执行如下命令。</p> 
<pre>
<code>   ./madpack -s &lt;SCHEMA_NAME&gt; -p opengauss -c &lt;USER_NAME&gt;@127.0.0.1:&lt;PORT&gt;/&lt;DATABASE_NAME&gt; install
</code></pre> 
<p>命令中参数说明如下：</p> 
<ul>
<li>-s：schema的名称。</li>
<li>-p：数据库平台，使用opengauss即可。</li>
<li>-c：连接数据库的参数。包括用户名、‘@’、IP地址、端口号和目标数据库名称。</li>
</ul>
<p>install为安装的命令，除此之外，还有reinstall（重新安装），uninstall（卸载）等命令可用。</p> 
<blockquote> 
 <p> <img alt="" src="https://images2.imgbox.com/b6/1a/ypQnPNvZ_o.gif"><strong>说明：</strong><br> - 目标数据库必须存在。<br> - IP请使用127.0.0.1，不要使用localhost。<br> - 涉及到大量PL/Python存储过程的安装、卸载等操作，需要数据库管理员权限用户来进行，普通用户没有权限创建和修改PL/Python存储过程，只能调用。<br> - 数据库兼容性，推荐兼容性为B。不同的数据库兼容性下，对空值，NULL等处理有较大差异。建议使用B兼容性。例如，CREATE DATABASE dbcompatibility='B'。 </p> 
</blockquote> 
<p> </p> 
<h1 id="使用指导-a-name-zh-cn-topic-0300593884-a">三、使用指导<a name="ZH-CN_TOPIC_0300593884"></a>
</h1> 
<h2 id="pl-python存储过程-a-name-section949463412312-a">PL/Python存储过程<a name="section949463412312"></a>
</h2> 
<p>当前PL/Python存储过程优先支持python2；默认版本也是python2。</p> 
<p>PL/Python中的函数通过标准的CREATE FUNCTION声明：</p> 
<pre>
<code>CREATE FUNCTION funcname (argument-list)
RETURNS return-type
AS $$
# PL/Python function body
$$ LANGUAGE plpythonu;
</code></pre> 
<p>函数体是一个简单的Python脚本，当函数被调用的时候，它的参数作为列表args的元素传递；命名参数也会被当做普通的变量传递到Python脚本中。命名参数的使用通常更易读。 结果将使用return或yield（结果集语句的情况） 照常从Python代码中返回。如果没有提供返回值，Python返回缺省的None。 PL/Python将Python中的None认为SQL空值。</p> 
<p>例如，返回两个整数中较大者的函数定义如下。</p> 
<pre>
<code>CREATE FUNCTION pymax(a integer, b integer) RETURNS integer AS $$   
if a &gt; b:     
    return a
return b 
$$ LANGUAGE plpythonu;
</code></pre> 
<blockquote> 
 <p><img alt="" src="https://images2.imgbox.com/77/70/KOtfFaBr_o.gif"> <strong>注意：</strong> </p> 
 <ul>
<li> <p>PL/Python函数中，后缀为plpythonu。‘u’说明是untrusted类型的存储过程。</p> </li>
<li> <p>Trusted：这个语言不能访问越权的数据。例如，数据库服务器的文件、数据库内部（包括直接访问共享内存）。</p> </li>
<li> <p>Untrusted：这个语言没有任何限制，允许访问任何数据（包括文件，网络，共享LIB库等，危害性较大），但是功能更加强大。</p> </li>
<li> <p>PL/Python属于untrusted类型的存储过程语言，当前仅允许管理员权限的用户创建和修改，普通用户仅支持使用。</p> </li>
<li> <p>定义PL/Python存储过程时，注意不要定义执行诸如import os；os.system(“rm -rf /”) 等危险语句。管理员权限的用户需要小心创建此类PL/Python存储过程。</p> </li>
</ul>
</blockquote> 
<h2 id="数据库null-none和空串处理-a-name-section17786836103220-a">数据库Null, None和空串处理<a name="section17786836103220"></a>
</h2> 
<p>如果向函数传递了一个SQL null值，参数值在Python中将会显示为None。在数据库中，不同的兼容性下，空串的行为会被当做NULL处理。</p> 
<p>同一个函数，在不同的兼容性下表现不同。</p> 
<pre>
<code>CREATE FUNCTION quote(t text, how text) RETURNS text AS $$
if how == "literal":
    return plpy.quote_literal(t)    
elif how == "nullable":
    return plpy.quote_nullable(t)    
elif how == "ident":
    return plpy.quote_ident(t)
else:        
    raise plpy.Error("unrecognized quote type %s" % how)
$$ LANGUAGE plpythonu;
</code></pre> 
<p><strong>示例1：</strong></p> 
<pre>
<code>SELECT quote(t, 'literal') FROM (VALUES ('abc'),('a''bc'),('''abc'''),(''),(''''),('xyzv')) AS v(t);
</code></pre> 
<p>数据库不同兼容性下的结果为：</p> 
<ul>
<li> <p>兼容性为A时，返回结果如下：</p> <pre>
<code>ERROR:  TypeError: argument 1 must be string, not None
CONTEXT:  Traceback (most recent call last):
PL/Python function "quote", line 3, in &lt;module&gt;
return plpy.quote_literal(t)
referenced column: quote
</code></pre> </li>
<li> <p>兼容性为B时，返回结果如下：</p> <pre>
<code>quote
-----------
'abc'
'a''bc'
'''abc'''
''
''''
'xyzv'
(6 rows)
</code></pre> </li>
</ul>
<p><strong>示例2：</strong></p> 
<pre>
<code>SELECT quote(t, 'nullable') FROM (VALUES ('abc'),('a''bc'),('''abc'''),(''),(''''),(NULL)) AS v(t);
</code></pre> 
<p>数据库不同兼容性下的结果为：</p> 
<ul>
<li> <p>兼容性为A时，返回结果如下：</p> <pre>
<code>quote
-----------
'abc'
'a''bc'
'''abc'''
NULL
''''
NULL
(6 rows)
</code></pre> </li>
<li> <p>兼容性为B时，返回结果如下：</p> <pre>
<code>quote
-----------
'abc'
'a''bc'
'''abc'''
''
''''
NULL
(6 rows)
</code></pre> </li>
</ul>
<p>可以看到，在兼容性“A”中，空串被当为NULL了。</p> 
<h2 id="触发器-a-name-section2450194543213-a">触发器<a name="section2450194543213"></a>
</h2> 
<p>当前PL/Python存储过程中，不支持触发器功能。</p> 
<h2 id="匿名代码块-a-name-section14931251153220-a">匿名代码块<a name="section14931251153220"></a>
</h2> 
<p>PL/Python也支持DO声明的匿名代码块：</p> 
<pre>
<code>DO $$
# PL/Python code
$$ LANGUAGE plpythonu;
</code></pre> 
<p>一个匿名代码块不接受参数，并且丢弃它可能返回的值。</p> 
<h2 id="共享数据-a-name-section6411402339-a">共享数据<a name="section6411402339"></a>
</h2> 
<p>每个函数都在Python解释器里获得自己的执行环境。</p> 
<p>全局字典SD在函数调用之间用于存储数据。这些变量是私有静态数据。每一个函数都有自己的SD数据空间，函数A的全局数据和函数参数是函数B不可用的。</p> 
<p>全局字典GD是公共数据，在一个gsql会话中，所有python函数都可访问和改变，使用时需要小心。</p> 
<p>当gsql断开或退出，共享数据就被释放。</p> 
<blockquote> 
 <p><img alt="" src="https://images2.imgbox.com/52/ee/Gxsez4Oo_o.gif"> <strong>注意：</strong> </p> 
 <ul>
<li> <p>运行DeepSQL或者PL/Python存储过程时，需要关闭线程池相关参数。否则PL/Python存储过程中的Sharing Data（“GD”、“SD”）等功能会失效。</p> </li>
<li> <p>在数据库中，当线程池功能关闭，每一个连入的gsql，数据库内会起一个新的线程去处理。在gsql中，如果调用到PL/Python存储过程，会在本线程中完成python解析器模块的初始化，其中包括初始化“GD”，“SD”等共享空间。</p> </li>
<li> <p>在线程池功能开启的状态下，一个gsql执行时，由当前空闲线程执行，每次执行可能分配到不同的线程上。导致共享数据紊乱。</p> </li>
</ul>
</blockquote> 
<h2 id="数据库访问-a-name-section9751115183311-a">数据库访问<a name="section9751115183311"></a>
</h2> 
<p>PL/Python语言模块自动import一个叫plpy的Python模块。</p> 
<p>plpy模块提供几个函数执行数据库命令：比如plpy.execute，plpy.prepare等。</p> 
<p>plpy模块也提供了函数plpy.debug(<em>msg</em>)、 plpy.log(<em>msg</em>)、plpy.info(<em>msg</em>)、 plpy.notice(<em>msg</em>)、plpy.warning(<em>msg</em>)、 plpy.error(<em>msg</em>)和plpy.fatal(<em>msg</em>)。 plpy.error和 plpy.fatal实际上抛出了一个Python异常，会导致当前事务或者子事务退出。</p> 
<p>另一个实用函数集是plpy.quote_literal(string)、 plpy.quote_nullable(string)和 plpy.quote_ident(string)。</p> 
<h2 id="关于审计-a-name-section20558414153315-a">关于审计<a name="section20558414153315"></a>
</h2> 
<p>PL/Python存储过程支持审计功能。具体设置可以参考<a href="https://opengauss.org/zh/docs/2.1.0/docs/Developerguide/%E5%AE%A1%E8%AE%A1.html" title="审计">审计</a>。</p> 
<h2 id="关于并发执行-a-name-section1686922123316-a">关于并发执行<a name="section1686922123316"></a>
</h2> 
<p>当前PL/Python存储过程对并发执行不友好，建议串行执行。</p> 
<blockquote> 
 <p><strong><img alt="" src="https://images2.imgbox.com/b1/f4/qnKrb5f7_o.gif">说明：</strong> 由于openGauss是多线程架构，C-python中，由于GIL锁（Global Interpreter Lock）的限制，多线程在Python中只能交替执行，无法做到真正的并发。 </p> 
</blockquote> 
<h2 id="库内算法-a-name-section20203192814330-a">库内算法<a name="section20203192814330"></a>
</h2> 
<p>具体库内算法介绍和使用，可参考MADlib官方网站（<a href="http://madlib.apache.org/docs/latest/index.html" title="MADlib文档">MADlib文档</a>）。</p> 
<blockquote> 
 <p><img alt="" src="https://images2.imgbox.com/5e/b5/VXxLGvqN_o.gif"> <strong>须知：</strong><br> - 当前仅支持机器学习算法，不支持深度学习（deep learning）模块。<br> - 当前数据库不支持xml，所以pmml模块和相关功能不支持。<br> - 数据库不支持jsonb模块，json格式的模型导出功能也不支持。</p> 
</blockquote> 
<h2 id="其他算法支持-a-name-section349233311335-a">其他算法支持<a name="section349233311335"></a>
</h2> 
<p>除了MADlib提供的算法外，openGauss又额外提供了以下三个算法。</p> 
<p><strong>表 1</strong> 额外增加的模块列表</p> 
<p><a name="table773615542912"></a></p> 
<table>
<thead><tr id="row107368582910">
<th id="mcps1.2.3.1.1"> <p id="p1129154002919"><a name="p1129154002919"></a>算法名称（中文）</p> </th>
<th id="mcps1.2.3.1.2"> <p id="p142925402293"><a name="p142925402293"></a>算法名称（英文）</p> </th>
</tr></thead>
<tbody>
<tr id="row67364542910">
<td style="vertical-align:top">梯度提升树</td>
<td style="vertical-align:top"> <p id="p77378515291"><a name="p77378515291"></a>gbdt</p> </td>
</tr>
<tr id="row1073718542915">
<td style="vertical-align:top"> <p id="p5737195122920"><a name="p5737195122920"></a>梯度提升</p> </td>
<td style="vertical-align:top"> <p id="p57371051294"><a name="p57371051294"></a>xgboost</p> </td>
</tr>
<tr id="row473775172916">
<td style="vertical-align:top"> <p id="p14737459292"><a name="p14737459292"></a>时间序列预测的算法</p> </td>
<td style="vertical-align:top"> <p id="p117377517294"><a name="p117377517294"></a>facebook_prophet</p> </td>
</tr>
</tbody>
</table>
<p></p> 
<p>使用时，需要安装依赖的python库：</p> 
<ul>
<li> <p>如果使用prophet算法：</p> <pre>
<code>pip install pystan
pip install holidays==0.9.8
pip install fbprophet==0.3.post2
</code></pre> </li>
<li> <p>如果使用xgboost算法：</p> <pre>
<code>pip install xgboost
pip install scikit-learn
</code></pre> </li>
<li> <p>gbdt不需要额外安装其他库。</p> </li>
</ul>
<p>详细操作请参考最佳实践。</p> 
<p></p> 
<h1 id="最佳实践-a-name-zh-cn-topic-0300596395-a">四、最佳实践<a name="ZH-CN_TOPIC_0300596395"></a>
</h1> 
<p>本章节介绍部分算法的使用，主要包含分类、回归、聚类、gbdt算法、xgboost算法和prohpet算法。</p> 
<p>首先需要创建一个数据库，并安装算法。</p> 
<pre>
<code>create database test1 dbcompatibility='B';
./madpack -s madlib -p opengauss -c opg@127.0.0.1:7651/test1 install
</code></pre> 
<h2 id="分类算法-a-name-section75701018131510-a">分类算法<a name="section75701018131510"></a>
</h2> 
<p>以svm分类房价为例子：</p> 
<ol>
<li> <p><a name="li9856428144310"></a>数据集准备。</p> <pre>
<code>DROP TABLE IF EXISTS houses;
CREATE TABLE houses (id INT, tax INT, bedroom INT, bath FLOAT, price INT,  size INT, lot INT);
INSERT INTO houses VALUES
(1 ,  590 ,       2 ,    1 ,  50000 ,  770 , 22100),
(2 , 1050 ,       3 ,    2 ,  85000 , 1410 , 12000),
(3 ,   20 ,       3 ,    1 ,  22500 , 1060 ,  3500),
(4 ,  870 ,       2 ,    2 ,  90000 , 1300 , 17500),
(5 , 1320 ,       3 ,    2 , 133000 , 1500 , 30000),
(6 , 1350 ,       2 ,    1 ,  90500 ,  820 , 25700),
(7 , 2790 ,       3 ,  2.5 , 260000 , 2130 , 25000),
(8 ,  680 ,       2 ,    1 , 142500 , 1170 , 22000),
(9 , 1840 ,       3 ,    2 , 160000 , 1500 , 19000),
(10 , 3680 ,       4 ,    2 , 240000 , 2790 , 20000),
(11 , 1660 ,       3 ,    1 ,  87000 , 1030 , 17500),
(12 , 1620 ,       3 ,    2 , 118600 , 1250 , 20000),
(13 , 3100 ,       3 ,    2 , 140000 , 1760 , 38000),
(14 , 2070 ,       2 ,    3 , 148000 , 1550 , 14000),
(15 ,  650 ,       3 ,  1.5 ,  65000 , 1450 , 12000);
</code></pre> </li>
<li> <p>模型训练。</p> <p>训练前配置相应schema和兼容性参数：</p> <pre>
<code>SET search_path="$user",public,madlib;
SET behavior_compat_options = 'bind_procedure_searchpath';
</code></pre> <p>使用默认的参数进行训练，分类的条件为‘price &lt; 100000’，SQL语句如下：</p> <pre>
<code>DROP TABLE IF EXISTS houses_svm, houses_svm_summary; 
SELECT madlib.svm_classification('public.houses','public.houses_svm','price &lt; 100000','ARRAY[1, tax, bath, size]');
</code></pre> </li>
<li> <p>查看模型。</p> <pre>
<code>x on
SELECT * FROM houses_svm;
x off
</code></pre> <p>结果如下：</p> <pre>
<code>-[ RECORD 1 ]------+-----------------------------------------------------------------
coef               | {.113989576847,-.00226133300602,-.0676303607996,.00179440841072}
loss               | .614496714256667
norm_of_gradient   | 108.171180769224
num_iterations     | 100
num_rows_processed | 15
num_rows_skipped   | 0
dep_var_mapping    | {f,t}
</code></pre> </li>
<li> <p>进行预测。</p> <pre>
<code>DROP TABLE IF EXISTS houses_pred; 
SELECT madlib.svm_predict('public.houses_svm','public.houses','id','public.houses_pred');
</code></pre> 
  <ul>
<li> <p>查看预测结果</p> <pre>
<code>SELECT *, price &lt; 100000 AS actual FROM houses JOIN houses_pred USING (id) ORDER BY id;
</code></pre> <p>结果如下：</p> <pre>
<code> id | tax  | bedroom | bath | price  | size |  lot  | prediction | decision_function | actual
----+------+---------+------+--------+------+-------+------------+-------------------+--------
  1 |  590 |       2 |    1 |  50000 |  770 | 22100 | t          |      .09386721875 | t
  2 | 1050 |       3 |    2 |  85000 | 1410 | 12000 | t          |     .134445058042 | t
  3 |   20 |       3 |    1 |  22500 | 1060 |  3500 | t          |   1.9032054712902 | t
  4 |  870 |       2 |    2 |  90000 | 1300 | 17500 | t          |    .3441000739464 | t
  5 | 1320 |       3 |    2 | 133000 | 1500 | 30000 | f          |   -.3146180966186 | f
  6 | 1350 |       2 |    1 |  90500 |  820 | 25700 | f          |  -1.5350254452892 | t
  7 | 2790 |       3 |  2.5 | 260000 | 2130 | 25000 | f          |  -2.5421154971142 | f
  8 |  680 |       2 |    1 | 142500 | 1170 | 22000 | t          |    .6081106124962 | f
  9 | 1840 |       3 |    2 | 160000 | 1500 | 19000 | f          |   -1.490511259749 | f
 10 | 3680 |       4 |    2 | 240000 | 2790 | 20000 | f          |   -3.336577140997 | f
 11 | 1660 |       3 |    1 |  87000 | 1030 | 17500 | f          |  -1.8592129109042 | t
 12 | 1620 |       3 |    2 | 118600 | 1250 | 20000 | f          |  -1.4416201011046 | f
 13 | 3100 |       3 |    2 | 140000 | 1760 | 38000 | f          |   -3.873244660547 | f
 14 | 2070 |       2 |    3 | 148000 | 1550 | 14000 | f          |  -1.9885277913972 | f
 15 |  650 |       3 |  1.5 |  65000 | 1450 | 12000 | t          |   1.1445697772786 | t
(15 rows)
</code></pre> </li>
<li> <p>查看误分率</p> <pre>
<code>SELECT COUNT(*) FROM houses_pred JOIN houses USING (id) WHERE houses_pred.prediction != (houses.price &lt; 100000);
</code></pre> <p>结果如下：</p> <pre>
<code>count
-------
     3
(1 row)
</code></pre> </li>
</ul>
</li>
<li> <p>使用svm其他核进行训练。</p> <pre>
<code>DROP TABLE IF EXISTS houses_svm_gaussian, houses_svm_gaussian_summary, houses_svm_gaussian_random; 
SELECT madlib.svm_classification( 'public.houses','public.houses_svm_gaussian','price &lt; 100000','ARRAY[1, tax, bath, size]','gaussian','n_components=10', '', 'init_stepsize=1, max_iter=200' );
</code></pre> <p>进行预测，并查看训练结果。</p> <pre>
<code>DROP TABLE IF EXISTS houses_pred_gaussian; 
SELECT madlib.svm_predict('public.houses_svm_gaussian','public.houses','id', 'public.houses_pred_gaussian');
SELECT COUNT(*) FROM houses_pred_gaussian JOIN houses USING (id) WHERE houses_pred_gaussian.prediction != (houses.price &lt; 100000);
</code></pre> <p>结果如下。</p> <pre>
<code> count 
-------+    
0 
(1 row)
</code></pre> </li>
<li> <p>其他参数</p> <p>除了指定不同的核方法外，还可以指定迭代次数，初始参数，比如init_stepsize, max_iter, class_weight等。</p> </li>
</ol>
<blockquote> 
 <p><img alt="" src="https://images2.imgbox.com/07/f9/sK04EpPM_o.gif"> <strong>须知：</strong> </p> 
 <pre>复制代码</pre> 
 <pre><code>SET search_path="$user",public,madlib;
SET behavior_compat_options = 'bind_procedure_searchpath';
</code></pre> 
 <p>执行算法前，需要设置search_path中schema，另外需要bind_procedure_searchpath，否则出现表找不到的情况。因为机器学习所有的方法安装在一个schema中，用户的表安装在用户的schema中，在这个例子中，算法安装在madlib中，用户表放置在public中。如果不设置，可能会出现执行算法时，找不到表的情况。执行算法时，建议把输入表的schema也加进去。</p> 
</blockquote> 
<h2 id="回归算法-a-name-section1358933811168-a">回归算法<a name="section1358933811168"></a>
</h2> 
<p>我们以线性回归预测波士顿房价为例：</p> 
<ol>
<li> <p>数据集准备。</p> <p>同svm的数据集，请参见<a href="https://opengauss.org/zh/docs/2.1.0/docs/Developerguide/%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5-14.html#li9856428144310" title="1">1</a>。</p> </li>
<li> <p>训练模型。</p> <pre>
<code>SET search_path="$user",public,madlib;
SET behavior_compat_options = 'bind_procedure_searchpath';
    
DROP TABLE IF EXISTS houses_linregr, houses_linregr_summary;
SELECT madlib.linregr_train( 'public.houses', 'public.houses_linregr',  'price', 'ARRAY[1, tax, bath, size]');
</code></pre> </li>
<li> <p>查看模型内容。</p> <pre>
<code>x ON
SELECT * FROM houses_linregr;
x OFF
</code></pre> <p>返回结果如下。</p> <pre>
<code>-[ RECORD 1 ]------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
coef                     | {-12849.4168959872,28.9613922651775,10181.6290712649,50.516894915353}
r2                       | .768577580597462
std_err                  | {33453.0344331377,15.8992104963991,19437.7710925915,32.9280231740856}
t_stats                  | {-.384103179688204,1.82156166004197,.523806408809163,1.53416118083608}
p_values                 | {.708223134615411,.0958005827189556,.610804093526516,.153235085548177}
condition_no             | 9002.50457069858
num_rows_processed       | 15
num_missing_rows_skipped | 0
variance_covariance      | {<!-- -->{1119105512.7847,217782.067878005,-283344228.394538,-616679.693190829},{217782.067878005,252.784894408806,-46373.1796964038,-369.864520095145},{-283344228.394538,-46373.1796964038,377826945.047986,-209088.217319699},{-616679.693190829,-369.864520095145,-209088.217319699,1084.25471015312}}
</code></pre> </li>
<li> <p>预测，并对比结果。</p> <pre>
<code>SELECT houses.*,
    madlib.linregr_predict( m.coef, ARRAY[1,tax,bath,size]) as predict,
    price - madlib.linregr_predict( m.coef, ARRAY[1,tax,bath,size]) as residual
FROM public.houses, public.houses_linregr AS m 
ORDER BY id;
</code></pre> <p>返回结果如下。</p> <pre>
<code> id | tax  | bedroom | bath | price  | size |  lot  |     predict      |     residual
----+------+---------+------+--------+------+-------+------------------+-------------------
  1 |  590 |       2 |    1 |  50000 |  770 | 22100 | 53317.4426965543 | -3317.44269655428
  2 | 1050 |       3 |    2 |  85000 | 1410 | 12000 | 109152.124955627 | -24152.1249556268
  3 |   20 |       3 |    1 |  22500 | 1060 |  3500 | 51459.3486308555 | -28959.3486308555
  4 |  870 |       2 |    2 |  90000 | 1300 | 17500 |  98382.215907206 | -8382.21590720599
  5 | 1320 |       3 |    2 | 133000 | 1500 | 30000 | 121518.221409606 |  11481.7785903935
  6 | 1350 |       2 |    1 |  90500 |  820 | 25700 | 77853.9455638568 |  12646.0544361432
  7 | 2790 |       3 |  2.5 | 260000 | 2130 | 25000 | 201007.926371722 |  58992.0736282778
  8 |  680 |       2 |    1 | 142500 | 1170 | 22000 | 76130.7259665615 |  66369.2740334385
  9 | 1840 |       3 |    2 | 160000 | 1500 | 19000 | 136578.145387499 |  23421.8546125013
 10 | 3680 |       4 |    2 | 240000 | 2790 | 20000 | 255033.901596231 | -15033.9015962306
 11 | 1660 |       3 |    1 |  87000 | 1030 | 17500 | 97440.5250982859 | -10440.5250982859
 12 | 1620 |       3 |    2 | 118600 | 1250 | 20000 | 117577.415360321 |  1022.58463967856
 13 | 3100 |       3 |    2 | 140000 | 1760 | 38000 | 186203.892319614 | -46203.8923196141
 14 | 2070 |       2 |    3 | 148000 | 1550 | 14000 | 155946.739425522 | -7946.73942552213
 15 |  650 |       3 |  1.5 |  65000 | 1450 | 12000 | 94497.4293105374 | -29497.4293105374
(15 rows)
</code></pre> </li>
</ol>
<h2 id="聚类算法-a-name-section652264210184-a">聚类算法<a name="section652264210184"></a>
</h2> 
<p>以kmeans为例：</p> 
<ol>
<li> <p>准备数据。</p> <pre>
<code>DROP TABLE IF EXISTS km_sample; 
CREATE TABLE km_sample(pid int, points double precision[]); 
INSERT INTO km_sample VALUES 
(1,  '{14.23, 1.71, 2.43, 15.6, 127, 2.8, 3.0600, 0.2800, 2.29, 5.64, 1.04, 3.92, 1065}'), 
(2,  '{13.2, 1.78, 2.14, 11.2, 1, 2.65, 2.76, 0.26, 1.28, 4.38, 1.05, 3.49, 1050}'), 
(3,  '{13.16, 2.36,  2.67, 18.6, 101, 2.8,  3.24, 0.3, 2.81, 5.6799, 1.03, 3.17, 1185}'), 
(4,  '{14.37, 1.95, 2.5, 16.8, 113, 3.85, 3.49, 0.24, 2.18, 7.8, 0.86, 3.45, 1480}'), 
(5,  '{13.24, 2.59, 2.87, 21, 118, 2.8, 2.69, 0.39, 1.82, 4.32, 1.04, 2.93, 735}'), 
(6,  '{14.2, 1.76, 2.45, 15.2, 112, 3.27, 3.39, 0.34, 1.97, 6.75, 1.05, 2.85, 1450}'), 
(7,  '{14.39, 1.87, 2.45, 14.6, 96, 2.5, 2.52, 0.3, 1.98, 5.25, 1.02, 3.58, 1290}'), 
(8,  '{14.06, 2.15, 2.61, 17.6, 121, 2.6, 2.51, 0.31, 1.25, 5.05, 1.06, 3.58, 1295}'), 
(9,  '{14.83, 1.64, 2.17, 14, 97, 2.8, 2.98, 0.29, 1.98, 5.2, 1.08, 2.85, 1045}'), 
(10, '{13.86, 1.35, 2.27, 16, 98, 2.98, 3.15, 0.22, 1.8500, 7.2199, 1.01, 3.55, 1045}');
</code></pre> </li>
<li> <p>运行kmeans算法。</p> <p>使用kmeans++进行计算，距离函数使用欧几里得距离。</p> <pre>
<code>SET search_path="$user",public,madlib;
SET behavior_compat_options = 'bind_procedure_searchpath';
    
DROP TABLE IF EXISTS km_result; 
CREATE TABLE km_result AS SELECT * FROM madlib.kmeanspp( 'public.km_sample',   -- Table of source data                              
                                                         'points',      -- Column containing point co-ordinates                              
                                                         2,             -- Number of centroids to calculate                              
                                                         'madlib.squared_dist_norm2',   -- Distance function                              
                                                         'madlib.avg',  -- Aggregate function                              
                                                         20,            -- Number of iterations                             
                                                         0.001          -- Fraction of centroids reassigned to keep iterating
);
</code></pre> <p>kmeans执行完后，不会自动创建表保存内容，所以需要用户自行创建table。</p> <pre>
<code>x on
 select * from km_result;
x off
</code></pre> <p>返回结果如下。</p> <pre>
<code>-[ RECORD 1 ]----+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
centroids        | {<!-- -->{14.0333333333333,1.84111111111111,2.41,15.5111111111111,96.2222222222222,2.91666666666667,3.01111111111111,.282222222222222,1.95444444444444,5.88553333333333,1.02222222222222,3.38222222222222,1211.66666666667},{13.24,2.59,2.87,21,118,2.8,2.69,.39,1.82,4.32,1.04,2.93,735}}
cluster_variance | {257041.999707571,0}
objective_fn     | 257041.999707571
frac_reassigned  | 0
num_iterations   | 2
</code></pre> </li>
<li> <p>应用聚类结果。</p> <p>执行以下函数，计算每个节点的临近节点和相应距离。</p> <pre>
<code>DROP TABLE IF EXISTS km_points_silh; 
SELECT * FROM madlib.simple_silhouette_points('public.km_sample',          -- Input points table
                                              'public.km_points_silh',      -- Output table
                                              'pid',                 -- Point ID column in input table
                                              'points',              -- Points column in input table
                                              'public.km_result',           -- Centroids table
                                              'centroids',           -- Column in centroids table containing centroids
                                              'madlib.squared_dist_norm2'   -- Distance function
); 
SELECT * FROM km_points_silh ORDER BY pid;
</code></pre> <p>返回结果如下。</p> <pre>
<code> pid | centroid_id | neighbor_centroid_id |       silh
-----+-------------+----------------------+------------------
   1 |           0 |                    1 | .793983543638996
   2 |           0 |                    1 | .688301735667703
   3 |           0 |                    1 | .996324103148159
   4 |           0 |                    1 | .869765755931474
   5 |           1 |                    0 |                1
   6 |           0 |                    1 | .888416176253661
   7 |           0 |                    1 | .980107240092519
   8 |           0 |                    1 | .975880363039906
   9 |           0 |                    1 | .712384473959954
  10 |           0 |                    1 | .712198411442872
(10 rows)
</code></pre> </li>
</ol>
<h2 id="gbdt算法-a-name-section183271318197-a">gbdt算法<a name="section183271318197"></a>
</h2> 
<p>gdbt的基学习器虽然是回归树，但算法本身支持分类和回归两种操作。以下将展示两种任务的具体实现。这里值得注意的一点是，本方法不支持标签列含有空值（NULL）的情况。</p> 
<p><strong>分类任务</strong>：</p> 
<ol>
<li> <p>准备数据。</p> <pre>
<code>DROPTABLEIFEXISTS dt_golf CASCADE;
DROPTABLEIFEXISTS train_output,train_output_summary;
CREATETABLE dt_golf (
    id integerNOTNULL,
"OUTLOOK"text,
    temperature double precision,
    humidity double precision,
"Cont_features"double precision[],
    cat_features text[],
    windy boolean,
    class integer
) ;
INSERTINTO dt_golf (id,"OUTLOOK",temperature,humidity,"Cont_features",cat_features, windy,class) VALUES
(1, 'sunny', 85, 85,ARRAY[85, 85], ARRAY['a', 'b'], false, 0),
(2, 'sunny', 80, 90, ARRAY[80, 90], ARRAY['a', 'b'], true, 0),
(3, 'overcast', 83, 78, ARRAY[83, 78], ARRAY['a', 'b'], false, 1),
(4, 'rain', 70, NULL, ARRAY[70, 96], ARRAY['a', 'b'], false, 1),
(5, 'rain', 68, 80, ARRAY[68, 80], ARRAY['a', 'b'], false, 1),
(6, 'rain', NULL, 70, ARRAY[65, 70], ARRAY['a', 'b'], true, 0),
(7, 'overcast', 64, 65, ARRAY[64, 65], ARRAY['c', 'b'], NULL , 1),
(8, 'sunny', 72, 95, ARRAY[72, 95], ARRAY['a', 'b'], false, 0),
(9, 'sunny', 69, 70, ARRAY[69, 70], ARRAY['a', 'b'], false, 1),
(10, 'rain', 75, 80, ARRAY[75, 80], ARRAY['a', 'b'], false, 1),
(11, 'sunny', 75, 70, ARRAY[75, 70], ARRAY['a', 'd'], true, 1),
(12, 'overcast', 72, 90, ARRAY[72, 90], ARRAY['c', 'b'], NULL, 1),
(13, 'overcast', 81, 75, ARRAY[81, 75], ARRAY['a', 'b'], false, 1),
(15, NULL, 81, 75, ARRAY[81, 75], ARRAY['a', 'b'], false, 1),
(16, 'overcast', NULL, 75, ARRAY[81, 75], ARRAY['a', 'd'], false,1),
(14, 'rain', 71, 80, ARRAY[71, 80], ARRAY['c', 'b'], true, 0);
</code></pre> </li>
<li> <p>训练模型。</p> <pre>
<code>select madlib.gbdt_train('dt_golf',         -- source table
                  'train_output',    -- output model table
                  'id'  ,            -- id column
                  'class',           -- response
                  '"OUTLOOK", temperature',          -- features
                  NULL,        -- exclude columns
                  1,       --weight
                  10,                -- num of trees
                  NULL,                 -- num of random features
                  10,       -- max depth
                  1,        -- min split
                  1,        -- min bucket
                  8,        -- number of bins per continuous variable
                  'max_surrogates=0',
                  TRUE
);
</code></pre> <p>模型训练结束会生成两个表，其中一张表train_output中保存着gdbt中的回归树模型，内容包括对每一个基学习器的参数记录。</p> <pre>
<code>       Column       |     Type      | Modifiers | Storage  | Stats target | Description
--------------------+---------------+-----------+----------+--------------+-------------
 iteration          | integer       |           | plain    |              |
 tree               | madlib.bytea8 |           | external |              |
 cat_levels_in_text | text[]        |           | extended |              |
 cat_n_levels       | integer[]     |           | extended |              |
 tree_depth         | integer       |           | plain    |              |
</code></pre> <pre>
<code> iteration |  cat_levels_in_text   | cat_n_levels | tree_depth
-----------+-----------------------+--------------+------------
         0 | {sunny,rain,overcast} | {3}          |          4
         1 | {sunny,rain,overcast} | {3}          |          5
         2 | {sunny,rain,overcast} | {3}          |          6
         3 | {sunny,rain,overcast} | {3}          |          4
         4 | {sunny,rain,overcast} | {3}          |          5
         5 | {sunny,rain,overcast} | {3}          |          5
         6 | {sunny,rain,overcast} | {3}          |          5
         7 | {sunny,rain,overcast} | {3}          |          5
         8 | {sunny,rain,overcast} | {3}          |          4
         9 | {sunny,rain,overcast} | {3}          |          3
(10 rows)
</code></pre> <p>另一张表train_output_summary，内容是对gdbt训练的整体描述：</p> <pre>
<code>select * from train_output_summary;
 method | cat_features | con_features | source_table | model_table  | null_proxy | learning_rate | is_classification | predict_dt_prob | num_trees
--------+--------------+--------------+--------------+--------------+------------+---------------+-------------------+-----------------+-----------
 GBDT   | "OUTLOOK"    | temperature  | dt_golf      | train_output |            |           .01 | t                 | response        |        10
(1 row)
</code></pre> </li>
<li> <p>预测。</p> <pre>
<code>select madlib.gbdt_predict('dt_golf2','train_output','test_output','id');
</code></pre> <p>查看预测结果</p> <pre>
<code>select test_output.id, test_prediction,class from test_output join dt_golf using (id);
id | test_prediction | class
----+-----------------+-------
  1 |             1.0 |     0
  2 |             1.0 |     0
  3 |             1.0 |     1
  4 |             1.0 |     1
  5 |             1.0 |     1
  6 |             1.0 |     0
  7 |             1.0 |     1
  8 |             0.0 |     0
  9 |             1.0 |     1
 10 |             1.0 |     1
 11 |             1.0 |     1
 12 |             1.0 |     1
 13 |             1.0 |     1
 15 |             0.0 |     1
 16 |             1.0 |     1
 14 |             0.0 |     0
(16 rows)
</code></pre> </li>
</ol>
<h2 id="回归任务-a-name-section731842104010-a">回归任务<a name="section731842104010"></a>
</h2> 
<ol>
<li> <p>准备数据。</p> <pre>
<code>DROP TABLE IF EXISTS crime;
CREATE TABLE crime (
    id SERIAL NOT NULL,
    CrimeRat DOUBLE PRECISION,
    MaleTeen INTEGER,
    South SMALLINT,
    Educ DOUBLE PRECISION,
    Police60 INTEGER,
    Police59 INTEGER,
    Labor INTEGER,
    Males INTEGER,
    Pop   INTEGER,
    NonWhite INTEGER,
    Unemp1  INTEGER,
    Unemp2  INTEGER,
    Median  INTEGER,
    BelowMed INTEGER
);
    
INSERT INTO crime(
    CrimeRat, MaleTeen, South, Educ, Police60, Police59, Labor, Males, Pop,
    NonWhite, Unemp1, Unemp2, Median, BelowMed
) VALUES
(79.1, 151, 1, 9.1, 58, 56, 510, 950, 33, 301, 108, 41, 394, 261),
(163.5, 143, 0, 11.3, 103, 95, 583, 1012, 13, 102, 96, 36, 557, 194),
(57.8, 142, 1, 8.9, 45, 44, 533, 969, 18, 219, 94, 33, 318, 250),
(196.9, 136, 0, 12.1, 149, 141, 577, 994, 157, 80, 102, 39, 673, 167),
(123.4, 141, 0, 12.1, 109, 101, 591, 985, 18, 30, 91, 20, 578, 174),
(68.2, 121, 0, 11.0, 118, 115, 547, 964, 25, 44, 84, 29, 689, 126),
(96.3, 127, 1, 11.1, 82, 79, 519, 982, 4, 139, 97, 38, 620, 168),
(155.5, 131, 1, 10.9, 115, 109, 542, 969, 50, 179, 79, 35, 472, 206),
(85.6, 157, 1, 9.0, 65, 62, 553, 955, 39, 286, 81, 28, 421, 239),
(70.5, 140, 0, 11.8, 71, 68, 632, 1029, 7, 15, 100, 24, 526, 174),
(167.4, 124, 0, 10.5, 121, 116, 580, 966, 101, 106, 77, 35, 657, 170),
(84.9, 134, 0, 10.8, 75, 71, 595, 972, 47, 59, 83, 31, 580, 172),
(51.1, 128, 0, 11.3, 67, 60, 624, 972, 28, 10, 77, 25, 507, 206),
(66.4, 135, 0, 11.7, 62, 61, 595, 986, 22, 46, 77, 27, 529, 190),
(79.8, 152, 1, 8.7, 57, 53, 530, 986, 30, 72, 92, 43, 405, 264),
(94.6, 142, 1, 8.8, 81, 77, 497, 956, 33, 321, 116, 47, 427, 247),
(53.9, 143, 0, 11.0, 66, 63, 537, 977, 10, 6, 114, 35, 487, 166),
(92.9, 135, 1, 10.4, 123, 115, 537, 978, 31, 170, 89, 34, 631, 165),
(75.0, 130, 0, 11.6, 128, 128, 536, 934, 51, 24, 78, 34, 627, 135),
(122.5, 125, 0, 10.8, 113, 105, 567, 985, 78, 94, 130, 58, 626, 166),
(74.2, 126, 0, 10.8, 74, 67, 602, 984, 34, 12, 102, 33, 557, 195),
(43.9, 157, 1, 8.9, 47, 44, 512, 962, 22, 423, 97, 34, 288, 276),
(121.6, 132, 0, 9.6, 87, 83, 564, 953, 43, 92, 83, 32, 513, 227),
(96.8, 131, 0, 11.6, 78, 73, 574, 1038, 7, 36, 142, 42, 540, 176),
(52.3, 130, 0, 11.6, 63, 57, 641, 984, 14, 26, 70, 21, 486, 196),
(199.3, 131, 0, 12.1, 160, 143, 631, 1071, 3, 77, 102, 41, 674, 152),
(34.2, 135, 0, 10.9, 69, 71, 540, 965, 6, 4, 80, 22, 564, 139),
(121.6, 152, 0, 11.2, 82, 76, 571, 1018, 10, 79, 103, 28, 537, 215),
(104.3, 119, 0, 10.7, 166, 157, 521, 938, 168, 89, 92, 36, 637, 154),
(69.6, 166, 1, 8.9, 58, 54, 521, 973, 46, 254, 72, 26, 396, 237),
(37.3, 140, 0, 9.3, 55, 54, 535, 1045, 6, 20, 135, 40, 453, 200),
(75.4, 125, 0, 10.9, 90, 81, 586, 964, 97, 82, 105, 43, 617, 163),
(107.2, 147, 1, 10.4, 63, 64, 560, 972, 23, 95, 76, 24, 462, 233),
(92.3, 126, 0, 11.8, 97, 97, 542, 990, 18, 21, 102, 35, 589, 166),
(65.3, 123, 0, 10.2, 97, 87, 526, 948, 113, 76, 124, 50, 572, 158),
(127.2, 150, 0, 10.0, 109, 98, 531, 964, 9, 24, 87, 38, 559, 153),
(83.1, 177, 1, 8.7, 58, 56, 638, 974, 24, 349, 76, 28, 382, 254),
(56.6, 133, 0, 10.4, 51, 47, 599, 1024, 7, 40, 99, 27, 425, 225),
(82.6, 149, 1, 8.8, 61, 54, 515, 953, 36, 165, 86, 35, 395, 251),
(115.1, 145, 1, 10.4, 82, 74, 560, 981, 96, 126, 88, 31, 488, 228),
(88.0, 148, 0, 12.2, 72, 66, 601, 998, 9, 19, 84, 20, 590, 144),
(54.2, 141, 0, 10.9, 56, 54, 523, 968, 4, 2, 107, 37, 489, 170),
(82.3, 162, 1, 9.9, 75, 70, 522, 996, 40, 208, 73, 27, 496, 224),
(103.0, 136, 0, 12.1, 95, 96, 574, 1012, 29, 36, 111, 37, 622, 162),
(45.5, 139, 1, 8.8, 46, 41, 480, 968, 19, 49, 135, 53, 457, 249),
(50.8, 126, 0, 10.4, 106, 97, 599, 989, 40, 24, 78, 25, 593, 171),
(84.9, 130, 0, 12.1, 90, 91, 623, 1049, 3, 22, 113, 40, 588, 160);
</code></pre> </li>
<li> <p>训练模型。</p> <pre>
<code>select madlib.gbdt_train('crime',         -- source table
                  'train_output',    -- output model table
                  'id'  ,            -- id column
                  'CrimeRat',           -- response
                 '*',          -- features
                  NULL,        -- exclude columns
                  1,       --weight
                  20,                -- num of trees
                  4,                 -- num of random features
                  10,       -- max depth
                  1,        -- min split
                  1,        -- min bucket
                  8,        -- number of bins per continuous variable
                  'max_surrogates=0',
                  FALSE
);
</code></pre> <p>当is_clasification设为FALSE时，模型为回归任务。默认状态下gbdt提供回归计算支持。方法生成两个表，其中一张表记录每棵树的集体信息和模型的二进制，一张表记录方法的参数信息。</p> </li>
<li> <p>预测。</p> <pre>
<code>select madlib.gbdt_predict('crime','train_output','test_output','id');
</code></pre> <p>查看预测结果：</p> <pre>
<code>select test_output.id, test_prediction,CrimeRat  from test_output join crime using (id);
    
 id |  test_prediction   | crimerat
----+--------------------+----------
  1 |               79.1 |     79.1
  2 |              163.5 |    163.5
  3 |               57.8 |     57.8
  4 |              196.9 |    196.9
  5 |              123.4 |    123.4
  6 |               68.2 |     68.2
  7 |   96.2999999992251 |     96.3
  8 | 155.49842087765936 |    155.5
  9 |              84.35 |     85.6
 10 |  70.50157912234037 |     70.5
 11 |  167.4000000007749 |    167.4
 12 |               84.9 |     84.9
 13 |               51.1 |     51.1
 14 |               66.4 |     66.4
 15 |               79.8 |     79.8
 16 |               94.6 |     94.6
 17 |               53.9 |     53.9
 18 |               92.9 |     92.9
 19 |               75.0 |       75
 20 |              122.5 |    122.5
 21 |               74.2 |     74.2
 22 |               43.9 |     43.9
 23 |              121.6 |    121.6
 24 |               96.8 |     96.8
 25 |               52.3 |     52.3
 26 |              199.3 |    199.3
 27 |               34.2 |     34.2
 28 |              121.6 |    121.6
 29 |              104.3 |    104.3
 30 |               69.6 |     69.6
 31 |               37.3 |     37.3
 32 |               75.4 |     75.4
 33 |              107.2 |    107.2
 34 |               92.3 |     92.3
 35 |   65.2999999992251 |     65.3
 36 | 127.19842087765963 |    127.2
 37 |  84.35000000002215 |     83.1
 38 |  56.60155638297881 |     56.6
 39 |  82.45000000075257 |     82.6
 40 | 115.10002273936168 |    115.1
 41 |               88.0 |       88
 42 |  54.19997726063828 |     54.2
 43 |  82.44999999999999 |     82.3
 44 | 103.00002273936173 |      103
 45 | 45.500000000000156 |     45.5
 46 |               50.8 |     50.8
 47 |               84.9 |     84.9
(47 rows)
</code></pre> </li>
</ol>
<h2 id="xgboost算法-a-name-section17622712161914-a">xgboost算法<a name="section17622712161914"></a>
</h2> 
<p>新增的xgboost支持分类和回归两种操作。下面以分类iris花为例，展示xgboost算法。</p> 
<p>xgboost支持grid search方式，可以同时训练多组参数。</p> 
<ol>
<li> <p>准备数据。</p> <pre>
<code>DROP TABLE IF EXISTS iris;
create table iris (id serial, a float, d float, c float, b float, label int);
    
INSERT into iris (a, b, c, d, label) values 
(5.1, 3.5, 1.4, 0.2, 0),(4.9, 3.0, 1.4, 0.2, 0),(4.7, 3.2, 1.3, 0.2, 0),(4.6, 3.1, 1.5, 0.2, 0),
(5.0, 3.6, 1.4, 0.2, 0),(5.4, 3.9, 1.7, 0.4, 0),(4.6, 3.4, 1.4, 0.3, 0),(5.0, 3.4, 1.5, 0.2, 0),
(4.4, 2.9, 1.4, 0.2, 0),(4.9, 3.1, 1.5, 0.1, 0),(5.4, 3.7, 1.5, 0.2, 0),(4.8, 3.4, 1.6, 0.2, 0),
(4.8, 3.0, 1.4, 0.1, 0),(4.3, 3.0, 1.1, 0.1, 0),(5.8, 4.0, 1.2, 0.2, 0),(5.7, 4.4, 1.5, 0.4, 0),
(5.4, 3.9, 1.3, 0.4, 0),(5.1, 3.5, 1.4, 0.3, 0),(5.7, 3.8, 1.7, 0.3, 0),(5.1, 3.8, 1.5, 0.3, 0),
(5.4, 3.4, 1.7, 0.2, 0),(5.1, 3.7, 1.5, 0.4, 0),(4.6, 3.6, 1.0, 0.2, 0),(5.1, 3.3, 1.7, 0.5, 0),
(4.8, 3.4, 1.9, 0.2, 0),(5.0, 3.0, 1.6, 0.2, 0),(5.0, 3.4, 1.6, 0.4, 0),(5.2, 3.5, 1.5, 0.2, 0),
(5.2, 3.4, 1.4, 0.2, 0),(4.7, 3.2, 1.6, 0.2, 0),(4.8, 3.1, 1.6, 0.2, 0),(5.4, 3.4, 1.5, 0.4, 0),
(5.2, 4.1, 1.5, 0.1, 0),(5.5, 4.2, 1.4, 0.2, 0),(4.9, 3.1, 1.5, 0.2, 0),(5.0, 3.2, 1.2, 0.2, 0),
(5.5, 3.5, 1.3, 0.2, 0),(4.9, 3.6, 1.4, 0.1, 0),(4.4, 3.0, 1.3, 0.2, 0),(5.1, 3.4, 1.5, 0.2, 0),
(5.0, 3.5, 1.3, 0.3, 0),(4.5, 2.3, 1.3, 0.3, 0),(4.4, 3.2, 1.3, 0.2, 0),(5.0, 3.5, 1.6, 0.6, 0),
(5.1, 3.8, 1.9, 0.4, 0),(4.8, 3.0, 1.4, 0.3, 0),(5.1, 3.8, 1.6, 0.2, 0),(4.6, 3.2, 1.4, 0.2, 0),
(5.3, 3.7, 1.5, 0.2, 0),(5.0, 3.3, 1.4, 0.2, 0),(7.0, 3.2, 4.7, 1.4, 1),(6.4, 3.2, 4.5, 1.5, 1),
(6.9, 3.1, 4.9, 1.5, 1),(5.5, 2.3, 4.0, 1.3, 1),(6.5, 2.8, 4.6, 1.5, 1),(5.7, 2.8, 4.5, 1.3, 1),
(6.3, 3.3, 4.7, 1.6, 1),(4.9, 2.4, 3.3, 1.0, 1),(6.6, 2.9, 4.6, 1.3, 1),(5.2, 2.7, 3.9, 1.4, 1),
(5.0, 2.0, 3.5, 1.0, 1),(5.9, 3.0, 4.2, 1.5, 1),(6.0, 2.2, 4.0, 1.0, 1),(6.1, 2.9, 4.7, 1.4, 1),
(5.6, 2.9, 3.6, 1.3, 1),(6.7, 3.1, 4.4, 1.4, 1),(5.6, 3.0, 4.5, 1.5, 1),(5.8, 2.7, 4.1, 1.0, 1),
(6.2, 2.2, 4.5, 1.5, 1),(5.6, 2.5, 3.9, 1.1, 1),(5.9, 3.2, 4.8, 1.8, 1),(6.1, 2.8, 4.0, 1.3, 1),
(6.3, 2.5, 4.9, 1.5, 1),(6.1, 2.8, 4.7, 1.2, 1),(6.4, 2.9, 4.3, 1.3, 1),(6.6, 3.0, 4.4, 1.4, 1),
(6.8, 2.8, 4.8, 1.4, 1),(6.7, 3.0, 5.0, 1.7, 1),(6.0, 2.9, 4.5, 1.5, 1),(5.7, 2.6, 3.5, 1.0, 1),
(5.5, 2.4, 3.8, 1.1, 1),(5.5, 2.4, 3.7, 1.0, 1),(5.8, 2.7, 3.9, 1.2, 1),(6.0, 2.7, 5.1, 1.6, 1),
(5.4, 3.0, 4.5, 1.5, 1),(6.0, 3.4, 4.5, 1.6, 1),(6.7, 3.1, 4.7, 1.5, 1),(6.3, 2.3, 4.4, 1.3, 1),
(5.6, 3.0, 4.1, 1.3, 1),(5.5, 2.5, 4.0, 1.3, 1),(5.5, 2.6, 4.4, 1.2, 1),(6.1, 3.0, 4.6, 1.4, 1),
(5.8, 2.6, 4.0, 1.2, 1),(5.0, 2.3, 3.3, 1.0, 1),(5.6, 2.7, 4.2, 1.3, 1),(5.7, 3.0, 4.2, 1.2, 1),
(5.7, 2.9, 4.2, 1.3, 1),(6.2, 2.9, 4.3, 1.3, 1),(5.1, 2.5, 3.0, 1.1, 1),(5.7, 2.8, 4.1, 1.3, 1),
(6.3, 3.3, 6.0, 2.5, 2),(5.8, 2.7, 5.1, 1.9, 2),(7.1, 3.0, 5.9, 2.1, 2),(6.3, 2.9, 5.6, 1.8, 2),
(6.5, 3.0, 5.8, 2.2, 2),(7.6, 3.0, 6.6, 2.1, 2),(4.9, 2.5, 4.5, 1.7, 2),(7.3, 2.9, 6.3, 1.8, 2),
(6.7, 2.5, 5.8, 1.8, 2),(7.2, 3.6, 6.1, 2.5, 2),(6.5, 3.2, 5.1, 2.0, 2),(6.4, 2.7, 5.3, 1.9, 2),
(6.8, 3.0, 5.5, 2.1, 2),(5.7, 2.5, 5.0, 2.0, 2),(5.8, 2.8, 5.1, 2.4, 2),(6.4, 3.2, 5.3, 2.3, 2),
(6.5, 3.0, 5.5, 1.8, 2),(7.7, 3.8, 6.7, 2.2, 2),(7.7, 2.6, 6.9, 2.3, 2),(6.0, 2.2, 5.0, 1.5, 2),
(6.9, 3.2, 5.7, 2.3, 2),(5.6, 2.8, 4.9, 2.0, 2),(7.7, 2.8, 6.7, 2.0, 2),(6.3, 2.7, 4.9, 1.8, 2),
(6.7, 3.3, 5.7, 2.1, 2),(7.2, 3.2, 6.0, 1.8, 2),(6.2, 2.8, 4.8, 1.8, 2),(6.1, 3.0, 4.9, 1.8, 2),
(6.4, 2.8, 5.6, 2.1, 2),(7.2, 3.0, 5.8, 1.6, 2),(7.4, 2.8, 6.1, 1.9, 2),(7.9, 3.8, 6.4, 2.0, 2),
(6.4, 2.8, 5.6, 2.2, 2),(6.3, 2.8, 5.1, 1.5, 2),(6.1, 2.6, 5.6, 1.4, 2),(7.7, 3.0, 6.1, 2.3, 2),
(6.3, 3.4, 5.6, 2.4, 2),(6.4, 3.1, 5.5, 1.8, 2),(6.0, 3.0, 4.8, 1.8, 2),(6.9, 3.1, 5.4, 2.1, 2),
(6.7, 3.1, 5.6, 2.4, 2),(6.9, 3.1, 5.1, 2.3, 2),(5.8, 2.7, 5.1, 1.9, 2),(6.8, 3.2, 5.9, 2.3, 2),
(6.7, 3.3, 5.7, 2.5, 2),(6.7, 3.0, 5.2, 2.3, 2),(6.3, 2.5, 5.0, 1.9, 2),(6.5, 3.0, 5.2, 2.0, 2),
(6.2, 3.4, 5.4, 2.3, 2),(5.9, 3.0, 5.1, 1.8, 2);
</code></pre> </li>
<li> <p>执行分类训练操作。</p> <pre>
<code>SET search_path="$user",public,madlib;
SET behavior_compat_options = 'bind_procedure_searchpath';
select madlib.xgboost_sk_Classifier('public.iris', 'public.iris_model_xgbc', 'id', 'label', 'a,b,c,d', NULL, 
$${'booster': ['gbtree'], 'eta':   (0.1, 0.9), 'max_depth': (5,1), 'objective': ('multi:softmax',)}$$,   -- 训练参数组合，如果有多个参数，请用元组或者列表的方式传入
TRUE);                                  -- 是否评估模型，多分类评价为精确度和kappa值；二分类评价指标为precision, recall, fscore和support；回归评价指标为mae, mse, R2squared和rmse
</code></pre> <p>xgboost支持多组参数并行训练，比如用例中eta值为0.1和0.9，最大深度为5或者1。</p> <pre>
<code>select id, train_timestamp, source_table, y_type, metrics, features, params from iris_model_xgbc;
</code></pre> <p>查看模型结果如下。</p> <pre>
<code> id |        train_timestamp        | source_table | y_type  |          metrics           | features  |                                     params
----+-------------------------------+--------------+---------+----------------------------+-----------+---------------------------------------------------------------------------------
  1 | 2020-12-14 20:15:05.904184+08 | public.iris  | integer | {'acc': 1.0, 'kappa': 1.0} | {a,b,c,d} | ('objective = multi:softmax', 'eta = 0.1', 'max_depth = 5', 'booster = gbtree')
  2 | 2020-12-14 20:15:05.904184+08 | public.iris  | integer | {'acc': 1.0, 'kappa': 1.0} | {a,b,c,d} | ('objective = multi:softmax', 'eta = 0.1', 'max_depth = 1', 'booster = gbtree')
  3 | 2020-12-14 20:15:05.904184+08 | public.iris  | integer | {'acc': 1.0, 'kappa': 1.0} | {a,b,c,d} | ('objective = multi:softmax', 'eta = 0.9', 'max_depth = 5', 'booster = gbtree')
  4 | 2020-12-14 20:15:05.904184+08 | public.iris  | integer | {'acc': 1.0, 'kappa': 1.0} | {a,b,c,d} | ('objective = multi:softmax', 'eta = 0.9', 'max_depth = 1', 'booster = gbtree')
(4 rows)
</code></pre> <p>结果表中，记录着训练时间，特征，结果类型，所用参数等。</p> <p>在本示例函数输入中，eta选择为2种，max_depth选择为2种，总共4种参数组合。所以在结果中，有4行结果；在metrics列中，记录4种参数组合的训练后的评价结果。用户可以输入多种参数组合，训练后，用户可以选择合适的模型留下。</p> </li>
<li> <p>预测结果。</p> <pre>
<code>select madlib.xgboost_sk_predict('public.iris', 'public.iris_model_xgbc', 'public.iris_xgbc_out', 'id');
select t1.id, prediction, label from iris as t1, iris_xgbc_out as t2 where t1.id = t2.id and prediction &lt;&gt; label;
</code></pre> <p>查看结果，预测和训练结果的对比，当前不匹配的行数为0，证明分类准确性较高。</p> <pre>
<code> id | prediction | label
----+------------+-------
(0 rows)
</code></pre> </li>
</ol>
<h2 id="prophet算法-a-name-section7372832141917-a">prophet算法<a name="section7372832141917"></a>
</h2> 
<p>新增facebook的prophet时序预测算法。下面以时序数据为例，展示prophet算法使用。</p> 
<ol>
<li> <p>准备数据。</p> <pre>
<code>DROP TABLE IF EXISTS ts_data;
CREATE TABLE ts_data(date date, value float);
    
INSERT into ts_data (date, value) values 
('2016-11-29 21:20:00', 5.6),('2016-11-29 21:30:00', 5.2),('2016-11-29 21:40:00', 5.3),('2016-11-29 21:50:00', 5.3),
('2016-11-29 22:00:00', 5.1),('2016-11-29 22:10:00', 5.8),('2016-11-29 22:20:00', 5.6),('2016-11-29 22:30:00', 5.4),
('2016-11-29 22:40:00', 5.4),('2016-11-29 22:50:00', 5.1),('2016-11-29 23:00:00', 5.2),('2016-11-29 23:10:00', 5.9),
('2016-11-29 23:20:00', 5.9),('2016-11-29 23:30:00', 5.1),('2016-11-29 23:40:00', 5.8),('2016-11-29 23:50:00', 6.0),
('2016-11-30 00:00:00', 5.9),('2016-11-30 00:10:00', 5.3),('2016-11-30 00:20:00', 5.4),('2016-11-30 00:30:00', 5.1),
('2016-11-30 00:40:00', 5.6),('2016-11-30 00:50:00', 5.7),('2016-11-30 01:00:00', 5.8),('2016-11-30 01:10:00', 5.4),
('2016-11-30 01:20:00', 5.8),('2016-11-30 01:30:00', 5.1),('2016-11-30 01:40:00', 5.6),('2016-11-30 01:50:00', 5.6),
('2016-11-30 02:00:00', 5.6),('2016-11-30 02:10:00', 5.9),('2016-11-30 02:20:00', 5.7),('2016-11-30 02:30:00', 5.4),
('2016-11-30 02:40:00', 5.6),('2016-11-30 02:50:00', 5.4),('2016-11-30 03:00:00', 5.1),('2016-11-30 03:10:00', 5.0),
('2016-11-30 03:20:00', 5.9),('2016-11-30 03:30:00', 5.8),('2016-11-30 03:40:00', 5.4),('2016-11-30 03:50:00', 5.7),
('2016-11-30 04:00:00', 5.6),('2016-11-30 04:10:00', 5.9),('2016-11-30 04:20:00', 5.1),('2016-11-30 04:30:00', 5.8),
('2016-11-30 04:40:00', 5.5),('2016-11-30 04:50:00', 5.1),('2016-11-30 05:00:00', 5.8),('2016-11-30 05:10:00', 5.5),
('2016-11-30 05:20:00', 5.7),('2016-11-30 05:30:00', 5.2),('2016-11-30 05:40:00', 5.7),('2016-11-30 05:50:00', 6.0),
('2016-11-30 06:00:00', 5.8),('2016-11-30 06:10:00', 5.6),('2016-11-30 06:20:00', 5.2),('2016-11-30 06:30:00', 5.8),
('2016-11-30 06:40:00', 5.3),('2016-11-30 06:50:00', 5.4),('2016-11-30 07:00:00', 5.8),('2016-11-30 07:10:00', 5.2),
('2016-11-30 07:20:00', 5.3),('2016-11-30 07:30:00', 5.3),('2016-11-30 07:40:00', 5.8),('2016-11-30 07:50:00', 5.9),
('2016-11-30 08:00:00', 5.6),('2016-11-30 08:10:00', 5.2),('2016-11-30 08:20:00', 5.4),('2016-11-30 08:30:00', 5.6),
('2016-11-30 08:40:00', 6.0),('2016-11-30 08:50:00', 5.4),('2016-11-30 09:00:00', 6.0),('2016-11-30 09:10:00', 5.1),
('2016-11-30 09:20:00', 5.1),('2016-11-30 09:30:00', 5.5),('2016-11-30 09:40:00', 5.6),('2016-11-30 09:50:00', 5.0),
('2016-11-30 10:00:00', 5.1),('2016-11-30 10:10:00', 5.7),('2016-11-30 10:20:00', 5.4),('2016-11-30 10:30:00', 5.4),
('2016-11-30 10:40:00', 5.7),('2016-11-30 10:50:00', 5.2),('2016-11-30 11:00:00', 5.4),('2016-11-30 11:10:00', 5.3),
('2016-11-30 11:20:00', 5.6),('2016-11-30 11:30:00', 5.0),('2016-11-30 11:40:00', 5.2),('2016-11-30 11:50:00', 5.2),
('2016-11-30 12:00:00', 5.5),('2016-11-30 12:10:00', 5.1),('2016-11-30 12:20:00', 5.7),('2016-11-30 12:30:00', 5.4),
('2016-11-30 12:40:00', 5.2),('2016-11-30 12:50:00', 5.5),('2016-11-30 13:00:00', 5.0),('2016-11-30 13:10:00', 5.5),
('2016-11-30 13:20:00', 5.6),('2016-11-30 13:30:00', 5.3),('2016-11-30 13:40:00', 5.5),('2016-11-30 13:50:00', 5.9),
('2016-11-30 14:00:00', 10.9),('2016-11-30 14:10:00', 10.6),('2016-11-30 14:20:00', 10.3),('2016-11-30 14:30:00', 11.0),
('2016-11-30 14:40:00', 10.0),('2016-11-30 14:50:00', 10.1),('2016-11-30 15:00:00', 10.2),('2016-11-30 15:10:00', 10.2),
('2016-11-30 15:20:00', 10.3),('2016-11-30 15:30:00', 10.1),('2016-11-30 15:40:00', 10.9),('2016-11-30 15:50:00', 10.1),
('2016-11-30 16:00:00', 11.0),('2016-11-30 16:10:00', 10.2),('2016-11-30 16:20:00', 10.7),('2016-11-30 16:30:00', 10.2),
('2016-11-30 16:40:00', 10.2),('2016-11-30 16:50:00', 10.2),('2016-11-30 17:00:00', 10.8),('2016-11-30 17:10:00', 10.6),
('2016-11-30 17:20:00', 10.5),('2016-11-30 17:30:00', 10.7),('2016-11-30 17:40:00', 10.9),('2016-11-30 17:50:00', 10.9),
('2016-11-30 18:00:00', 10.1),('2016-11-30 18:10:00', 10.3),('2016-11-30 18:20:00', 10.1),('2016-11-30 18:30:00', 10.6),
('2016-11-30 18:40:00', 10.3),('2016-11-30 18:50:00', 10.8),('2016-11-30 19:00:00', 10.9),('2016-11-30 19:10:00', 10.8),
('2016-11-30 19:20:00', 10.6),('2016-11-30 19:30:00', 11.0),('2016-11-30 19:40:00', 10.3),('2016-11-30 19:50:00', 10.9),
('2016-11-30 20:00:00', 10.6),('2016-11-30 20:10:00', 10.6),('2016-11-30 20:20:00', 10.5),('2016-11-30 20:30:00', 10.4),
('2016-11-30 20:40:00', 10.9),('2016-11-30 20:50:00', 10.9),('2016-11-30 21:00:00', 10.7),('2016-11-30 21:10:00', 10.6),
('2016-11-30 21:20:00', 10.5),('2016-11-30 21:30:00', 10.8),('2016-11-30 21:40:00', 10.4),('2016-11-30 21:50:00', 10.0),
('2016-11-30 22:00:00', 10.6),('2016-11-30 22:10:00', 10.6),('2016-11-30 22:20:00', 10.6),('2016-11-30 22:30:00', 10.1),
('2016-11-30 22:40:00', 10.4),('2016-11-30 22:50:00', 10.8),('2016-11-30 23:00:00', 10.4),('2016-11-30 23:10:00', 10.6),
('2016-11-30 23:20:00', 10.1),('2016-11-30 23:30:00', 10.2),('2016-11-30 23:40:00', 10.6),('2016-11-30 23:50:00', 10.8),
('2016-12-01 00:00:00', 10.6),('2016-12-01 00:10:00', 10.2),('2016-12-01 00:20:00', 10.9),('2016-12-01 00:30:00', 10.3),
('2016-12-01 00:40:00', 10.3),('2016-12-01 00:50:00', 10.1),('2016-12-01 01:00:00', 10.7),('2016-12-01 01:10:00', 10.5),
('2016-12-01 01:20:00', 10.4),('2016-12-01 01:30:00', 10.7),('2016-12-01 01:40:00', 10.5),('2016-12-01 01:50:00', 10.7),
('2016-12-01 02:00:00', 10.8),('2016-12-01 02:10:00', 10.9),('2016-12-01 02:20:00', 10.9),('2016-12-01 02:30:00', 10.1),
('2016-12-01 02:40:00', 10.4),('2016-12-01 02:50:00', 10.7),('2016-12-01 03:00:00', 10.7),('2016-12-01 03:10:00', 10.5),
('2016-12-01 03:20:00', 10.2),('2016-12-01 03:30:00', 10.2),('2016-12-01 03:40:00', 10.8),('2016-12-01 03:50:00', 10.2),
('2016-12-01 04:00:00', 10.9),('2016-12-01 04:10:00', 10.4),('2016-12-01 04:20:00', 10.6),('2016-12-01 04:30:00', 11.0),
('2016-12-01 04:40:00', 10.4),('2016-12-01 04:50:00', 10.3),('2016-12-01 05:00:00', 10.7),('2016-12-01 05:10:00', 10.6),
('2016-12-01 05:20:00', 10.9),('2016-12-01 05:30:00', 11.0),('2016-12-01 05:40:00', 10.9),('2016-12-01 05:50:00', 10.0),
('2016-12-01 06:00:00', 10.8),('2016-12-01 06:10:00', 10.0),('2016-12-01 06:20:00', 10.1),('2016-12-01 06:30:00', 10.5),
('2016-12-01 06:40:00', 15.5),('2016-12-01 06:50:00', 15.7),('2016-12-01 07:00:00', 15.1),('2016-12-01 07:10:00', 15.6),
('2016-12-01 07:20:00', 15.5),('2016-12-01 07:30:00', 15.4),('2016-12-01 07:40:00', 15.7),('2016-12-01 07:50:00', 15.6),
('2016-12-01 08:00:00', 15.3),('2016-12-01 08:10:00', 15.6),('2016-12-01 08:20:00', 15.1),('2016-12-01 08:30:00', 15.6),
('2016-12-01 08:40:00', 15.9),('2016-12-01 08:50:00', 16.0),('2016-12-01 09:00:00', 15.4),('2016-12-01 09:10:00', 15.0),
('2016-12-01 09:20:00', 15.0),('2016-12-01 09:30:00', 15.4),('2016-12-01 09:40:00', 15.9),('2016-12-01 09:50:00', 15.6),
('2016-12-01 10:00:00', 15.7),('2016-12-01 10:10:00', 15.4),('2016-12-01 10:20:00', 15.2),('2016-12-01 10:30:00', 15.2),
('2016-12-01 10:40:00', 15.8),('2016-12-01 10:50:00', 15.4),('2016-12-01 11:00:00', 16.0),('2016-12-01 11:10:00', 15.9),
('2016-12-01 11:20:00', 15.1),('2016-12-01 11:30:00', 15.0),('2016-12-01 11:40:00', 15.0),('2016-12-01 11:50:00', 15.4),
('2016-12-01 12:00:00', 15.5),('2016-12-01 12:10:00', 15.3),('2016-12-01 12:20:00', 16.0),('2016-12-01 12:30:00', 15.1),
('2016-12-01 12:40:00', 15.5),('2016-12-01 12:50:00', 16.0),('2016-12-01 13:00:00', 15.7),('2016-12-01 13:10:00', 15.9),
('2016-12-01 13:20:00', 15.4),('2016-12-01 13:30:00', 15.3),('2016-12-01 13:40:00', 15.9),('2016-12-01 13:50:00', 15.8),
('2016-12-01 14:00:00', 15.4),('2016-12-01 14:10:00', 15.9),('2016-12-01 14:20:00', 15.3),('2016-12-01 14:30:00', 16.0),
('2016-12-01 14:40:00', 15.5),('2016-12-01 14:50:00', 15.0),('2016-12-01 15:00:00', 15.1),('2016-12-01 15:10:00', 16.0),
('2016-12-01 15:20:00', 15.8),('2016-12-01 15:30:00', 15.9),('2016-12-01 15:40:00', 15.4),('2016-12-01 15:50:00', 15.1),
('2016-12-01 16:00:00', 15.8),('2016-12-01 16:10:00', 15.2),('2016-12-01 16:20:00', 15.4),('2016-12-01 16:30:00', 15.8),
('2016-12-01 16:40:00', 15.8),('2016-12-01 16:50:00', 15.1),('2016-12-01 17:00:00', 15.3),('2016-12-01 17:10:00', 15.6),
('2016-12-01 17:20:00', 15.3),('2016-12-01 17:30:00', 15.8),('2016-12-01 17:40:00', 15.0),('2016-12-01 17:50:00', 15.3),
('2016-12-01 18:00:00', 15.5),('2016-12-01 18:10:00', 15.4),('2016-12-01 18:20:00', 15.3),('2016-12-01 18:30:00', 15.8),
('2016-12-01 18:40:00', 15.2),('2016-12-01 18:50:00', 15.9),('2016-12-01 19:00:00', 15.4),('2016-12-01 19:10:00', 15.3),
('2016-12-01 19:20:00', 15.1),('2016-12-01 19:30:00', 15.3),('2016-12-01 19:40:00', 15.9),('2016-12-01 19:50:00', 15.3),
('2016-12-01 20:00:00', 15.3),('2016-12-01 20:10:00', 15.2),('2016-12-01 20:20:00', 15.0),('2016-12-01 20:30:00', 15.3),
('2016-12-01 20:40:00', 15.1),('2016-12-01 20:50:00', 15.1),('2016-12-01 21:00:00', 15.6),('2016-12-01 21:10:00', 15.8),
('2016-12-01 21:20:00', 15.4),('2016-12-01 21:30:00', 15.2),('2016-12-01 21:40:00', 16.0),('2016-12-01 21:50:00', 15.5),
('2016-12-01 22:00:00', 15.4),('2016-12-01 22:10:00', 15.7),('2016-12-01 22:20:00', 15.3),('2016-12-01 22:30:00', 15.9),
('2016-12-01 22:40:00', 15.9),('2016-12-01 22:50:00', 15.2),('2016-12-01 23:00:00', 15.8),('2016-12-01 23:10:00', 15.9),
('2016-12-01 23:20:00', 20.9),('2016-12-01 23:30:00', 20.4),('2016-12-01 23:40:00', 20.3),('2016-12-01 23:50:00', 20.1),
('2016-12-02 00:00:00', 20.7),('2016-12-02 00:10:00', 20.7),('2016-12-02 00:20:00', 20.5),('2016-12-02 00:30:00', 20.4),
('2016-12-02 00:40:00', 20.4),('2016-12-02 00:50:00', 20.1),('2016-12-02 01:00:00', 20.2),('2016-12-02 01:10:00', 20.9),
('2016-12-02 01:20:00', 20.6),('2016-12-02 01:30:00', 20.0),('2016-12-02 01:40:00', 20.4),('2016-12-02 01:50:00', 20.2),
('2016-12-02 02:00:00', 20.6),('2016-12-02 02:10:00', 20.4),('2016-12-02 02:20:00', 20.5),('2016-12-02 02:30:00', 20.4),
('2016-12-02 02:40:00', 20.5),('2016-12-02 02:50:00', 20.7),('2016-12-02 03:00:00', 20.2),('2016-12-02 03:10:00', 20.2),
('2016-12-02 03:20:00', 20.1),('2016-12-02 03:30:00', 20.5),('2016-12-02 03:40:00', 20.5),('2016-12-02 03:50:00', 20.0),
('2016-12-02 04:00:00', 20.7),('2016-12-02 04:10:00', 20.8),('2016-12-02 04:20:00', 20.6),('2016-12-02 04:30:00', 20.4),
('2016-12-02 04:40:00', 20.5),('2016-12-02 04:50:00', 20.8),('2016-12-02 05:00:00', 20.1),('2016-12-02 05:10:00', 20.9),
('2016-12-02 05:20:00', 20.5),('2016-12-02 05:30:00', 20.4),('2016-12-02 05:40:00', 20.2),('2016-12-02 05:50:00', 20.4),
('2016-12-02 06:00:00', 20.8),('2016-12-02 06:10:00', 20.7),('2016-12-02 06:20:00', 20.9),('2016-12-02 06:30:00', 20.1),
('2016-12-02 06:40:00', 20.3),('2016-12-02 06:50:00', 20.2),('2016-12-02 07:00:00', 20.4),('2016-12-02 07:10:00', 20.7),
('2016-12-02 07:20:00', 20.4),('2016-12-02 07:30:00', 20.8),('2016-12-02 07:40:00', 20.8),('2016-12-02 07:50:00', 20.1),
('2016-12-02 08:00:00', 20.3),('2016-12-02 08:10:00', 20.7),('2016-12-02 08:20:00', 20.9),('2016-12-02 08:30:00', 21.0),
('2016-12-02 08:40:00', 20.2),('2016-12-02 08:50:00', 20.5),('2016-12-02 09:00:00', 20.2),('2016-12-02 09:10:00', 20.8),
('2016-12-02 09:20:00', 20.9),('2016-12-02 09:30:00', 20.5),('2016-12-02 09:40:00', 20.9),('2016-12-02 09:50:00', 20.7),
('2016-12-02 10:00:00', 20.3),('2016-12-02 10:10:00', 21.0),('2016-12-02 10:20:00', 20.5),('2016-12-02 10:30:00', 20.3),
('2016-12-02 10:40:00', 20.2),('2016-12-02 10:50:00', 20.3),('2016-12-02 11:00:00', 20.4),('2016-12-02 11:10:00', 20.4),
('2016-12-02 11:20:00', 21.0),('2016-12-02 11:30:00', 20.3),('2016-12-02 11:40:00', 20.3),('2016-12-02 11:50:00', 20.9),
('2016-12-02 12:00:00', 20.8),('2016-12-02 12:10:00', 20.9),('2016-12-02 12:20:00', 20.7),('2016-12-02 12:30:00', 20.7);
</code></pre> </li>
<li> <p>执行训练操作：</p> <pre><code>SET search_path="$user",public,madlib;
SET behavior_compat_options = 'bind_procedure_searchpath';
select madlib.prophet_fit('public.ts_data', 'public.prophet_model', 
$${'ds': 'date', 'y': 'value'}$$, -- 列名映射， prophet要求时间列名必须为'ds'， 时序值列名'y'
$${'growth': 'linear', 'changepoints': ['2016-11-30 05:40:00']}$$ -- 训练参数组合，如果有多个参数，请用元组方式传入
);</code></pre> <p>查询模型表：</p> <pre>
<code> select id, y_type, params from public.prophet_model;
    
 id |      y_type      |                            params
----+------------------+---------------------------------------------------------------
  1 | double precision | {'changepoints': ['2016-11-30 05:40:00'], 'growth': 'linear'}
</code></pre> <p>在模型表中，记录着训练时间，结果类型，所用参数等。</p> </li>
<li> <p>执行预测操作</p> <pre>
<code>select madlib.prophet_predict('public.prophet_model','public.prophet_output', 10, '10T');
</code></pre> <p>查看预测结果：</p> <pre>
<code>select ds, yhat, yhat_lower, yhat_upper from public.prophet_output;
    
     ds     |     yhat      |  yhat_lower   |  yhat_upper
------------+---------------+---------------+---------------
 2016-12-02 | 20.6943848045 | 17.7671496048 | 23.4160694837
 2016-12-02 | 20.7408355633 | 17.9264413164 | 23.6426403933
 2016-12-02 | 20.7872863221 | 17.9298207895 | 23.4548814727
 2016-12-02 |  20.833737081 |  18.234443228 | 23.5317342873
 2016-12-02 | 20.8801878398 | 18.2471709649 | 23.8345735574
 2016-12-02 | 20.9266385986 | 18.1780101465 |  23.696087927
 2016-12-02 | 20.9730893575 | 18.4292088648 | 23.7209823631
 2016-12-02 | 21.0195401163 | 18.2623494126 | 23.7341427068
 2016-12-02 | 21.0659908751 | 18.1173966769 | 23.7919478206
 2016-12-02 |  21.112441634 | 18.5018042056 | 23.9508963879
(10 rows)</code></pre> <p> </p> </li>
</ol>
<h1 id="常见问题处理-a-name-zh-cn-topic-0300596396-a">五、常见问题处理<a name="ZH-CN_TOPIC_0300596396"></a>
</h1> 
<ul>
<li> <p><strong>问题描述</strong>：编译数据库时，提示python模块，“can not be used when making a shared object；recompile with -fPIC”或者 “libpython22.7.a: could not read symbols: Bad value”。</p> <p><strong>处理方式</strong>：</p> 
  <ol>
<li>请检查python版本和环境变量。</li>
<li>查看是否安装python-devel，或者编译python时，是否启用了–enable-shared。</li>
</ol>
</li>
<li> <p><strong>问题描述</strong>：执行gdb或者gstack命令，报错 “gdb: symbol lookup error: gdb: undefined symbol: PyUnicodeUCS4_FromEncodedObject”。</p> <p><strong>处理方式</strong>：这个问题一般发生在自行编译python2的环境上，Python2在编译安装时可以通过参数 –enable-unicode=ucs2 或 –enable-unicode=ucs4分别指定使用2个字节或者4个字节表示一个unicode字符，python2缺省使用–enable-unicode=ucs2。Python3默认使用4个字节表示一个unicode字符。</p> <p>可以在系统中自带的python2下执行：“import sys；print sys.maxunicode”并查看结果，如果结果是65535，说明系统默认的是ucs2；如果结果是1114111，说明用的ucs4编码。</p> <p>自行编译python2时，如果系统中内置的python2使用的ucs4，系统中的gdb也会依赖ucs4。因此自行编译的python2在configure时，需要添加–enable-unicode=ucs4。</p> </li>
<li> <p><strong>问题描述</strong>：在kmeans等算法里，报错“Data table does not exist”。</p> <p><strong>处理方式</strong>：算法所在的schema和输入表不在一个schema下，可以设置SET behavior_compat_options = 'bind_procedure_searchpath';解决这个问题。</p> </li>
<li> <p><strong>问题描述</strong>：python启动报错，或者import报错。</p> <p><strong>处理方式：</strong></p> 
  <ol>
<li>检查环境变量比如PYTHONHOME，PYTHONPATH。</li>
<li>安装必备依赖包。</li>
</ol>
</li>
<li> <p><strong>问题描述</strong>：Regression等算法报错“ERROR: spiexceptions.UndefinedFunction: operator does not exist: json -&gt;&gt; unknown.”。</p> <p><strong>处理方式</strong>：数据库不支持json导出功能，不支持此功能。</p> </li>
<li> <p><strong>问题描述</strong>：MADlib中进行编译时，如果使用make -sj，会遇到boost相关的报错。例如，“fatal error: boost/mpl/if.hpp: No such file or directory”。</p> <p><strong>处理方式</strong>：非问题，MADlib编译时，会先解压这几个安装包。如果是并行编译，会出现一边编译，一边解压的情况。如果编译用到这个文件，另一边还没有解压完成，会出现这类报错。再次执行make -sj即可解决。</p> </li>
<li> <p><strong>问题描述</strong>：执行./madpack 安装时，遇到报错：“ERROR : Failed to connect to database”。</p> <p><strong>处理方式</strong>：需要排查数据库是否启动，目标库是否存在，数据库端口是否被占用，安装用户是否具有管理员权限。另外执行madpack安装时，IP请使用127.0.0.1，不要使用localhost，否则也会出现连接失败的情况。</p> </li>
</ul>
<p>今天的分享就到这里了，感谢小伙伴的阅读，让我们一起探索数据库前沿知识。</p>
                </div>

		</div>
	</article>
</main>




			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程小白.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://www.w3counter.com/tracker.js?id=150625"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>
	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>