<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<title>2021AIWIN 手写体 OCR 识别竞赛总结（任务一） - 编程小白</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程小白" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程小白</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">2021AIWIN 手写体 OCR 识别竞赛总结（任务一）</h1>
			
		</header>
		<div class="content post__content clearfix">
			


                <div id="content_views" class="markdown_views prism-atelier-sulphurpool-light">
                    
                        
                    
                    <h2>
<a id="2021AIWIN__OCR__0"></a>2021AIWIN 手写体 OCR 识别竞赛总结（任务一）</h2> 
<p>参加了“世界人工智能创新大赛”——手写体 OCR 识别竞赛（任务一），取得了Top1的成绩。下面通过这篇文章来介绍我们队伍的方案。队伍随机组的，有人找我我就加了进来，这是我第一次做OCR相关的项目，所以随意起了个名字。</p> 
<p><img src="https://images2.imgbox.com/0b/48/B8O1NFnv_o.png" alt="image-20220118132446753"></p> 
<h1>
<a id="_6"></a>赛题</h1> 
<p><strong>一、赛题考官</strong></p> 
<p>交通银行</p> 
<p><strong>二、赛题背景</strong></p> 
<p>银行日常业务中涉及到各类凭证的识别录入，例如身份证录入、支票录入、对账单录入等。以往的录入方式主要是以人工录入为主，效率较低，人力成本较高。近几年来，OCR相关技术以其自动执行、人为干预较少等特点正逐步替代传统的人工录入方式。但OCR技术在实际应用中也存在一些问题，在各类凭证字段的识别中，手写体由于其字体差异性大、字数不固定、语义关联性较低、凭证背景干扰等原因，导致OCR识别率准确率不高，需要大量人工校正，对日常的银行录入业务造成了一定的影响。</p> 
<p><strong>三、赛题任务</strong></p> 
<p>本次赛题将提供手写体图像切片数据集，数据集从真实业务场景中，经过切片脱敏得到，参赛队伍通过识别技术，获得对应的识别结果。即：</p> 
<p>输入：手写体图像切片数据集</p> 
<p>输出：对应的识别结果</p> 
<p>赛题在赛程中分设为两个独立任务，各自设定不同条件的训练集、测试集和建模环境，概述如下：</p> 
<p>任务一：提供开放可下载的训练集及测试集，允许线下建模或线上提供 Notebook 环境及 Terminal 容器环境（脱网）建模，输出识别结果完成赛题。</p> 
<p>任务二：提供不可下载的训练集，要求线上通过 Terminal 容器环境（脱网）建模后提交模型，由系统输入测试集（即对选手不可见），输出识别结果完成赛题。</p> 
<p>上述两个任务的更具体情况请参见第五节赛题赛程的详细说明。</p> 
<p><strong>四、赛题数据</strong></p> 
<p><strong>A.</strong> <strong>数据规模和内容覆盖</strong></p> 
<table>
<thead><tr>
<th></th>
<th>任务一</th>
<th>任务二</th>
</tr></thead>
<tbody>
<tr>
<td>训练集（含验证集，请自行划分）</td>
<td>8 千张图像，包含年份、金额2种信息</td>
<td>3 万张图像，包含银行名称、年份、月份、日期、金额5 种信息。</td>
</tr>
<tr>
<td>测试集</td>
<td>2 千张图像</td>
<td>设定 AB榜：A 榜：5 千张图像B 榜：5 千张图像</td>
</tr>
</tbody>
</table>
<p>B.<strong>数据内容示例：</strong></p> 
<p>原始手写体图像共分为三类，分别涉及银行名称、年月日、金额三大类，分别示意如下：</p> 
<p><img src="https://images2.imgbox.com/86/66/szX7aqki_o.png" alt="img"></p> 
<p>相应图片切片中可能混杂有一定量的干扰信息，分别示例如下；</p> 
<p><img src="https://images2.imgbox.com/b8/c5/RwMZziQm_o.png" alt="img"></p> 
<p>识别结果 JSON 在训练集中的格式如下（<strong>请注意选手提交的结果文件</strong> <strong>JSON</strong> <strong>和训练集中的</strong> <strong>JSON</strong> <strong>格式不同</strong>）：</p> 
<p>json 文件内容规范：</p> 
<p>{<!-- --></p> 
<p>“image1”: “陆万捌千零贰拾伍元整”,</p> 
<p>“image2”: “付经管院工资”,</p> 
<p>“image3”: “”,</p> 
<p>…</p> 
<p>}</p> 
<p><strong>五、赛题赛程和提交要求</strong></p> 
<p>本赛题共分成三个大阶段：</p> 
<p>线上比赛（包含任务一和任务二） ———— 解决方案复审 ———— 终选答辩</p> 
<p>赛程总览示意如下：</p> 
<p><img src="https://images2.imgbox.com/7a/f9/CttMp2uZ_o.png" alt="img"></p> 
<h1>
<a id="_87"></a>具体方案</h1> 
<p>通过在网上查阅资料，得知OCR比赛最常用的模型是CRNN+CTC。所以我最开始也是采用这个方案。</p> 
<p><img src="https://images2.imgbox.com/42/a1/FC7RyRbt_o.png" alt="image-20220118133621906"></p> 
<p>上图是我找到的资料，有好多个版本。因为是第一次做OCR的项目，所以我优先选择有数据集的项目，这样可以快速的了解模型的输入输出。</p> 
<p>所以我选择的第一个Attention_ocr.pytorch-master.zip，从名字上可以看出这个是加入注意力机制，感觉效果会好一些。</p> 
<h2>
<a id="_97"></a>构建数据集</h2> 
<p>下图是Attention_ocr.pytorch-master.zip自带的数据集截图，从截图上可以看出，数据的格式：“图片路径+空格+标签”。我们也需要按照这样的格式构建数据集。</p> 
<p><img src="https://images2.imgbox.com/ac/d0/NgVHZe0Z_o.png" alt="image-20220118134943952"></p> 
<p>新建makedata.py文件，插入下面的代码。</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> os
<span class="token keyword">import</span> json
<span class="token comment">#官方给的数据集</span>
image_path_amount <span class="token operator">=</span> <span class="token string">"./data/train/amount/images"</span> 
image_path_date <span class="token operator">=</span> <span class="token string">"./data/train/date/images"</span>
<span class="token comment">#增强数据集</span>
image_path_test<span class="token operator">=</span><span class="token string">'./data/gan_test_15000/images/0'</span>
image_path_train<span class="token operator">=</span><span class="token string">'./data/gan_train_15500_0/images/0'</span>
amount_list <span class="token operator">=</span> os<span class="token punctuation">.</span>listdir<span class="token punctuation">(</span>image_path_amount<span class="token punctuation">)</span>
amount_list <span class="token operator">=</span> os<span class="token punctuation">.</span>listdir<span class="token punctuation">(</span>image_path_amount<span class="token punctuation">)</span>

new_amount_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
<span class="token keyword">for</span> filename <span class="token keyword">in</span> amount_list<span class="token punctuation">:</span>
    new_amount_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>image_path_amount <span class="token operator">+</span> <span class="token string">"/"</span> <span class="token operator">+</span> filename<span class="token punctuation">)</span>

date_list <span class="token operator">=</span> os<span class="token punctuation">.</span>listdir<span class="token punctuation">(</span>image_path_date<span class="token punctuation">)</span>
new_date_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
<span class="token keyword">for</span> filename <span class="token keyword">in</span> date_list<span class="token punctuation">:</span>
    new_date_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>image_path_date <span class="token operator">+</span> <span class="token string">"/"</span> <span class="token operator">+</span> filename<span class="token punctuation">)</span>
new_test_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
<span class="token keyword">for</span> filename <span class="token keyword">in</span> amount_list<span class="token punctuation">:</span>
    new_test_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>image_path_amount <span class="token operator">+</span> <span class="token string">"/"</span> <span class="token operator">+</span> filename<span class="token punctuation">)</span>

new_train_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
<span class="token keyword">for</span> filename <span class="token keyword">in</span> amount_list<span class="token punctuation">:</span>
    new_train_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>image_path_amount <span class="token operator">+</span> <span class="token string">"/"</span> <span class="token operator">+</span> filename<span class="token punctuation">)</span>

</code></pre> 
<p>image_path_amount和image_path_date是官方给定的数据集路径。</p> 
<p>image_path_test和image_path_train是增强的数据集（在后面会讲如何做增强）</p> 
<p>创建建立list，保存图片的路径。</p> 
<pre><code class="prism language-Python">amount_json = "./data/train/amount/gt.json"
date_json = "./data/train/date/gt.json"
train_json = "train_data.json"
test_json = "test_data.json"
with open(amount_json, "r", encoding='utf-8') as f:
    load_dict_amount = json.load(f)
with open(date_json, "r", encoding='utf-8') as f:
    load_dict_date = json.load(f)
with open(train_json, "r", encoding='utf-8') as f:
    load_dict_train = json.load(f)
with open(test_json, "r", encoding='utf-8') as f:
    load_dict_test = json.load(f)
</code></pre> 
<p>四个json文件对应上面的四个list，json文件存储的是图片的名字和图片的标签，把json解析出来存到字典中。</p> 
<pre><code class="prism language-python"><span class="token comment">#聚合list</span>
all_list <span class="token operator">=</span> new_amount_list <span class="token operator">+</span> new_date_list<span class="token operator">+</span>new_test_list<span class="token operator">+</span>new_train_list
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> train_test_split
<span class="token comment">#切分训练集合和验证集</span>
train_list<span class="token punctuation">,</span> test_list <span class="token operator">=</span> train_test_split<span class="token punctuation">(</span>all_list<span class="token punctuation">,</span> test_size<span class="token operator">=</span><span class="token number">0.15</span><span class="token punctuation">,</span> random_state<span class="token operator">=</span><span class="token number">42</span><span class="token punctuation">)</span>
<span class="token comment">#聚合字典</span>
all_dic <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span><span class="token punctuation">}</span>
all_dic<span class="token punctuation">.</span>update<span class="token punctuation">(</span>load_dict_amount<span class="token punctuation">)</span>
all_dic<span class="token punctuation">.</span>update<span class="token punctuation">(</span>load_dict_date<span class="token punctuation">)</span>
all_dic<span class="token punctuation">.</span>update<span class="token punctuation">(</span>load_dict_train<span class="token punctuation">)</span>
all_dic<span class="token punctuation">.</span>update<span class="token punctuation">(</span>load_dict_test<span class="token punctuation">)</span>
<span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">'train.txt'</span><span class="token punctuation">,</span> <span class="token string">'w'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
    <span class="token keyword">for</span> line <span class="token keyword">in</span> train_list<span class="token punctuation">:</span>
        f<span class="token punctuation">.</span>write<span class="token punctuation">(</span>line <span class="token operator">+</span> <span class="token string">" "</span> <span class="token operator">+</span> all_dic<span class="token punctuation">[</span>line<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">'/'</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token operator">+</span><span class="token string">"n"</span><span class="token punctuation">)</span>
<span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">'val.txt'</span><span class="token punctuation">,</span> <span class="token string">'w'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
    <span class="token keyword">for</span> line <span class="token keyword">in</span> test_list<span class="token punctuation">:</span>
        f<span class="token punctuation">.</span>write<span class="token punctuation">(</span>line <span class="token operator">+</span> <span class="token string">" "</span> <span class="token operator">+</span> all_dic<span class="token punctuation">[</span>line<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">'/'</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token operator">+</span><span class="token string">"n"</span><span class="token punctuation">)</span>
</code></pre> 
<p>将四个list聚合为一个list。</p> 
<p>使用train_test_split切分训练集和验证集。</p> 
<p>聚合字典。</p> 
<p>然后分别遍历trainlist和testlist，将其写入train.txt和val.txt。</p> 
<p>到这里数据集就制作完成了。得到train.txt和val.txt</p> 
<p><img src="https://images2.imgbox.com/8f/81/cAQx0a7m_o.png" alt="image-20220118145805987"></p> 
<p>查看train.txt</p> 
<p><img src="https://images2.imgbox.com/3d/8e/VOshZygU_o.png" alt="image-20220118145909198"></p> 
<p>数据集和自带的数据集格式一样了，然后我们就可以开始训练了。</p> 
<h1>
<a id="class_198"></a>获取class</h1> 
<p>新建getclass.py文件夹，加入以下代码：</p> 
<pre><code>import json

amount_json = "./data/train/amount/gt.json"
date_json = "./data/train/date/gt.json"
with open(amount_json, "r", encoding='utf-8') as f:
    load_dict_amount = json.load(f)
with open(date_json, "r", encoding='utf-8') as f:
    load_dict_date = json.load(f)
all_dic = {}
all_dic.update(load_dict_amount)
all_dic.update(load_dict_date)
list_key=[]
for keyline in all_dic.values():
    for key in keyline:
        if key not in list_key:
            list_key.append(key)
with open('data/char_std_5990.txt', 'w') as f:
    for line in list_key:
        f.write(line+"n")
</code></pre> 
<p>执行完就可以得到存储class的txt文件。打开char_std_5990.txt,看到有21个类。</p> 
<p><img src="https://images2.imgbox.com/16/a8/eFrboq51_o.png" alt="image-20220118152118479"></p> 
<h1>
<a id="_228"></a>改进模型</h1> 
<p>crnn的卷积部分类似VGG，我对模型的改进主要有一下几个方面：</p> 
<p>1、加入激活函数Swish。</p> 
<p>2、加入BatchNorm。</p> 
<p>3、加入SE注意力机制。</p> 
<p>4、适当加深模型。</p> 
<p>代码如下：</p> 
<pre><code>self.cnn = nn.Sequential(
            nn.Conv2d(nc, 64, 3, 1, 1), Swish(), nn.BatchNorm2d(64),
            nn.MaxPool2d(2, 2),  # 64x16x50
            nn.Conv2d(64, 128, 3, 1, 1), Swish(), nn.BatchNorm2d(128),
            nn.MaxPool2d(2, 2),  # 128x8x25
            nn.Conv2d(128, 256, 3, 1, 1), nn.BatchNorm2d(256), Swish(),  # 256x8x25
            nn.Conv2d(256, 256, 3, 1, 1), nn.BatchNorm2d(256), Swish(),  # 256x8x25
            SELayer(256, 16),
            nn.MaxPool2d((2, 2), (2, 1), (0, 1)),  # 256x4x25
            nn.Conv2d(256, 512, 3, 1, 1), nn.BatchNorm2d(512), Swish(),  # 512x4x25
            nn.Conv2d(512, 512, 1), nn.BatchNorm2d(512), Swish(),
            nn.Conv2d(512, 512, 3, 1, 1), nn.BatchNorm2d(512), Swish(),  # 512x4x25
            SELayer(512, 16),
            nn.MaxPool2d((2, 2), (2, 1), (0, 1)),  # 512x2x25
            nn.Conv2d(512, 512, 2, 1, 0), nn.BatchNorm2d(512), Swish())  # 512x1x25
</code></pre> 
<p>SE和Swish</p> 
<pre><code class="prism language-Python">class SELayer(nn.Module):
    def __init__(self, channel, reduction=16):
        super(SELayer, self).__init__()
        self.avg_pool = nn.AdaptiveAvgPool2d(1)
        self.fc = nn.Sequential(
            nn.Linear(channel, channel // reduction, bias=True),
            nn.LeakyReLU(inplace=True),
            nn.Linear(channel // reduction, channel, bias=True),
            nn.Sigmoid()
        )

    def forward(self, x):
        b, c, _, _ = x.size()
        y = self.avg_pool(x).view(b, c)
        y = self.fc(y).view(b, c, 1, 1)
        return x * y.expand_as(x)

class Swish(nn.Module):
    def forward(self, x):
        return x * torch.sigmoid(x)
</code></pre> 
<h2>
<a id="_285"></a>训练</h2> 
<p>打开train.py ,在训练之前，我们还要调节一下参数。</p> 
<pre><code class="prism language-python">parser <span class="token operator">=</span> argparse<span class="token punctuation">.</span>ArgumentParser<span class="token punctuation">(</span><span class="token punctuation">)</span>
parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--trainlist'</span><span class="token punctuation">,</span>  default<span class="token operator">=</span><span class="token string">'train.txt'</span><span class="token punctuation">)</span>
parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--vallist'</span><span class="token punctuation">,</span>  default<span class="token operator">=</span><span class="token string">'val.txt'</span><span class="token punctuation">)</span>
parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--workers'</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'number of data loading workers'</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--batchSize'</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'input batch size'</span><span class="token punctuation">)</span>
parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--imgH'</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'the height of the input image to network'</span><span class="token punctuation">)</span>
parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--imgW'</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'the width of the input image to network'</span><span class="token punctuation">)</span>
parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--nh'</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'size of the lstm hidden state'</span><span class="token punctuation">)</span>
parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--niter'</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">300</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'number of epochs to train for'</span><span class="token punctuation">)</span>
parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--lr'</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">float</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">0.00005</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'learning rate for Critic, default=0.00005'</span><span class="token punctuation">)</span>
parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--beta1'</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">float</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'beta1 for adam. default=0.5'</span><span class="token punctuation">)</span>
parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--cuda'</span><span class="token punctuation">,</span> action<span class="token operator">=</span><span class="token string">'store_true'</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'enables cuda'</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--ngpu'</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'number of GPUs to use'</span><span class="token punctuation">)</span>
parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--encoder'</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">str</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token string">''</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">"path to encoder (to continue training)"</span><span class="token punctuation">)</span>
parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--decoder'</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">str</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token string">''</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'path to decoder (to continue training)'</span><span class="token punctuation">)</span>
parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--experiment'</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token string">'./expr/attentioncnn'</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'Where to store samples and models'</span><span class="token punctuation">)</span>
parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--displayInterval'</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'Interval to be displayed'</span><span class="token punctuation">)</span>
parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--valInterval'</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'Interval to be displayed'</span><span class="token punctuation">)</span>
parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--saveInterval'</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'Interval to be displayed'</span><span class="token punctuation">)</span>
parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--adam'</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> action<span class="token operator">=</span><span class="token string">'store_true'</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'Whether to use adam (default is rmsprop)'</span><span class="token punctuation">)</span>
parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--adadelta'</span><span class="token punctuation">,</span> action<span class="token operator">=</span><span class="token string">'store_true'</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'Whether to use adadelta (default is rmsprop)'</span><span class="token punctuation">)</span>
parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--keep_ratio'</span><span class="token punctuation">,</span>default<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> action<span class="token operator">=</span><span class="token string">'store_true'</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'whether to keep ratio for image resize'</span><span class="token punctuation">)</span>
parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--random_sample'</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> action<span class="token operator">=</span><span class="token string">'store_true'</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'whether to sample the dataset with random sampler'</span><span class="token punctuation">)</span>
parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--teaching_forcing_prob'</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">float</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'where to use teach forcing'</span><span class="token punctuation">)</span>
parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--max_width'</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">129</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'the width of the featuremap out from cnn'</span><span class="token punctuation">)</span>
parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">"--output_file"</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token string">'deep_model.log'</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">str</span><span class="token punctuation">,</span> required<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
opt <span class="token operator">=</span> parser<span class="token punctuation">.</span>parse_args<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<p>trainlist：训练集，默认是train.txt。</p> 
<p>vallist：验证集路径，默认是val.txt。</p> 
<p>batchSize：批大小，根据显存大小设置。</p> 
<p>imgH：图片的高度，crnn模型默认为32，这里不需要修改。</p> 
<p>imgW：图片宽度，我在这里设置为512。</p> 
<p>keep_ratio：设置为True，设置为True后，程序会保持图片的比率，然后在一个batch内统一尺寸，这样训练的模型精度更高。</p> 
<p>lr：学习率，设置为0.00005，这里要注意，不要太大，否则不收敛。</p> 
<p>其他的参数就不一一介绍了，大家可以自行尝试。</p> 
<p>运行结果：</p> 
<p><img src="https://images2.imgbox.com/f0/7a/VTtpWbb4_o.png" alt="image-20220118161714707"></p> 
<p>训练完成后，可以在expr文件夹下面找到模型。</p> 
<p><img src="https://images2.imgbox.com/03/e0/rQcCDztK_o.png" alt="image-20220118161851392"></p> 
<h2>
<a id="_343"></a>推理</h2> 
<p>在推理之前，我们还需要确认最长的字符串，新建getmax.py,添加如下代码：</p> 
<pre><code class="prism language-Python">import os
import json

image_path_amount = "./data/train/amount/images"
image_path_date = "./data/train/date/images"
amount_list = os.listdir(image_path_amount)
new_amount_list = []
for filename in amount_list:
    new_amount_list.append(image_path_amount + "/" + filename)
date_list = os.listdir(image_path_date)
new_date_list = []
for filename in date_list:
    new_date_list.append(image_path_date + "/" + filename)
amount_json = "./data/train/amount/gt.json"
date_json = "./data/train/date/gt.json"
with open(amount_json, "r", encoding='utf-8') as f:
    load_dict_amount = json.load(f)
with open(date_json, "r", encoding='utf-8') as f:
    load_dict_date = json.load(f)
all_list = new_amount_list + new_date_list
from sklearn.model_selection import train_test_split

all_dic = {}
all_dic.update(load_dict_amount)
all_dic.update(load_dict_date)

maxLen = 0
for i in all_dic.values():
    if (len(i) &gt; maxLen):
        maxLen = len(i)
print(maxLen)

</code></pre> 
<p>运行结果：28</p> 
<p>将test.py中的max_length设置为28。</p> 
<p>修改模型的路径，包括encoder_path和decoder_path。</p> 
<pre><code>    encoder_path = './expr/attentioncnn/encoder_22.pth'
    decoder_path = './expr/attentioncnn/decoder_22.pth'
</code></pre> 
<p>修改测试集的路径：</p> 
<pre><code class="prism language-Python">    for path in tqdm(glob.glob('./data/测试集/date/images/*.jpg')):
        text, prob = test(path)
        if prob&lt;0.8:
            count+=1
        result_dict[os.path.basename(path)] = {
            'result': text,
            'confidence': prob
        }

    for path in tqdm(glob.glob('./data/测试集/amount/images/*.jpg')):
        text, prob = test(path)
        if prob&lt;0.8:
            count+=1
        result_dict[os.path.basename(path)] = {
            'result': text,
            'confidence': prob
        }
</code></pre> 
<h1>
<a id="_415"></a>数据增强</h1> 
<p>前面提到了数据增强，增强用的百度的StyleText。下载地址：</p> 
<p><a href="https://gitee.com/bossminicat/PaddleOCR">PaddleOCR: PaddleOCR dome (gitee.com)</a></p> 
<h2>
<a id="_425"></a>一、工具简介</h2> 
<p><img src="https://images2.imgbox.com/8f/8e/QPLnWGn3_o.png" alt="3"></p> 
<p><img src="https://images2.imgbox.com/a1/f8/ldCR0Qpf_o.png" alt="1"></p> 
<p>Style-Text数据合成工具是基于百度和华科合作研发的文本编辑算法《Editing Text in the Wild》https://arxiv.org/abs/1908.03047</p> 
<p>不同于常用的基于GAN的数据合成工具，Style-Text主要框架包括：1.文本前景风格迁移模块 2.背景抽取模块 3.融合模块。经过这样三步，就可以迅速实现图像文本风格迁移。下图是一些该数据合成工具效果图。</p> 
<p><img src="https://images2.imgbox.com/32/2c/C8mWPGNh_o.png" alt="2"></p> 
<h2>
<a id="_439"></a>二、环境配置</h2> 
<ol>
<li>安装PaddleOCR。</li>
<li>进入<code>StyleText</code>目录，下载模型，并解压：</li>
</ol> 
<pre><code class="prism language-bash"><span class="token builtin class-name">cd</span> StyleText
<span class="token function">wget</span> https://paddleocr.bj.bcebos.com/dygraph_v2.0/style_text/style_text_models.zip
<span class="token function">unzip</span> style_text_models.zip
</code></pre> 
<p>如果您将模型保存再其他位置，请在<code>configs/config.yml</code>中修改模型文件的地址，修改时需要同时修改这三个配置：</p> 
<pre><code>bg_generator:
  pretrain: style_text_models/bg_generator
...
text_generator:
  pretrain: style_text_models/text_generator
...
fusion_generator:
  pretrain: style_text_models/fusion_generator
</code></pre> 
<h2>
<a id="_463"></a>三、快速上手</h2> 
<h2>
<a id="_465"></a>合成单张图</h2> 
<p>输入一张风格图和一段文字语料，运行tools/synth_image，合成单张图片，结果图像保存在当前目录下：</p> 
<pre><code class="prism language-python">python3 tools<span class="token operator">/</span>synth_image<span class="token punctuation">.</span>py <span class="token operator">-</span>c configs<span class="token operator">/</span>config<span class="token punctuation">.</span>yml <span class="token operator">-</span><span class="token operator">-</span>style_image examples<span class="token operator">/</span>style_images<span class="token operator">/</span><span class="token number">2.</span>jpg <span class="token operator">-</span><span class="token operator">-</span>text_corpus PaddleOCR <span class="token operator">-</span><span class="token operator">-</span>language en
</code></pre> 
<ul>
<li>注1：语言选项和语料相对应，目前支持英文(en)、简体中文(ch)和韩语(ko)。</li>
<li>注2：Style-Text生成的数据主要应用于OCR识别场景。基于当前PaddleOCR识别模型的设计，我们主要支持高度在32左右的风格图像。<br> 如果输入图像尺寸相差过多，效果可能不佳。</li>
<li>注3：可以通过修改配置文件<code>configs/config.yml</code>中的<code>use_gpu</code>(true或者false)参数来决定是否使用GPU进行预测。</li>
</ul> 
<p>例如，输入如下图片和语料"PaddleOCR":</p> 
<p><img src="https://images2.imgbox.com/8b/93/px8Rkhl1_o.png" alt="img"></p> 
<p>生成合成数据<code>fake_fusion.jpg</code>：</p> 
<p><img src="https://images2.imgbox.com/3f/42/UCwAqANZ_o.png" alt="img"></p> 
<p>除此之外，程序还会生成并保存中间结果<code>fake_bg.jpg</code>：为风格参考图去掉文字后的背景；</p> 
<p><img src="https://images2.imgbox.com/77/ba/zUWStbQf_o.png" alt="img"></p> 
<p><code>fake_text.jpg</code>：是用提供的字符串，仿照风格参考图中文字的风格，生成在灰色背景上的文字图片。</p> 
<p><img src="https://images2.imgbox.com/da/d4/oWMim8Q0_o.png" alt="img"></p> 
<h3>
<a id="_498"></a>批量合成</h3> 
<p>在实际应用场景中，经常需要批量合成图片，补充到训练集中。Style-Text可以使用一批风格图片和语料，批量合成数据。合成过程如下：</p> 
<ol><li> <p>在<code>configs/dataset_config.yml</code>中配置目标场景风格图像和语料的路径，具体如下：</p> 
  <ul>
<li>
<code>Global</code>： 
    <ul><li>
<code>output_dir:</code>：保存合成数据的目录。</li></ul> </li>
<li>
<code>StyleSampler</code>： 
    <ul>
<li>
<code>image_home</code>：风格图片目录；</li>
<li>
<code>label_file</code>：风格图片路径列表文件，如果所用数据集有label，则label_file为label文件路径；</li>
<li>
<code>with_label</code>：标志<code>label_file</code>是否为label文件。</li>
</ul> </li>
<li>
<code>CorpusGenerator</code>： 
    <ul>
<li>
<code>method</code>：语料生成方法，目前有<code>FileCorpus</code>和<code>EnNumCorpus</code>可选。如果使用<code>EnNumCorpus</code>，则不需要填写其他配置，否则需要修改<code>corpus_file</code>和<code>language</code>；</li>
<li>
<code>language</code>：语料的语种，目前支持英文(en)、简体中文(ch)和韩语(ko)；</li>
<li>
<code>corpus_file</code>: 语料文件路径。语料文件应使用文本文件。语料生成器首先会将语料按行切分，之后每次随机选取一行。</li>
</ul> </li>
</ul> </li></ol> 
<h1>
<a id="_515"></a>完整代码</h1> 
<pre><code> https://download.csdn.net/download/hhhhhhhhhhwwwwwwwwww/76484242
</code></pre>
                </div>
                
                

		</div>
	</article>
</main>




			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程小白.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://www.w3counter.com/tracker.js?id=150625"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>
	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>