<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<title>实验七 循环神经网络（3）LSTM的记忆能力实验 - 编程小白</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程小白" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程小白</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">实验七 循环神经网络（3）LSTM的记忆能力实验</h1>
			
		</header>
		<div class="content post__content clearfix">
			


                <div id="content_views" class="markdown_views prism-atom-one-dark">
                    
                        
                    
                    <p></p>
<div class="toc">
 <h3>目录</h3>
 <ul>
<li>
<ul>
<li><a href="#63_LSTM_2">6.3 LSTM的记忆能力实验</a></li>
<li>
<ul>
<li><a href="#631__12">6.3.1 模型构建</a></li>
<li>
<ul>
<li><a href="#6311_LSTM_15">6.3.1.1 LSTM层</a></li>
<li><a href="#6312__305">6.3.1.2 模型汇总</a></li>
</ul>
    </li>
<li><a href="#632__310">6.3.2 模型训练</a></li>
<li>
<ul>
<li><a href="#6321__311">6.3.2.1 训练指定长度的数字预测模型</a></li>
<li><a href="#6322__673">6.3.2.2 多组训练</a></li>
<li><a href="#6323__858">6.3.2.3 损失曲线展示</a></li>
</ul>
    </li>
<li><a href="#633__901">6.3.3 模型评价</a></li>
<li>
<ul>
<li><a href="#6331__903">6.3.3.1 在测试集上进行模型评价</a></li>
<li><a href="#6332__944">6.3.3.2 模型在不同长度的数据集上的准确率变化图</a></li>
<li><a href="#6333_LSTM_966">6.3.3.3 LSTM模型门状态和单元状态的变化</a></li>
</ul>
   </li>
</ul>
  </li>
</ul>
  </li>
<li><a href="#_1155">思考题</a></li>
<li>
<ul>
<li><a href="#1LSTMSRN_1156">【思考题1】LSTM与SRN实验结果对比，谈谈看法。</a></li>
<li><a href="#2LSTMSRN_1159">【思考题2】LSTM与SRN在不同长度数据集上的准确度对比，谈谈看法。</a></li>
<li><a href="#3LSTM_1162">【思考题3】分析LSTM中单元状态和门数值的变化图，并用自己的话解释该图。</a></li>
<li><a href="#_1165">总结：</a></li>
</ul>
 </li>
</ul>
</div>
<p></p> 
<h2>
<a id="63_LSTM_2"></a>6.3 LSTM的记忆能力实验</h2> 
<p>长短期记忆网络（Long Short-Term Memory Network，LSTM）是一种可以有效缓解长程依赖问题的循环神经网络．LSTM 的特点是引入了一个新的内部状态（Internal State）<span class="katex--inline"><span class="katex"><span class="katex-mathml">
    
     
      
       
        c
       
       
        ∈
       
       
        
         R
        
        
         D
        
       
      
      
       c in mathbb{R}^D
      
     
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.5782em;vertical-align: -0.0391em"></span><span class="mord mathdefault">c</span><span class="mspace" style="margin-right: 0.277778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right: 0.277778em"></span></span><span class="base"><span class="strut" style="height: 0.841331em;vertical-align: 0em"></span><span class="mord"><span class="mord"><span class="mord mathbb">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.841331em"><span class="" style="margin-right: 0.05em"><span class="pstrut" style="height: 2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right: 0.02778em">D</span></span></span></span></span></span></span></span></span></span></span></span> 和门控机制（Gating Mechanism）．不同时刻的内部状态以近似线性的方式进行传递，从而缓解梯度消失或梯度爆炸问题．同时门控机制进行信息筛选，可以有效地增加记忆能力．例如，输入门可以让网络忽略无关紧要的输入信息，遗忘门可以使得网络保留有用的历史信息．在上一节的数字求和任务中，如果模型能够记住前两个非零数字，同时忽略掉一些不重要的干扰信息，那么即时序列很长，模型也有效地进行预测.</p> 
<p>LSTM 模型在第 <span class="katex--inline"><span class="katex"><span class="katex-mathml">
    
     
      
       
        t
       
      
      
       t
      
     
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.61508em;vertical-align: 0em"></span><span class="mord mathdefault">t</span></span></span></span></span> 步时，循环单元的内部结构如图6.10所示．</p> 

 <img src="https://images2.imgbox.com/56/5b/lBIFNxNq_o.png" width="700">
 
<br>

 图6.10 LSTM网络的循环单元结构
 
<h3>
<a id="631__12"></a>6.3.1 模型构建</h3> 
<p>在本实验中，我们将使用第6.1.2.4节中定义Model_RNN4SeqClass模型，并构建 LSTM 算子．只需要实例化 LSTM 算，并传入Model_RNN4SeqClass模型，就可以用 LSTM 进行数字求和实验</p> 
<h4>
<a id="6311_LSTM_15"></a>6.3.1.1 LSTM层</h4> 
<p>LSTM层的代码与SRN层结构相似，只是在SRN层的基础上增加了内部状态、输入门、遗忘门和输出门的定义和计算。这里LSTM层的输出也依然为序列的最后一个位置的隐状态向量。代码实现如下：</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F
<span class="token keyword">import</span> torch
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn

<span class="token comment"># 声明LSTM和相关参数</span>
<span class="token keyword">class</span> <span class="token class-name">LSTM</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> input_size<span class="token punctuation">,</span> hidden_size<span class="token punctuation">,</span> Wi_attr<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> Wf_attr<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> Wo_attr<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> Wc_attr<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span>
                 Ui_attr<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> Uf_attr<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> Uo_attr<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> Uc_attr<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> bi_attr<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> bf_attr<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span>
                 bo_attr<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> bc_attr<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>LSTM<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>input_size <span class="token operator">=</span> input_size
        self<span class="token punctuation">.</span>hidden_size <span class="token operator">=</span> hidden_size

        <span class="token comment"># 初始化模型参数</span>
        <span class="token keyword">if</span> Wi_attr<span class="token operator">==</span><span class="token boolean">None</span><span class="token punctuation">:</span>
             Wi<span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>size<span class="token operator">=</span><span class="token punctuation">[</span>input_size<span class="token punctuation">,</span> hidden_size<span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
             Wi <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>Wi_attr<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>W_i <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>Wi<span class="token punctuation">)</span>

        <span class="token keyword">if</span> Wf_attr<span class="token operator">==</span><span class="token boolean">None</span><span class="token punctuation">:</span>
             Wf<span class="token operator">=</span>torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>size<span class="token operator">=</span><span class="token punctuation">[</span>input_size<span class="token punctuation">,</span> hidden_size<span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
             Wf <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>Wf_attr<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>W_f <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>Wf<span class="token punctuation">)</span>

        <span class="token keyword">if</span> Wo_attr<span class="token operator">==</span><span class="token boolean">None</span><span class="token punctuation">:</span>
             Wo<span class="token operator">=</span>torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>size<span class="token operator">=</span><span class="token punctuation">[</span>input_size<span class="token punctuation">,</span> hidden_size<span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
             Wo <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>Wo_attr<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>W_o <span class="token operator">=</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>Wo<span class="token punctuation">)</span>

        <span class="token keyword">if</span> Wc_attr<span class="token operator">==</span><span class="token boolean">None</span><span class="token punctuation">:</span>
            Wc<span class="token operator">=</span>torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>size<span class="token operator">=</span><span class="token punctuation">[</span>input_size<span class="token punctuation">,</span> hidden_size<span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            Wc <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>Wc_attr<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>W_c <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>Wc<span class="token punctuation">)</span>

        <span class="token keyword">if</span> Ui_attr<span class="token operator">==</span><span class="token boolean">None</span><span class="token punctuation">:</span>
            Ui <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>size<span class="token operator">=</span><span class="token punctuation">[</span>hidden_size<span class="token punctuation">,</span> hidden_size<span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            Ui <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>Ui_attr<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>U_i <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>Ui<span class="token punctuation">)</span>
        <span class="token keyword">if</span> Uf_attr <span class="token operator">==</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            Uf <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>size<span class="token operator">=</span><span class="token punctuation">[</span>hidden_size<span class="token punctuation">,</span> hidden_size<span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            Uf <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>Uf_attr<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>U_f <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>Uf<span class="token punctuation">)</span>

        <span class="token keyword">if</span> Uo_attr <span class="token operator">==</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            Uo <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>size<span class="token operator">=</span><span class="token punctuation">[</span>hidden_size<span class="token punctuation">,</span> hidden_size<span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            Uo <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>Uo_attr<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>U_o <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>Uo<span class="token punctuation">)</span>

        <span class="token keyword">if</span> Uc_attr <span class="token operator">==</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            Uc <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>size<span class="token operator">=</span><span class="token punctuation">[</span>hidden_size<span class="token punctuation">,</span> hidden_size<span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            Uc <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>Uc_attr<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>U_c <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>Uc<span class="token punctuation">)</span>

        <span class="token keyword">if</span> bi_attr <span class="token operator">==</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            bi <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>size<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span>hidden_size<span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            bi <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>bi_attr<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>b_i <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>bi<span class="token punctuation">)</span>
        <span class="token keyword">if</span> bf_attr <span class="token operator">==</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            bf <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>size<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span>hidden_size<span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            bf <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>bf_attr<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>b_f <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>bf<span class="token punctuation">)</span>

        <span class="token keyword">if</span> bo_attr <span class="token operator">==</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            bo <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>size<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span>hidden_size<span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            bo <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>bo_attr<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>b_o <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>bo<span class="token punctuation">)</span>
        <span class="token keyword">if</span> bc_attr <span class="token operator">==</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            bc <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>size<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span>hidden_size<span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            bc <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>bc_attr<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>b_c <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>bc<span class="token punctuation">)</span>

    <span class="token comment"># 初始化状态向量和隐状态向量</span>
    <span class="token keyword">def</span> <span class="token function">init_state</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> batch_size<span class="token punctuation">)</span><span class="token punctuation">:</span>
        hidden_state <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>size<span class="token operator">=</span><span class="token punctuation">[</span>batch_size<span class="token punctuation">,</span> self<span class="token punctuation">.</span>hidden_size<span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
        cell_state <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>size<span class="token operator">=</span><span class="token punctuation">[</span>batch_size<span class="token punctuation">,</span> self<span class="token punctuation">.</span>hidden_size<span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
        <span class="token keyword">return</span> hidden_state<span class="token punctuation">,</span> cell_state

    <span class="token comment"># 定义前向计算</span>
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> inputs<span class="token punctuation">,</span> states<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># inputs: 输入数据，其shape为batch_size x seq_len x input_size</span>
        batch_size<span class="token punctuation">,</span> seq_len<span class="token punctuation">,</span> input_size <span class="token operator">=</span> inputs<span class="token punctuation">.</span>shape

        <span class="token comment"># 初始化起始的单元状态和隐状态向量，其shape为batch_size x hidden_size</span>
        <span class="token keyword">if</span> states <span class="token keyword">is</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            states <span class="token operator">=</span> self<span class="token punctuation">.</span>init_state<span class="token punctuation">(</span>batch_size<span class="token punctuation">)</span>
        hidden_state<span class="token punctuation">,</span> cell_state <span class="token operator">=</span> states

        <span class="token comment"># 执行LSTM计算，包括：输入门、遗忘门和输出门、候选内部状态、内部状态和隐状态向量</span>
        <span class="token keyword">for</span> step <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>seq_len<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token comment"># 获取当前时刻的输入数据step_input: 其shape为batch_size x input_size</span>
            step_input <span class="token operator">=</span> inputs<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> step<span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span>
            <span class="token comment"># 计算输入门, 遗忘门和输出门, 其shape为：batch_size x hidden_size</span>
            I_gate <span class="token operator">=</span> F<span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>step_input<span class="token punctuation">,</span> self<span class="token punctuation">.</span>W_i<span class="token punctuation">)</span> <span class="token operator">+</span> torch<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>hidden_state<span class="token punctuation">,</span> self<span class="token punctuation">.</span>U_i<span class="token punctuation">)</span> <span class="token operator">+</span> self<span class="token punctuation">.</span>b_i<span class="token punctuation">)</span>
            F_gate <span class="token operator">=</span> F<span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>step_input<span class="token punctuation">,</span> self<span class="token punctuation">.</span>W_f<span class="token punctuation">)</span> <span class="token operator">+</span> torch<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>hidden_state<span class="token punctuation">,</span> self<span class="token punctuation">.</span>U_f<span class="token punctuation">)</span> <span class="token operator">+</span> self<span class="token punctuation">.</span>b_f<span class="token punctuation">)</span>
            O_gate <span class="token operator">=</span> F<span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>step_input<span class="token punctuation">,</span> self<span class="token punctuation">.</span>W_o<span class="token punctuation">)</span> <span class="token operator">+</span> torch<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>hidden_state<span class="token punctuation">,</span> self<span class="token punctuation">.</span>U_o<span class="token punctuation">)</span> <span class="token operator">+</span> self<span class="token punctuation">.</span>b_o<span class="token punctuation">)</span>
            <span class="token comment"># 计算候选状态向量, 其shape为：batch_size x hidden_size</span>
            C_tilde <span class="token operator">=</span> F<span class="token punctuation">.</span>tanh<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>step_input<span class="token punctuation">,</span> self<span class="token punctuation">.</span>W_c<span class="token punctuation">)</span> <span class="token operator">+</span> torch<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>hidden_state<span class="token punctuation">,</span> self<span class="token punctuation">.</span>U_c<span class="token punctuation">)</span> <span class="token operator">+</span> self<span class="token punctuation">.</span>b_c<span class="token punctuation">)</span>
            <span class="token comment"># 计算单元状态向量, 其shape为：batch_size x hidden_size</span>
            cell_state <span class="token operator">=</span> F_gate <span class="token operator">*</span> cell_state <span class="token operator">+</span> I_gate <span class="token operator">*</span> C_tilde
            <span class="token comment"># 计算隐状态向量，其shape为：batch_size x hidden_size</span>
            hidden_state <span class="token operator">=</span> O_gate <span class="token operator">*</span> F<span class="token punctuation">.</span>tanh<span class="token punctuation">(</span>cell_state<span class="token punctuation">)</span>

        <span class="token keyword">return</span> hidden_state
</code></pre> 
<pre><code class="prism language-python">Wi_attr <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token number">0.2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token number">0.2</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
Wf_attr <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token number">0.2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token number">0.2</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
Wo_attr <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token number">0.2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token number">0.2</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
Wc_attr <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token number">0.2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token number">0.2</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
Ui_attr <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
Uf_attr <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
Uo_attr <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
Uc_attr <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
bi_attr <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token number">0.1</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
bf_attr <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token number">0.1</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
bo_attr <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token number">0.1</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
bc_attr <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token number">0.1</span><span class="token punctuation">]</span><span class="token punctuation">]</span>

lstm <span class="token operator">=</span> LSTM<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> Wi_attr<span class="token operator">=</span>Wi_attr<span class="token punctuation">,</span> Wf_attr<span class="token operator">=</span>Wf_attr<span class="token punctuation">,</span> Wo_attr<span class="token operator">=</span>Wo_attr<span class="token punctuation">,</span> Wc_attr<span class="token operator">=</span>Wc_attr<span class="token punctuation">,</span>
                 Ui_attr<span class="token operator">=</span>Ui_attr<span class="token punctuation">,</span> Uf_attr<span class="token operator">=</span>Uf_attr<span class="token punctuation">,</span> Uo_attr<span class="token operator">=</span>Uo_attr<span class="token punctuation">,</span> Uc_attr<span class="token operator">=</span>Uc_attr<span class="token punctuation">,</span>
                 bi_attr<span class="token operator">=</span>bi_attr<span class="token punctuation">,</span> bf_attr<span class="token operator">=</span>bf_attr<span class="token punctuation">,</span> bo_attr<span class="token operator">=</span>bo_attr<span class="token punctuation">,</span> bc_attr<span class="token operator">=</span>bc_attr<span class="token punctuation">)</span>

inputs <span class="token operator">=</span> torch<span class="token punctuation">.</span>as_tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
hidden_state <span class="token operator">=</span> lstm<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>hidden_state<span class="token punctuation">)</span>

</code></pre> 
<p>运行结果：</p> 
<pre><code>tensor([[0.0594, 0.0952]], grad_fn=&lt;MulBackward0&gt;)
</code></pre> 
<p>这里我们可以将自己实现的SRN和pytorch框架内置的SRN返回的结果进行打印展示，nn.LSTM，实现代码如下。</p> 
<pre><code class="prism language-python"><span class="token comment"># 这里创建一个随机数组作为测试数据，数据shape为batch_size x seq_len x input_size</span>
batch_size<span class="token punctuation">,</span> seq_len<span class="token punctuation">,</span> input_size <span class="token operator">=</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">,</span> <span class="token number">32</span>
inputs <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>size<span class="token operator">=</span><span class="token punctuation">[</span>batch_size<span class="token punctuation">,</span> seq_len<span class="token punctuation">,</span> input_size<span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token comment"># 设置模型的hidden_size</span>
hidden_size <span class="token operator">=</span> <span class="token number">32</span>
torch_lstm <span class="token operator">=</span> nn<span class="token punctuation">.</span>LSTM<span class="token punctuation">(</span>input_size<span class="token punctuation">,</span> hidden_size<span class="token punctuation">)</span>
self_lstm <span class="token operator">=</span> LSTM<span class="token punctuation">(</span>input_size<span class="token punctuation">,</span> hidden_size<span class="token punctuation">)</span>

self_hidden_state <span class="token operator">=</span> self_lstm<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>
torch_outputs<span class="token punctuation">,</span> <span class="token punctuation">(</span>torch_hidden_state<span class="token punctuation">,</span> torch_cell_state<span class="token punctuation">)</span> <span class="token operator">=</span> torch_lstm<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"self_lstm hidden_state: "</span><span class="token punctuation">,</span> self_hidden_state<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"torch_lstm outpus:"</span><span class="token punctuation">,</span> torch_outputs<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"torch_lstm hidden_state:"</span><span class="token punctuation">,</span> torch_hidden_state<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"torch_lstm cell_state:"</span><span class="token punctuation">,</span> torch_cell_state<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
</code></pre> 
<p>运行结果：</p> 
<pre><code>self_lstm hidden_state:  torch.Size([8, 32])
torch_lstm outpus: torch.Size([8, 20, 32])
torch_lstm hidden_state: torch.Size([1, 20, 32])
torch_lstm cell_state: torch.Size([1, 20, 32])
</code></pre> 
<p>可以看到，自己实现的LSTM由于没有考虑多层因素，因此没有层次这个维度，因此其输出shape为[8, 32]。同时由于在以上代码使用Paddle内置API实例化LSTM时，默认定义的是1层的单向SRN，因此其shape为[1, 8, 32]，同时隐状态向量为[8,20, 32].</p> 
<p>在进行实验时，首先定义输入数据<code>inputs</code>，然后将该数据分别传入pytorch内置的LSTM与自己实现的LSTM模型中，最后通过对比两者的隐状态输出向量。代码实现如下：</p> 
<pre><code class="prism language-python">
<span class="token keyword">import</span> torch
torch<span class="token punctuation">.</span>seed<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># 这里创建一个随机数组作为测试数据，数据shape为batch_size x seq_len x input_size</span>
batch_size<span class="token punctuation">,</span> seq_len<span class="token punctuation">,</span> input_size<span class="token punctuation">,</span> hidden_size <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">10</span>
inputs <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token punctuation">[</span>batch_size<span class="token punctuation">,</span> seq_len<span class="token punctuation">,</span> input_size<span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token comment"># 设置模型的hidden_size</span>
torch_lstm <span class="token operator">=</span> nn<span class="token punctuation">.</span>LSTM<span class="token punctuation">(</span>input_size<span class="token punctuation">,</span> hidden_size<span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

<span class="token comment"># 获取torch_lstm中的参数，并设置相应的paramAttr,用于初始化lstm</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>torch_lstm<span class="token punctuation">.</span>weight_ih_l0<span class="token punctuation">.</span>T<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
chunked_W <span class="token operator">=</span> torch<span class="token punctuation">.</span>split<span class="token punctuation">(</span>torch_lstm<span class="token punctuation">.</span>weight_ih_l0<span class="token punctuation">.</span>T<span class="token punctuation">,</span> split_size_or_sections<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
chunked_U <span class="token operator">=</span> torch<span class="token punctuation">.</span>split<span class="token punctuation">(</span>torch_lstm<span class="token punctuation">.</span>weight_hh_l0<span class="token punctuation">.</span>T<span class="token punctuation">,</span> split_size_or_sections<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
chunked_b <span class="token operator">=</span> torch<span class="token punctuation">.</span>split<span class="token punctuation">(</span>torch_lstm<span class="token punctuation">.</span>bias_hh_l0<span class="token punctuation">.</span>T<span class="token punctuation">,</span> split_size_or_sections<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>

Wi_attr <span class="token operator">=</span> chunked_W<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
Wf_attr <span class="token operator">=</span> chunked_W<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>
Wc_attr <span class="token operator">=</span> chunked_W<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span>
Wo_attr <span class="token operator">=</span> chunked_W<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span>
Ui_attr <span class="token operator">=</span> chunked_U<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
Uf_attr <span class="token operator">=</span> chunked_U<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>
Uc_attr <span class="token operator">=</span> chunked_U<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span>
Uo_attr <span class="token operator">=</span> chunked_U<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span>
bi_attr <span class="token operator">=</span> chunked_b<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
bf_attr <span class="token operator">=</span> chunked_b<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>
bc_attr <span class="token operator">=</span> chunked_b<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span>
bo_attr <span class="token operator">=</span> chunked_b<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span>
self_lstm <span class="token operator">=</span> LSTM<span class="token punctuation">(</span>input_size<span class="token punctuation">,</span> hidden_size<span class="token punctuation">,</span> Wi_attr<span class="token operator">=</span>Wi_attr<span class="token punctuation">,</span> Wf_attr<span class="token operator">=</span>Wf_attr<span class="token punctuation">,</span> Wo_attr<span class="token operator">=</span>Wo_attr<span class="token punctuation">,</span> Wc_attr<span class="token operator">=</span>Wc_attr<span class="token punctuation">,</span>
                 Ui_attr<span class="token operator">=</span>Ui_attr<span class="token punctuation">,</span> Uf_attr<span class="token operator">=</span>Uf_attr<span class="token punctuation">,</span> Uo_attr<span class="token operator">=</span>Uo_attr<span class="token punctuation">,</span> Uc_attr<span class="token operator">=</span>Uc_attr<span class="token punctuation">,</span>
                 bi_attr<span class="token operator">=</span>bi_attr<span class="token punctuation">,</span> bf_attr<span class="token operator">=</span>bf_attr<span class="token punctuation">,</span> bo_attr<span class="token operator">=</span>bo_attr<span class="token punctuation">,</span> bc_attr<span class="token operator">=</span>bc_attr<span class="token punctuation">)</span>

<span class="token comment"># 进行前向计算，获取隐状态向量，并打印展示</span>
self_hidden_state <span class="token operator">=</span> self_lstm<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>
torch_outputs<span class="token punctuation">,</span> <span class="token punctuation">(</span>torch_hidden_state<span class="token punctuation">,</span> _<span class="token punctuation">)</span> <span class="token operator">=</span> torch_lstm<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"torch SRN:n"</span><span class="token punctuation">,</span> torch_hidden_state<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"self SRN:n"</span><span class="token punctuation">,</span> self_hidden_state<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<p>运行结果：</p> 
<pre><code>torch SRN:
 [[ 0.18889587  0.22909477 -0.09446836  0.12350862 -0.10332021  0.1447071
  -0.09885797  0.21804206  0.24330382 -0.01940097]
 [ 0.0015913  -0.04910816 -0.20106004  0.05199507  0.0731848  -0.11231253
  -0.16018324  0.02682209  0.05274585 -0.05101069]
 [-0.28802228  0.01322857  0.05574065  0.03401611  0.07091789  0.05456219
  -0.07439326  0.23246141  0.09514102  0.1679858 ]
 [ 0.06339199 -0.17604417 -0.25506425  0.13275442 -0.01235366 -0.01637743
  -0.05622694 -0.02631905 -0.06070121 -0.02347214]
 [-0.16658303 -0.23682319 -0.17211306  0.09990654  0.12816645 -0.22735865
  -0.23990081  0.03094203 -0.05261126  0.03364622]]
self SRN:
 [[-0.02027875 -0.16522248 -0.27700496  0.22390729 -0.16141854 -0.11002751
  -0.26292458 -0.00784523 -0.28317857 -0.00937643]
 [-0.07514299  0.14097507 -0.1628691   0.18740548  0.22439012 -0.11031323
  -0.03122664  0.2146629  -0.05938914 -0.09684459]]
</code></pre> 
<p>可以看到，两者的输出基本是一致的。另外，还可以进行对比两者在运算速度方面的差异。代码实现如下：</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> time

<span class="token comment"># 这里创建一个随机数组作为测试数据，数据shape为batch_size x seq_len x input_size</span>
batch_size<span class="token punctuation">,</span> seq_len<span class="token punctuation">,</span> input_size <span class="token operator">=</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">,</span> <span class="token number">32</span>
inputs <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token punctuation">[</span>batch_size<span class="token punctuation">,</span> seq_len<span class="token punctuation">,</span> input_size<span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token comment"># 设置模型的hidden_size</span>
hidden_size <span class="token operator">=</span> <span class="token number">32</span>
self_lstm <span class="token operator">=</span> LSTM<span class="token punctuation">(</span>input_size<span class="token punctuation">,</span> hidden_size<span class="token punctuation">)</span>
torch_lstm <span class="token operator">=</span> nn<span class="token punctuation">.</span>LSTM<span class="token punctuation">(</span>input_size<span class="token punctuation">,</span> hidden_size<span class="token punctuation">)</span>

<span class="token comment"># 计算自己实现的SRN运算速度</span>
model_time <span class="token operator">=</span> <span class="token number">0</span>
<span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    strat_time <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>
    hidden_state <span class="token operator">=</span> self_lstm<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>
    <span class="token comment"># 预热10次运算，不计入最终速度统计</span>
    <span class="token keyword">if</span> i <span class="token operator">&lt;</span> <span class="token number">10</span><span class="token punctuation">:</span>
        <span class="token keyword">continue</span>
    end_time <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>
    model_time <span class="token operator">+=</span> <span class="token punctuation">(</span>end_time <span class="token operator">-</span> strat_time<span class="token punctuation">)</span>
avg_model_time <span class="token operator">=</span> model_time <span class="token operator">/</span> <span class="token number">90</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'self_lstm speed:'</span><span class="token punctuation">,</span> avg_model_time<span class="token punctuation">,</span> <span class="token string">'s'</span><span class="token punctuation">)</span>

<span class="token comment"># 计算torch内置的SRN运算速度</span>
model_time <span class="token operator">=</span> <span class="token number">0</span>
<span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    strat_time <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>
    outputs<span class="token punctuation">,</span> <span class="token punctuation">(</span>hidden_state<span class="token punctuation">,</span> cell_state<span class="token punctuation">)</span> <span class="token operator">=</span> torch_lstm<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>
    <span class="token comment"># 预热10次运算，不计入最终速度统计</span>
    <span class="token keyword">if</span> i <span class="token operator">&lt;</span> <span class="token number">10</span><span class="token punctuation">:</span>
        <span class="token keyword">continue</span>
    end_time <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>
    model_time <span class="token operator">+=</span> <span class="token punctuation">(</span>end_time <span class="token operator">-</span> strat_time<span class="token punctuation">)</span>
avg_model_time <span class="token operator">=</span> model_time <span class="token operator">/</span> <span class="token number">90</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'torch_lstm speed:'</span><span class="token punctuation">,</span> avg_model_time<span class="token punctuation">,</span> <span class="token string">'s'</span><span class="token punctuation">)</span>
</code></pre> 
<p>运行结果：</p> 
<pre><code>self_lstm speed: 0.005891463491651747 s
torch_lstm speed: 0.001395318243238661 s
</code></pre> 
<p>可以看到，由于pytorch框架的LSTM底层采用了C++实现并进行优化，pytorch框架内置的LSTM运行效率远远高于自己实现的LSTM。</p> 
<h4>
<a id="6312__305"></a>6.3.1.2 模型汇总</h4> 
<p>在本节实验中，我们将使用6.1.2.4的Model_RNN4SeqClass作为预测模型，不同在于在实例化时将传入实例化的LSTM层。</p> 
<blockquote> 
 <p>动手联系6.2 在我们手动实现的LSTM算子中，是逐步计算每个时刻的隐状态。请思考如何实现更加高效的LSTM算子。</p> 
</blockquote> 
<h3>
<a id="632__310"></a>6.3.2 模型训练</h3> 
<h4>
<a id="6321__311"></a>6.3.2.1 训练指定长度的数字预测模型</h4> 
<p>本节将基于RunnerV3类进行训练，首先定义模型训练的超参数，并保证和简单循环网络的超参数一致. 然后定义一个<code>train</code>函数，其可以通过指定长度的数据集，并进行训练. 在<code>train</code>函数中，首先加载长度为<code>length</code>的数据，然后实例化各项组件并创建对应的Runner，然后训练该Runner。同时在本节将使用4.5.4节定义的准确度（Accuracy）作为评估指标，代码实现如下：</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> os
<span class="token keyword">import</span> random
<span class="token keyword">import</span> torch
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np

<span class="token comment"># 训练轮次</span>
num_epochs <span class="token operator">=</span> <span class="token number">500</span>
<span class="token comment"># 学习率</span>
lr <span class="token operator">=</span> <span class="token number">0.001</span>
<span class="token comment"># 输入数字的类别数</span>
num_digits <span class="token operator">=</span> <span class="token number">10</span>
<span class="token comment"># 将数字映射为向量的维度</span>
input_size <span class="token operator">=</span> <span class="token number">32</span>
<span class="token comment"># 隐状态向量的维度</span>
hidden_size <span class="token operator">=</span> <span class="token number">32</span>
<span class="token comment"># 预测数字的类别数</span>
num_classes <span class="token operator">=</span> <span class="token number">19</span>
<span class="token comment"># 批大小 </span>
batch_size <span class="token operator">=</span> <span class="token number">8</span>
<span class="token comment"># 模型保存目录</span>
save_dir <span class="token operator">=</span> <span class="token string">"./checkpoints"</span>

<span class="token comment"># 可以设置不同的length进行不同长度数据的预测实验</span>
<span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span>length<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"n====&gt; Training LSTM with data of length </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>length<span class="token punctuation">}</span></span><span class="token string">."</span></span><span class="token punctuation">)</span>
    np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
    random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>

    <span class="token comment"># 加载长度为length的数据</span>
    data_path <span class="token operator">=</span> <span class="token string-interpolation"><span class="token string">f"./datasets/</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>length<span class="token punctuation">}</span></span><span class="token string">"</span></span>
    train_examples<span class="token punctuation">,</span> dev_examples<span class="token punctuation">,</span> test_examples <span class="token operator">=</span> load_data<span class="token punctuation">(</span>data_path<span class="token punctuation">)</span>
    train_set<span class="token punctuation">,</span> dev_set<span class="token punctuation">,</span> test_set <span class="token operator">=</span> DigitSumDataset<span class="token punctuation">(</span>train_examples<span class="token punctuation">)</span><span class="token punctuation">,</span> DigitSumDataset<span class="token punctuation">(</span>dev_examples<span class="token punctuation">)</span><span class="token punctuation">,</span> DigitSumDataset<span class="token punctuation">(</span>test_examples<span class="token punctuation">)</span>
    train_loader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>train_set<span class="token punctuation">,</span> batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">)</span>
    dev_loader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>dev_set<span class="token punctuation">,</span> batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">)</span>
    test_loader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>test_set<span class="token punctuation">,</span> batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">)</span>
    <span class="token comment"># 实例化模型</span>
    base_model <span class="token operator">=</span> LSTM<span class="token punctuation">(</span>input_size<span class="token punctuation">,</span> hidden_size<span class="token punctuation">)</span>
    model <span class="token operator">=</span> Model_RNN4SeqClass<span class="token punctuation">(</span>base_model<span class="token punctuation">,</span> num_digits<span class="token punctuation">,</span> input_size<span class="token punctuation">,</span> hidden_size<span class="token punctuation">,</span> num_classes<span class="token punctuation">)</span> 
    <span class="token comment"># 指定优化器</span>
    optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>lr<span class="token operator">=</span>lr<span class="token punctuation">,</span> params<span class="token operator">=</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token comment"># 定义评价指标</span>
    metric <span class="token operator">=</span> Accuracy<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment"># 定义损失函数</span>
    loss_fn <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment"># 基于以上组件，实例化Runner</span>
    runner <span class="token operator">=</span> RunnerV3<span class="token punctuation">(</span>model<span class="token punctuation">,</span> optimizer<span class="token punctuation">,</span> loss_fn<span class="token punctuation">,</span> metric<span class="token punctuation">)</span>

    <span class="token comment"># 进行模型训练</span>
    model_save_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>save_dir<span class="token punctuation">,</span> <span class="token string-interpolation"><span class="token string">f"best_lstm_model_</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>length<span class="token punctuation">}</span></span><span class="token string">.pdparams"</span></span><span class="token punctuation">)</span>
    runner<span class="token punctuation">.</span>train<span class="token punctuation">(</span>train_loader<span class="token punctuation">,</span> dev_loader<span class="token punctuation">,</span> num_epochs<span class="token operator">=</span>num_epochs<span class="token punctuation">,</span> eval_steps<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">,</span> log_steps<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">,</span> save_path<span class="token operator">=</span>model_save_path<span class="token punctuation">)</span>

    <span class="token keyword">return</span> runner
</code></pre> 
<p>上面涉及到的代码(放在上面代码的前面)：</p> 
<pre><code class="prism language-python">
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> Dataset<span class="token punctuation">,</span>DataLoader
<span class="token keyword">import</span> torch
<span class="token keyword">class</span> <span class="token class-name">DigitSumDataset</span><span class="token punctuation">(</span>Dataset<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> data<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>data <span class="token operator">=</span> data

    <span class="token keyword">def</span> <span class="token function">__getitem__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> idx<span class="token punctuation">)</span><span class="token punctuation">:</span>
        example <span class="token operator">=</span> self<span class="token punctuation">.</span>data<span class="token punctuation">[</span>idx<span class="token punctuation">]</span>
        seq <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>example<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>int64<span class="token punctuation">)</span>
        label <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>example<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>int64<span class="token punctuation">)</span>
        <span class="token keyword">return</span> seq<span class="token punctuation">,</span> label

    <span class="token keyword">def</span> <span class="token function">__len__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> <span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>data<span class="token punctuation">)</span>

<span class="token keyword">import</span> os
<span class="token comment"># 加载数据</span>
<span class="token keyword">def</span> <span class="token function">load_data</span><span class="token punctuation">(</span>data_path<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># 加载训练集</span>
    train_examples <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    train_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>data_path<span class="token punctuation">,</span> <span class="token string">"train.txt"</span><span class="token punctuation">)</span>
    <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>train_path<span class="token punctuation">,</span> <span class="token string">"r"</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">"utf-8"</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
        <span class="token keyword">for</span> line <span class="token keyword">in</span> f<span class="token punctuation">.</span>readlines<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token comment"># 解析一行数据，将其处理为数字序列seq和标签label</span>
            items <span class="token operator">=</span> line<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">"t"</span><span class="token punctuation">)</span>
            seq <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> items<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">" "</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
            label <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>items<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
            train_examples<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">(</span>seq<span class="token punctuation">,</span> label<span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token comment"># 加载验证集</span>
    dev_examples <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    dev_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>data_path<span class="token punctuation">,</span> <span class="token string">"dev.txt"</span><span class="token punctuation">)</span>
    <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>dev_path<span class="token punctuation">,</span> <span class="token string">"r"</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">"utf-8"</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
        <span class="token keyword">for</span> line <span class="token keyword">in</span> f<span class="token punctuation">.</span>readlines<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token comment"># 解析一行数据，将其处理为数字序列seq和标签label</span>
            items <span class="token operator">=</span> line<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">"t"</span><span class="token punctuation">)</span>
            seq <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> items<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">" "</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
            label <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>items<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
            dev_examples<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">(</span>seq<span class="token punctuation">,</span> label<span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token comment"># 加载测试集</span>
    test_examples <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    test_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>data_path<span class="token punctuation">,</span> <span class="token string">"test.txt"</span><span class="token punctuation">)</span>
    <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>test_path<span class="token punctuation">,</span> <span class="token string">"r"</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">"utf-8"</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
        <span class="token keyword">for</span> line <span class="token keyword">in</span> f<span class="token punctuation">.</span>readlines<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token comment"># 解析一行数据，将其处理为数字序列seq和标签label</span>
            items <span class="token operator">=</span> line<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">"t"</span><span class="token punctuation">)</span>
            seq <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> items<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">" "</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
            label <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>items<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
            test_examples<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">(</span>seq<span class="token punctuation">,</span> label<span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">return</span> train_examples<span class="token punctuation">,</span> dev_examples<span class="token punctuation">,</span> test_examples

<span class="token keyword">class</span> <span class="token class-name">Embedding</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> num_embeddings<span class="token punctuation">,</span> embedding_dim<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>Embedding<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>W <span class="token operator">=</span> nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>xavier_uniform_<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>empty<span class="token punctuation">(</span>num_embeddings<span class="token punctuation">,</span> embedding_dim<span class="token punctuation">)</span><span class="token punctuation">,</span>gain<span class="token operator">=</span><span class="token number">1.0</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> inputs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 根据索引获取对应词向量</span>
        embs <span class="token operator">=</span> self<span class="token punctuation">.</span>W<span class="token punctuation">[</span>inputs<span class="token punctuation">]</span>
        <span class="token keyword">return</span> embs

<span class="token comment"># emb_layer = Embedding(10, 5)</span>
<span class="token comment"># inputs = torch.tensor([0, 1, 2, 3])</span>
<span class="token comment"># emb_layer(inputs)</span>


<span class="token comment"># 基于RNN实现数字预测的模型</span>
<span class="token keyword">class</span> <span class="token class-name">Model_RNN4SeqClass</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> model<span class="token punctuation">,</span> num_digits<span class="token punctuation">,</span> input_size<span class="token punctuation">,</span> hidden_size<span class="token punctuation">,</span> num_classes<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>Model_RNN4SeqClass<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token comment"># 传入实例化的RNN层，例如SRN</span>
        self<span class="token punctuation">.</span>rnn_model <span class="token operator">=</span> model
        <span class="token comment"># 词典大小</span>
        self<span class="token punctuation">.</span>num_digits <span class="token operator">=</span> num_digits
        <span class="token comment"># 嵌入向量的维度</span>
        self<span class="token punctuation">.</span>input_size <span class="token operator">=</span> input_size
        <span class="token comment"># 定义Embedding层</span>
        self<span class="token punctuation">.</span>embedding <span class="token operator">=</span> Embedding<span class="token punctuation">(</span>num_digits<span class="token punctuation">,</span> input_size<span class="token punctuation">)</span>
        <span class="token comment"># 定义线性层</span>
        self<span class="token punctuation">.</span>linear <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>hidden_size<span class="token punctuation">,</span> num_classes<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> inputs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 将数字序列映射为相应向量</span>
        inputs_emb <span class="token operator">=</span> self<span class="token punctuation">.</span>embedding<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>
        <span class="token comment"># 调用RNN模型</span>
        hidden_state <span class="token operator">=</span> self<span class="token punctuation">.</span>rnn_model<span class="token punctuation">(</span>inputs_emb<span class="token punctuation">)</span>
        <span class="token comment"># 使用最后一个时刻的状态进行数字预测</span>
        logits <span class="token operator">=</span> self<span class="token punctuation">.</span>linear<span class="token punctuation">(</span>hidden_state<span class="token punctuation">)</span>
        <span class="token keyword">return</span> logits

<span class="token keyword">class</span> <span class="token class-name">RunnerV3</span><span class="token punctuation">(</span><span class="token builtin">object</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> model<span class="token punctuation">,</span> optimizer<span class="token punctuation">,</span> loss_fn<span class="token punctuation">,</span> metric<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>model <span class="token operator">=</span> model
        self<span class="token punctuation">.</span>optimizer <span class="token operator">=</span> optimizer
        self<span class="token punctuation">.</span>loss_fn <span class="token operator">=</span> loss_fn
        self<span class="token punctuation">.</span>metric <span class="token operator">=</span> metric  <span class="token comment"># 只用于计算评价指标</span>

        <span class="token comment"># 记录训练过程中的评价指标变化情况</span>
        self<span class="token punctuation">.</span>dev_scores <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>

        <span class="token comment"># 记录训练过程中的损失函数变化情况</span>
        self<span class="token punctuation">.</span>train_epoch_losses <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>  <span class="token comment"># 一个epoch记录一次loss</span>
        self<span class="token punctuation">.</span>train_step_losses <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>  <span class="token comment"># 一个step记录一次loss</span>
        self<span class="token punctuation">.</span>dev_losses <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>

        <span class="token comment"># 记录全局最优指标</span>
        self<span class="token punctuation">.</span>best_score <span class="token operator">=</span> <span class="token number">0</span>

    <span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> train_loader<span class="token punctuation">,</span> dev_loader<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 将模型切换为训练模式</span>
        self<span class="token punctuation">.</span>model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>

        <span class="token comment"># 传入训练轮数，如果没有传入值则默认为0</span>
        num_epochs <span class="token operator">=</span> kwargs<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">"num_epochs"</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span>
        <span class="token comment"># 传入log打印频率，如果没有传入值则默认为100</span>
        log_steps <span class="token operator">=</span> kwargs<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">"log_steps"</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">)</span>
        <span class="token comment"># 评价频率</span>
        eval_steps <span class="token operator">=</span> kwargs<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">"eval_steps"</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span>

        <span class="token comment"># 传入模型保存路径，如果没有传入值则默认为"best_model.pdparams"</span>
        save_path <span class="token operator">=</span> kwargs<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">"save_path"</span><span class="token punctuation">,</span> <span class="token string">"best_model.pdparams"</span><span class="token punctuation">)</span>

        custom_print_log <span class="token operator">=</span> kwargs<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">"custom_print_log"</span><span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">)</span>

        <span class="token comment"># 训练总的步数</span>
        num_training_steps <span class="token operator">=</span> num_epochs <span class="token operator">*</span> <span class="token builtin">len</span><span class="token punctuation">(</span>train_loader<span class="token punctuation">)</span>

        <span class="token keyword">if</span> eval_steps<span class="token punctuation">:</span>
            <span class="token keyword">if</span> self<span class="token punctuation">.</span>metric <span class="token keyword">is</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
                <span class="token keyword">raise</span> RuntimeError<span class="token punctuation">(</span><span class="token string">'Error: Metric can not be None!'</span><span class="token punctuation">)</span>
            <span class="token keyword">if</span> dev_loader <span class="token keyword">is</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
                <span class="token keyword">raise</span> RuntimeError<span class="token punctuation">(</span><span class="token string">'Error: dev_loader can not be None!'</span><span class="token punctuation">)</span>

        <span class="token comment"># 运行的step数目</span>
        global_step <span class="token operator">=</span> <span class="token number">0</span>

        <span class="token comment"># 进行num_epochs轮训练</span>
        <span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token comment"># 用于统计训练集的损失</span>
            total_loss <span class="token operator">=</span> <span class="token number">0</span>
            <span class="token keyword">for</span> step<span class="token punctuation">,</span> data <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>train_loader<span class="token punctuation">)</span><span class="token punctuation">:</span>
                X<span class="token punctuation">,</span> y <span class="token operator">=</span> data
                <span class="token comment"># 获取模型预测</span>
                logits <span class="token operator">=</span> self<span class="token punctuation">.</span>model<span class="token punctuation">(</span>X<span class="token punctuation">)</span>
                loss <span class="token operator">=</span> self<span class="token punctuation">.</span>loss_fn<span class="token punctuation">(</span>logits<span class="token punctuation">,</span> y<span class="token punctuation">.</span><span class="token builtin">long</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># 默认求mean</span>
                total_loss <span class="token operator">+=</span> loss

                <span class="token comment"># 训练过程中，每个step的loss进行保存</span>
                self<span class="token punctuation">.</span>train_step_losses<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">(</span>global_step<span class="token punctuation">,</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

                <span class="token keyword">if</span> log_steps <span class="token keyword">and</span> global_step <span class="token operator">%</span> log_steps <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
                    <span class="token keyword">print</span><span class="token punctuation">(</span>
                        <span class="token string-interpolation"><span class="token string">f"[Train] epoch: </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>epoch<span class="token punctuation">}</span></span><span class="token string">/</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>num_epochs<span class="token punctuation">}</span></span><span class="token string">, step: </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>global_step<span class="token punctuation">}</span></span><span class="token string">/</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>num_training_steps<span class="token punctuation">}</span></span><span class="token string">, loss: </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token format-spec">.5f</span><span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>

                <span class="token comment"># 梯度反向传播，计算每个参数的梯度值</span>
                loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>

                <span class="token keyword">if</span> custom_print_log<span class="token punctuation">:</span>
                    custom_print_log<span class="token punctuation">(</span>self<span class="token punctuation">)</span>

                <span class="token comment"># 小批量梯度下降进行参数更新</span>
                self<span class="token punctuation">.</span>optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
                <span class="token comment"># 梯度归零</span>
                self<span class="token punctuation">.</span>optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>

                <span class="token comment"># 判断是否需要评价</span>
                <span class="token keyword">if</span> eval_steps <span class="token operator">&gt;</span> <span class="token number">0</span> <span class="token keyword">and</span> global_step <span class="token operator">&gt;</span> <span class="token number">0</span> <span class="token keyword">and</span> 
                        <span class="token punctuation">(</span>global_step <span class="token operator">%</span> eval_steps <span class="token operator">==</span> <span class="token number">0</span> <span class="token keyword">or</span> global_step <span class="token operator">==</span> <span class="token punctuation">(</span>num_training_steps <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>

                    dev_score<span class="token punctuation">,</span> dev_loss <span class="token operator">=</span> self<span class="token punctuation">.</span>evaluate<span class="token punctuation">(</span>dev_loader<span class="token punctuation">,</span> global_step<span class="token operator">=</span>global_step<span class="token punctuation">)</span>
                    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"[Evaluate]  dev score: </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>dev_score<span class="token punctuation">:</span><span class="token format-spec">.5f</span><span class="token punctuation">}</span></span><span class="token string">, dev loss: </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>dev_loss<span class="token punctuation">:</span><span class="token format-spec">.5f</span><span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>

                    <span class="token comment"># 将模型切换为训练模式</span>
                    self<span class="token punctuation">.</span>model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>

                    <span class="token comment"># 如果当前指标为最优指标，保存该模型</span>
                    <span class="token keyword">if</span> dev_score <span class="token operator">&gt;</span> self<span class="token punctuation">.</span>best_score<span class="token punctuation">:</span>
                        self<span class="token punctuation">.</span>save_model<span class="token punctuation">(</span>save_path<span class="token punctuation">)</span>
                        <span class="token keyword">print</span><span class="token punctuation">(</span>
                            <span class="token string-interpolation"><span class="token string">f"[Evaluate] best accuracy performence has been updated: </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>self<span class="token punctuation">.</span>best_score<span class="token punctuation">:</span><span class="token format-spec">.5f</span><span class="token punctuation">}</span></span><span class="token string"> --&gt; </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>dev_score<span class="token punctuation">:</span><span class="token format-spec">.5f</span><span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>
                        self<span class="token punctuation">.</span>best_score <span class="token operator">=</span> dev_score

                global_step <span class="token operator">+=</span> <span class="token number">1</span>

            <span class="token comment"># 当前epoch 训练loss累计值</span>
            trn_loss <span class="token operator">=</span> <span class="token punctuation">(</span>total_loss <span class="token operator">/</span> <span class="token builtin">len</span><span class="token punctuation">(</span>train_loader<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
            <span class="token comment"># epoch粒度的训练loss保存</span>
            self<span class="token punctuation">.</span>train_epoch_losses<span class="token punctuation">.</span>append<span class="token punctuation">(</span>trn_loss<span class="token punctuation">)</span>

        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"[Train] Training done!"</span><span class="token punctuation">)</span>

    <span class="token comment"># 模型评估阶段，使用'torch.no_grad()'控制不计算和存储梯度</span>
    <span class="token decorator annotation punctuation">@torch<span class="token punctuation">.</span>no_grad</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">def</span> <span class="token function">evaluate</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> dev_loader<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">assert</span> self<span class="token punctuation">.</span>metric <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span>

        <span class="token comment"># 将模型设置为评估模式</span>
        self<span class="token punctuation">.</span>model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>

        global_step <span class="token operator">=</span> kwargs<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">"global_step"</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>

        <span class="token comment"># 用于统计训练集的损失</span>
        total_loss <span class="token operator">=</span> <span class="token number">0</span>

        <span class="token comment"># 重置评价</span>
        self<span class="token punctuation">.</span>metric<span class="token punctuation">.</span>reset<span class="token punctuation">(</span><span class="token punctuation">)</span>

        <span class="token comment"># 遍历验证集每个批次</span>
        <span class="token keyword">for</span> batch_id<span class="token punctuation">,</span> data <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>dev_loader<span class="token punctuation">)</span><span class="token punctuation">:</span>
            X<span class="token punctuation">,</span> y <span class="token operator">=</span> data

            <span class="token comment"># 计算模型输出</span>
            logits <span class="token operator">=</span> self<span class="token punctuation">.</span>model<span class="token punctuation">(</span>X<span class="token punctuation">)</span>

            <span class="token comment"># 计算损失函数</span>
            loss <span class="token operator">=</span> self<span class="token punctuation">.</span>loss_fn<span class="token punctuation">(</span>logits<span class="token punctuation">,</span> y<span class="token punctuation">.</span><span class="token builtin">long</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
            <span class="token comment"># 累积损失</span>
            total_loss <span class="token operator">+=</span> loss

            <span class="token comment"># 累积评价</span>
            self<span class="token punctuation">.</span>metric<span class="token punctuation">.</span>update<span class="token punctuation">(</span>logits<span class="token punctuation">,</span> y<span class="token punctuation">)</span>

        dev_loss <span class="token operator">=</span> <span class="token punctuation">(</span>total_loss <span class="token operator">/</span> <span class="token builtin">len</span><span class="token punctuation">(</span>dev_loader<span class="token punctuation">)</span><span class="token punctuation">)</span>
        dev_score <span class="token operator">=</span> self<span class="token punctuation">.</span>metric<span class="token punctuation">.</span>accumulate<span class="token punctuation">(</span><span class="token punctuation">)</span>

        <span class="token comment"># 记录验证集loss</span>
        <span class="token keyword">if</span> global_step <span class="token operator">!=</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>dev_losses<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">(</span>global_step<span class="token punctuation">,</span> dev_loss<span class="token punctuation">)</span><span class="token punctuation">)</span>
            self<span class="token punctuation">.</span>dev_scores<span class="token punctuation">.</span>append<span class="token punctuation">(</span>dev_score<span class="token punctuation">)</span>

        <span class="token keyword">return</span> dev_score<span class="token punctuation">,</span> dev_loss

    <span class="token comment"># 模型评估阶段，使用'torch.no_grad()'控制不计算和存储梯度</span>
    <span class="token decorator annotation punctuation">@torch<span class="token punctuation">.</span>no_grad</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">def</span> <span class="token function">predict</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 将模型设置为评估模式</span>
        self<span class="token punctuation">.</span>model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token comment"># 运行模型前向计算，得到预测值</span>
        logits <span class="token operator">=</span> self<span class="token punctuation">.</span>model<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token keyword">return</span> logits

    <span class="token keyword">def</span> <span class="token function">save_model</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> save_path<span class="token punctuation">)</span><span class="token punctuation">:</span>
        torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>self<span class="token punctuation">.</span>model<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> save_path<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">load_model</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> model_path<span class="token punctuation">)</span><span class="token punctuation">:</span>
        state_dict <span class="token operator">=</span> torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span>model_path<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>model<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>state_dict<span class="token punctuation">)</span>

<span class="token keyword">class</span> <span class="token class-name">Accuracy</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> is_logist<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 用于统计正确的样本个数</span>
        self<span class="token punctuation">.</span>num_correct <span class="token operator">=</span> <span class="token number">0</span>
        <span class="token comment"># 用于统计样本的总数</span>
        self<span class="token punctuation">.</span>num_count <span class="token operator">=</span> <span class="token number">0</span>

        self<span class="token punctuation">.</span>is_logist <span class="token operator">=</span> is_logist

    <span class="token keyword">def</span> <span class="token function">update</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> outputs<span class="token punctuation">,</span> labels<span class="token punctuation">)</span><span class="token punctuation">:</span>

        <span class="token comment"># 判断是二分类任务还是多分类任务，shape[1]=1时为二分类任务，shape[1]&gt;1时为多分类任务</span>
        <span class="token keyword">if</span> outputs<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">:</span>  <span class="token comment"># 二分类</span>
            outputs <span class="token operator">=</span> torch<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
            <span class="token keyword">if</span> self<span class="token punctuation">.</span>is_logist<span class="token punctuation">:</span>
                <span class="token comment"># logist判断是否大于0</span>
                preds <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">(</span>outputs <span class="token operator">&gt;=</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
            <span class="token keyword">else</span><span class="token punctuation">:</span>
                <span class="token comment"># 如果不是logist，判断每个概率值是否大于0.5，当大于0.5时，类别为1，否则类别为0</span>
                preds <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">(</span>outputs <span class="token operator">&gt;=</span> <span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            <span class="token comment"># 多分类时，使用'torch.argmax'计算最大元素索引作为类别</span>
            preds <span class="token operator">=</span> torch<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>

        <span class="token comment"># 获取本批数据中预测正确的样本个数</span>
        labels <span class="token operator">=</span> torch<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span>labels<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
        batch_correct <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>preds <span class="token operator">==</span> labels<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>
        batch_count <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>labels<span class="token punctuation">)</span>

        <span class="token comment"># 更新num_correct 和 num_count</span>
        self<span class="token punctuation">.</span>num_correct <span class="token operator">+=</span> batch_correct
        self<span class="token punctuation">.</span>num_count <span class="token operator">+=</span> batch_count

    <span class="token keyword">def</span> <span class="token function">accumulate</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 使用累计的数据，计算总的指标</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>num_count <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
            <span class="token keyword">return</span> <span class="token number">0</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>num_correct <span class="token operator">/</span> self<span class="token punctuation">.</span>num_count

    <span class="token keyword">def</span> <span class="token function">reset</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 重置正确的数目和总数</span>
        self<span class="token punctuation">.</span>num_correct <span class="token operator">=</span> <span class="token number">0</span>
        self<span class="token punctuation">.</span>num_count <span class="token operator">=</span> <span class="token number">0</span>

    <span class="token keyword">def</span> <span class="token function">name</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> <span class="token string">"Accuracy"</span>



</code></pre> 
<h4>
<a id="6322__673"></a>6.3.2.2 多组训练</h4> 
<p>接下来，分别进行数据长度为10, 15, 20, 25, 30, 35的数字预测模型训练实验，训练后的<code>runner</code>保存至<code>runners</code>字典中。</p> 
<pre><code class="prism language-python">lstm_runners <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span><span class="token punctuation">}</span>

lengths <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">15</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">,</span> <span class="token number">25</span><span class="token punctuation">,</span> <span class="token number">30</span><span class="token punctuation">,</span> <span class="token number">35</span><span class="token punctuation">]</span>
<span class="token keyword">for</span> length <span class="token keyword">in</span> lengths<span class="token punctuation">:</span>
    runner <span class="token operator">=</span> train<span class="token punctuation">(</span>length<span class="token punctuation">)</span>
    lstm_runners<span class="token punctuation">[</span>length<span class="token punctuation">]</span> <span class="token operator">=</span> runner
</code></pre> 
<p>运行结果(部分展示)：</p> 
<pre><code>[Evaluate]  dev score: 0.88000, dev loss: 0.65520
[Evaluate] best accuracy performence has been updated: 0.87000 --&gt; 0.88000
[Train] epoch: 471/500, step: 17900/19000, loss: 0.00103
[Evaluate]  dev score: 0.88000, dev loss: 0.65717
[Train] epoch: 473/500, step: 18000/19000, loss: 0.00156
[Evaluate]  dev score: 0.88000, dev loss: 0.66018
[Train] epoch: 476/500, step: 18100/19000, loss: 0.00158
[Evaluate]  dev score: 0.88000, dev loss: 0.66119
[Train] epoch: 478/500, step: 18200/19000, loss: 0.00255
[Evaluate]  dev score: 0.88000, dev loss: 0.66236
[Train] epoch: 481/500, step: 18300/19000, loss: 0.00080
[Evaluate]  dev score: 0.88000, dev loss: 0.66521
[Train] epoch: 484/500, step: 18400/19000, loss: 0.00103
[Evaluate]  dev score: 0.88000, dev loss: 0.66682
[Train] epoch: 486/500, step: 18500/19000, loss: 0.00131
[Evaluate]  dev score: 0.88000, dev loss: 0.66822
[Train] epoch: 489/500, step: 18600/19000, loss: 0.00166
[Evaluate]  dev score: 0.88000, dev loss: 0.67098
[Train] epoch: 492/500, step: 18700/19000, loss: 0.00124
[Evaluate]  dev score: 0.88000, dev loss: 0.67337
[Train] epoch: 494/500, step: 18800/19000, loss: 0.00105
[Evaluate]  dev score: 0.88000, dev loss: 0.67340
[Train] epoch: 497/500, step: 18900/19000, loss: 0.00069
[Evaluate]  dev score: 0.88000, dev loss: 0.67506
[Evaluate]  dev score: 0.88000, dev loss: 0.67903
[Train] Training done!
</code></pre> 
<pre><code>[Train] epoch: 376/500, step: 14300/19000, loss: 0.03295
[Evaluate]  dev score: 0.86000, dev loss: 0.77074
[Evaluate] best accuracy performence has been updated: 0.85000 --&gt; 0.86000
[Train] epoch: 378/500, step: 14400/19000, loss: 0.02419
[Evaluate]  dev score: 0.86000, dev loss: 0.76510
[Train] epoch: 381/500, step: 14500/19000, loss: 0.02038
[Evaluate]  dev score: 0.86000, dev loss: 0.75816
[Train] epoch: 384/500, step: 14600/19000, loss: 0.03184
[Evaluate]  dev score: 0.86000, dev loss: 0.75432
[Train] epoch: 386/500, step: 14700/19000, loss: 0.01263
[Evaluate]  dev score: 0.85000, dev loss: 0.75332
[Train] epoch: 389/500, step: 14800/19000, loss: 0.01752
[Evaluate]  dev score: 0.85000, dev loss: 0.75455
[Train] epoch: 392/500, step: 14900/19000, loss: 0.02649
[Evaluate]  dev score: 0.85000, dev loss: 0.75574
[Train] epoch: 394/500, step: 15000/19000, loss: 0.01463
[Evaluate]  dev score: 0.85000, dev loss: 0.75772
[Train] epoch: 397/500, step: 15100/19000, loss: 0.01591
[Evaluate]  dev score: 0.85000, dev loss: 0.76009
[Train] epoch: 400/500, step: 15200/19000, loss: 0.02183
[Evaluate]  dev score: 0.85000, dev loss: 0.76348
[Train] epoch: 402/500, step: 15300/19000, loss: 0.00849
[Evaluate]  dev score: 0.85000, dev loss: 0.76631
[Train] epoch: 405/500, step: 15400/19000, loss: 0.01774
[Evaluate]  dev score: 0.85000, dev loss: 0.76891
[Train] epoch: 407/500, step: 15500/19000, loss: 0.01031
[Evaluate]  dev score: 0.85000, dev loss: 0.77206
[Train] epoch: 410/500, step: 15600/19000, loss: 0.00540
[Evaluate]  dev score: 0.85000, dev loss: 0.77642
[Train] epoch: 413/500, step: 15700/19000, loss: 0.00560
[Evaluate]  dev score: 0.85000, dev loss: 0.78110
[Train] epoch: 415/500, step: 15800/19000, loss: 0.00747
[Evaluate]  dev score: 0.85000, dev loss: 0.78641
[Train] epoch: 418/500, step: 15900/19000, loss: 0.00736
[Evaluate]  dev score: 0.85000, dev loss: 0.79182
[Train] epoch: 421/500, step: 16000/19000, loss: 0.02328
[Evaluate]  dev score: 0.85000, dev loss: 0.79689
[Train] epoch: 423/500, step: 16100/19000, loss: 0.00671
[Evaluate]  dev score: 0.83000, dev loss: 0.80291
[Train] epoch: 426/500, step: 16200/19000, loss: 0.01137
[Evaluate]  dev score: 0.83000, dev loss: 0.80719
[Train] epoch: 428/500, step: 16300/19000, loss: 0.00901
[Evaluate]  dev score: 0.83000, dev loss: 0.81101
[Train] epoch: 431/500, step: 16400/19000, loss: 0.00662
[Evaluate]  dev score: 0.83000, dev loss: 0.81447
[Train] epoch: 434/500, step: 16500/19000, loss: 0.01120
[Evaluate]  dev score: 0.83000, dev loss: 0.81732
[Train] epoch: 436/500, step: 16600/19000, loss: 0.00577
[Evaluate]  dev score: 0.83000, dev loss: 0.81990
[Train] epoch: 439/500, step: 16700/19000, loss: 0.00676
[Evaluate]  dev score: 0.83000, dev loss: 0.82178
[Train] epoch: 442/500, step: 16800/19000, loss: 0.01297
[Evaluate]  dev score: 0.83000, dev loss: 0.82374
[Train] epoch: 444/500, step: 16900/19000, loss: 0.00452
[Evaluate]  dev score: 0.83000, dev loss: 0.82601
[Train] epoch: 447/500, step: 17000/19000, loss: 0.00556
[Evaluate]  dev score: 0.83000, dev loss: 0.82745
[Train] epoch: 450/500, step: 17100/19000, loss: 0.01203
[Evaluate]  dev score: 0.83000, dev loss: 0.82950
[Train] epoch: 452/500, step: 17200/19000, loss: 0.00360
[Evaluate]  dev score: 0.83000, dev loss: 0.83090
[Train] epoch: 455/500, step: 17300/19000, loss: 0.00699
[Evaluate]  dev score: 0.83000, dev loss: 0.83299
[Train] epoch: 457/500, step: 17400/19000, loss: 0.00435
[Evaluate]  dev score: 0.83000, dev loss: 0.83533
[Train] epoch: 460/500, step: 17500/19000, loss: 0.00223
[Evaluate]  dev score: 0.83000, dev loss: 0.83608
[Train] epoch: 463/500, step: 17600/19000, loss: 0.00262
[Evaluate]  dev score: 0.83000, dev loss: 0.83843
[Train] epoch: 465/500, step: 17700/19000, loss: 0.00462
[Evaluate]  dev score: 0.83000, dev loss: 0.84042
[Train] epoch: 468/500, step: 17800/19000, loss: 0.00352
[Evaluate]  dev score: 0.83000, dev loss: 0.84169
[Train] epoch: 471/500, step: 17900/19000, loss: 0.01054
[Evaluate]  dev score: 0.83000, dev loss: 0.84364
[Train] epoch: 473/500, step: 18000/19000, loss: 0.00397
[Evaluate]  dev score: 0.83000, dev loss: 0.84550
[Train] epoch: 476/500, step: 18100/19000, loss: 0.00419
[Evaluate]  dev score: 0.83000, dev loss: 0.84744
[Train] epoch: 478/500, step: 18200/19000, loss: 0.00464
[Evaluate]  dev score: 0.83000, dev loss: 0.85005
[Train] epoch: 481/500, step: 18300/19000, loss: 0.00312
[Evaluate]  dev score: 0.83000, dev loss: 0.84981
[Train] epoch: 484/500, step: 18400/19000, loss: 0.00503
[Evaluate]  dev score: 0.83000, dev loss: 0.85256
[Train] epoch: 486/500, step: 18500/19000, loss: 0.00275
[Evaluate]  dev score: 0.83000, dev loss: 0.85765
[Train] epoch: 489/500, step: 18600/19000, loss: 0.00316
[Evaluate]  dev score: 0.83000, dev loss: 0.85330
[Train] epoch: 492/500, step: 18700/19000, loss: 0.00663
[Evaluate]  dev score: 0.83000, dev loss: 0.85381
[Train] epoch: 494/500, step: 18800/19000, loss: 0.00211
[Evaluate]  dev score: 0.83000, dev loss: 0.85953
[Train] epoch: 497/500, step: 18900/19000, loss: 0.00231
[Evaluate]  dev score: 0.83000, dev loss: 0.85619
[Evaluate]  dev score: 0.83000, dev loss: 0.86070
[Train] Training done!
</code></pre> 
<pre><code>[Train] epoch: 481/500, step: 18300/19000, loss: 0.10370
[Evaluate]  dev score: 0.82000, dev loss: 0.79325
[Train] epoch: 484/500, step: 18400/19000, loss: 0.41272
[Evaluate]  dev score: 0.83000, dev loss: 0.81523
[Evaluate] best accuracy performence has been updated: 0.82000 --&gt; 0.83000
[Train] epoch: 486/500, step: 18500/19000, loss: 0.21549
[Evaluate]  dev score: 0.84000, dev loss: 0.80410
[Evaluate] best accuracy performence has been updated: 0.83000 --&gt; 0.84000
[Train] epoch: 489/500, step: 18600/19000, loss: 0.12459
[Evaluate]  dev score: 0.83000, dev loss: 0.78478
[Train] epoch: 492/500, step: 18700/19000, loss: 0.21927
[Evaluate]  dev score: 0.83000, dev loss: 0.77985
[Train] epoch: 494/500, step: 18800/19000, loss: 0.22846
[Evaluate]  dev score: 0.84000, dev loss: 0.78622
[Train] epoch: 497/500, step: 18900/19000, loss: 0.03285
[Evaluate]  dev score: 0.84000, dev loss: 0.77512
[Evaluate]  dev score: 0.84000, dev loss: 0.77360
[Train] Training done!
</code></pre> 
<pre><code>[Train] epoch: 473/500, step: 18000/19000, loss: 0.35202
[Evaluate]  dev score: 0.87000, dev loss: 0.46193
[Train] epoch: 476/500, step: 18100/19000, loss: 0.09771
[Evaluate]  dev score: 0.91000, dev loss: 0.38287
[Evaluate] best accuracy performence has been updated: 0.90000 --&gt; 0.91000
[Train] epoch: 478/500, step: 18200/19000, loss: 0.02467
[Evaluate]  dev score: 0.89000, dev loss: 0.42026
[Train] epoch: 481/500, step: 18300/19000, loss: 0.01818
[Evaluate]  dev score: 0.89000, dev loss: 0.42676
[Train] epoch: 484/500, step: 18400/19000, loss: 0.04383
[Evaluate]  dev score: 0.89000, dev loss: 0.42994
[Train] epoch: 486/500, step: 18500/19000, loss: 0.02579
[Evaluate]  dev score: 0.89000, dev loss: 0.43919
[Train] epoch: 489/500, step: 18600/19000, loss: 0.02788
[Evaluate]  dev score: 0.88000, dev loss: 0.44569
[Train] epoch: 492/500, step: 18700/19000, loss: 0.05951
[Evaluate]  dev score: 0.88000, dev loss: 0.43005
[Train] epoch: 494/500, step: 18800/19000, loss: 0.02288
[Evaluate]  dev score: 0.88000, dev loss: 0.44650
[Train] epoch: 497/500, step: 18900/19000, loss: 0.02292
[Evaluate]  dev score: 0.88000, dev loss: 0.45742
[Evaluate]  dev score: 0.88000, dev loss: 0.44346
[Train] Training done!
</code></pre> 
<h4>
<a id="6323__858"></a>6.3.2.3 损失曲线展示</h4> 
<p>分别画出基于LSTM的各个长度的数字预测模型训练过程中，在训练集和验证集上的损失曲线，代码实现如下：</p> 
<pre><code class="prism language-python"><span class="token comment"># 画出训练过程中的损失图</span>
<span class="token keyword">for</span> length <span class="token keyword">in</span> lengths<span class="token punctuation">:</span>
    runner <span class="token operator">=</span> lstm_runners<span class="token punctuation">[</span>length<span class="token punctuation">]</span>
    fig_name <span class="token operator">=</span> <span class="token string-interpolation"><span class="token string">f"./images/6.11_</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>length<span class="token punctuation">}</span></span><span class="token string">.pdf"</span></span>
    plot_training_loss<span class="token punctuation">(</span>runner<span class="token punctuation">,</span> fig_name<span class="token punctuation">,</span> sample_step<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">)</span>
</code></pre> 
<p>plot_training_loss：</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
<span class="token keyword">def</span> <span class="token function">plot_training_loss</span><span class="token punctuation">(</span>runner<span class="token punctuation">,</span> fig_name<span class="token punctuation">,</span> sample_step<span class="token punctuation">)</span><span class="token punctuation">:</span>
    plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span><span class="token punctuation">)</span>
    train_items <span class="token operator">=</span> runner<span class="token punctuation">.</span>train_step_losses<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">:</span>sample_step<span class="token punctuation">]</span>
    train_steps <span class="token operator">=</span> <span class="token punctuation">[</span>x<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token keyword">for</span> x <span class="token keyword">in</span> train_items<span class="token punctuation">]</span>
    train_losses <span class="token operator">=</span> <span class="token punctuation">[</span>x<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token keyword">for</span> x <span class="token keyword">in</span> train_items<span class="token punctuation">]</span>
    plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>train_steps<span class="token punctuation">,</span> train_losses<span class="token punctuation">,</span> color<span class="token operator">=</span><span class="token string">'#e4007f'</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">"Train loss"</span><span class="token punctuation">)</span>

    dev_steps <span class="token operator">=</span> <span class="token punctuation">[</span>x<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token keyword">for</span> x <span class="token keyword">in</span> runner<span class="token punctuation">.</span>dev_losses<span class="token punctuation">]</span>
    dev_losses <span class="token operator">=</span> <span class="token punctuation">[</span>x<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token keyword">for</span> x <span class="token keyword">in</span> runner<span class="token punctuation">.</span>dev_losses<span class="token punctuation">]</span>
    plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>dev_steps<span class="token punctuation">,</span> dev_losses<span class="token punctuation">,</span> color<span class="token operator">=</span><span class="token string">'#f19ec2'</span><span class="token punctuation">,</span> linestyle<span class="token operator">=</span><span class="token string">'--'</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">"Dev loss"</span><span class="token punctuation">)</span>

    <span class="token comment"># 绘制坐标轴和图例</span>
    plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">"loss"</span><span class="token punctuation">,</span> fontsize<span class="token operator">=</span><span class="token string">'large'</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">"step"</span><span class="token punctuation">,</span> fontsize<span class="token operator">=</span><span class="token string">'large'</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span>loc<span class="token operator">=</span><span class="token string">'upper right'</span><span class="token punctuation">,</span> fontsize<span class="token operator">=</span><span class="token string">'x-large'</span><span class="token punctuation">)</span>

    plt<span class="token punctuation">.</span>savefig<span class="token punctuation">(</span>fig_name<span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>

</code></pre> 
<p>图6.11展示了LSTM模型在不同长度数据集上进行训练后的损失变化，同SRN模型一样，随着序列长度的增加，训练集上的损失逐渐不稳定，验证集上的损失整体趋向于变大，这说明当序列长度增加时，保持长期依赖的能力同样在逐渐变弱. 同图6.5相比，LSTM模型在序列长度增加时，收敛情况比SRN模型更好。</p> 
<p><img src="https://images2.imgbox.com/89/2c/Yv2Siv3V_o.png" alt="1"><br> <img src="https://images2.imgbox.com/4c/5c/O9Hlfxv4_o.png" alt="2"><br> <img src="https://images2.imgbox.com/95/b9/QJ335YfV_o.png" alt="3"><br> <img src="https://images2.imgbox.com/4e/ef/YyF9CbOI_o.png" alt="4"><br> <img src="https://images2.imgbox.com/69/2a/FU3ECxDJ_o.png" alt="5"><br> <img src="https://images2.imgbox.com/14/1a/FRw23uWl_o.png" alt="6"><br> <br></p>

 图6.11 LSTM在不同长度数据集训练损失变化图

<p></p> 
<h3>
<a id="633__901"></a>6.3.3 模型评价</h3> 
<h4>
<a id="6331__903"></a>6.3.3.1 在测试集上进行模型评价</h4> 
<p>使用测试数据对在训练过程中保存的最好模型进行评价，观察模型在测试集上的准确率. 同时获取模型在训练过程中在验证集上最好的准确率，实现代码如下:</p> 
<pre><code class="prism language-python">lstm_dev_scores <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
lstm_test_scores <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
<span class="token keyword">for</span> length <span class="token keyword">in</span> lengths<span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Evaluate LSTM with data length </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>length<span class="token punctuation">}</span></span><span class="token string">."</span></span><span class="token punctuation">)</span>
    runner <span class="token operator">=</span> lstm_runners<span class="token punctuation">[</span>length<span class="token punctuation">]</span>
    <span class="token comment"># 加载训练过程中效果最好的模型</span>
    model_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>save_dir<span class="token punctuation">,</span> <span class="token string-interpolation"><span class="token string">f"best_lstm_model_</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>length<span class="token punctuation">}</span></span><span class="token string">.pdparams"</span></span><span class="token punctuation">)</span>
    runner<span class="token punctuation">.</span>load_model<span class="token punctuation">(</span>model_path<span class="token punctuation">)</span>

    <span class="token comment"># 加载长度为length的数据</span>
    data_path <span class="token operator">=</span> <span class="token string-interpolation"><span class="token string">f"./datasets/</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>length<span class="token punctuation">}</span></span><span class="token string">"</span></span>
    train_examples<span class="token punctuation">,</span> dev_examples<span class="token punctuation">,</span> test_examples <span class="token operator">=</span> load_data<span class="token punctuation">(</span>data_path<span class="token punctuation">)</span>
    test_set <span class="token operator">=</span> DigitSumDataset<span class="token punctuation">(</span>test_examples<span class="token punctuation">)</span>
    test_loader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>test_set<span class="token punctuation">,</span> batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">)</span>

    <span class="token comment"># 使用测试集评价模型，获取测试集上的预测准确率</span>
    score<span class="token punctuation">,</span> _ <span class="token operator">=</span> runner<span class="token punctuation">.</span>evaluate<span class="token punctuation">(</span>test_loader<span class="token punctuation">)</span>
    lstm_test_scores<span class="token punctuation">.</span>append<span class="token punctuation">(</span>score<span class="token punctuation">)</span>
    lstm_dev_scores<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token builtin">max</span><span class="token punctuation">(</span>runner<span class="token punctuation">.</span>dev_scores<span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token keyword">for</span> length<span class="token punctuation">,</span> dev_score<span class="token punctuation">,</span> test_score <span class="token keyword">in</span> <span class="token builtin">zip</span><span class="token punctuation">(</span>lengths<span class="token punctuation">,</span> lstm_dev_scores<span class="token punctuation">,</span> lstm_test_scores<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"[LSTM] length:</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>length<span class="token punctuation">}</span></span><span class="token string">, dev_score: </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>dev_score<span class="token punctuation">}</span></span><span class="token string">, test_score: </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>test_score<span class="token punctuation">:</span><span class="token format-spec"> .5f</span><span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>
</code></pre> 
<p>运行结果：</p> 
<pre><code>Evaluate LSTM with data length 15.
Evaluate LSTM with data length 20.
Evaluate LSTM with data length 25.
Evaluate LSTM with data length 30.
Evaluate LSTM with data length 35.
[LSTM] length:10, dev_score: 0.92, test_score:  0.84000
[LSTM] length:15, dev_score: 0.87, test_score:  0.92000
[LSTM] length:20, dev_score: 0.75, test_score:  0.74000
[LSTM] length:25, dev_score: 0.77, test_score:  0.82000
[LSTM] length:30, dev_score: 0.61, test_score:  0.54000
[LSTM] length:35, dev_score: 0.29, test_score:  0.19000
</code></pre> 
<h4>
<a id="6332__944"></a>6.3.3.2 模型在不同长度的数据集上的准确率变化图</h4> 
<p>接下来，将SRN和LSTM在不同长度的验证集和测试集数据上的准确率绘制成图片，以方面观察。</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>lengths<span class="token punctuation">,</span> lstm_dev_scores<span class="token punctuation">,</span> <span class="token string">'-o'</span><span class="token punctuation">,</span> color<span class="token operator">=</span><span class="token string">'#e8609b'</span><span class="token punctuation">,</span>  label<span class="token operator">=</span><span class="token string">"LSTM Dev Accuracy"</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>lengths<span class="token punctuation">,</span> lstm_test_scores<span class="token punctuation">,</span><span class="token string">'-o'</span><span class="token punctuation">,</span> color<span class="token operator">=</span><span class="token string">'#000000'</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">"LSTM Test Accuracy"</span><span class="token punctuation">)</span>

<span class="token comment">#绘制坐标轴和图例</span>
plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">"accuracy"</span><span class="token punctuation">,</span> fontsize<span class="token operator">=</span><span class="token string">'large'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">"sequence length"</span><span class="token punctuation">,</span> fontsize<span class="token operator">=</span><span class="token string">'large'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span>loc<span class="token operator">=</span><span class="token string">'lower left'</span><span class="token punctuation">,</span> fontsize<span class="token operator">=</span><span class="token string">'x-large'</span><span class="token punctuation">)</span>

fig_name <span class="token operator">=</span> <span class="token string">"./images/6.12.pdf"</span>
plt<span class="token punctuation">.</span>savefig<span class="token punctuation">(</span>fig_name<span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<p>图6.12 展示了LSTM模型与SRN模型在不同长度数据集上的准确度对比。随着数据集长度的增加，LSTM模型在验证集和测试集上的准确率整体也趋向于降低；同时LSTM模型的准确率显著高于SRN模型，表明LSTM模型保持长期依赖的能力要优于SRN模型.<br> <img src="https://images2.imgbox.com/ca/9c/GYfjrdNk_o.png" alt="6"></p> 
<p><br></p>

 图6.12 LSTM与SRN网络在不同长度数据集上的准确度对比图

<p></p> 
<h4>
<a id="6333_LSTM_966"></a>6.3.3.3 LSTM模型门状态和单元状态的变化</h4> 
<p>LSTM模型通过门控机制控制信息的单元状态的更新，这里可以观察当LSTM在处理一条数字序列的时候，相应门和单元状态是如何变化的。首先需要对以上LSTM模型实现代码中，定义相应列表进行存储这些门和单元状态在每个时刻的向量。</p> 
<pre><code class="prism language-python"><span class="token comment"># 声明LSTM和相关参数</span>
<span class="token keyword">class</span> <span class="token class-name">LSTM</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> input_size<span class="token punctuation">,</span> hidden_size<span class="token punctuation">,</span> Wi_attr<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> Wf_attr<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> Wo_attr<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> Wc_attr<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span>
                 Ui_attr<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> Uf_attr<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> Uo_attr<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> Uc_attr<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> bi_attr<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> bf_attr<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span>
                 bo_attr<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> bc_attr<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>LSTM<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>input_size <span class="token operator">=</span> input_size
        self<span class="token punctuation">.</span>hidden_size <span class="token operator">=</span> hidden_size

        <span class="token comment"># 初始化模型参数</span>
        <span class="token keyword">if</span> Wi_attr<span class="token operator">==</span><span class="token boolean">None</span><span class="token punctuation">:</span>
             Wi<span class="token operator">=</span>torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>size<span class="token operator">=</span><span class="token punctuation">[</span>input_size<span class="token punctuation">,</span> hidden_size<span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
             Wi <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>Wi_attr<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>W_i <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>Wi<span class="token punctuation">)</span>

        <span class="token keyword">if</span> Wf_attr<span class="token operator">==</span><span class="token boolean">None</span><span class="token punctuation">:</span>
             Wf<span class="token operator">=</span>torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>size<span class="token operator">=</span><span class="token punctuation">[</span>input_size<span class="token punctuation">,</span> hidden_size<span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
             Wf <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>Wf_attr<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>W_f <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>Wf<span class="token punctuation">)</span>

        <span class="token keyword">if</span> Wo_attr<span class="token operator">==</span><span class="token boolean">None</span><span class="token punctuation">:</span>
             Wo<span class="token operator">=</span>torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>size<span class="token operator">=</span><span class="token punctuation">[</span>input_size<span class="token punctuation">,</span> hidden_size<span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
             Wo <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>Wo_attr<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>W_o <span class="token operator">=</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>Wo<span class="token punctuation">)</span>

        <span class="token keyword">if</span> Wc_attr<span class="token operator">==</span><span class="token boolean">None</span><span class="token punctuation">:</span>
            Wc<span class="token operator">=</span>torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>size<span class="token operator">=</span><span class="token punctuation">[</span>input_size<span class="token punctuation">,</span> hidden_size<span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            Wc <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>Wc_attr<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>W_c <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>Wc<span class="token punctuation">)</span>

        <span class="token keyword">if</span> Ui_attr<span class="token operator">==</span><span class="token boolean">None</span><span class="token punctuation">:</span>
            Ui <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>size<span class="token operator">=</span><span class="token punctuation">[</span>hidden_size<span class="token punctuation">,</span> hidden_size<span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            Ui <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>Ui_attr<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>U_i <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>Ui<span class="token punctuation">)</span>
        <span class="token keyword">if</span> Uf_attr <span class="token operator">==</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            Uf <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>size<span class="token operator">=</span><span class="token punctuation">[</span>hidden_size<span class="token punctuation">,</span> hidden_size<span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            Uf <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>Uf_attr<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>U_f <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>Uf<span class="token punctuation">)</span>

        <span class="token keyword">if</span> Uo_attr <span class="token operator">==</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            Uo <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>size<span class="token operator">=</span><span class="token punctuation">[</span>hidden_size<span class="token punctuation">,</span> hidden_size<span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            Uo <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>Uo_attr<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>U_o <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>Uo<span class="token punctuation">)</span>

        <span class="token keyword">if</span> Uc_attr <span class="token operator">==</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            Uc <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>size<span class="token operator">=</span><span class="token punctuation">[</span>hidden_size<span class="token punctuation">,</span> hidden_size<span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            Uc <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>Uc_attr<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>U_c <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>Uc<span class="token punctuation">)</span>

        <span class="token keyword">if</span> bi_attr <span class="token operator">==</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            bi <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>size<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span>hidden_size<span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            bi <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>bi_attr<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>b_i <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>bi<span class="token punctuation">)</span>
        <span class="token keyword">if</span> bf_attr <span class="token operator">==</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            bf <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>size<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span>hidden_size<span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            bf <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>bf_attr<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>b_f <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>bf<span class="token punctuation">)</span>
        <span class="token keyword">if</span> bo_attr <span class="token operator">==</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            bo <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>size<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span>hidden_size<span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            bo <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>bo_attr<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>b_o <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>bo<span class="token punctuation">)</span>
        <span class="token keyword">if</span> bc_attr <span class="token operator">==</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            bc <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>size<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span>hidden_size<span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            bc <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>bc_attr<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>b_c <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>bc<span class="token punctuation">)</span>

    <span class="token comment"># 初始化状态向量和隐状态向量</span>
    <span class="token keyword">def</span> <span class="token function">init_state</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> batch_size<span class="token punctuation">)</span><span class="token punctuation">:</span>
        hidden_state <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>size<span class="token operator">=</span><span class="token punctuation">[</span>batch_size<span class="token punctuation">,</span> self<span class="token punctuation">.</span>hidden_size<span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
        cell_state <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>size<span class="token operator">=</span><span class="token punctuation">[</span>batch_size<span class="token punctuation">,</span> self<span class="token punctuation">.</span>hidden_size<span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
        <span class="token keyword">return</span> hidden_state<span class="token punctuation">,</span> cell_state

    <span class="token comment"># 定义前向计算</span>
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> inputs<span class="token punctuation">,</span> states<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># inputs: 输入数据，其shape为batch_size x seq_len x input_size</span>
        batch_size<span class="token punctuation">,</span> seq_len<span class="token punctuation">,</span> input_size <span class="token operator">=</span> inputs<span class="token punctuation">.</span>shape

        <span class="token comment"># 初始化起始的单元状态和隐状态向量，其shape为batch_size x hidden_size</span>
        <span class="token keyword">if</span> states <span class="token keyword">is</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            states <span class="token operator">=</span> self<span class="token punctuation">.</span>init_state<span class="token punctuation">(</span>batch_size<span class="token punctuation">)</span>
        hidden_state<span class="token punctuation">,</span> cell_state <span class="token operator">=</span> states

    
        <span class="token comment"># 定义相应的门状态和单元状态向量列表</span>
        self<span class="token punctuation">.</span>Is <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        self<span class="token punctuation">.</span>Fs <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        self<span class="token punctuation">.</span>Os <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        self<span class="token punctuation">.</span>Cs <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        <span class="token comment"># 初始化状态向量和隐状态向量</span>
        cell_state <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>size<span class="token operator">=</span><span class="token punctuation">[</span>batch_size<span class="token punctuation">,</span> self<span class="token punctuation">.</span>hidden_size<span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
        hidden_state <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>size<span class="token operator">=</span><span class="token punctuation">[</span>batch_size<span class="token punctuation">,</span> self<span class="token punctuation">.</span>hidden_size<span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>

        <span class="token comment"># 执行LSTM计算，包括：隐藏门、输入门、遗忘门、候选状态向量、状态向量和隐状态向量</span>
        <span class="token keyword">for</span> step <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>seq_len<span class="token punctuation">)</span><span class="token punctuation">:</span>
            input_step <span class="token operator">=</span> inputs<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> step<span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span>
            I_gate <span class="token operator">=</span> F<span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>input_step<span class="token punctuation">,</span> self<span class="token punctuation">.</span>W_i<span class="token punctuation">)</span> <span class="token operator">+</span> torch<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>hidden_state<span class="token punctuation">,</span> self<span class="token punctuation">.</span>U_i<span class="token punctuation">)</span> <span class="token operator">+</span> self<span class="token punctuation">.</span>b_i<span class="token punctuation">)</span>
            F_gate <span class="token operator">=</span> F<span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>input_step<span class="token punctuation">,</span> self<span class="token punctuation">.</span>W_f<span class="token punctuation">)</span> <span class="token operator">+</span> torch<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>hidden_state<span class="token punctuation">,</span> self<span class="token punctuation">.</span>U_f<span class="token punctuation">)</span> <span class="token operator">+</span> self<span class="token punctuation">.</span>b_f<span class="token punctuation">)</span>
            O_gate <span class="token operator">=</span> F<span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>input_step<span class="token punctuation">,</span> self<span class="token punctuation">.</span>W_o<span class="token punctuation">)</span> <span class="token operator">+</span> torch<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>hidden_state<span class="token punctuation">,</span> self<span class="token punctuation">.</span>U_o<span class="token punctuation">)</span> <span class="token operator">+</span> self<span class="token punctuation">.</span>b_o<span class="token punctuation">)</span>
            C_tilde <span class="token operator">=</span> F<span class="token punctuation">.</span>tanh<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>input_step<span class="token punctuation">,</span> self<span class="token punctuation">.</span>W_c<span class="token punctuation">)</span> <span class="token operator">+</span> torch<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>hidden_state<span class="token punctuation">,</span> self<span class="token punctuation">.</span>U_c<span class="token punctuation">)</span> <span class="token operator">+</span> self<span class="token punctuation">.</span>b_c<span class="token punctuation">)</span>
            cell_state <span class="token operator">=</span> F_gate <span class="token operator">*</span> cell_state <span class="token operator">+</span> I_gate <span class="token operator">*</span> C_tilde
            hidden_state <span class="token operator">=</span> O_gate <span class="token operator">*</span> F<span class="token punctuation">.</span>tanh<span class="token punctuation">(</span>cell_state<span class="token punctuation">)</span>
            <span class="token comment"># 存储门状态向量和单元状态向量</span>
            self<span class="token punctuation">.</span>Is<span class="token punctuation">.</span>append<span class="token punctuation">(</span>I_gate<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            self<span class="token punctuation">.</span>Fs<span class="token punctuation">.</span>append<span class="token punctuation">(</span>F_gate<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            self<span class="token punctuation">.</span>Os<span class="token punctuation">.</span>append<span class="token punctuation">(</span>O_gate<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            self<span class="token punctuation">.</span>Cs<span class="token punctuation">.</span>append<span class="token punctuation">(</span>cell_state<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> hidden_state
</code></pre> 
<p>接下来，需要使用新的LSTM模型，重新实例化一个runner，本节使用序列长度为10的模型进行此项实验，因此需要加载序列长度为10的模型。</p> 
<pre><code class="prism language-python"><span class="token comment"># 实例化模型</span>
base_model <span class="token operator">=</span> LSTM<span class="token punctuation">(</span>input_size<span class="token punctuation">,</span> hidden_size<span class="token punctuation">)</span>
model <span class="token operator">=</span> Model_RNN4SeqClass<span class="token punctuation">(</span>base_model<span class="token punctuation">,</span> num_digits<span class="token punctuation">,</span> input_size<span class="token punctuation">,</span> hidden_size<span class="token punctuation">,</span> num_classes<span class="token punctuation">)</span> 
<span class="token comment"># 指定优化器</span>
optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>lr<span class="token operator">=</span>lr<span class="token punctuation">,</span> params<span class="token operator">=</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment"># 定义评价指标</span>
metric <span class="token operator">=</span> Accuracy<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment"># 定义损失函数</span>
loss_fn <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment"># 基于以上组件，重新实例化Runner</span>
runner <span class="token operator">=</span> RunnerV3<span class="token punctuation">(</span>model<span class="token punctuation">,</span> optimizer<span class="token punctuation">,</span> loss_fn<span class="token punctuation">,</span> metric<span class="token punctuation">)</span>

length <span class="token operator">=</span> <span class="token number">10</span>
<span class="token comment"># 加载训练过程中效果最好的模型</span>
model_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>save_dir<span class="token punctuation">,</span> <span class="token string-interpolation"><span class="token string">f"best_lstm_model_</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>length<span class="token punctuation">}</span></span><span class="token string">.pdparams"</span></span><span class="token punctuation">)</span>
runner<span class="token punctuation">.</span>load_model<span class="token punctuation">(</span>model_path<span class="token punctuation">)</span>
</code></pre> 
<p>接下来，给定一条数字序列，并使用数字预测模型进行数字预测，这样便会将相应的门状态和单元状态向量保存至模型中. 然后分别从模型中取出这些向量，并将这些向量进行绘制展示。代码实现如下：</p> 
<pre><code class="prism language-python">
<span class="token keyword">import</span> seaborn <span class="token keyword">as</span> sns
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
<span class="token keyword">def</span> <span class="token function">plot_tensor</span><span class="token punctuation">(</span>inputs<span class="token punctuation">,</span> tensor<span class="token punctuation">,</span>  save_path<span class="token punctuation">,</span> vmin<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> vmax<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    tensor <span class="token operator">=</span> np<span class="token punctuation">.</span>stack<span class="token punctuation">(</span>tensor<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
    tensor <span class="token operator">=</span> np<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span>tensor<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>T

    plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token comment"># vmin, vmax定义了色彩图的上下界</span>
    ax <span class="token operator">=</span> sns<span class="token punctuation">.</span>heatmap<span class="token punctuation">(</span>tensor<span class="token punctuation">,</span> vmin<span class="token operator">=</span>vmin<span class="token punctuation">,</span> vmax<span class="token operator">=</span>vmax<span class="token punctuation">)</span> 
    ax<span class="token punctuation">.</span>set_xticklabels<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>
    ax<span class="token punctuation">.</span>figure<span class="token punctuation">.</span>savefig<span class="token punctuation">(</span>save_path<span class="token punctuation">)</span>


<span class="token comment"># 定义模型输入</span>
inputs <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span>
X <span class="token operator">=</span> torch<span class="token punctuation">.</span>as_tensor<span class="token punctuation">(</span>inputs<span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
X <span class="token operator">=</span> X<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
<span class="token comment"># 进行模型预测，并获取相应的预测结果</span>
logits <span class="token operator">=</span> runner<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>X<span class="token punctuation">)</span>
predict_label <span class="token operator">=</span> torch<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>logits<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"predict result: </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>predict_label<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>

<span class="token comment"># 输入门</span>
Is <span class="token operator">=</span> runner<span class="token punctuation">.</span>model<span class="token punctuation">.</span>rnn_model<span class="token punctuation">.</span>Is
plot_tensor<span class="token punctuation">(</span>inputs<span class="token punctuation">,</span> Is<span class="token punctuation">,</span> save_path<span class="token operator">=</span><span class="token string">"./images/6.13_I.pdf"</span><span class="token punctuation">)</span>
<span class="token comment"># 遗忘门</span>
Fs <span class="token operator">=</span> runner<span class="token punctuation">.</span>model<span class="token punctuation">.</span>rnn_model<span class="token punctuation">.</span>Fs
plot_tensor<span class="token punctuation">(</span>inputs<span class="token punctuation">,</span> Fs<span class="token punctuation">,</span> save_path<span class="token operator">=</span><span class="token string">"./images/6.13_F.pdf"</span><span class="token punctuation">)</span>
<span class="token comment"># 输出门</span>
Os <span class="token operator">=</span> runner<span class="token punctuation">.</span>model<span class="token punctuation">.</span>rnn_model<span class="token punctuation">.</span>Os
plot_tensor<span class="token punctuation">(</span>inputs<span class="token punctuation">,</span> Os<span class="token punctuation">,</span> save_path<span class="token operator">=</span><span class="token string">"./images/6.13_O.pdf"</span><span class="token punctuation">)</span>
<span class="token comment"># 单元状态</span>
Cs <span class="token operator">=</span> runner<span class="token punctuation">.</span>model<span class="token punctuation">.</span>rnn_model<span class="token punctuation">.</span>Cs
plot_tensor<span class="token punctuation">(</span>inputs<span class="token punctuation">,</span> Cs<span class="token punctuation">,</span> save_path<span class="token operator">=</span><span class="token string">"./images/6.13_C.pdf"</span><span class="token punctuation">,</span> vmin<span class="token operator">=</span><span class="token operator">-</span><span class="token number">5</span><span class="token punctuation">,</span> vmax<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span>
</code></pre> 
<p>图6.13 当LSTM处理序列数据[6, 7, 0, 0, 1, 0, 0, 0, 0, 0]的过程中单元状态和门数值的变化图，其中横坐标为输入数字，纵坐标为相应门或单元状态向量的维度，颜色的深浅代表数值的大小。可以看到，当输入门遇到不同位置的数字0时，保持了相对一致的数值大小，表明对于0元素保持相同的门控过滤机制，避免输入信息的变化给当前模型带来困扰；当遗忘门遇到数字1后，遗忘门数值在一些维度上变小，表明对某些信息进行了遗忘；随着序列的输入，输出门和单元状态在某些维度上数值变小，在某些维度上数值变大，表明输出门在根据信息的重要性选择信息进行输出，同时单元状态也在保持着对文本预测重要的一些信息.</p> 

 <img src="https://images2.imgbox.com/10/ef/8EYm9vDQ_o.png" width="100%">
 
<br>

 图6.13 LSTM中单元状态和门数值的变化图
 
<h1>
<a id="_1155"></a>思考题</h1> 
<h2>
<a id="1LSTMSRN_1156"></a>【思考题1】LSTM与SRN实验结果对比，谈谈看法。</h2> 
<p>LSTM模型在序列长度增加时，收敛情况比SRN模型更好。因为本身LSTM的设计就是通过门控机制来解决SRN的长程依赖问题。</p> 
<h2>
<a id="2LSTMSRN_1159"></a>【思考题2】LSTM与SRN在不同长度数据集上的准确度对比，谈谈看法。</h2> 
<p>对比来看，LSTM模型的准确率显著高于SRN模型。但是综合来看，他们在随数据集长度的增加，准确率都在降低。</p> 
<h2>
<a id="3LSTM_1162"></a>【思考题3】分析LSTM中单元状态和门数值的变化图，并用自己的话解释该图。</h2> 
<p>横坐标为输入数字，纵坐标为相应门或单元状态向量的维度，颜色的深浅代表数值的大小。可以看到，当输入门遇到不同位置的数字0时，保持了相对一致的数值大小，表明对于0元素保持相同的门控过滤机制，避免输入信息的变化给当前模型带来困扰；当遗忘门遇到数字1后，遗忘门数值在一些维度上变小，表明对某些信息进行了遗忘；随着序列的输入，输出门和单元状态在某些维度上数值变小，在某些维度上数值变大，表明输出门在根据信息的重要性选择信息进行输出，同时单元状态也在保持着对文本预测重要的一些信息.</p> 
<h2>
<a id="_1165"></a>总结：</h2> 
<p><img src="https://images2.imgbox.com/cc/0d/q2TDfxHd_o.png" alt="总结"></p>
                </div>
                
                

		</div>
	</article>
</main>




			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程小白.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://www.w3counter.com/tracker.js?id=150625"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>
	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>