<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<title>Kafka安装及架构 - 编程小白</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程小白" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程小白</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Kafka安装及架构</h1>
			
		</header>
		<div class="content post__content clearfix">
			


        
                <div id="content_views" class="markdown_views prism-atom-one-dark">
                    
                        
                    
                    <h2>
<a id="kafka_0"></a>kafka的特点</h2> 
<ul>
<li>高吞吐量、低延迟：kafka每秒可以处理几十万条消息，它的延迟最低只有几毫秒，每个topic可以分多个partition, 由多个consumer group 对partition进行consume操作。</li>
<li>可扩展性：kafka集群支持热扩展</li>
<li>持久性、可靠性：消息被持久化到本地磁盘，并且支持数据备份防止数据丢失</li>
<li>容错性：允许集群中有节点失败（若副本数量为n,则允许n-1个节点失败）</li>
<li>高并发：支持数千个客户端同时读写</li>
</ul> 
<h2>
<a id="_8"></a>安装</h2> 
<ol>
<li>上传安装包</li>
<li>解压</li>
</ol> 
<pre><code class="prism language-sql"> tar <span class="token operator">-</span>zxvf kafka_2<span class="token punctuation">.</span><span class="token number">11</span><span class="token operator">-</span><span class="token number">2.2</span><span class="token number">.2</span><span class="token punctuation">.</span>tgz tar  <span class="token operator">-</span>C <span class="token operator">/</span>opt<span class="token operator">/</span>apps<span class="token operator">/</span>
</code></pre> 
<p>3.修改配置文件</p> 
<pre><code class="prism language-sql">（<span class="token number">1</span>）进入配置文件目录
<span class="token punctuation">[</span>root<span class="token variable">@linux01</span> apps<span class="token punctuation">]</span><span class="token comment"># cd kafka_2.12-2.3.1/config</span>
（<span class="token number">2</span>）编辑配置文件
vi server<span class="token punctuation">.</span>properties
<span class="token comment">#为依次增长的：0、1、2、3、4，集群中唯一 id</span>
broker<span class="token punctuation">.</span>id<span class="token operator">=</span><span class="token number">0</span>   
<span class="token comment">#数据存储的⽬录 </span>
log<span class="token punctuation">.</span>dirs<span class="token operator">=</span><span class="token operator">/</span>opt<span class="token operator">/</span><span class="token keyword">data</span><span class="token operator">/</span>kafkadata
<span class="token comment">#底层存储的数据（日志）留存时长（默认7天）</span>
log<span class="token punctuation">.</span>retention<span class="token punctuation">.</span>hours<span class="token operator">=</span><span class="token number">168</span>
<span class="token comment">#底层存储的数据（日志）留存量（默认1G） </span>
log<span class="token punctuation">.</span>retention<span class="token punctuation">.</span>bytes<span class="token operator">=</span><span class="token number">1073741824</span>
<span class="token comment">#指定zk集群地址</span>
zookeeper<span class="token punctuation">.</span><span class="token keyword">connect</span><span class="token operator">=</span>linux01:<span class="token number">2181</span><span class="token punctuation">,</span>linux02:<span class="token number">2181</span><span class="token punctuation">,</span>linux03:<span class="token number">2181</span>
</code></pre> 
<ol start="4"><li>分发安装包</li></ol> 
<pre><code class="prism language-sql"><span class="token keyword">for</span>  i  <span class="token operator">in</span> {<!-- --><span class="token number">2.</span><span class="token number">.3</span>} 
<span class="token keyword">do</span> 
scp  <span class="token operator">-</span>r  kafka_2<span class="token punctuation">.</span><span class="token number">11</span><span class="token operator">-</span><span class="token number">2.2</span><span class="token number">.2</span>  linux0$i:$PWD 
done
</code></pre> 
<p>5.环境变量配置</p> 
<pre><code class="prism language-sql">vi <span class="token operator">/</span>etc<span class="token operator">/</span>profile
export KAFKA_HOME<span class="token operator">=</span><span class="token operator">/</span>opt<span class="token operator">/</span>apps<span class="token operator">/</span>kafka_2<span class="token punctuation">.</span><span class="token number">11</span><span class="token operator">-</span><span class="token number">2.2</span><span class="token number">.2</span>
export PATH<span class="token operator">=</span>$PATH:$KAFKA_HOME<span class="token operator">/</span>bin 

source <span class="token operator">/</span>etc<span class="token operator">/</span>profile
<span class="token comment"># 注意：还需要分发环境变量</span>
</code></pre> 
<ol start="6"><li>一键启停脚本：</li></ol> 
<pre><code class="prism language-sql"><span class="token comment">#!/bin/bash</span>

<span class="token keyword">case</span> $<span class="token number">1</span> <span class="token operator">in</span>
<span class="token string">"start"</span><span class="token punctuation">)</span>{
        <span class="token keyword">for</span> i <span class="token operator">in</span> linux01 linux02 linux03
        <span class="token keyword">do</span>
        echo <span class="token comment">---------- kafka $i 启动 ------------</span>
                ssh $i <span class="token string">"source /etc/profile;  /opt/app/kafka2.4.1/bin/kafka-server-start.sh -daemon /opt/app/kafka2.4.1/config/server.properties"</span>
        done
}<span class="token punctuation">;</span><span class="token punctuation">;</span>
<span class="token string">"stop"</span><span class="token punctuation">)</span>{
        <span class="token keyword">for</span> i <span class="token operator">in</span> linux01 linux02 linux03
        <span class="token keyword">do</span>
        echo <span class="token comment">---------- kafka $i 停止 ------------</span>
                ssh $i <span class="token string">"source /etc/profile;  /opt/app/kafka2.4.1/bin/kafka-server-stop.sh "</span>
        done
}<span class="token punctuation">;</span><span class="token punctuation">;</span>
esac
</code></pre> 
<h2>
<a id="_75"></a>应用场景</h2> 
<ul>
<li>日志收集：一个公司可以用kafka可以收集各种服务的log，通过kafka以统一接口服务的方式开放给各种consumer，例如hadoop、HBase、Solr等。</li>
<li>消息系统：解耦和生产者和消费者、缓存消息等。</li>
<li>用户行为跟踪：kafka经常被用来记录web用户或者app用户的各种活动，如浏览网页、搜索、点击等活动，这些活动信息被各个服务器发布到kafka的topic中，然后订阅者通过订阅这些topic来做实时的监控分析，或者装载到hadoop、数据仓库中做离线分析和挖掘。</li>
<li>运营指标：kafka也经常用来记录运营监控数据。包括收集各种分布式应用的数据，生产各种操作的集中反馈，比如报警和报告。</li>
<li>作为流式处理的数据源：比如spark streaming和 Flink</li>
</ul> 
<h2>
<a id="kafka_82"></a>kafka架构</h2> 
<p><img src="https://images2.imgbox.com/99/7e/FZLjeh2R_o.png" alt="在这里插入图片描述"></p> 
<h3>
<a id="topicpartition_86"></a>主题topic和分区partition</h3> 
<ul>
<li>topic<br> Kafka中存储数据的逻辑分类；你可以理解为数据库中“表”的概念；<br> 比如，将app端日志、微信小程序端日志、业务库订单表数据分别放入不同的topic</li>
<li>partition分区（提升kafka吞吐量）<br> topic中数据的具体管理单元；（你可以理解为hbase中表的“region"概念）</li>
<li>每个partition由一个kafka broker服务器管理；</li>
<li>每个topic 可以划分为多个partition，分布到多个broker上管理；</li>
<li>每个partition都可以有多个副本；保证数据安全</li>
</ul> 
<pre><code>分区对于 kafka 集群的好处是：实现topic数据的负载均衡。提高写入、读出的并发度，提高吞吐量。
</code></pre> 
<ul>
<li>分区副本replica<br> 每个topic的每个partition都可以配置多个副本（replica），以提高数据的可靠性；<br> 每个partition的所有副本中，必有一个leader副本，其他的就是follower副本（observer副本）；follower定期找leader同步最新的数据；对外提供服务只有leader；</li>
<li>分区follower<br> partition replica中的一个角色，它通过心跳通信不断从leader中拉取、复制数据（只负责备份）。<br> 如果leader所在节点宕机，follower中会选举出新的leader；</li>
<li>消息偏移量offset<br> partition内部每条消息都会被分配一个递增id（offset）；通过offset可以快速定位到消息的存储位置；<br> kafka 只保证按一个partition中的消息的顺序，不保证一个 topic的整体（多个partition 间）的顺序。<br> 我们在说到偏移量的时候，是哪一个topic的哪一个分区的哪一个，偏移量他的数据只能追加，不能被修改<br> <img src="https://images2.imgbox.com/04/4c/kJmH02Lr_o.png" alt="在这里插入图片描述"><br> 自我推导设计：</li>
<li>kafka是用来存数据的；</li>
<li>现实世界数据有分类，所以存储系统也应有数据分类管理功能，如mysql的表；kafka有topic；</li>
<li>如一个topic的数据全部交给一台server存储和管理，则读写吞吐量有限；</li>
<li>所以，一个topic的数据应该可以分成多个部分（partition）分别交给多台server存储和管理；</li>
<li>如一台server宕机，这台server负责的partition将不可用，所以，一个partition应有多个副本；</li>
<li>一个partition有多个副本，则副本间的数据一致性难以保证，因此要有一个leader统领读写；</li>
<li>一个leader万一挂掉，则该partition又不可用，因此还要有leader的动态选举机制；</li>
<li>集群有哪些topic，topic有哪几个分区，server在线情况，等等元信息和状态信息需要在集群内部及客户端之间共享，则引入了zookeeper；</li>
<li>客户端在读取数据时，往往需要知道自己所读取到的位置，因而要引入消息偏移量维护机制；<br> broker服务器：一台 kafka服务器就是一个broker。一个kafka集群由多个 broker 组成。<br> 生产者producer：消息生产者，就是向kafka broker发消息的客户端。<br> 消费者consumer</li>
<li>consumer ：消费者，从kafka broker 取消息的客户端。</li>
<li>consumer group：消费组，单个或多个consumer可以组成一个消费组；<br> 消费组是用来实现消息的广播（发给所有的 consumer）和单播（发给任意一个 consumer）的手段；<br> <img src="https://images2.imgbox.com/3b/cb/HC7lp3sQ_o.png" alt="在这里插入图片描述">
</li>
</ul> 
<h3>
<a id="kafka_128"></a>kafka的数据存储结构</h3> 
<p>物理存储目录结构 __consumer_offset<br> 存储目录 名称规范： topic名称-分区号<br> <img src="https://images2.imgbox.com/d1/f4/8l3LeQyl_o.png" alt="在这里插入图片描述"></p> 
<ul><li>数据文件 名称规范：<br> 生产者生产的消息会不断追加到log文件末尾，为防止log文件过大导致数据定位效率低下，Kafka采取了分片和索引机制</li></ul> 
<ol>
<li>每个partition的数据将分为多个segment存储</li>
<li>每个segment对应两个文件：“.index"文件和“.log"文件。<br> <img src="https://images2.imgbox.com/7a/6b/hhgX2S8T_o.png" alt="在这里插入图片描述"><br> index和log文件以当前segment的第一条消息的offset命名。</li>
</ol> 
<p><img src="https://images2.imgbox.com/37/6e/D7X2L2N9_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/22/c6/z83UYC8O_o.png" alt="在这里插入图片描述"><br> index索引文件中的数据为： 消息offset -&gt; log文件中该消息的物理偏移量位置；<br> Kafka 中的索引文件以稀疏索引（ sparse index ）的方式构造消息的索引，它并不保证每个消息在索引文件中都有对应的索引；每当写入一定量（由 broker 端参数 log.index.interval.bytes 指定，默认值为 4096 ，即 4KB ）的消息时，偏移量索引文件和时间戳索引文件分别增加一个偏移量索引项和时间戳索引项，增大或减小 log.index.interval.bytes的值，对应地可以缩小或增加索引项的密度；<br> 查询指定偏移量时，使用二分查找法来快速定位偏移量的位置。</p> 
<h3>
<a id="message_145"></a>消息message存储结构</h3> 
<p>在客户端编程代码中，消息的封装类有两种：ProducerRecord、ConsumerRecord；<br> 简单来说，kafka中的每个massage由一对key-value构成；<br> Kafka中的message格式经历了3个版本的变化了：v0 、 v1 、 v2</p> 
<p><img src="https://images2.imgbox.com/51/87/ACprle64_o.png" alt="在这里插入图片描述"><br> 各个字段的含义介绍如下：</p> 
<ul>
<li>crc：占用4个字节，主要用于校验消息的内容；</li>
<li>magic：这个占用1个字节，主要用于标识日志格式版本号，此版本的magic值为1</li>
<li>attributes：占用1个字节，这里面存储了消息压缩使用的编码以及Timestamp类型。目前Kafka 支持 gzip、snappy 以及 lz4（0.8.2引入） 三种压缩格式；[0,1,2]三位bit表示压缩类型。[3]位表示时间戳类型（0，create time；1，append time），[4,5,6,7]位保留；</li>
<li>key length：占用4个字节。主要标识 Key的内容的长度；</li>
<li>key：占用 N个字节，存储的是 key 的具体内容；</li>
<li>value length：占用4个字节。主要标识 value 的内容的长度；</li>
<li>value：value即是消息的真实内容，在 Kafka 中这个也叫做payload。</li>
</ul> 
<h2>
<a id="_161"></a>日志分段切分条件</h2> 
<p>日志分段文件切分包含以下4个条件，满足其一即可：</p> 
<ol>
<li>当前日志分段文件的大小超过了broker端参数 log.segment.bytes 配置的值。<br> log.segment.bytes参数的默认值为 1073741824，即1GB</li>
<li>当前日志分段中消息的最小时间戳与当前系统的时间戳的差值大于log.roll.ms或log.roll.hours参数配置的值。如果同时配置了log.roll.ms和log.roll.hours 参数，那么 log.roll.ms 的优先级高，默认情况下，只配置了log.roll.hours参数，其值为168,即7天。</li>
<li>偏移量索引文件或时间戳索引文件的大小达到 broker 端参数 log.index.size.max.bytes 配置的值。<br> log.index.size .max.bytes的默认值为 10485760，即10MB</li>
<li>追加的消息的偏移量与当前日志分段的起始偏移量之间的差值大于Integer.MAX_VALUE, 即要追加的消息的偏移量不能转变为相对偏移量（offset - baseOffset &gt; Integer.MAX_VALUE）。</li>
</ol> 
<h2>
<a id="Controller_170"></a>什么是Controller</h2> 
<p>Controller作为Kafka集群中的核心组件，它的主要作用是在 Apache ZooKeeper 的帮助下管理和协调整个 Kafka 集群。<br> Controller与Zookeeper进行交互，获取与更新集群中的元数据信息。其他broker并不直接与zookeeper进行通信，而是与 Controller 进行通信并同步Controller中的元数据信息。<br> Kafka集群中每个节点都可以充当Controller节点，但集群中同时只能有一个Controller节点。<br> 在Kafka集群中会有一个或者多个broker，其中有一个broker会被选举为控制器（Kafka Controller），它负责维护整个集群中所有分区和副本的状态及分区leader的选举。<br> 当某个分区的leader副本出现故障时，由控制器负责为该分区选举新的leader副本。当检测到某个分区的ISR集合发生变化时，由控制器负责通知所有broker更新其元数据信息。当使用kafka-topics.sh脚本为某个topic增加分区数量时，同样还是由控制器负责分区的重新分配。<br> Kafka中的控制器选举的工作依赖于Zookeeper，成功竞选为控制器的broker会在Zookeeper中创建/controller这个临时（EPHEMERAL）节点，此临时节点的内容参考如下：<br> {“version”:1,“brokerid”:0,“timestamp”:“1529210278988”}<br> 其中version在目前版本中固定为1，brokerid表示成为控制器的broker的id编号，timestamp表示竞选成为控制器时的时间戳。<br> 在任意时刻，集群中有且仅有一个控制器。每个broker启动的时候会去尝试去读取zookeeper上的/controller节点的brokerid的值，如果读取到brokerid的值不为-1，则表示已经有其它broker节点成功竞选为控制器，所以当前broker就会放弃竞选；如果Zookeeper中不存在/controller这个节点，或者这个节点中的数据异常，那么就会尝试去创建/controller这个节点，当前broker去创建节点的时候，也有可能其他broker同时去尝试创建这个节点，只有创建成功的那个broker才会成为控制器，而创建失败的broker则表示竞选失败。每个broker都会在内存中保存当前控制器的brokerid值，这个值可以标识为activeControllerId。<br> <img src="https://images2.imgbox.com/9e/5a/ZwedOhD1_o.png" alt="在这里插入图片描述"></p> 
<h3>
<a id="controller_183"></a>controller的职责</h3> 
<ul><li>监听partition相关变化</li></ul> 
<pre><code class="prism language-sql">对Zookeeper中的<span class="token operator">/</span>admin<span class="token operator">/</span>reassign_partitions节点注册PartitionReassignmentListener，用来处理分区重分配的动作。
对Zookeeper中的<span class="token operator">/</span>isr_change_notification节点注册IsrChangeNotificetionListener，用来处理ISR集合变更的动作。
对Zookeeper中的<span class="token operator">/</span>admin<span class="token operator">/</span>preferred<span class="token operator">-</span>replica<span class="token operator">-</span>election节点添加PreferredReplicaElectionListener，用来处理优先副本选举。
</code></pre> 
<ul><li>监听topic增减变化</li></ul> 
<pre><code class="prism language-sql">对Zookeeper中的<span class="token operator">/</span>brokers<span class="token operator">/</span>topics节点添加TopicChangeListener，用来处理topic增减的变化；
对Zookeeper中的<span class="token operator">/</span>admin<span class="token operator">/</span>delete_topics节点添加TopicDeletionListener，用来处理删除topic的动作。
</code></pre> 
<ul><li>监听broker相关的变化</li></ul> 
<pre><code class="prism language-sql">对Zookeeper中的<span class="token operator">/</span>brokers<span class="token operator">/</span>ids<span class="token operator">/</span>节点添加BrokerChangeListener，用来处理broker增减的变化。
</code></pre> 
<ul><li>更新集群的元数据信息</li></ul> 
<pre><code class="prism language-sql">从Zookeeper中读取获取当前所有与topic、<span class="token keyword">partition</span>以及broker有关的信息并进行相应的管理。对各topic所对应的Zookeeper中的<span class="token operator">/</span>brokers<span class="token operator">/</span>topics<span class="token operator">/</span><span class="token punctuation">[</span>topic<span class="token punctuation">]</span>节点添加PartitionModificationsListener，用来监听topic中的分区分配变化。并将最新信息同步给其他所有broker。
</code></pre> 
<ul>
<li>启动并管理分区状态机和副本状态机。</li>
<li>如果参数auto.leader.rebalance.enable设置为true，则还会开启一个名为“auto-leader-rebalance-task”的定时任务来负责维护分区的leader副本的均衡。</li>
</ul> 
<h3>
<a id="_207"></a>分区的负载分布</h3> 
<p>客户端请求创建一个topic时，每一个分区副本在broker上的分配，是由集群controller来决定；<br> 结论：里面会创建出来两个随机数<br> 第一个随机数确定0号分区leader的位置，往后1号分区2号分区的leader依次往后顺延1<br> 第二个随机数确定每个分区的第一个副本的位置 在leader所在机器上往后顺延（随机数+1）台机器，<br> 该台机器就是第一个副本的位置，剩余副本依次往后顺延1</p> 
<pre><code>举例：
broker_id = 0~19 一共20台机器
分区数20,副本数10
第一个随机数：19
第二个随机数：0
(0,ArrayBuffer(19, 0, 1, 2, 3, 4, 5, 6, 7, 8))
(1,ArrayBuffer(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
(2,ArrayBuffer(1, 2, 3, 4, 5, 6, 7, 8, 9, 10))
(3,ArrayBuffer(2, 3, 4, 5, 6, 7, 8, 9, 10, 11))
(4,ArrayBuffer(3, 4, 5, 6, 7, 8, 9, 10, 11, 12))
(5,ArrayBuffer(4, 5, 6, 7, 8, 9, 10, 11, 12, 13))
(6,ArrayBuffer(5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
(7,ArrayBuffer(6, 7, 8, 9, 10, 11, 12, 13, 14, 15))
(8,ArrayBuffer(7, 8, 9, 10, 11, 12, 13, 14, 15, 16))
(9,ArrayBuffer(8, 9, 10, 11, 12, 13, 14, 15, 16, 17))
(10,ArrayBuffer(9, 10, 11, 12, 13, 14, 15, 16, 17, 18))
(11,ArrayBuffer(10, 11, 12, 13, 14, 15, 16, 17, 18, 19))
(12,ArrayBuffer(11, 12, 13, 14, 15, 16, 17, 18, 19, 0))
(13,ArrayBuffer(12, 13, 14, 15, 16, 17, 18, 19, 0, 1))
(14,ArrayBuffer(13, 14, 15, 16, 17, 18, 19, 0, 1, 2))
(15,ArrayBuffer(14, 15, 16, 17, 18, 19, 0, 1, 2, 3))
(16,ArrayBuffer(15, 16, 17, 18, 19, 0, 1, 2, 3, 4))
(17,ArrayBuffer(16, 17, 18, 19, 0, 1, 2, 3, 4, 5))
(18,ArrayBuffer(17, 18, 19, 0, 1, 2, 3, 4, 5, 6))
(19,ArrayBuffer(18, 19, 0, 1, 2, 3, 4, 5, 6, 7))
</code></pre> 
<p>其分布策略源码如下：</p> 
<pre><code class="prism language-sql">private def assignReplicasToBrokersRackUnaware<span class="token punctuation">(</span>
nPartitions: <span class="token keyword">Int</span><span class="token punctuation">,</span> <span class="token comment">//分区的个数   10</span>
replicationFactor: <span class="token keyword">Int</span><span class="token punctuation">,</span>  <span class="token comment">//副本的个数  5 </span>
brokerList: Seq<span class="token punctuation">[</span><span class="token keyword">Int</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token comment">//broker的集合    8   0~7</span>
fixedStartIndex: <span class="token keyword">Int</span><span class="token comment">//默认值是-1  固定开始的索引位置</span>
startPartitionId: <span class="token keyword">Int</span><span class="token punctuation">)</span>: Map<span class="token punctuation">[</span><span class="token keyword">Int</span><span class="token punctuation">,</span> Seq<span class="token punctuation">[</span><span class="token keyword">Int</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token comment">//默认值是-1 分区开始的位置</span>
<span class="token operator">=</span> {
  val ret <span class="token operator">=</span> mutable<span class="token punctuation">.</span>Map<span class="token punctuation">[</span><span class="token keyword">Int</span><span class="token punctuation">,</span> Seq<span class="token punctuation">[</span><span class="token keyword">Int</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
  val brokerArray <span class="token operator">=</span> brokerList<span class="token punctuation">.</span>toArray
  val startIndex <span class="token operator">=</span> <span class="token keyword">if</span> <span class="token punctuation">(</span>fixedStartIndex <span class="token operator">&gt;=</span> <span class="token number">0</span><span class="token punctuation">)</span> {
      fixedStartIndex
  }<span class="token keyword">else</span> {
          rand<span class="token punctuation">.</span>nextInt<span class="token punctuation">(</span>brokerArray<span class="token punctuation">.</span>length<span class="token punctuation">)</span>
  }
  var currentPartitionId <span class="token operator">=</span> math<span class="token punctuation">.</span><span class="token function">max</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> startPartitionId<span class="token punctuation">)</span> 
  var nextReplicaShift <span class="token operator">=</span> <span class="token keyword">if</span> <span class="token punctuation">(</span>fixedStartIndex <span class="token operator">&gt;=</span> <span class="token number">0</span><span class="token punctuation">)</span> {
          fixedStartIndex 
  }<span class="token keyword">else</span> {
          rand<span class="token punctuation">.</span>nextInt<span class="token punctuation">(</span>brokerArray<span class="token punctuation">.</span>length<span class="token punctuation">)</span>
  }
  <span class="token keyword">for</span> <span class="token punctuation">(</span>_ <span class="token operator">&lt;</span><span class="token operator">-</span> <span class="token number">0</span> until nPartitions<span class="token punctuation">)</span> {
    <span class="token keyword">if</span> <span class="token punctuation">(</span>currentPartitionId <span class="token operator">&gt;</span> <span class="token number">0</span> <span class="token operator">&amp;&amp;</span> <span class="token punctuation">(</span>currentPartitionId <span class="token operator">%</span> brokerArray<span class="token punctuation">.</span>length <span class="token operator">=</span><span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>{
      nextReplicaShift <span class="token operator">+</span><span class="token operator">=</span> <span class="token number">1</span>
        }

    val firstReplicaIndex <span class="token operator">=</span> <span class="token punctuation">(</span>currentPartitionId <span class="token operator">+</span> startIndex<span class="token punctuation">)</span> <span class="token operator">%</span> brokerArray<span class="token punctuation">.</span>length 
    val replicaBuffer <span class="token operator">=</span> mutable<span class="token punctuation">.</span>ArrayBuffer<span class="token punctuation">(</span>brokerArray<span class="token punctuation">(</span>firstReplicaIndex<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> <span class="token punctuation">(</span>j <span class="token operator">&lt;</span><span class="token operator">-</span> <span class="token number">0</span> until replicationFactor <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span> {                          
      replicaBuffer <span class="token operator">+</span><span class="token operator">=</span> brokerArray<span class="token punctuation">(</span>replicaIndex<span class="token punctuation">(</span>firstReplicaIndex<span class="token punctuation">,</span> nextReplicaShift<span class="token punctuation">,</span> j<span class="token punctuation">,</span> brokerArray<span class="token punctuation">.</span>length<span class="token punctuation">)</span><span class="token punctuation">)</span>
    }
    ret<span class="token punctuation">.</span>put<span class="token punctuation">(</span>currentPartitionId<span class="token punctuation">,</span> replicaBuffer<span class="token punctuation">)</span>
    currentPartitionId <span class="token operator">+</span><span class="token operator">=</span> <span class="token number">1</span>
  }
  ret
}
                   
private def replicaIndex<span class="token punctuation">(</span>firstReplicaIndex: <span class="token keyword">Int</span><span class="token punctuation">,</span> secondReplicaShift: <span class="token keyword">Int</span><span class="token punctuation">,</span> replicaIndex: <span class="token keyword">Int</span><span class="token punctuation">,</span> nBrokers: <span class="token keyword">Int</span><span class="token punctuation">)</span>: <span class="token keyword">Int</span> <span class="token operator">=</span> {
  val shift <span class="token operator">=</span> <span class="token number">1</span> <span class="token operator">+</span> <span class="token punctuation">(</span>secondReplicaShift <span class="token operator">+</span> replicaIndex<span class="token punctuation">)</span> <span class="token operator">%</span> <span class="token punctuation">(</span>nBrokers <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span>
  <span class="token punctuation">(</span>firstReplicaIndex <span class="token operator">+</span> shift<span class="token punctuation">)</span> <span class="token operator">%</span> nBrokers
}
</code></pre> 
<ul>
<li><strong>副本因子不能大于 Broker 的个数；<br> 报错：Replication factor: 4 larger than available brokers：3</strong></li>
<li>partition_0的第1个副本（leader副本）放置位置是随机从 brokerList 选择的；</li>
<li>其他分区的第1个副本（leader）放置位置相对于paritition_0分区依次往后移（也就是如果我们有5个 Broker，5个分区，假设partition0分区放在broker4上，那么partition1将会放在broker5上；patition2将会放在broker1上；partition3在broker2，依次类）；</li>
<li>各分区剩余的副本相对于分区前一个副本偏移随机数nextReplicaShift+1，然后后面的副本依次加1</li>
</ul> 
<h3>
<a id="Leader_290"></a>分区Leader的选举机制</h3> 
<p>分区 leader 副本的选举由控制器controller负责具体实施。<br> 当创建分区（创建主题或增加分区都有创建分区的动作）或Leader下线（此时分区需要选举一个新的leader上线来对外提供服务）的时候都需要执行 leader 的选举动作。<br> 选举策略：按照 ISR集合中副本的顺序查找第一个存活的副本，并且这个副本在 ISR 集合中</p>
                </div>
                
                

		</div>
	</article>
</main>




			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程小白.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://www.w3counter.com/tracker.js?id=150625"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>
	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>