<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<title>Redis 主从，哨兵，cluster集群 - 编程小白</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程小白" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程小白</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Redis 主从，哨兵，cluster集群</h1>
			
		</header>
		<div class="content post__content clearfix">
			


        
                <div id="content_views" class="htmledit_views">
                    <p>redis实现高可用<br> ●主从复制：主从复制是高可用Redis的基础，哨兵和集群都是在主从复制基础上实现高可用的。主从复制主要实现了数据的多机备份，以及对于读操作的负载均衡和简单的故障恢复。缺陷：故障恢复无法自动化；写操作无法负载均衡；存储能力受到单机的限制。<br> ●哨兵：在主从复制的基础上，哨兵实现了自动化的故障恢复。缺陷：写操作无法负载均衡；存储能力受到单机的限制；哨兵无法对从节点进行自动故障转移，在读写分离场景下，从节点故障会导致读服务不可用，需要对从节点做额外的监控、切换操作。<br> ●集群：通过集群，Redis解决了写操作无法负载均衡，以及存储能力受到单机限制的问题，实现了较为完善的高可用方案。</p> 
<p><br> ---------------------- Redis 主从复制 ----------------------------------------<br> 主从复制，是指将一台Redis服务器的数据，复制到其他的Redis服务器。前者称为主节点(Master)，后者称为从节点(Slave)；数据的复制是单向的，只能由主节点到从节点。</p> 
<p>默认情况下，每台Redis服务器都是主节点；且一个主节点可以有多个从节点(或没有从节点)，但一个从节点只能有一个主节点。</p> 
<p><br> #主从复制的作用：<br> ●数据冗余：主从复制实现了数据的热备份，是持久化之外的一种数据冗余方式。<br> ●故障恢复：当主节点出现问题时，可以由从节点提供服务，实现快速的故障恢复；实际上是一种服务的冗余。<br> ●负载均衡：在主从复制的基础上，配合读写分离，可以由主节点提供写服务，由从节点提供读服务（即写Redis数据时应用连接主节点，读Redis数据时应用连接从节点），分担服务器负载；尤其是在写少读多的场景下，通过多个从节点分担读负载，可以大大提高Redis服务器的并发量。<br> ●高可用基石：除了上述作用以外，主从复制还是哨兵和集群能够实施的基础，因此说主从复制是Redis高可用的基础。</p> 
<p>#主从复制流程：<br> （1）若启动一个Slave机器进程，则它会向Master机器发送一个“sync command”命令，请求同步连接。<br> （2）无论是第一次连接还是重新连接，Master机器都会启动一个后台进程，将数据快照保存到数据文件中（执行rdb操作），同时Master还会记录修改数据的所有命令并缓存在数据文件中。<br> （3）后台进程完成缓存操作之后，Master机器就会向Slave机器发送数据文件，Slave端机器将数据文件保存到硬盘上，然后将其加载到内存中，接着Master机器就会将修改数据的所有操作一并发送给Slave端机器。若Slave出现故障导致宕机，则恢复正常后会自动重新连接。<br> （4）Master机器收到Slave端机器的连接后，将其完整的数据文件发送给Slave端机器，如果Master同时收到多个Slave发来的同步请求，则Master会在后台启动一个进程以保存数据文件，然后将其发送给所有的Slave端机器，确保所有的Slave端机器都正常。</p> 
<p>---------------------- 搭建Redis 主从复制 ----------------------------------------<br> Master节点：192.168.92.30<br> Slave1节点：192.168.92.40<br> Slave2节点：192.168.92.60</p> 
<p>先为三台虚拟机安装redis环境<br> -----安装 Redis-----<br> //环境准备<br> systemctl stop firewalld<br> systemctl disable firewalld<br> setenforce 0<br> sed -i 's/enforcing/disabled/' /etc/selinux/config</p> 
<p>#修改内核参数<br> echo 'vm.overcommit_memory = 1         ##内存分配策略  1， 表示内核允许分配所有的物理内存，而不管当前的内存状态如何。   <br> net.core.somaxconn = 2048' &gt;&gt;/etc/sysctl.conf<br> sysctl -p</p> 
<p>//安装redis<br> yum install -y gcc gcc-c++ make</p> 
<p>tar zxvf /opt/redis-7.0.9.tar.gz -C /opt/<br> cd /opt/redis-7.0.9<br> make<br> make PREFIX=/usr/local/redis install<br> #由于Redis源码包中直接提供了 Makefile 文件，所以在解压完软件包后，不用先执行 ./configure 进行配置，可直接执行 make 与 make install 命令进行安装。</p> 
<p><br> #创建redis工作目录<br> mkdir /usr/local/redis/{conf,log,data}</p> 
<p>cp /opt/redis-7.0.9/redis.conf /usr/local/redis/conf/</p> 
<p>useradd -M -s /sbin/nologin redis<br> chown -R redis.redis /usr/local/redis/</p> 
<p>#环境变量<br> echo 'PATH=$PATH:/usr/local/redis/bin' &gt;&gt;/etc/profile<br> source /etc/profile</p> 
<p>//定义systemd服务管理脚本<br> echo '[Unit]<br> Description=Redis Server<br> After=network.target</p> 
<p>[Service]<br> User=redis<br> Group=redis<br> Type=forking<br> TimeoutSec=0<br> PIDFile=/usr/local/redis/log/redis_6379.pid<br> ExecStart=/usr/local/redis/bin/redis-server /usr/local/redis/conf/redis.conf<br> ExecReload=/bin/kill -s HUP $MAINPID<br> ExecStop=/bin/kill -s QUIT $MAINPID<br> PrivateTmp=true</p> 
<p>[Install]<br> WantedBy=multi-user.target' &gt;/usr/lib/systemd/system/redis-server.service</p> 
<p>前面的三台都做 后面区分<br> -----修改 Redis 配置文件（Master节点操作）-----<br> vim /usr/local/redis/conf/redis.conf<br> bind 0.0.0.0                                    #87行，修改监听地址为0.0.0.0<br> protected-mode no                                #111行，将本机访问保护模式设置no<br> port 6379                                        #138行，Redis默认的监听6379端口<br> daemonize yes                                    #309行，设置为守护进程，后台启动<br> pidfile /usr/local/redis/log/redis_6379.pid        #341行，指定 PID 文件<br> logfile "/usr/local/redis/log/redis_6379.log"    #354行，指定日志文件<br> dir /usr/local/redis/data                        #504行，指定持久化文件所在目录<br> #requirepass abc123                                #1037行，可选，设置redis密码<br> appendonly yes                                    #1380行，开启AOF</p> 
<p>systemctl restart redis-server.service</p> 
<p>两台slave节点<br> -----修改 Redis 配置文件（Slave节点操作）-----<br> vim /usr/local/redis/conf/redis.conf<br> bind 0.0.0.0                                    #87行，修改监听地址为0.0.0.0<br> protected-mode no                                #111行，将本机访问保护模式设置no<br> port 6379                                        #138行，Redis默认的监听6379端口<br> daemonize yes                                    #309行，设置为守护进程，后台启动<br> pidfile /usr/local/redis/log/redis_6379.pid        #341行，指定 PID 文件<br> logfile "/usr/local/redis/log/redis_6379.log"    #354行，指定日志文件<br> dir /usr/local/redis/data                        #504行，指定持久化文件所在目录<br> #requirepass abc123                                #1037行，可选，设置redis密码<br> appendonly yes                                    #1380行，开启AOF<br> replicaof 192.168.80.10 6379                    #528行，指定要同步的Master节点IP和端口<br> #masterauth abc123                                #535行，可选，指定Master节点的密码，仅在Master节点设置了requirepass</p> 
<p><br> systemctl restart redis-server.service</p> 
<p><br> -----验证主从效果-----<br> 在Master节点上看日志：<br> tail -f /usr/local/redis/log/redis_6379.log <br> Replica 192.168.80.11:6379 asks for synchronization<br> Replica 192.168.80.12:6379 asks for synchronization<br> Synchronization with replica 192.168.80.11:6379 succeeded<br> Synchronization with replica 192.168.80.12:6379 succeeded</p> 
<p>在Master节点上验证从节点：看这个master的从节点有哪些<br> redis-cli info replication<br> # Replication<br> role:master<br> connected_slaves:2<br> slave0:ip=192.168.80.11,port=6379,state=online,offset=1246,lag=0<br> slave1:ip=192.168.80.12,port=6379,state=online,offset=1246,lag=1</p> 
<p>---------------------- Redis 哨兵模式 ----------------------------------------<br> 主从切换技术的方法是：当服务器宕机后，需要手动一台从机切换为主机，这需要人工干预，不仅费时费力而且还会造成一段时间内服务不可用。为了解决主从复制的缺点，就有了哨兵机制。</p> 
<p>哨兵的核心功能：在主从复制的基础上，哨兵引入了主节点的自动故障转移。</p> 
<p><br> #哨兵模式的作用：<br> ●监控：哨兵会不断地检查主节点和从节点是否运作正常。</p> 
<p>●自动故障转移：当主节点不能正常工作时，哨兵会开始自动故障转移操作，它会将失效主节点的其中一个从节点升级为新的主节点，并让其它从节点改为复制新的主节点。</p> 
<p>●通知（提醒）：哨兵可以将故障转移的结果发送给客户端。</p> 
<p><br> 哨兵结构由两部分组成，哨兵节点和数据节点：<br> ●哨兵节点：哨兵系统由一个或多个哨兵节点组成，哨兵节点是特殊的redis节点，不存储数据。<br> ●数据节点：主节点和从节点都是数据节点。</p> 
<p><br> #故障转移机制：<br> 1.由哨兵节点定期监控发现主节点是否出现了故障<br> 每个哨兵节点每隔1秒会向主节点、从节点及其它哨兵节点发送一次ping命令做一次心跳检测。如果主节点在一定时间范围内不回复或者是回复一个错误消息，那么这个哨兵就会认为这个主节点主观下线了（单方面的）。当超过半数哨兵节点认为该主节点主观下线了，这样就客观下线了。</p> 
<p>2.当主节点出现故障，此时哨兵节点会通过Raft算法（选举算法）实现选举机制共同选举出一个哨兵节点为leader，来负责处理主节点的故障转移和通知。所以整个运行哨兵的集群的数量不得少于3个节点。</p> 
<p>3.由leader哨兵节点执行故障转移，过程如下：<br> ●将某一个从节点升级为新的主节点，让其它从节点指向新的主节点；<br> ●若原主节点恢复也变成从节点，并指向新的主节点；<br> ●通知客户端主节点已经更换。</p> 
<p>需要特别注意的是，客观下线是主节点才有的概念；如果从节点和哨兵节点发生故障，被哨兵主观下线后，不会再有后续的客观下线和故障转移操作。</p> 
<p><br> #主节点的选举：<br> 1.过滤掉不健康的（已下线的），没有回复哨兵 ping 响应的从节点。<br> 2.选择配置文件中从节点优先级配置最高的。（replica-priority，默认值为100）<br> 3.选择复制偏移量最大，也就是复制最完整的从节点。</p> 
<p><br> 哨兵的启动依赖于主从模式，所以须把主从模式安装好的情况下再去做哨兵模式</p> 
<p>---------------------- 搭建Redis 哨兵模式 ----------------------------------------<br> Master节点：192.168.80.10<br> Slave1节点：192.168.80.11<br> Slave2节点：192.168.80.12</p> 
<p>systemctl stop firewalld<br> setenforce 0</p> 
<p>-----修改 Redis 哨兵模式的配置文件（所有节点操作）-----<br> cp /opt/redis-7.0.9/sentinel.conf /usr/local/redis/conf/<br> chown redis.redis /usr/local/redis/conf/sentinel.conf</p> 
<p>vim /usr/local/redis/conf/sentinel.conf<br> protected-mode no                                    #6行，关闭保护模式<br> port 26379                                            #10行，Redis哨兵默认的监听端口<br> daemonize yes                                        #15行，指定sentinel为后台启动<br> pidfile /usr/local/redis/log/redis-sentinel.pid        #20行，指定 PID 文件<br> logfile "/usr/local/redis/log/sentinel.log"            #25行，指定日志存放路径<br> dir /usr/local/redis/data                            #54行，指定数据库存放路径<br> sentinel monitor mymaster 192.168.80.10 6379 2        #73行，修改 指定该哨兵节点监控192.168.80.10:6379这个主节点，该主节点的名称是mymaster，最后的2的含义与主节点的故障判定有关：至少需要2个哨兵节点同意，才能判定主节点故障并进行故障转移<br> #sentinel auth-pass mymaster abc123                    #76行，可选，指定Master节点的密码，仅在Master节点设置了requirepass<br> sentinel down-after-milliseconds mymaster 3000        #114行，判定服务器down掉的时间周期，默认30000毫秒（30秒）<br> sentinel failover-timeout mymaster 180000            #214行，同一个sentinel对同一个master两次failover之间的间隔时间（180秒）</p> 
<p><br> -----启动哨兵模式-----<br> 先启master，再启slave<br> cd /usr/local/redis/conf/<br> redis-sentinel sentinel.conf &amp;</p> 
<p><br> -----查看哨兵信息-----<br> redis-cli -p 26379 info Sentinel<br> # Sentinel<br> sentinel_masters:1<br> sentinel_tilt:0<br> sentinel_running_scripts:0<br> sentinel_scripts_queue_length:0<br> sentinel_simulate_failure_flags:0<br> master0:name=mymaster,status=ok,address=192.168.80.10:6379,slaves=2,sentinels=3</p> 
<p>-----故障模拟-----<br> #查看redis-server进程号：<br> ps -ef | grep redis<br> root      57031      1  0 15:20 ?        00:00:07 /usr/local/bin/redis-server 0.0.0.0:6379<br> root      57742      1  1 16:05 ?        00:00:07 redis-sentinel *:26379 [sentinel]<br> root      57883  57462  0 16:17 pts/1    00:00:00 grep --color=auto redis</p> 
<p>#杀死 Master 节点上redis-server的进程号<br> kill -9 57031            #Master节点上redis-server的进程号</p> 
<p>#验证结果<br> tail -f /usr/local/redis/log/sentinel.log<br> 6709:X 13 Mar 2023 12:27:29.517 # +sdown master mymaster 192.168.80.10 6379<br> 6709:X 13 Mar 2023 12:27:29.594 * Sentinel new configuration saved on disk<br> 6709:X 13 Mar 2023 12:27:29.594 # +new-epoch 1<br> 6709:X 13 Mar 2023 12:27:29.595 * Sentinel new configuration saved on disk<br> 6709:X 13 Mar 2023 12:27:29.595 # +vote-for-leader c64fac46fcd98350006900c330998364d6af635d 1<br> 6709:X 13 Mar 2023 12:27:29.620 # +odown master mymaster 192.168.80.10 6379 #quorum 2/2<br> 6709:X 13 Mar 2023 12:27:29.621 # Next failover delay: I will not start a failover before Mon Mar 13 12:33:30 2023<br> 6709:X 13 Mar 2023 12:27:30.378 # +config-update-from sentinel c64fac46fcd98350006900c330998364d6af635d 192.168.80.11 26379 @ mymaster 192.168.80.10 6379<br> 6709:X 13 Mar 2023 12:27:30.378 # +switch-master mymaster 192.168.80.10 6379 192.168.80.11 6379<br> 6709:X 13 Mar 2023 12:27:30.378 * +slave slave 192.168.80.13:6379 192.168.80.13 6379 @ mymaster 192.168.80.11 6379<br> 6709:X 13 Mar 2023 12:27:30.378 * +slave slave 192.168.80.10:6379 192.168.80.10 6379 @ mymaster 192.168.80.11 6379<br> 6709:X 13 Mar 2023 12:27:30.381 * Sentinel new configuration saved on disk<br> 6709:X 13 Mar 2023 12:27:33.379 # +sdown slave 192.168.80.10:6379 192.168.80.10 6379 @ mymaster 192.168.80.11 6379</p> 
<p><br> 2.redis-cli -p 26379 INFO Sentinel<br> # Sentinel<br> sentinel_masters:1<br> sentinel_tilt:0<br> sentinel_tilt_since_seconds:-1<br> sentinel_running_scripts:0<br> sentinel_scripts_queue_length:0<br> sentinel_simulate_failure_flags:0<br> master0:name=mymaster,status=ok,address=192.168.80.11:6379,slaves=2,sentinels=3</p> 
<p>---------------------- Redis 群集模式 ----------------------------------------<br> 集群，即Redis Cluster，是Redis 3.0开始引入的分布式存储方案。</p> 
<p>集群由多组节点(Node)组成，Redis的数据分布在这些节点中。集群中的节点分为主节点和从节点：只有主节点负责读写请求和集群信息的维护；从节点只进行主节点数据和状态信息的复制。</p> 
<p><br> #集群的作用，可以归纳为两点：<br> （1）数据分区：数据分区(或称数据分片)是集群最核心的功能。<br> 集群将数据分散到多个节点，一方面突破了Redis单机内存大小的限制，存储容量大大增加；另一方面每个主节点都可以对外提供读服务和写服务，大大提高了集群的响应能力。<br> Redis单机内存大小受限问题，在介绍持久化和主从复制时都有提及；例如，如果单机内存太大，bgsave和bgrewriteaof的fork操作可能导致主进程阻塞，主从环境下主机切换时可能导致从节点长时间无法提供服务，全量复制阶段主节点的复制缓冲区可能溢出。</p> 
<p>（2）高可用：集群支持主从复制和主节点的自动故障转移（与哨兵类似）；当任一节点发生故障时，集群仍然可以对外提供服务。</p> 
<p>#Redis集群的数据分片：<br> Redis集群引入了哈希槽的概念<br> Redis集群有16384个哈希槽（编号0-16383）<br> 集群的每组节点负责一部分哈希槽<br> 每个Key通过CRC16校验后对16384取余来决定放置哪个哈希槽，通过这个值，去找到对应的插槽所对应的节点，然后直接自动跳转到这个对应的节点上进行存取操作</p> 
<p>#以3个节点组成的集群为例：<br> 节点A包含0到5460号哈希槽<br> 节点B包含5461到10922号哈希槽<br> 节点C包含10923到16383号哈希槽</p> 
<p>#Redis集群的主从复制模型<br> 集群中具有A、B、C三个节点，如果节点B失败了，整个集群就会因缺少5461-10922这个范围的槽而不可以用。<br> 为每个节点添加一个从节点A1、B1、C1整个集群便有三个Master节点和三个slave节点组成，在节点B失败后，集群选举B1位为的主节点继续服务。当B和B1都失败后，集群将不可用。</p> 
<p><br> ---------------------- 搭建Redis 群集模式 ----------------------------------------<br> redis的集群一般需要6个节点，3主3从。方便起见，这里所有节点在同一台服务器上模拟：<br> 以端口号进行区分：3个主节点端口号：6001/6002/6003，对应的从节点端口号：6004/6005/6006。</p> 
<p>cd /usr/local/redis/<br> mkdir -p redis-cluster/redis600{1..6}</p> 
<p>for i in {1..6}<br> do<br> cp /opt/redis-7.0.9/redis.conf /usr/local/redis/redis-cluster/redis600$i<br> cp /opt/redis-7.0.9/src/redis-cli /opt/redis-7.0.9/src/redis-server /usr/local/redis/redis-cluster/redis600$i<br> done</p> 
<p>#开启群集功能：<br> #其他5个文件夹的配置文件以此类推修改，注意6个端口都要不一样。<br> cd /usr/local/redis/redis-cluster/redis6001<br> vim redis.conf<br> #bind 127.0.0.1                                    #87行，注释掉bind项，默认监听所有网卡<br> protected-mode no                                #111行，关闭保护模式<br> port 6001                                        #138行，修改redis监听端口<br> daemonize yes                                    #309行，设置为守护进程，后台启动<br> pidfile /usr/local/redis/log/redis_6001.pid        #341行，指定 PID 文件<br> logfile "/usr/local/redis/log/redis_6001.log"    #354行，指定日志文件<br> dir ./                                            #504行，指定持久化文件所在目录<br> appendonly yes                                    #1379行，开启AOF<br> cluster-enabled yes                                #1576行，取消注释，开启群集功能<br> cluster-config-file nodes-6001.conf                #1584行，取消注释，群集名称文件设置<br> cluster-node-timeout 15000                        #1590行，取消注释群集超时时间设置</p> 
<p><br> #启动redis节点<br> 分别进入那六个文件夹，执行命令：redis-server redis.conf ，来启动redis节点<br> cd /usr/local/redis/redis-cluster/redis6001<br> redis-server redis.conf</p> 
<p>for d in {1..6}<br> do<br> cd /usr/local/redis/redis-cluster/redis600$d<br> ./redis-server redis.conf<br> done</p> 
<p>ps -ef | grep redis</p> 
<p>#启动集群<br> redis-cli --cluster create 127.0.0.1:6001 127.0.0.1:6002 127.0.0.1:6003 127.0.0.1:6004 127.0.0.1:6005 127.0.0.1:6006 --cluster-replicas 1</p> 
<p>#六个实例分为三组，每组一主一从，前面的做主节点，后面的做从节点。下面交互的时候 需要输入 yes 才可以创建。<br> --replicas 1 表示每个主节点有1个从节点。</p> 
<p>#测试群集<br> redis-cli -p 6001 -c                    #加-c参数，节点之间就可以互相跳转<br> 127.0.0.1:6001&gt; cluster slots            #查看节点的哈希槽编号范围<br> 1) 1) (integer) 5461<br>    2) (integer) 10922                                    #哈希槽编号范围<br>    3) 1) "127.0.0.1"<br>       2) (integer) 6003                                    #主节点IP和端口号<br>       3) "fdca661922216dd69a63a7c9d3c4540cd6baef44"<br>    4) 1) "127.0.0.1"<br>       2) (integer) 6004                                    #从节点IP和端口号<br>       3) "a2c0c32aff0f38980accd2b63d6d952812e44740"<br> 2) 1) (integer) 0<br>    2) (integer) 5460<br>    3) 1) "127.0.0.1"<br>       2) (integer) 6001<br>       3) "0e5873747a2e26bdc935bc76c2bafb19d0a54b11"<br>    4) 1) "127.0.0.1"<br>       2) (integer) 6006<br>       3) "8842ef5584a85005e135fd0ee59e5a0d67b0cf8e"<br> 3) 1) (integer) 10923<br>    2) (integer) 16383<br>    3) 1) "127.0.0.1"<br>       2) (integer) 6002<br>       3) "816ddaa3d1469540b2ffbcaaf9aa867646846b30"<br>    4) 1) "127.0.0.1"<br>       2) (integer) 6005<br>       3) "f847077bfe6722466e96178ae8cbb09dc8b4d5eb"</p> 
<p>127.0.0.1:6001&gt; set name zhangsan<br> -&gt; Redirected to slot [5798] located at 127.0.0.1:6003<br> OK</p> 
<p>127.0.0.1:6001&gt; cluster keyslot name                    #查看name键的槽编号</p> 
<p>redis-cli -p 6004 -c<br> 127.0.0.1:6004&gt; keys *                            #对应的slave节点也有这条数据，但是别的节点没有<br> 1) "name"</p> 
<p><br> redis-cli -p 6001 -c cluster nodes</p>
                </div>

		</div>
	</article>
</main>




			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程小白.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://www.w3counter.com/tracker.js?id=150625"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>
	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>