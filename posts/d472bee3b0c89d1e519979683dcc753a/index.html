<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<title>k8s day06 - 编程小白</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程小白" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程小白</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">k8s day06</h1>
			
		</header>
		<div class="content post__content clearfix">
			


        
                <div id="content_views" class="htmledit_views">
                    <p>污点通常情况下是作用在worker节点上，其可以影响Pod的调度。</p> 
<p>污点的语法格式如下:<br>     key[=value]:effect<br>     <br> 相关字段说明:<br>     key:<br>         字母或数字开头，可以包含字母、数字、连字符(-)、点(.)和下划线(_)，最多253个字符。<br>         也可以以DNS子域前缀和单个"/"开头<br>     <br>     value:<br>         该值是可选的。如果给定，它必须以字母或数字开头，可以包含字母、数字、连字符、点和下划线，最多63个字符。<br>     <br>     effect:[ɪˈfekt]<br>         effect必须是NoSchedule、PreferNoSchedule或NoExecute。<br>             NoSchedule: [noʊ,ˈskedʒuːl]<br>                 该节点不再接收新的Pod调度，但不会驱赶已经调度到该节点的Pod。<br>             PreferNoSchedule: [prɪˈfɜːr,noʊ,ˈskedʒuː] <br>                 该节点可以接受调度，但会尽可能将Pod调度到其他节点，换句话说，让该节点的调度优先级降低啦。<br>             NoExecute:[ˈnoʊ,eksɪkjuːt] <br>                 该节点不再接收新的Pod调度，与此同时，会立刻驱逐已经调度到该节点的Pod。<br>                 <br>                 <br> 实战案例:<br>     (1)查看污点(taints[teɪnts])<br> kubectl describe nodes | grep Taints </p> 
<p>    (2)打污点<br> kubectl taint node k8s153.oldboyedu.com school=oldboyedu:PreferNoSchedule<br> kubectl taint node k8s153.oldboyedu.com school=oldboyedu:NoSchedule<br> kubectl taint node k8s153.oldboyedu.com school=oldboyedu:NoExecute</p> 
<p>    (3)取消污点<br> kubectl taint node k8s153.oldboyedu.com school-<br> kubectl taint node k8s153.oldboyedu.com school=oldboyedu:NoSchedule-<br> kubectl taint node k8s153.oldboyedu.com school=oldboyedu:NoExecute-</p> 
<p>污点容忍（toleration[ˌtɑːləˈreɪʃn]）:<br>     所谓的污点容忍，就是允许Pod调度到存在污点的节点。<br>     <br>     <br> 实战案例:<br>     1.所有节点创建污点<br> kubectl taint node k8s151.oldboyedu.com school=oldboyedu:NoSchedule<br> kubectl taint node k8s152.oldboyedu.com school=oldboyedu:PreferNoSchedule<br> kubectl taint node k8s153.oldboyedu.com school=oldboyedu:NoExecute</p> 
<p>    2.容忍污点<br> [root@k8s151.oldboyedu.com deploy]# cat 04-deploy-taints.yaml <br> kind: Deployment<br> apiVersion: extensions/v1beta1<br> metadata:<br>   name: oldboyedu-linux82-deploy-nginx-taints-001<br> spec:<br>   replicas: 3<br>   selector:<br>      matchLabels:<br>         school: oldboyedu<br>   template:<br>      metadata:<br>         name: linux82-web<br>         labels:<br>            school: oldboyedu<br>      spec:<br>         # 配置污点容忍，则容器可以调度到具有该污点的节点<br>         tolerations:<br>           # 若key不定义，则表示匹配所有的key值。<br>         - key: school<br>           value: oldboyedu<br>           # operator表示key和value之间的关系，有效值为: Exists(存在),Equal(等于).默认值为"Equal"<br>           # 若operator的值为Exists，value的值必须为空，表示只要存在school这个KEY，默认匹配所有的值。<br>           operator: Equal<br>         - key: node-role.kubernetes.io/master<br>           operator: Exists<br>           # 注意，effect若不配置，则默认匹配所有的污点类型<br>           # 若指定，则有效值为: NoSchedule,PreferNoSchedule,NoExecute<br>           effect: NoSchedule<br>         containers:<br>         - name: linux82-web<br>           image: k8s151.oldboyedu.com:5000/oldboyedu-web/nginx:1.20.1<br> [root@k8s151.oldboyedu.com deploy]# </p> 
<p>亲和性(affinity)概述<br>     节点亲和性(nodeAffinity):<br>         用于控制Pod调度到哪些worker节点上，以及不能部署在哪些机器上。</p> 
<p>    Pod亲和性(podAffinity):<br>         Pod可以和哪些Pod部署在同一个拓扑域。</p> 
<p>    Pod反亲和性(podAntiAffinity):<br>         Pod可以和哪些Pod部署在不同一个拓扑域。<br>         <br>         <br>         <br> 节点亲和性(nodeAffinity)<br>     (1)worker节点打标签<br> kubectl label nodes k8s151.oldboyedu.com school=oldboyedu<br> kubectl label nodes k8s152.oldboyedu.com school=yitiantian<br> kubectl label nodes k8s151.oldboyedu.com class=linux82<br> kubectl label nodes k8s152.oldboyedu.com class=jiaoshi05<br> kubectl get no --show-labels</p> 
<p><br>     (2)创建资源清单<br> cat &gt; 05-pods-nodeAffinity.yaml &lt;&lt;'EOF'<br> apiVersion: extensions/v1beta1<br> kind: Deployment<br> metadata:<br>   name: oldboyedu-linux82-affinity-nodeaffinity<br>   labels:<br>     school: oldboyedue<br> spec:<br>   replicas: 10<br>   template:<br>     metadata:<br>        name: linux82-web<br>        labels:<br>           apps: web<br>     spec:<br>       # 容忍污点<br>       tolerations:<br>       - operator: Exists<br>       # 亲和性<br>       affinity:<br>          # 节点亲和性<br>          nodeAffinity:<br>             # 硬限制，必须满足的条件<br>             requiredDuringSchedulingIgnoredDuringExecution:<br>               # 定义节点选择器列表 <br>               nodeSelectorTerms:<br>                 # 基于节点的标签进行关联<br>               - matchExpressions:<br>                 - key: class<br>                   operator: NotIn<br>                   values:<br>                   - linux82<br>                   - jiaoshi05<br>             # 软限制，不一定要满足，但会优先满足，相当于提高了调度的优先级<br>             preferredDuringSchedulingIgnoredDuringExecution:<br>               # 配置权重<br>             - weight: 10<br>               # 偏向性<br>               preference:<br>                  # 基于节点的标签进行关联<br>                  matchExpressions:<br>                    # 表示节点的标签名称<br>                  - key: school<br>                    # 关联关系，表示key和values的关系<br>                    #  In<br>                    #     包含，要求values字段不能为空。<br>                    #  NotIn<br>                    #     不包含，要求values字段不能为空。<br>                    #  Exists<br>                    #     存在，要求values字段必须为空。<br>                    #  DoesNotExist<br>                    #     不存在，要求values字段必须为空。<br>                    #  Gt<br>                    #     大于，要求values字段必须是一个单一的元素，且值将被解释为整数。<br>                    #  Lt<br>                    #     小于，要求values字段必须是一个单一的元素，且值将被解释为整数。<br>                    operator: In<br>                    # 定义标签的值<br>                    values: <br>                    - "oldboyedu"<br>                    - "yitiantian"<br>                    - "laonanhai"<br>       containers:<br>       - name: linux82-web<br>         image: k8s151.oldboyedu.com:5000/oldboyedu-web/nginx:1.20.1<br> EOF</p> 
<p><br> Pod亲和性(podAffinity):<br> cat &gt; 06-pods-podAffinity.yaml &lt;&lt;'EOF'<br> apiVersion: extensions/v1beta1<br> kind: Deployment<br> metadata:<br>   name: oldboyedu-linux82-affinity-podaffinity<br> spec:<br>   replicas: 20<br>   selector:<br>     matchLabels:<br>       apps: oldboyedu-web<br>   template:<br>     metadata:<br>       name: linux82-web<br>       labels:<br>         apps: oldboyedu-web<br>     spec:<br>       tolerations:<br>       - operator: Exists<br>       affinity:<br>         # 定义Pod的亲和性<br>         podAffinity:<br>           # 定义硬限制<br>           requiredDuringSchedulingIgnoredDuringExecution:<br>             # 指定的拓扑域为"kubernetes.io/hostname"时:<br>             #      就会发现所有的Pod被调度到同一个节点的现象，这是因为所有的node节点key其values值不同导致的。<br>             # 指定的拓扑域为"beta.kubernetes.io/os"时:<br>             #      就会发现所有的Pod被调度到不同的节点，这是因为所有的node节点的key其values值相同。<br>           # - topologyKey: kubernetes.io/hostname<br>           - topologyKey: beta.kubernetes.io/os<br>           # 值得注意的是，如果有的节点没有school这个key，在K8S 1.15.12版本中测试发现，有可能会调度到没有school的KEY节点哟!<br>           # - topologyKey: school<br>             # 注意，上面的topologyKey拓扑域并不能立刻确定Pod应该调度到哪个节点，<br>             # 因为可能选择较多(即节点的key相同value不相同的情况)，所以需要借助pod的标签选择器进行再次确认!<br>             labelSelector:<br>                matchExpressions:<br>                  # 此处的KEY并非是node的标签，而是pods的标签哟~<br>                - key: apps<br>                  # 注意，如果Pod出现了key值相同，但value不相同的标签，这个时候不建议使用Exists<br>                  # 而是建设设置白名单，即采用"operator: In"的方式进行匹配，当然此时values不能为空。<br>                  operator: Exists<br>       containers:<br>       - name: linux82-web<br>         image: k8s151.oldboyedu.com:5000/oldboyedu-web/nginx:1.20.1<br> EOF</p> 
<p>Pod反亲和性(podAntiAffinity):<br> cat &gt; 07-podAntiAffinity &lt;&lt;'EOF'<br> apiVersion: extensions/v1beta1<br> kind: Deployment<br> metadata:<br>   name: oldboyedu-linux82-affinity-podantiaffinity<br> spec:<br>   replicas: 10<br>   selector:<br>     matchLabels:<br>       apps: oldboyedu-web<br>   template:<br>     metadata:<br>       name: linux82-web<br>       labels:<br>         apps: oldboyedu-web<br>     spec:<br>       tolerations:<br>       - operator: Exists<br>       affinity:<br>         # 定义Pod的反亲和性<br>         podAntiAffinity:<br>           requiredDuringSchedulingIgnoredDuringExecution:<br>           - topologyKey: kubernetes.io/hostname<br>             labelSelector:<br>                matchExpressions:<br>                - key: apps<br>                  values:<br>                  - oldboyedu-web<br>                  operator: In<br>       containers:<br>       - name: linux82-web<br>         image: k8s151.oldboyedu.com:5000/oldboyedu-web/nginx:1.20.1<br> EOF</p> 
<p><br> 节点选择器nodeSelector:<br>     1.节点打标签<br> kubectl label nodes --all --overwrite school=oldboyedu<br> kubectl label nodes k8s152.oldboyedu.com school-</p> 
<p>    2.创建资源清单<br> cat &gt; 08-pods-nodeSelector.yaml &lt;&lt;'EOF'<br> apiVersion: extensions/v1beta1<br> kind: Deployment<br> metadata:<br>   name: oldboyedu-linux82-affinity-podantiaffinity<br> spec:<br>   replicas: 10<br>   selector:<br>     matchLabels:<br>       apps: oldboyedu-web<br>   template:<br>     metadata:<br>       name: linux82-web<br>       labels:<br>         apps: oldboyedu-web<br>     spec:<br>       tolerations:<br>       - operator: Exists<br>       # 将Pod调度到包含特定标签的节点<br>       nodeSelector:<br>         school: oldboyedu<br>       containers:<br>       - name: ds-web-linux82<br>         image: k8s151.oldboyedu.com:5000/oldboyedu-web/nginx:1.20.1<br> EOF</p> 
<p>Job概述:<br>     一次性任务，Pod完成作业后并不重启容器。其重启策略为"restartPolicy: Never"<br>     <br>     <br> Job控制器参考案例：<br> cat &gt; 01-job.yaml &lt;&lt;EOF<br> apiVersion: batch/v1<br> kind: Job<br> metadata:<br>   name: oldboyedu-linux82-pi<br> spec:<br>   template:<br>     spec:<br>       containers:<br>       - name: pi<br>         image: perl:5.34<br>         # 它计算π到2000个位置并打印出来。大约需要10秒才能完成。<br>         # command: ["perl",  "-Mbignum=bpi", "-wle", "print bpi(2000)"]<br>         command: <br>         - "/bin/sh"<br>         - "-c"<br>         - "for ((i=0;i&lt;3600;i++)); do echo $i &gt; /dev/stdout; sleep 1 ;done"<br>       # 注意，此处的重启策略表示容器退出时是否重新创建，但手动杀死容器，发现依旧会自动拉起，这是CM组件保证了这个特性。<br>       restartPolicy: Never<br>   # 指定标记此作业失败之前的重试次数。官方文档说默认值为6次，但实际测试为7次。<br>   # 此处我指定为2次，表示容器启动失败时，会尝试重新启动新的Pod次数为2.<br>   backoffLimit: 2<br> EOF<br>     </p> 
<p>CronJob概述:<br>     周期性任务，CronJob底层逻辑是周期性创建Job控制器来实现周期性任务的。<br>     <br>     <br> CronJob控制器参考案例:<br> cat &gt; cronjob.yaml &lt;&lt;'EOF'<br> apiVersion: batch/v1beta1<br> kind: CronJob<br> metadata:<br>   name: oldboyedu-hello<br> spec:<br>   # 定义调度格式，参考链接：https://en.wikipedia.org/wiki/Cron<br>   # ┌───────────── 分钟 (0 - 59)<br>   # │ ┌───────────── 小时 (0 - 23)<br>   # │ │ ┌───────────── 月的某天 (1 - 31)<br>   # │ │ │ ┌───────────── 月份 (1 - 12)<br>   # │ │ │ │ ┌───────────── 周的某天 (0 - 6)（周日到周一；在某些系统上，7 也是星期日）<br>   # │ │ │ │ │                          或者是 sun，mon，tue，web，thu，fri，sat<br>   # │ │ │ │ │<br>   # │ │ │ │ │<br>   # * * * * *<br>   schedule: "* * * * *"<br>   jobTemplate:<br>     spec:<br>       template:<br>         spec:<br>           containers:<br>           - name: hello<br>             image: k8s151.oldboyedu.com:5000/oldboyedu-linux/busybox:1.28<br>             imagePullPolicy: IfNotPresent<br>             command:<br>             - /bin/sh<br>             - -c<br>             - date; echo Hello from the oldboyedu linux82 Kubernetes cluster<br>           restartPolicy: OnFailure<br> EOF</p> 
<p>DaemonSet概述：<br>     DaemonSet确保全部worker节点上运行一个Pod的副本，换句话说，在不考虑污点的情况下，保证每个worker节点有且只有一个Pod副本。</p> 
<p>    DaemonSet的一些典型用法：<br>         (1)在每个节点上运行集群守护进程(flannel等)<br>         (2)在每个节点上运行日志收集守护进程(flume，filebeat，fluentd等)<br>         (3)在每个节点上运行监控守护进程（zabbix agent，node_exportor等）</p> 
<p><br>     温馨提示:<br>         (1)当有新节点加入集群时，也会为新节点新增一个Pod;<br>         (2)当有节点从集群移除时，这些Pod也会被回收;<br>         (3)删除DaemonSet将会删除它创建的所有Pod;<br>         (4)如果节点被打了污点的话，且DaemonSet中未定义污点容忍，则Pod并不会被调度到该节点上;("flannel案例")</p> 
<p>DaemonSet参考案例:<br> cat &gt; 01-ds-nginx.yaml &lt;&lt;EOF<br> kind: DaemonSet<br> apiVersion: extensions/v1beta1<br> metadata:<br>   name: oldboyedu-linux82-ds-nginx<br> spec:<br>   selector:<br>      matchLabels:<br>         school: oldboyedu<br>   template:<br>      metadata:<br>         name: linux82-web<br>         labels:<br>            school: oldboyedu<br>      spec:<br>         tolerations:<br>         - operator: Exists<br>         containers:<br>         - name: linux82-web<br>           image: k8s151.oldboyedu.com:5000/oldboyedu-web/nginx:1.20.1<br> EOF</p> 
<p><br> StatefulSets概述:<br>     以Nginx的为例，当任意一个Nginx挂掉，其处理的逻辑是相同的，即仅需重新创建一个Pod副本即可，这类服务我们称之为无状态服务。</p> 
<p>    以MySQL主从同步为例，master，slave两个库任意一个库挂掉，其处理逻辑是不相同的，这类服务我们称之为有状态服务。</p> 
<p>    有状态服务面临的难题:<br>         (1)启动/停止顺序;<br>         (2)pod实例的数据是独立存储;<br>         (3)需要固定的IP地址或者主机名;<br>         <br>      <br>     StatefulSet一般用于有状态服务，StatefulSets对于需要满足以下一个或多个需求的应用程序很有价值。<br>         (1)稳定唯一的网络标识符。<br>         (2)稳定独立持久的存储。<br>         (4)有序优雅的部署和缩放。<br>         (5)有序自动的滚动更新。    <br>         <br>         <br>     稳定的网络标识:<br>         其本质对应的是一个service资源，只不过这个service没有定义VIP，我们称之为headless service，即"无头服务"。<br>         通过"headless service"来维护Pod的网络身份，会为每个Pod分配一个数字编号并且按照编号顺序部署。<br>         综上所述，无头服务（"headless service"）要求满足以下两点:<br>             (1)将svc资源的clusterIP字段设置None，即"clusterIP: None";<br>             (2)将sts资源的serviceName字段声明为无头服务的名称;<br>                 <br>                 <br>     独享存储:<br>         Statefulset的存储卷使用VolumeClaimTemplate创建，称为"存储卷申请模板"。<br>         当sts资源使用VolumeClaimTemplate创建一个PVC时，同样也会为每个Pod分配并创建唯一的pvc编号，每个pvc绑定对应pv，从而保证每个Pod都有独立的存储。</p> 
<p>StatefulSets控制器-网络唯一标识之headless：<br>     (1)编写资源清单<br> cat &gt; 01-statefulset-headless-network.yaml &lt;&lt;'EOF'<br> apiVersion: v1<br> kind: Service<br> metadata:<br>   name: linux82-headless<br> spec:<br>   ports:<br>   - port: 80<br>     name: web<br>   # 将clusterIP字段设置为None表示为一个无头服务(headless services)，即svc将不会分配VIP。<br>   clusterIP: None<br>   selector:<br>     app: nginx</p> 
<p>---</p> 
<p>apiVersion: apps/v1<br> kind: StatefulSet<br> metadata:<br>   name: linux82-web<br> spec:<br>   selector:<br>     matchLabels:<br>       app: nginx<br>   # 声明无头服务    <br>   serviceName: linux82-headless<br>   replicas: 3 <br>   template:<br>     metadata:<br>       labels:<br>         app: nginx<br>     spec:<br>       containers:<br>       - name: nginx<br>         image: k8s151.oldboyedu.com:5000/oldboyedu-web/nginx:1.20.1<br>         ports:<br>         - containerPort: 80<br> EOF</p> 
<p><br>     (2)使用响应式API创建测试Pod<br> # kubectl run -it dns-test --rm --image=k8s151.oldboyedu.com:5000/oldboyedu-linux/alpine -- sh<br> #<br> # for i in `seq 0 2`;do ping linux82-web-${i}.linux82-headless.default.svc.cluster.local  -c 3;done</p> 
<p>StatefulSets控制器-独享存储<br>     (1)编写资源清单<br> cat &gt; 02-statefulset-headless-volumeClaimTemplates.yaml &lt;&lt;'EOF'<br> apiVersion: v1<br> kind: Service<br> metadata:<br>   name: linux82-headless<br> spec:<br>   ports:<br>   - port: 80<br>     name: web<br>   # 将clusterIP字段设置为None表示为一个无头服务，即svc将不会分配VIP。<br>   clusterIP: None<br>   selector:<br>     app: nginx<br>     <br> ---</p> 
<p>apiVersion: apps/v1<br> kind: StatefulSet<br> metadata:<br>   name: linux82-web<br> spec:<br>   selector:<br>     matchLabels:<br>       app: nginx<br>   # 声明无头服务    <br>   serviceName: linux82-headless<br>   replicas: 3 <br>   # 卷申请模板，会为每个Pod去创建唯一的pvc并与之关联哟!<br>   volumeClaimTemplates:<br>   - metadata:<br>       name: data<br>     spec:<br>       accessModes: [ "ReadWriteOnce" ]<br>       # 声明咱们自定义的动态存储类，即sc资源。<br>       storageClassName: "linux82-sc"<br>       resources:<br>         requests:<br>           storage: 2Gi<br>   template:<br>     metadata:<br>       labels:<br>         app: nginx<br>     spec:<br>       containers:<br>       - name: nginx<br>         image: nginx:1.20.1<br>         ports:<br>         - containerPort: 80<br>         volumeMounts:<br>         - name: data<br>           mountPath: /usr/share/nginx/html<br>           <br> ---</p> 
<p>apiVersion: v1<br> kind: Service<br> metadata:<br>   name: oldboyedu-linux82-sts<br> spec:<br>   selector:<br>      app: nginx<br>   ports:<br>   - port: 80<br>     targetPort: 80<br> EOF</p> 
<p>    <br>     (2)连接到Pod逐个修改nginx首页文件<br> # kubectl exec -it linux81-web-0 -- bash<br> echo AAAAAAAAAAAA &gt; /usr/share/nginx/html/index.html</p> 
<p># kubectl exec -it linux81-web-1 -- bash<br> echo BBBBBBBBBBBB &gt; /usr/share/nginx/html/index.html</p> 
<p># kubectl exec -it linux81-web-2 -- bash<br> echo CCCCCCCCCCCC &gt; /usr/share/nginx/html/index.html<br>     <br>     <br>     (3)测试SVC访问<br> # vim /etc/resolv.conf   # 不修改宿主机的配置文件的话，可以直接启动pod进行测试即可。<br> nameserver 10.254.0.10<br> # curl oldboyedu-linux81-sts.default.svc.cluster.local</p> 
<p><br> 持久卷Persistent Volume(简称"PV"):<br>     (1)编写PV资源清单<br> cat &gt; manual-pv.yaml &lt;&lt;'EOF'<br> apiVersion: v1<br> kind: PersistentVolume<br> metadata:<br>   name: oldboyedu-linux82-pv01<br>   labels:<br>     school: oldboyedu<br> spec:<br>    # 声明PV的访问模式，常用的有"ReadWriteOnce","ReadOnlyMany"和"ReadWriteMany":<br>    #   ReadWriteOnce:(简称:"RWO")<br>    #      只允许单个worker节点读写存储卷，但是该节点的多个Pod是可以同时访问该存储卷的。<br>    #   ReadOnlyMany:(简称:"ROX")<br>    #      允许多个worker节点进行只读存储卷。<br>    #   ReadWriteMany:(简称:"RWX")<br>    #      允许多个worker节点进行读写存储卷。<br>    #   ReadWriteOncePod:(简称:"RWOP")<br>    #       该卷可以通过单个Pod以读写方式装入。<br>    #       如果您想确保整个集群中只有一个pod可以读取或写入PVC，请使用ReadWriteOncePod访问模式。<br>    #       这仅适用于CSI卷和Kubernetes版本1.22+。<br>    accessModes:<br>    - ReadWriteMany<br>    # 声明存储卷的类型为nfs<br>    nfs:<br>      path: /oldboyedu/data/kubernetes/pv/linux82/pv001<br>      server: 10.0.0.151<br>    # 指定存储卷的回收策略，常用的有"Retain"和"Delete"<br>    #    Retain:<br>    #       "保留回收"策略允许手动回收资源。<br>    #       删除PersistentVolumeClaim时，PersistentVolume仍然存在，并且该卷被视为"已释放"。<br>    #       在管理员手动回收资源之前，使用该策略其他Pod将无法直接使用。<br>    #    Delete:<br>    #       对于支持删除回收策略的卷插件，k8s将删除pv及其对应的数据卷数据。<br>    #    Recycle:<br>    #       对于"回收利用"策略官方已弃用。相反，推荐的方法是使用动态资源调配。<br>    #       如果基础卷插件支持，回收回收策略将对卷执行基本清理（rm -rf /thevolume/*），并使其再次可用于新的声明。<br>    persistentVolumeReclaimPolicy: Retain<br>    # 声明存储的容量<br>    capacity:<br>      storage: 2Gi</p> 
<p>---</p> 
<p>apiVersion: v1<br> kind: PersistentVolume<br> metadata:<br>   name: oldboyedu-linux82-pv02<br>   labels:<br>     school: oldboyedu<br> spec:<br>    accessModes:<br>    - ReadWriteMany<br>    nfs:<br>      path: /oldboyedu/data/kubernetes/pv/linux82/pv002<br>      server: 10.0.0.151<br>    persistentVolumeReclaimPolicy: Retain<br>    capacity:<br>      storage: 5Gi</p> 
<p>---</p> 
<p>apiVersion: v1<br> kind: PersistentVolume<br> metadata:<br>   name: oldboyedu-linux82-pv03<br>   labels:<br>     school: oldboyedu<br> spec:<br>    accessModes:<br>    - ReadWriteMany<br>    nfs:<br>      path: /oldboyedu/data/kubernetes/pv/linux82/pv003<br>      server: 10.0.0.151<br>    persistentVolumeReclaimPolicy: Retain<br>    capacity:<br>      storage: 10Gi<br> EOF</p> 
<p><br>     (2)创建pv<br> kubectl apply -f manual-pv.yaml</p> 
<p><br>     (3)查看pv资源<br> kubectl get pv<br>         NAME : <br>             pv的名称<br>         CAPACITY : <br>             pv的容量<br>         ACCESS MODES: <br>             pv的访问模式<br>         RECLAIM POLICY:<br>             pv的回收策略。<br>         STATUS :<br>             pv的状态。<br>         CLAIM:<br>             pv被哪个pvc使用。<br>         STORAGECLASS  <br>             sc的名称。<br>         REASON   <br>             pv出错时的原因。<br>         AGE<br>             创建的时间。</p> 
<p>    (4)创建PVC对应的nfs挂载路径（如下图所示）<br> mkdir -pv /oldboyedu/data/kubernetes/pv/linux82/pv00{1..3}<br> ll -R /oldboyedu/data/kubernetes/pv/linux81</p> 
<p><br> 参考链接:<br>     https://kubernetes.io/docs/concepts/storage/persistent-volumes/#access-modes<br>     https://kubernetes.io/docs/concepts/storage/persistent-volumes/#reclaiming<br>     <br>     <br>     <br>     <br> 持久卷声明Persistent Volume Claim(简称"PVC")<br>     (1)编写pvc的资源清单<br> cat &gt; manual-pvc.yaml &lt;&lt;'EOF'<br> apiVersion: v1<br> kind: PersistentVolumeClaim<br> metadata:<br>   name: oldboyedu-linux82-pvc<br> spec:<br>   # 声明资源的访问模式<br>   accessModes:<br>   - ReadWriteMany<br>   # 声明资源的使用量<br>   resources:<br>     limits:<br>        storage: 4Gi<br>     requests:<br>        storage: 3Gi<br> EOF</p> 
<p><br>     (2)创建资源<br> kubectl apply -f manual-pvc.yaml</p> 
<p>    (3)查看pvc资源<br> kubectl get pvc</p> 
<p><br> Pod引用PVC：<br> cat &gt; 09-pvc.yaml &lt;&lt;EOF<br> apiVersion: extensions/v1beta1<br> kind: Deployment<br> metadata:<br>   name: oldboyedu-linux82-deploy<br> spec:<br>   replicas: 5<br>   selector:<br>     matchLabels:<br>       apps: oldboyedu-web<br>   template:<br>     metadata:<br>       name: oldboyedu-linux82-pvc<br>       labels:<br>          apps:  oldboyedu-web<br>     spec:<br>       volumes:<br>       - name: myweb<br>         # 声明NFS存储卷<br>         # nfs: <br>         #   server: 10.0.0.201<br>         #   path: /oldboyedu/data/kubernetes<br>         # 声明PVC<br>         persistentVolumeClaim:<br>           claimName: oldboyedu-linux82-pvc<br>       tolerations:<br>       - operator: Exists<br>       containers:<br>       - name: linux82-web<br>         image: k8s151.oldboyedu.com:5000/oldboyedu-web/nginx:1.20.1<br>         volumeMounts:<br>         - name: myweb<br>           mountPath: /usr/share/nginx/html<br> EOF</p> 
<p>删除pvc验证pv的回收策略:<br>     Retain:<br>        "保留回收"策略允许手动回收资源,删除pvc时，pv仍然存在，并且该卷被视为"已释放(Released)"。<br>        在管理员手动回收资源之前，使用该策略其他Pod将无法直接使用。<br>        温馨提示:<br>            (1)在k8s1.15.12版本测试时，删除pvc发现nfs存储卷的数据并不会被删除，pv也不会被删除;<br>            <br>     Delete:<br>        对于支持删除回收策略的卷插件，k8s将删除pv及其对应的数据卷数据。建议使用动态存储类(sc)实现，才能看到效果哟！<br>        对于AWS EBS, GCE PD, Azure Disk, or OpenStack Cinder等存储卷会被删除。<br>        温馨提示:<br>            (1)在k8s1.15.12版本测试时，在不使用sc时，则删除pvc发现nfs存储卷的数据并不会被删除；<br>            (2)在k8s1.15.12版本测试时，在使用sc后，可以看到删除效果哟;</p> 
<p>    Recycle:<br>        对于"回收利用"策略官方已弃用。相反，推荐的方法是使用动态资源调配。<br>        如果基础卷插件支持，回收回收策略将对卷执行基本清理（rm -rf /thevolume/*），并使其再次可用于新的声明。<br>        温馨提示，在k8s1.15.12版本测试时，删除pvc发现nfs存储卷的数据被删除。</p> 
<p><br> 临时更改pv的回收策略:<br>     kubectl patch pv oldboyedu-linux82-pv02  -p '{"spec":{"persistentVolumeReclaimPolicy":"Retain"}}'</p> 
<p><br>     参考链接:<br>         https://kubernetes.io/docs/tasks/administer-cluster/change-pv-reclaim-policy/<br>         <br>         <br>     温馨提示:<br>         基于命令行的方式修改配置，基本上都是临时修改，当资源被删除后，重新创建时依旧会根据资源清单的配置创建哟。<br>         <br>         <br>         <br> 部署nfs动态存储类:<br> (1)k8s组件原生并不支持NFS动态存储<br> https://kubernetes.io/docs/concepts/storage/storage-classes/#provisioner</p> 
<p>(2)NFS不提供内部配置器实现动态存储，但可以使用外部配置器。<br> git clone https://gitee.com/yinzhengjie/k8s-external-storage.git</p> 
<p>(3)修改配置文件<br> cd k8s-external-storage/nfs-client/deploy<br> vim deployment.yaml <br> ...<br> spec:<br>   ...<br>   template:<br>     ...<br>     spec:<br>       ...<br>       containers:<br>         - name: nfs-client-provisioner<br>           ...<br>           env:<br>             - name: PROVISIONER_NAME<br>               value: fuseim.pri/ifs<br>               # 指定NFS服务器地址<br>             - name: NFS_SERVER<br>               value: 10.0.0.201<br>               # 指定NFS的共享路径<br>             - name: NFS_PATH<br>               value: /oldboyedu/data/kubernetes/sc<br>       volumes:<br>         - name: nfs-client-root<br>           # 配置NFS共享<br>           nfs:<br>             server: 10.0.0.201<br>             path: /oldboyedu/data/kubernetes/sc</p> 
<p><br> (4)nfs服务器端创建sc需要共享路径<br> mkdir -pv /oldboyedu/data/kubernetes/sc</p> 
<p>(5)创建动态存储类<br> kubectl apply -f class.yaml &amp;&amp; kubectl get sc</p> 
<p>(6)创建授权角色<br> kubectl apply -f rbac.yaml </p> 
<p>(7)部署nfs动态存储配置器<br> kubectl apply -f deployment.yaml </p> 
<p>(8)查看是否部署成功（如下图所示）<br> kubectl get sc,po</p> 
<p>温馨提示:<br>     生产环境建议设置回收策略为保留（Retain）。<br> cat &gt; class.yaml  &lt;&lt;'EOF'<br> apiVersion: storage.k8s.io/v1<br> kind: StorageClass<br> metadata:<br>   name: managed-nfs-storage<br> # provisioner: fuseim.pri/ifs # or choose another name, must match deployment's env PROVISIONER_NAME'<br> provisioner: oldboyedu/linux<br> parameters:<br>   # 注意哈，仅对"reclaimPolicy: Delete"时生效，如果回收策略是"reclaimPolicy: Retain"，则无视此参数!<br>   # 如果设置为false，删除数据后，不会在存储卷路径创建"archived-*"前缀的目录哟!<br>   # archiveOnDelete: "false"<br>   # 如果设置为true，删除数据后，会在存储卷路径创建"archived-*"前缀的目录哟<br>   archiveOnDelete: "true"<br> # 声明PV回收策略，默认值为Delete<br> reclaimPolicy: Retain<br> EOF</p> 
<p>今日内容回顾:<br>     - 污点 <br>         影响POD调度。<br>     - 污点容忍    ***<br>         当一个pod能够容忍一个worker节点的所有污点。<br>     - 亲和性:  ***<br>         - 节点亲和性<br>         - Pod亲和性<br>         - Pod的反亲和性<br>     - 节点选择器<br>     - 一波控制器来袭:<br>         - Job:<br>             一次性任务。失败时可以指定重试次数。<br>         - CronJob:<br>             周期性任务。底层调用的是Job。<br>         - DaemonSet : *****<br>             每个节点都只能运行一个pod副本。<br>         - StatefulSet:<br>             适合用状态服务的部署。<br>         - rc:<br>         - rs:<br>         - Deployment: *****  CAK ---&gt; 75%+<br>             部署微服务.<br>     - pv     ***<br>         绑定后端的真是存储设备。<br>     - pvc    *****<br>         绑定pv。<br>     - sc    *****<br>         自动创建pv。<br>     <br>             <br> 今日作业:<br>     (1)晚上课堂的所有练习并完善思维导图;<br>     (2)将"jasonyin2020/oldboyedu-games:v0.3"镜像使用deployment组件部署，要求如下:<br>         - 使用cm资源配置nginx配置文件<br>         - 使用svc暴露服务<br>         - 使用sc存储网站的代码<br>         - 要求将该镜像传输到harbor的私有仓库，要求用户名为:"linux82"，密码为:"oldboyEDU@2022"，需要使用secret资源<br>         - 要求所有节点打污点"school=oldboyedu"<br>         - 要求上述所有资源清单使用单独的文件，然后再合并为一个资源清单。<br>         - 要求浏览器访问任意worker节点的[80-90]端口时能够访问到11个游戏哟<br>         <br>         <br> 扩展作业:<br>     (1)调研isito服务的基础使用;<br>         关于版本支持:<br>             https://istio.io/latest/docs/releases/supported-releases/<br>         </p>
                </div>

		</div>
	</article>
</main>




			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程小白.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://www.w3counter.com/tracker.js?id=150625"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>
	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>