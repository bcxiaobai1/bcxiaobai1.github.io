<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<title>深入理解MySQL：InnoDB 引擎、日志、事务、索引、锁 及MySQL调优 - 编程小白</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程小白" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程小白</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">深入理解MySQL：InnoDB 引擎、日志、事务、索引、锁 及MySQL调优</h1>
			
		</header>
		<div class="content post__content clearfix">
			


                <div id="content_views" class="markdown_views prism-atom-one-dark">
                    
                        
                    
                    <p></p>
<div class="toc">
 <h3>文章目录</h3>
 <ul>
<li><a href="#_2">逻辑架构</a></li>
<li><a href="#_15">日志系统</a></li>
<li>
<ul>
<li><a href="#1redo_logbinlog_16">1.redo log与binlog的对比</a></li>
<li><a href="#2redo_log_42">2.redo log</a></li>
<li><a href="#3binlog_82">3.binlog</a></li>
<li><a href="#4_125">4.两阶段提交</a></li>
</ul>
  </li>
<li><a href="#_150">事务隔离</a></li>
<li>
<ul>
<li><a href="#1_156">1.隔离级别</a></li>
<li><a href="#2MVCC_179">2.多版本并发控制（MVCC）</a></li>
<li><a href="#3phantom_read_234">3.幻读（phantom read）</a></li>
<li><a href="#4dirty_read_246">4.脏读（dirty read）</a></li>
<li><a href="#5nonrepeatable_read_250">5.不可重复读（non-repeatable read）</a></li>
</ul>
  </li>
<li><a href="#_258">索引</a></li>
<li>
<ul>
<li><a href="#1InnoDB__262">1.InnoDB 的索引模型</a></li>
<li><a href="#2_271">2.索引维护</a></li>
<li><a href="#3_284">3.覆盖索引</a></li>
<li><a href="#4_290">4.最左前缀原则</a></li>
<li><a href="#5_300">5.索引下推</a></li>
<li><a href="#6_304">6.索引失效</a></li>
</ul>
  </li>
<li><a href="#_312">锁</a></li>
<li>
<ul>
<li><a href="#1_317">1.全局锁</a></li>
<li><a href="#2_332">2.表级锁</a></li>
<li><a href="#3_351">3.行锁</a></li>
<li><a href="#4_Gap_Lock_395">4.间隙锁 (Gap Lock)</a></li>
<li><a href="#5nextkey_lock_419">5.next-key lock</a></li>
</ul>
  </li>
<li><a href="#_432">主备高可用</a></li>
<li>
<ul>
<li><a href="#1_433">1.主备一致性</a></li>
<li><a href="#2_437">2.主备流程</a></li>
<li><a href="#3_456">3.主备延迟</a></li>
<li><a href="#4_488">4.并行复制策略</a></li>
<li><a href="#5_541">5.一主多从的主备切换过程</a></li>
<li><a href="#6_573">6.如何判断主库异常</a></li>
</ul>
  </li>
<li><a href="#_599">实践调优</a></li>
<li>
<ul>
<li><a href="#1change_buffer_600">1.change buffer</a></li>
<li><a href="#2_640">2.索引选择异常和处理</a></li>
<li><a href="#3_652">3.字符串索引策略</a></li>
<li><a href="#4_658">4.刷脏页的控制策略</a></li>
<li><a href="#5_680">5.收缩表空间</a></li>
<li><a href="#6count_700">6.count(*)优化</a></li>
<li><a href="#7order_by_721">7.order by机制</a></li>
<li><a href="#8_766">8.查询优化</a></li>
<li><a href="#9_780">9.短连接风暴</a></li>
<li><a href="#10QPS__789">10.QPS 突增问题</a></li>
<li><a href="#11IO_797">11.IO性能瓶颈</a></li>
<li><a href="#12_804">12.读写分离优化</a></li>
<li><a href="#13_857">13.误删修复</a></li>
</ul>
  </li>
<li><a href="#explain_899">explain分析执行计划</a></li>
</ul>
</div>
<p></p> 
<h1>
<a id="_2"></a>逻辑架构</h1> 
<p><img src="https://images2.imgbox.com/6c/a2/jBHrnTcM_o.png" alt="在这里插入图片描述"></p> 
<table>
<thead><tr>
<th>阶段</th>
<th>注意事项</th>
</tr></thead>
<tbody>
<tr>
<td>连接器</td>
<td>建立连接成本过高，尽量使用长连接，维护长连接的方式有两种：定期断开长连接或定期执行mysql_reset_connection 来重新初始化连接资源</td>
</tr>
<tr>
<td>查询缓存</td>
<td>（key-value形式）key是查询语句，value是查询结果，查询缓存命中率不高，弊大于利，在mysql8.0已被移除</td>
</tr>
<tr>
<td>分析器</td>
<td>判断表是否存在，列是否存在，判断sql语句是否满足语法规则，不满足返回 You have an error in your SQL syntax</td>
</tr>
<tr>
<td>优化器</td>
<td>选择索引（依据扫描行数，是否使用临时表，是否排序），存在join时，决定各表的连接顺序</td>
</tr>
<tr>
<td>执行器</td>
<td>判断表权限，调用引擎接口</td>
</tr>
</tbody>
</table>
<h1>
<a id="_15"></a>日志系统</h1> 
<h2>
<a id="1redo_logbinlog_16"></a>1.redo log与binlog的对比</h2> 
<table>
<thead><tr>
<th></th>
<th>redo log</th>
<th>binlog</th>
</tr></thead>
<tbody>
<tr>
<td>存在位置</td>
<td>InnoDB 引擎特有的</td>
<td>Server 层实现的，所有引擎都可以使用</td>
</tr>
<tr>
<td>日志性质</td>
<td>物理日志，记录的是“在某个数据页上做了什么修改”</td>
<td>逻辑日志，记录的是这个语句的原始逻辑，比如“给 ID=2 这一行的 c 字段加 1</td>
</tr>
<tr>
<td>写入方式</td>
<td>循环写的，空间固定会用完</td>
<td>追加写，写到一定大小后会切换到下一个，并不会覆盖以前的日志</td>
</tr>
<tr>
<td>写入逻辑</td>
<td>事务在执行过程中，生成的 redo log 要先写到 redo log buffer ，<strong>redo log buffer 是全局共用的</strong>
</td>
<td>事务执行过程中，先把日志写到 binlog cache，事务提交的时候，再把 binlog cache 写到 binlog 文件中， <strong>binlog cache 是每个线程自己维护的</strong>
</td>
</tr>
<tr>
<td>单步持久化到磁盘开关</td>
<td>innodb_flush_log_at_trx_commit=1</td>
<td>sync_binlog=1</td>
</tr>
<tr>
<td>主要职责</td>
<td>异常重启恢复</td>
<td>备份迁移，归档</td>
</tr>
<tr>
<td>重建数据状态</td>
<td>只能重建到最新状态</td>
<td>可以重建到任何历史状态</td>
</tr>
</tbody>
</table>
<p><strong>“双 1”配置</strong>：指的是 sync_binlog 和 innodb_flush_log_at_trx_commit 都设置成 1，也就是说，一个事务完整提交前，需要等待两次刷盘，一次是 redo log（prepare 阶段），一次是 binlog</p> 
<p>两种日志均实现了数据库的<strong>Write-Ahead Logging</strong>，即先写日志，再写磁盘，减少磁盘写 IO</p> 
<p>WAL 机制主要得益于两个方面：</p> 
<ol>
<li>redo log 和 binlog 都是顺序写，磁盘的顺序写比随机写速度要快</li>
<li>组提交机制，可以大幅度降低磁盘的 IOPS 消耗</li>
</ol> 
<p>binlog 没有崩溃恢复的能力，由于 <strong>WAL技术</strong>，有些修改是还没有落盘的，但是事物已经提交，这时候如果崩溃，重启后看 binlog 会认为这些修改已经落盘了（或者说根本没法判断落没落盘），这样就会丢失修改</p> 
<p>而 redo log 的 checkpoint 机制保障了异常重启的恢复能力，在 checkpoint 后面的记录肯定是没有刷盘的，所以只需要重放一遍即可，当崩毁恢复时，redo log 负责将内存数据更新成最新的，然后再刷脏页，而不是由 redo log 直接恢复数据</p> 
<p><strong>binlog cache 是每个线程自己维护的，而 redo log buffer 是全局共用的原因</strong>：binlog 是一种逻辑性的日志，记录的是一个事务完整的语句。当用来做主从同步，如果分散写，可能造成事务不完整，分多次执行，从而导致不可预知的问题。 而 redo log 属于物理性的日志，记录的是物理地址的变动，因此，分散写也不会改变最终的结果</p> 
<h2>
<a id="2redo_log_42"></a>2.redo log</h2> 
<p><strong>redo log的逻辑架构</strong></p> 
<p><img src="https://images2.imgbox.com/1c/a8/oIN0KJJ8_o.png" alt="在这里插入图片描述"></p> 
<ul>
<li>write pos 是当前记录的位置，一边写一边后移</li>
<li>write pos 和 checkpoint 之间的空余部分，用来记录新的操作</li>
<li>如果 write pos 追上 checkpoint，表示没有空余部分，这时候不能再执行新的更新，得停下来先擦掉一些记录，把 checkpoint 推进</li>
</ul> 
<p><strong>LSN</strong></p> 
<p>LSN是指日志逻辑序列号（log sequence number），LSN 是单调递增的，用来对应 redo log 的一个个写入点。每次写入长度为 length 的 redo log， LSN 的值就会加上 length</p> 
<p>LSN 也会写到 InnoDB 的数据页中，来确保数据页不会被多次执行重复的 redo log</p> 
<p><strong>redo log 的写入机制</strong></p> 
<p>redo log buffer 是一块内存，还未提交的事务会先写 入redo log buffer 再写入 redo log</p> 
<p><img src="https://images2.imgbox.com/13/bd/drTROtAe_o.png" alt="在这里插入图片描述">redo log 的三种存储状态：</p> 
<ul>
<li>存在 redo log buffer 中，物理上是在 MySQL 进程内存中，就是图中的红色部分</li>
<li>写到磁盘 (write)，但是没有持久化（fsync)，物理上是在文件系统的 page cache 里面，也就是图中的黄色部分</li>
<li>持久化到磁盘，对应的是 hard disk，也就是图中的绿色部分</li>
</ul> 
<p>日志写到 redo log buffer 和 wirte 到 page cache 都很快，但是持久化到磁盘的速度就慢多了</p> 
<p>redo log 的写入策略，由InnoDB 提供的 innodb_flush_log_at_trx_commit 参数控制：</p> 
<ul>
<li>设置为 0 的时候，表示每次事务提交时都只是把 redo log 留在 redo log buffer 中</li>
<li>设置为 1 的时候，表示每次事务提交时都将 redo log 直接持久化到磁盘</li>
<li>设置为 2 的时候，表示每次事务提交时都只是把 redo log 写到 page cache</li>
</ul> 
<p>没有提交的事务的 redo log ，但可能已经持久化到磁盘的情况有：</p> 
<ol>
<li>后台每秒的轮询，会把 redo log buffer 中的日志，调用 write 写到文件系统的 page cache，然后调用 fsync 持久化到磁盘</li>
<li>redo log buffer 占用的空间即将达到 innodb_log_buffer_size 一半的时候，后台线程会主动写盘</li>
<li>并行的事务提交的时候，顺带将这个事务的 redo log buffer 持久化到磁盘</li>
</ol> 
<h2>
<a id="3binlog_82"></a>3.binlog</h2> 
<p>MySQL 能够成为现下最流行的开源数据库，binlog 功不可没，其几乎所有的高可用架构，都直接依赖于 binlog</p> 
<p><strong>binlog 的写入机制</strong></p> 
<p><img src="https://images2.imgbox.com/fb/1a/huS1NYWT_o.png" alt="在这里插入图片描述"><br> 如图，每个线程有自己的 binlog cache，但是共用同一份 binlog 文件</p> 
<ul>
<li>图中的 <strong>write</strong>，指的就是指把日志写入到文件系统的 page cache，并没有把数据持久化到磁盘，所以速度比较快</li>
<li>图中的 <strong>fsync</strong>，才是将数据持久化到磁盘的操作。一般情况下，我们认为 fsync 才占磁盘的 IOPS</li>
</ul> 
<p>write 和 fsync 的时机，由参数 sync_binlog 控制</p> 
<ul>
<li>sync_binlog=0 的时候，表示每次提交事务都只 write，不 fsync</li>
<li>sync_binlog=1 的时候，表示每次提交事务都会执行 fsync</li>
<li>sync_binlog=N(N&gt;1) 的时候，表示每次提交事务都 write，但累积 N 个事务后才 fsync</li>
</ul> 
<p>sync_binlog 设置为 N 的风险是：如果主机发生异常重启，会丢失最近 N 个事务的 binlog 日志</p> 
<p><strong>binlog的格式</strong></p> 
<ol>
<li> <p><strong>statement</strong>，<strong>记录了SQL语句原文</strong>，最后会有 COMMIT 确保完整性<br> <img src="https://images2.imgbox.com/ba/e6/UoEhA76b_o.png" alt="在这里插入图片描述"></p> </li>
<li> <p><strong>row</strong>，<strong>记录了操作的表和行</strong>，最后会有一个 XID event 确保完整性<br> <img src="https://images2.imgbox.com/91/9d/oj7eNZNq_o.png" alt="在这里插入图片描述"></p> </li>
<li> <p><strong>mixed</strong>，即 statement + row</p> </li>
</ol> 
<p>statement 格式下，记录到 binlog 里的是语句原文，因此可能会出现这样一种情况：在主库执行这条 SQL 语句的时候，用的是索引 a，而在备库执行这条 SQL 语句的时候，却使用了索引 b。因此，MySQL 认为这样写是有风险的</p> 
<p>当 binlog_format 使用 row 格式的时候，binlog 里面记录了真实删除行的主键 id，这样 binlog 传到备库去的时候，就肯定会删除真实的行，不会有主备删除不同行的问题</p> 
<p>statement 格式的 binlog 可能会导致主备不一致，row 格式的缺点是很占空间，所以，MySQL 就取了个折中方案，也就是有了 mixed 格式的 binlog。mixed 格式的意思是，MySQL 自己会判断这条 SQL 语句是否可能引起主备不一致，如果有可能，就用 row 格式，否则就用 statement 格式</p> 
<p>现在越来越多的场景要求把 MySQL 的 binlog 格式设置成 row。这么做的主要理由是<strong>恢复数据</strong></p> 
<h2>
<a id="4_125"></a>4.两阶段提交</h2> 
<p><strong>两阶段提交是为了让两份日志之间的逻辑一致</strong></p> 
<p>两阶段提交过程图：</p> 
<p><img src="https://images2.imgbox.com/f0/4c/fI9xLXUu_o.png" alt="在这里插入图片描述"></p> 
<p>redolog 和 binlog 具有关联行，在恢复数据时，redolog 用于恢复主机故障时的未更新的物理数据，binlog 用于备份操作。每个阶段的 log 操作都是记录在磁盘的，在恢复数据时，redolog 状态为 commit 则说明 binlog 也成功，直接恢复数据；如果 redo log 是 prepare，则需要查询对应的 binlog 事务是否成功，决定是回滚还是执行，也就是为了保持故障恢复（redo log）和备份恢复（binlog）的结果一致性</p> 
<p><strong>组提交</strong></p> 
<p>虽然 innodb_flush_log_at_trx_commit 设置成 1，单步刷盘，但这个过程的执行是需要消耗时间的，在这个时间段内，其它事物也在执行，所以可以把它们组成一个组，一起刷盘，一次组提交里面，在并发更新场景下，第一个事务写完 redo log buffer 以后，接下来这个 fsync 越晚调用，组员可能越多，节约 IOPS 的效果就越好</p> 
<p><img src="https://images2.imgbox.com/1a/51/gDCH8rip_o.png" alt="在这里插入图片描述"><br> <strong>提升 binlog 组提交的效果参数</strong></p> 
<ul>
<li>binlog_group_commit_sync_delay 参数，表示延迟多少微秒后才调用 fsync</li>
<li>binlog_group_commit_sync_no_delay_count 参数，表示累积多少次以后才调用 fsync</li>
</ul> 
<h1>
<a id="_150"></a>事务隔离</h1> 
<p>事务的特性：ACID（Atomicity、Consistency、Isolation、Durability，即原子性、一致性、隔离性、持久性）</p> 
<p>事务是保证一组数据库操作的原子性，要么全部成功，要么全部失败</p> 
<h2>
<a id="1_156"></a>1.隔离级别</h2> 
<table>
<thead><tr>
<th>事务隔离级别</th>
<th>含义</th>
</tr></thead>
<tbody>
<tr>
<td>读未提交（read uncommitted）</td>
<td>一个事务还没提交时，它做的变更就能被别的事务看到</td>
</tr>
<tr>
<td>读提交（read committed）</td>
<td>一个事务提交之后，它做的变更才会被其他事务看到</td>
</tr>
<tr>
<td>可重复读（repeatable read）</td>
<td>一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。当然在可重复读隔离级别下，未提交变更对其他事务也是不可见的</td>
</tr>
<tr>
<td>串行化（serializable）</td>
<td>是对于同一行记录，“写”会加“写锁”，“读”会加“读锁”。当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行</td>
</tr>
</tbody>
</table>
<p>不同隔离级别对于并发事务出现的问题的解决情况</p> 
<table>
<thead><tr>
<th></th>
<th>脏读</th>
<th>不可重复读</th>
<th>幻读</th>
</tr></thead>
<tbody>
<tr>
<td>读未提交</td>
<td>N</td>
<td>N</td>
<td>N</td>
</tr>
<tr>
<td>读提交</td>
<td>Y</td>
<td>N</td>
<td>N</td>
</tr>
<tr>
<td>可重复读</td>
<td>Y</td>
<td>Y</td>
<td>N</td>
</tr>
<tr>
<td>串行化</td>
<td>Y</td>
<td>Y</td>
<td>Y</td>
</tr>
</tbody>
</table>
<h2>
<a id="2MVCC_179"></a>2.多版本并发控制（MVCC）</h2> 
<p>MySQL中两种视图概念</p> 
<table>
<thead><tr>
<th></th>
<th>view</th>
<th>一致性读视图</th>
</tr></thead>
<tbody><tr>
<td>概念</td>
<td>查询语句虚拟表，查询方法与表一样</td>
<td>InnoDB 实现 MVCC 时的一致性读视图（consisitent read view），用于支持 RC（Read Committed，读提交）和 RR（Repeatable Read，可重复读）隔离级别的实现</td>
</tr></tbody>
</table>
<p>两种事务启动命令的对比</p> 
<table>
<thead><tr>
<th></th>
<th>begin/start transaction</th>
<th>transaction with consistent snapshot</th>
</tr></thead>
<tbody><tr>
<td>一致性视图的创建时机</td>
<td>一致性视图是在执行第一个快照读语句时创建</td>
<td>一致性视图是在执行 start transaction with consistent snapshot 时创建</td>
</tr></tbody>
</table>
<p>隔离级别的实现依靠于视图，不同时刻启动的事务都有不同的视图，一行记录在系统中可以存在多个版本，这就是<strong>多版本并发控制（MVCC）</strong>，系统会自行判断，当没有视图使用回滚段时候，回滚日志会被删除，而此处也是尽量不要使用长事务的原因，长事务意味着会保留古老的视图，十分占用内存空间</p> 
<p><img src="https://images2.imgbox.com/fe/78/pG0UcZz6_o.png" alt="在这里插入图片描述"></p> 
<p><strong>多版本并发控制（MVCC）的实现</strong></p> 
<p><img src="https://images2.imgbox.com/a9/75/kUquSeGt_o.png" alt="在这里插入图片描述"></p> 
<ol>
<li>每个事务都有一个事务ID,叫做 <strong>transaction id</strong> (严格递增)</li>
<li>事务在启动时，找到已提交的最大事务ID记为 <strong>up_limit_id</strong>
</li>
<li>事务在更新一条语句时，比如 id=1 改为了 id=2，会把 id=1 和该行之前的 row trx_id 写到undo log 里，并且在数据页上把id的值改为 2，并且把修改这条语句的 transaction id 记在该行行头</li>
<li>一个事务要查看一条数据时，必须先用该事务的 <strong>up_limit_id</strong> 与该行的 transaction id做比对，如果 up_limit_id &gt;= transaction id，那么可以看，如果 up_limit_id &lt; transaction id，则只能去 undo log 里去取。去 undo log 查找数据的时候，也需要做比对，必须 up_limit_id &gt; transaction id，才返回数据</li>
</ol> 
<p><strong>当前读</strong></p> 
<p>由于当前读都是先读后写，只能读当前的值，所以为当前读，会更新事务内的 up_limit_id 为该事务的 transaction id，如果有其他事务占用行锁，则进入锁等待</p> 
<p><strong>快照读和当前读</strong></p> 
<p>当前读指的是 select for update 或者 select in share mode，指的是在更新之前必须先查寻当前的值，因此叫当前读。 快照读指的是在语句执行之前或者在事务开始的时候会创建一个视图，后面的读都是基于这个视图的，不会再去查询最新的值</p> 
<p><strong>读提交的逻辑和可重复读的区别</strong></p> 
<ul>
<li>在可重复读隔离级别下，只需要在事务开始的时候创建一致性视图，之后事务里的其他查询都共用这个一致性视图</li>
<li>在读提交隔离级别下，每一个语句执行前都会重新算出一个新的视图</li>
</ul> 
<h2>
<a id="3phantom_read_234"></a>3.幻读（phantom read）</h2> 
<p>幻读指的是一个事务在前后两次查询同一个范围的时候，后一次查询看到了前一次查询没有看到的行，同时，幻读仅专指“新插入的行”</p> 
<p><strong>在可重复读隔离级别下，普通的查询是快照读，是不会看到别的事务插入的数据的。因此，幻读在“当前读”下才会出现</strong></p> 
<p>幻读会导致语义被破坏及数据不一致的问题</p> 
<p>幻读产生的原因：即使给所有行加上了锁，也避免不了幻读，这是因为给行加锁的时候，这条记录还不存在，没法加锁</p> 
<p>为了解决幻读问题，InnoDB 引入了新的锁，也就是<strong>间隙锁 (Gap Lock)</strong>，后文有讲到</p> 
<h2>
<a id="4dirty_read_246"></a>4.脏读（dirty read）</h2> 
<p>脏读指事务读取到了另一个事务更新了但是未提交的数据，然后另一个事务由于某种错误发生回滚，那么该事务读取到的就是脏数据</p> 
<h2>
<a id="5nonrepeatable_read_250"></a>5.不可重复读（non-repeatable read）</h2> 
<p>不可重复读指在数据库访问时，一个事务在前后两次相同的访问中却读到了不同的数据内容</p> 
<p>幻读和不可重复读的本质是一样的，两者都表现为两次读取的结果不一致。但是<strong>不可重复读指的是两次读取同一条记录的值不同，而幻读指的是两次读取的记录数量不同</strong></p> 
<p>不可重复读重点在于update和delete，而幻读的重点在于insert</p> 
<h1>
<a id="_258"></a>索引</h1> 
<p>索引的出现其实就是为了提高数据查询的效率，就像书的目录一样，实现于存储引擎层</p> 
<h2>
<a id="1InnoDB__262"></a>1.InnoDB 的索引模型</h2> 
<p>InnoDB 使用 B+ 树索引模型，B+ 树能够很好地配合磁盘的读写特性，减少单次查询的磁盘访问次数</p> 
<ul>
<li>主键索引的叶子节点存的是整行数据。在 InnoDB 里，主键索引也被称为聚簇索引（clustered index）</li>
<li>非主键索引的叶子节点内容是主键的值。在 InnoDB 里，非主键索引也被称为二级索引（secondary index）</li>
</ul> 
<p>主键查询方式只需要搜索 ID 这颗 B+ 树，非主键索引需要先搜索非主键索引树，拿到 ID值，再回到主键索引树再搜索一次，这个过程就是<strong>回表</strong></p> 
<h2>
<a id="2_271"></a>2.索引维护</h2> 
<p>如果插入对象所在的数据页已经满了，根据 B+ 树的算法，这时候需要申请一个新的数据页，然后挪动部分数据过去。这个过程称为<strong>页分裂</strong>，页分裂的逆过程称为<strong>页合并</strong>，在这两种情况下，性能会受到50%的影响</p> 
<p><strong>使用自增主键作为索引</strong>可以有效提升效率，两个原因：</p> 
<ol>
<li>保证插入记录的有序性，所有的操作都是追加操作，不会触发页分裂</li>
<li>从存储空间的角度，主键长度越小，普通索引的叶子节点就越小，普通索引占用的空间也就越小</li>
</ol> 
<p><strong>重建索引</strong>也是维护索引的重要手段：索引可能因为删除，或者页分裂等原因，导致数据页有空洞，重建索引的过程会创建一个新的索引，把数据按顺序插入，这样页面的利用率最高，也就是索引更紧凑、更省空间</p> 
<h2>
<a id="3_284"></a>3.覆盖索引</h2> 
<p>当查询字段已经在普通索引树上时，可以直接返回查询结果，<strong>不需要回表</strong>，也就是说在这次查询里面已经覆盖了查询需求，所以称作覆盖索引</p> 
<p>覆盖索引可以减少树的搜索次数，显著提升查询性能，所以使用覆盖索引是一个常用的性能优化手段</p> 
<h2>
<a id="4_290"></a>4.最左前缀原则</h2> 
<p>最左前缀原则可以避免建立不必要的索引</p> 
<p>mysql做词法分析语法分析的时候是通过建立最左子树来建立语法树的，解析的过程也是从左到右所以遵循最左前缀的原则</p> 
<p>也就是说，索引项会按照索引定义里面出现的字段顺序排序</p> 
<p>而建立联合索引的第一原则是，如果通过调整顺序，可以少维护一个索引，那么这个顺序往往就是需要优先考虑采用的</p> 
<h2>
<a id="5_300"></a>5.索引下推</h2> 
<p>在查询语句中存在 where 子句且 where 子句条件字段存在索引，那么mysql会在索引遍历过程中，对索引中包含的字段先做判断，<strong>直接过滤掉不满足条件的记录</strong>，减少回表次数，这个优化是在 mysql5.6 后推出的</p> 
<h2>
<a id="6_304"></a>6.索引失效</h2> 
<p>三种索引失效的情况：</p> 
<ol>
<li>对索引字段做函数操作，可能会破坏索引值的有序性，因此优化器就决定放弃走树搜索功能</li>
<li>隐式转换字段类型</li>
<li>字符集不同（隐式字符编码转换）</li>
</ol> 
<h1>
<a id="_312"></a>锁</h1> 
<p>数据库锁设计的初衷是处理并发问题。作为多用户共享的资源，当出现并发访问的时候，数据库需要合理地控制资源的访问规则。而锁就是用来实现这些访问规则的重要数据结构</p> 
<p>根据加锁的范围，MySQL 里面的锁大致可以分成全局锁、表级锁和行锁三类</p> 
<h2>
<a id="1_317"></a>1.全局锁</h2> 
<p>全局锁命令：<strong>Flush tables with read lock (FTWRL)</strong></p> 
<p>使用场景：全库逻辑备份，使全库只读</p> 
<p>说到备份，官方自带的逻辑备份工具是 mysqldump。当 mysqldump 使用参数 –single-transaction 的时候，导数据之前就会启动一个事务，来确保拿到一致性视图。而由于 MVCC 的支持，这个过程中数据是可以正常更新的</p> 
<p>而 <strong>single-transaction</strong> 方法只适用于所有的表使用事务引擎的库，对于不支持事务的 MyISAM 引擎只能使用 FTWRL 方法，这也是 MyISAM 被 InnoDB 取代的重要原因之一</p> 
<p>而为什么不使用 set global readonly=true 使全库只读的原因有：</p> 
<ol>
<li>readonly 值会被用作判断备库</li>
<li>异常处理机制与FTWRL方法存在差异：如果执行 FTWRL 命令之后由于客户端发生异常断开，那么 MySQL 会自动释放这个全局锁，整个库回到可以正常更新的状态。而将整个库设置为 readonly 之后，如果客户端发生异常，则数据库就会一直保持 readonly 状态，这样会导致整个库长时间处于不可写状态，风险较高</li>
</ol> 
<h2>
<a id="2_332"></a>2.表级锁</h2> 
<p>MySQL 里面表级别的锁有两种：一种是表锁，一种是元数据锁（meta data lock，MDL)</p> 
<p><strong>表锁</strong></p> 
<p>表锁的语法是 lock tables … read/write</p> 
<p>lock tables 语法除了会限制别的线程的读写外，<strong>也限定了本线程接下来的操作对象</strong>，也就是说加了写锁后，本线程只能进行写操作，锁的粒度较大</p> 
<p><strong>元数据锁（meta data lock，MDL)</strong></p> 
<p>元数据锁主要用于隔离 DML（Data Manipulation Language，数据操纵语言，如select）和DDL（Data Definition Language，数据定义语言，如改表头新增一列）操作之间的干扰。每执行一条 DML、DDL 语句时都会申请 MDL 锁，DML 操作需要 MDL 读锁，DDL 操作需要 MDL 写锁（MDL 加锁过程是系统自动控制，无法直接干预，<strong>读读共享，读写互斥，写写互斥</strong>）</p> 
<p>事务中的 MDL 锁，在语句执行开始时申请，但是语句结束后并不会马上释放，而会等到整个事务提交后再释放，这也是尽量不要使用长事务的原因之一</p> 
<p>如果要给热点数据做<strong>表结构变更</strong>要带上超时时间，拿不到写锁就放弃</p> 
<h2>
<a id="3_351"></a>3.行锁</h2> 
<p>加锁语句：加上 lock in share mode 或 for update</p> 
<p>行锁就是针对数据表中行记录的锁</p> 
<p>MySQL 的行锁是在引擎层实现的，MyISAM 引擎就不支持行锁，并发锁粒度较大，这也是 MyISAM 被 InnoDB 取代的原因之一</p> 
<p><strong>两阶段锁协议</strong></p> 
<p>在 InnoDB 事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放。这个就是两阶段锁协议</p> 
<p><strong>死锁和死锁检测</strong></p> 
<p>当并发系统中不同线程出现<strong>循环资源依赖</strong>，涉及的线程都在等待别的线程释放资源时，就会导致这几个线程都进入无限等待的状态，称为死锁</p> 
<p>出现死锁后的两种策略：</p> 
<ol>
<li>直接进入等待，直到超时，超时时间设置参数为： innodb_lock_wait_timeout（默认50s），所以 InnoDB 的行锁是<strong>悲观锁</strong>
</li>
<li>发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数 innodb_deadlock_detect 设置为 on，表示开启这个逻辑</li>
</ol> 
<p>开启死锁检测后，每一个新线程都要判断是否会因为自己的加入而导致死锁，这个时间复杂度是 O(n)，而n个线程则是 O(n²)，当并发度过高时会消耗大量的CPU资源</p> 
<p>降低死锁检测性能消耗的方式有三种：</p> 
<ol>
<li>在确保自己的业务不会出现死锁检测的前提下，直接关闭死锁检测</li>
<li>使用控制并发量的中间件，将并发量控制在一个能接受的范围内</li>
<li>将热更新的行数据拆分成逻辑上的多行来减少锁冲突，但是业务复杂度可能会大大提高</li>
</ol> 
<blockquote> 
 <p><strong>tips</strong>：为了避免系统死锁，进入锁等待的线程并不会占用并发线程数</p> 
</blockquote> 
<p><strong>lock in share mode 与 for update</strong></p> 
<p>lock in share mode 走的是IS锁（意向共享锁），即在符合条件的 rows 上都加了共享锁，这样的话，其他 session 可以读取这些记录，也可以继续添加 IS 锁，但是无法修改这些记录直到这个加锁的 session 执行完成（否则直接锁等待超时）</p> 
<p>for update 走的是IX锁（意向排它锁），即在符合条件的 rows 上都加了排它锁，其他session也就无法在这些记录上添加任何的 S 锁或 X 锁。如果不存在一致性非锁定读的话，那么其他 session 是无法读取和修改这些记录的，但是innodb有非锁定读（快照读并不需要加锁），for update 之后并不会阻塞其他 session 的快照读取操作，除了 select …lock in share mode 和 select … for update 这种显示加锁的查询操作</p> 
<p>for update 的加锁方式无非是比 lock in share mode 的方式多阻塞了 lock in share mode 的查询方式，并不会阻塞快照读</p> 
<p>如果要用 lock in share mode 来给行加读锁避免数据被更新的话，就必须得绕过覆盖索引的优化，在查询字段中加入索引中不存在的字段</p> 
<h2>
<a id="4_Gap_Lock_395"></a>4.间隙锁 (Gap Lock)</h2> 
<p>顾名思义，间隙锁，锁的就是两个值之间的空隙</p> 
<p>间隙锁的出现是为了解决幻读问题</p> 
<p>间隙锁在可重复读隔离级别下才会生效</p> 
<p><strong>与行锁的对比</strong></p> 
<p>对于行锁来说：读锁之间不冲突, 写锁与读锁冲突, 写锁与写锁冲突，所以与行锁冲突的是另外一个锁，而跟间隙锁存在冲突关系的，是“往这个间隙中插入一个记录”这个操作</p> 
<p>间隙锁的引入也带来了一些新的问题，比如：降低并发度，可能导致死锁</p> 
<p><strong>间隙锁加锁规则</strong></p> 
<ol>
<li> <p>对主键或唯一索引，如果当前读时，where条件全部精确命中（ = 或者 in），这种场景本身就不会出现幻读，所以只会加行记录锁</p> </li>
<li> <p>没有索引的列，当前读操作时，会加全表Gap间隙锁</p> </li>
<li> <p>非唯一索引列，如果 where 条件部分命中（&gt;、&lt;、like 等）或者全未命中，则会加附近Gap间隙锁</p> </li>
</ol> 
<h2>
<a id="5nextkey_lock_419"></a>5.next-key lock</h2> 
<p>间隙锁和行锁合称 next-key lock</p> 
<p>加锁规则：</p> 
<ol>
<li>加锁的基本单位是 next-key lock。next-key lock 是前开后闭区间</li>
<li>查找过程中访问到的对象才会加锁，当使用覆盖索引时，主键索引不会加锁</li>
<li>索引上的等值查询，给唯一索引加锁的时候，next-key lock 退化为行锁</li>
<li>索引上的等值查询，向右遍历时且最后一个值不满足等值条件的时候，next-key lock 退化为间隙锁，同时，在删除数据的时候尽量加 limit 可以减小锁的范围</li>
<li>唯一索引上的范围查询会访问到不满足条件的第一个值为止</li>
</ol> 
<h1>
<a id="_432"></a>主备高可用</h1> 
<h2>
<a id="1_433"></a>1.主备一致性</h2> 
<p>如上文所述，binlog 保证了主备的一致，</p> 
<h2>
<a id="2_437"></a>2.主备流程</h2> 
<p><img src="https://images2.imgbox.com/e8/11/UbdvuLX1_o.png" alt="在这里插入图片描述"></p> 
<ol>
<li>在备库 B 上通过 change master 命令，设置主库 A 的 IP、端口、用户名、密码，以及要从哪个位置开始请求 binlog，这个位置包含文件名和日志偏移量</li>
<li>在备库 B 上执行 start slave 命令，这时候备库会启动两个线程，就是图中的 io_thread 和 sql_thread。其中 io_thread 负责与主库建立连接</li>
<li>主库 A 校验完用户名、密码后，开始按照备库 B 传过来的位置，从本地读取 binlog，发给 B</li>
<li>备库 B 拿到 binlog 后，写到本地文件，称为中转日志（relay log）</li>
<li>sql_thread 读取中转日志，解析出日志里的命令，并执行</li>
</ol> 
<p><strong>循环复制问题</strong></p> 
<p>当两库互为主备时，两库可能会互传binlog造成循环复制，解决方法：</p> 
<ol>
<li>规定两个库的 server id 必须不同，如果相同，则它们之间不能设定为主备关系</li>
<li>一个备库接到 binlog 并在重放的过程中，生成与原 binlog 的 server id 相同的新的 binlog</li>
<li>每个库在收到从自己的主库发过来的日志后，先判断 server id，如果跟自己的相同，表示这个日志是自己生成的，就直接丢弃这个日志</li>
</ol> 
<h2>
<a id="3_456"></a>3.主备延迟</h2> 
<p>同一个事务在主库与备库开始执行的时间戳之差叫做同步延迟，也叫主备延迟，在备库上执行 show slave status 命令查看 <strong>seconds_behind_master</strong> 的值即是主备延迟，当主备两库系统时间不一致时主备延迟在计算时会自动减去这个值并不会影响其准确性</p> 
<p><strong>主备延迟的来源</strong></p> 
<ol>
<li>
<strong>备库所在机器的性能要比主库所在的机器性能差</strong>，解决方案是采用对称部署或配置“双1”</li>
<li>
<strong>备库压力大</strong>，解决方案是一主多从部署或通过 binlog 输出到外部系统，比如 Hadoop 这类系统，让外部系统提供统计类查询的能力</li>
<li>
<strong>大事务</strong>，主库必须等事务结束才能写 binlog ，这个时间会扩大主备延迟</li>
</ol> 
<p><strong>可靠性优先策略</strong></p> 
<p>在进行主备切换时，会先检查备库 seconds_behind_master 的值是否小于 5s ，小于则把主库的 readonly 设置为 true 表示主库只读，后再次检查备库 seconds_behind_master 的值是否为 0s ，为 0s 则将备库的 readonly 设置为 false 表示备库可写，进而进行主备切换</p> 
<p>在这个过程中系统存在主备库均只可读的阶段，也就是存在不可用时间</p> 
<p><strong>可用性优先策略</strong></p> 
<p>不等主备数据同步，直接把连接切到备库，并且让备库可以读写，那么系统几乎就没有不可用时间，但是可能存在数据不一致的代价</p> 
<p><strong>备库并行复制能力</strong></p> 
<p>如果备库执行日志的能力低于主库生成日志的能力，那么主备延迟会剧增，备库追不上主库节奏，会造成主备不一致问题</p> 
<p>而并行复制能力，也就是多线程复制，可以很好的解决这个问题</p> 
<p>多线程模型</p> 
<p><img src="https://images2.imgbox.com/88/ad/XfaHoe9U_o.png" alt="在这里插入图片描述"><br> coordinator 就是原来的 sql_thread, 不过现在其不再直接更新数据了，只负责读取中转日志和分发事务。真正更新日志的，变成了 worker 线程，而 work 线程的个数，就是由参数 slave_parallel_workers 决定</p> 
<h2>
<a id="4_488"></a>4.并行复制策略</h2> 
<p>而跨线程需要保证原子性，同一行的两个事务，在主库和备库执行的先后顺序不一样可能会导致主备不一致</p> 
<p>所以，coordinator 在分发的时候，需要满足以下这两个基本要求：</p> 
<ol>
<li>不能造成更新覆盖。这就要求更新同一行的两个事务，必须被分发到同一个 worker 中</li>
<li>同一个事务不能被拆开，必须放到同一个 worker 中</li>
</ol> 
<p>每个事务在分发的时候，跟所有 worker 的冲突关系包括以下三种情况：</p> 
<ol>
<li>如果跟所有 worker 都不冲突，coordinator 线程就会把这个事务分配给最空闲的 woker</li>
<li>如果跟多于一个 worker 冲突，coordinator 线程就进入等待状态，直到和这个事务存在冲突关系的 worker 只剩下 1 个</li>
<li>如果只跟一个 worker 冲突，coordinator 线程就会把这个事务分配给这个存在冲突关系的 worker</li>
</ol> 
<p><strong>按表分发策略</strong>：如果两个事务更新不同的表，它们就可以并行。因为数据是存储在表里的，所以按表分发，可以保证两个 worker 不会更新同一行，当事务与多于一个 worker 冲突时，则进入队列等待</p> 
<p><strong>按行分发策略</strong>：如果两个事务没有更新相同的行，它们在备库上可以并行执行。显然，这个模式要求 binlog 格式必须是 row，因为 statement 记录的是语句，无法看出来该事务更新了哪几行</p> 
<p>由于按行分发粒度更小，相比较按表并行分发策略，按行并行策略在决定线程分发的时候，需要消耗更多的计算资源，同时两策略都有一些约束条件：</p> 
<ol>
<li>要能够从 binlog 里面解析出表名、主键值和唯一索引的值。也就是说，主库的 binlog 格式必须是 row</li>
<li>表必须有主键</li>
<li>不能有外键。表上如果有外键，级联更新的行不会记录在 binlog 中，这样冲突检测就不准确</li>
</ol> 
<p><strong>按行分发策略优化</strong>：设置一个阈值，单个事务如果超过设置的行数阈值则退化为单线程执行，具体过程：coordinator 暂时先 hold 住这个事务，等所有 worker 执行完毕，coordinator 自己执行这个事务，执行完后再恢复并行</p> 
<p><strong>MySQL 5.6 版本的并行复制策略</strong></p> 
<p>MySQL 5.6 版本的并行复制策略是按库分发，粒度很大，相比于前面两个策略，按库分发在判断冲突时无需消耗大量 CPU 资源及不要求 binlog 的格式</p> 
<p><strong>MariaDB 的并行复制策略</strong></p> 
<p>MariaDB 的并行复制策略利用了 redo log 组提交 (group commit) 优化，即能够在同一组里提交的事务，一定不会修改同一行与能够在同一组里提交的事务，一定不会修改同一行，具体实现时 MariaDB 会将 commit_id 相同的事务分发到同一个 worker 上</p> 
<p>之前业界的思路都是在“<strong>分析 binlog，并拆分到 worker</strong>”上。而 MariaDB 的这个策略，目标是“<strong>模拟主库的并行模式</strong>”，十分具有创新性</p> 
<p>但这个策略容易被大事务拖后腿，当遇到大事务时，仅有一个 worker 在工作，并行也就退化成了串行</p> 
<p><strong>MySQL 5.7.22 的并行复制策略</strong></p> 
<p>由参数 binlog-transaction-dependency-tracking 控制，这个参数的可选值有以下三种</p> 
<ol>
<li>
<strong>COMMIT_ORDER</strong>，表示在两阶段提交时，同时进入 prepare 和 commit 的事务可以并行的策略</li>
<li>
<strong>WRITESET</strong>，表示的是对于事务涉及更新的每一行，计算出这一行的 hash 值，组成集合 writeset。如果两个事务没有操作相同的行，也就是说它们的 writeset 没有交集，就可以并行</li>
<li>
<strong>WRITESET_SESSION</strong>，是在 WRITESET 的基础上多了一个约束，即在主库上同一个线程先后执行的两个事务，在备库执行的时候，要保证相同的先后顺序</li>
</ol> 
<p><strong>优势</strong>：</p> 
<ol>
<li>writeset 由主库生成，直接写入到 binlog ，备库执行时不需要解析 binlog 内容（event 里的行数据），节省了很多计算量</li>
<li>不需要把整个事务的 binlog 都扫一遍才能决定分发到哪个 worker，更省内存</li>
<li>由于备库的分发策略不依赖于 binlog 内容，所以 binlog 是 statement 格式也是可以的</li>
</ol> 
<h2>
<a id="5_541"></a>5.一主多从的主备切换过程</h2> 
<p>一主多从的主备切换过程图</p> 
<p><img src="https://images2.imgbox.com/08/6b/BQa4plAo_o.png" alt="在这里插入图片描述"></p> 
<blockquote> 
 <p><strong>tips</strong>：备库和从库的概念是不同的，虽然二者都是只读的，但是从库对外提供服务，而备库只是为主库提供备份</p> 
</blockquote> 
<p><strong>基于位点的主备切换</strong></p> 
<p>当通过 change master 命令将节点 B 设置成节点 A’ 的从库时，不可避免需要设置位点参数，但是位点存在不精确的问题</p> 
<p><strong>基于 GTID 的主备切换</strong></p> 
<p>GTID 的全称是 Global Transaction Identifier，也就是全局事务 ID，是一个事务在提交的时候生成的，是这个事务的唯一标识，由两部分组成，格式是 <strong>GTID=server_uuid:gno</strong></p> 
<ul>
<li>server_uuid 是一个实例第一次启动时自动生成的，是一个全局唯一的值</li>
<li>gno 是一个整数，初始值是 1，每次提交事务的时候分配给这个事务，并加 1</li>
</ul> 
<p><strong>transaction_id 与 gno 的区别</strong>：transaction_id 就是指事务 id，事务 id 是在事务执行过程中分配的，如果这个事务回滚了，事务 id 也会递增，而 gno 是在事务提交的时候才会分配，两个都是递增，不同点是事务id自增但不一定连续，因为会被回滚，而gno在提交时分配，所以是连续递增的</p> 
<p>每个 MySQL 实例都维护了一个 GTID 集合，用来对应“这个实例执行过的所有事务”</p> 
<p><strong>切换逻辑</strong></p> 
<ol>
<li> <p>实例 B 指定主库 A’，基于主备协议建立连接</p> </li>
<li> <p>实例 B 把 set_b 发给主库 A’。实例 A’算出 set_a 与 set_b 的差集，也就是所有存在于 set_a，但是不存在于 set_b 的 GTID 的集合，判断 A’本地是否包含了这个差集需要的所有 binlog 事务<br> a. 如果不包含，表示 A’已经把实例 B 需要的 binlog 给删掉了，直接返回错误<br> b. 如果确认全部包含，A’从自己的 binlog 文件里面，找出第一个不在 set_b 的事务，发给 B</p> </li>
<li> <p>之后就从这个事务开始，往后读文件，按顺序取 binlog 发给 B 去执行</p> </li>
</ol> 
<h2>
<a id="6_573"></a>6.如何判断主库异常</h2> 
<p><strong>select 1 判断</strong></p> 
<p>select 1 成功返回，只能说明这个库的进程还在，并不能说明主库没问题，比如当并发线程数达到了最大值，系统死锁后，select 1 依旧能成功返回</p> 
<p><strong>查表判断</strong></p> 
<p>为了能够检测 InnoDB 并发线程数过多导致的系统不可用情况，需要设计一个访问 InnoDB 的场景。一般的做法是，在系统库（mysql 库）里创建一个表，比如命名为 health_check，里面只放一行数据，然后定期执行</p> 
<p>但是更新事务要写 binlog，而一旦 binlog 所在磁盘的空间占用率达到 100%，那么所有的更新语句和事务提交的 commit 语句就都会被堵住。但是，系统这时候还是可以正常读数据</p> 
<p><strong>更新判断</strong></p> 
<p>要放个有意义的字段，常见做法是放一个 timestamp 字段，用来表示最后一次执行检测的时间</p> 
<p>但是，备库的检测也是要写 binlog，如果主库 A 和备库 B 都用相同的更新命令，就可能出现行冲突，也就是可能会导致主备同步停止</p> 
<p>为了让主备之间的更新不产生冲突，可以在 mysql.health_check 表上存入多行数据，并用 A、B 的 server_id 做主键</p> 
<p>但是，当 IO 利用率 100% 时，update 语句仍能正常运行，原因在于外部检测的随机性，对主库可用性检测不可控</p> 
<p><strong>内部统计</strong></p> 
<p>MySQL 的 performance_schema 表信息，可以详细检查其内部的流程是否有异常</p> 
<h1>
<a id="_599"></a>实践调优</h1> 
<h2>
<a id="1change_buffer_600"></a>1.change buffer</h2> 
<p>当需要更新一个数据页，如果数据页在内存中就直接更新，如果不在内存中，在不影响数据一致性的前提下，InnoDB 会将这些更新操作缓存在 change buffer 中。下次查询需要访问这个数据页的时候，将数据页读入内存，然后执行 change buffer 中的与这个页有关的操作</p> 
<p><strong>相关概念</strong>：</p> 
<ol>
<li> <p>change buffer 是可以持久化的数据。在内存中有拷贝，会被写入到磁盘上，同时 change buffer 的操作也<strong>会记录到 redo log</strong> 里，因此崩溃恢复的时候，change buffer 能找回来</p> </li>
<li> <p>将 change buffer 中的操作应用到原数据页上，得到最新结果的过程，称为<strong>merge</strong></p> </li>
<li> <p>访问这个数据页会触发 merge，系统有后台线程定期 merge，在数据库正常关闭的过程中，也会执行 merge</p> </li>
<li> <p>change buffer 用的是 buffer pool 里的内存，change buffer 的大小，可以通过参数 innodb_change_buffer_max_size 来动态设置。这个参数设置为50的时候，表示 change buffer 的大小最多只能占用 buffer pool 的 50%</p> </li>
<li> <p>将数据从磁盘读入内存涉及随机 IO 的访问，是数据库里面成本最高的操作之一，change buffer 因为<strong>减少了随机磁盘访问</strong>，所以对更新性能的提升很明显</p> </li>
</ol> 
<p><strong>唯一索引的更新不能使用change buffer</strong></p> 
<p>对于唯一索引来说，所有的更新操作都要先判断这个操作是否违反唯一性约束，用不上 change buffer 的优化机制</p> 
<p><strong>change buffer使用场景</strong></p> 
<p>在一个数据页做murge之前，change buffer 记录的变更越多，收益就越大</p> 
<p>对于写多读少的业务来说，页面在写完以后马上被访问到的概率比较小，此时 change buffer 的使用效果最好。这种业务模型常见的就是账单类、日志类的系统</p> 
<p>反过来，假设一个业务的更新模式是写入之后马上会做查询，那么即使满足了条件，将更新先记录在 change buffe，但之后由于马上要访问这个数据页，会立即触发 merge 过程</p> 
<p>这样随机访问 IO 的次数不会减少，反而增加了 change buffer 的维护代价。所以，对于这种业务模式来说，change buffer 反而起到了副作用</p> 
<p><strong>索引的选择和实践</strong></p> 
<p>尽可能使用普通索引</p> 
<p>log 主要节省的是随机写磁盘的 IO 消耗(转成顺序写)，而 change buffer 主要节省的则是随机读磁盘的IO消耗</p> 
<h2>
<a id="2_640"></a>2.索引选择异常和处理</h2> 
<p>优化器会根据<strong>扫描行数</strong>，<strong>是否使用临时表</strong>，<strong>是否排序</strong>进行综合判断选择一个最优的索引，以最小代价方案执行，而MySQL有时会因为扫描行数不够精确选错索引，所以需要优化</p> 
<p>扫描行数的判断依据于<strong>基数（cardinality）</strong>，基数表示的是区分度，也就是索引中不同值的个数，基数越大，区分度越好</p> 
<p>基数的统计方式是<strong>采样统计</strong>，选取N个数据页，统计不同值的平均值再乘以索引页面数作为基数，而采样统计不可避免存在误差，就会导致基数精确度不够，扫描行数判断失误，索引选择异常</p> 
<p>选错索引可能有两种情况 ：</p> 
<ol>
<li>也就是上述，由于索引统计信息不准确，导致判断扫描行数不准确，此种情况可用 analyze table 来解决</li>
<li>由于临时表，排序字段，导致优化器误判，此种情况可用 force index 来强行指定索引，也可以通过修改语句引导优化器，还可以通过增加或者删除索引来绕过这个问题</li>
</ol> 
<h2>
<a id="3_652"></a>3.字符串索引策略</h2> 
<ol>
<li>直接创建完整索引，比较占用空间</li>
<li>创建前缀索引，节省空间，但会增加查询扫描次数，并且不能使用覆盖索引</li>
<li>倒序存储，再创建前缀索引，用于绕过字符串本身前缀的区分度不够的问题</li>
<li>创建 hash 字段索引，查询性能稳定，有额外的存储和计算消耗，跟第三种方式一样，都不支持范围扫描</li>
</ol> 
<h2>
<a id="4_658"></a>4.刷脏页的控制策略</h2> 
<p>当内存数据页跟磁盘数据页内容不一致的时候，我们称这个内存页为<strong>脏页</strong>。内存数据写入到磁盘后，内存和磁盘上的数据页的内容就一致了，称为<strong>干净页</strong></p> 
<p>触发刷脏页的四种情况：</p> 
<ol>
<li>InnoDB 的 redo log 写满，更新全部堵住，写性能跌为 0</li>
<li>系统内存不足，当需要新的内存页，而内存不够用的时候，就要淘汰一些数据页，空出内存给别的数据页使用，如果淘汰的是“脏页”，就要先刷脏页</li>
<li>系统空闲的时候，主动刷脏页以保证效率</li>
<li>MySQL 正常关闭的情况。这时候，MySQL 会把内存的脏页都 flush 到磁盘上，这样下次 MySQL 启动的时候，就可以直接从磁盘上读数据，启动速度会很快</li>
</ol> 
<p><strong>控制策略</strong></p> 
<p>需要正确设置 innodb_io_capacity 参数，告知InnoDB其所在主机的 IO 能力，建议设置成磁盘的 IOPS，此时 InnoDB 已经知晓该主机全力刷脏页的能力，会按照全力刷脏页的<strong>百分比</strong>来刷新脏页</p> 
<p>百分比的设置参考两个因素：<strong>脏页比例</strong>和 <strong>redo log 写盘速度</strong></p> 
<p><img src="https://images2.imgbox.com/29/78/FEthbjzg_o.png" alt=" "></p> 
<p>根据上述算得的 F1(M) 和 F2(N) 两个值，取其中较大的值记为 R，之后引擎就可以按照 innodb_io_capacity 定义的能力乘以 R% 来控制刷脏页的速度</p> 
<h2>
<a id="5_680"></a>5.收缩表空间</h2> 
<p>delete 命令只是把记录的位置，或者数据页标记为了“可复用”，但磁盘文件的大小是不会变的。也可以认为是一种逻辑删除，所以物理空间没有实际释放，只是标记为可复用，表文件的大小不变。这些可以复用但未被使用的空间，就是空洞</p> 
<p>清理空洞，正确收缩表空间的方式是<strong>重建表</strong>，MySQL 会创建一个临时表并自动完成转存数据、交换表名、删除旧表的操作</p> 
<p>MySQL5.6以后引入了 <strong>Online DDL</strong>，对重建表的过程进行了优化，将复制过程中的增删操作写入日志文件（row log）最后再合并进入临时表，实现在重建表的过程中对数据进行增删操作，本质上是 Copy-On-Write 的思想，同时，<strong>alter 语句在启动的时候会获取 MDL 写锁，但是这个写锁在真正拷贝数据之前会退化成读锁</strong></p> 
<p><strong>Online 和 inplace</strong><br> 重建表的过程在存储引擎中实现，对于server端来说，无感知，这种方式叫做 inplace，即<strong>原地操作</strong></p> 
<p>DDL 过程如果是 Online 的，就一定是 inplace 的，inplace 的 DDL，有可能不是 Online 的</p> 
<p><strong>optimize table、analyze table 和 alter table的区别</strong>：</p> 
<ol>
<li>alter table t engine = InnoDB （即recreate）采取的是Online DDL</li>
<li>analyze table t 其实不是重建表，只是对表的索引信息做重新统计，没有修改数据，这个过程中加了 MDL 读锁</li>
<li>optimize table t 等于 recreate+analyze</li>
</ol> 
<h2>
<a id="6count_700"></a>6.count(*)优化</h2> 
<p><strong>count(*) 的实现方式</strong></p> 
<p>MyISAM 会存储总行数，可以直接返回，效率很高，而 InnoDB 由于存在事务设计，基于MVCC（多版本并发控制），所以每一行都要判断其是否可见，只能一行一行统计计数，所以效率不高，不过这个过程存在一个简单优化，MySQL 会选择最小的索引树进行遍历，减少扫描量以提升性能</p> 
<p>优化方案：</p> 
<ol>
<li>
<strong>用缓存系统保存计数</strong>，存入 redis 中，但存在<strong>丢失更新</strong>（redis异常重启）和<strong>逻辑上不正确</strong>（无法保证“ MySQ L插入一行数据”跟“ Redis 计数加 1 ”这两个操作的原子性）的问题，不推荐使用</li>
<li>
<strong>在数据库保存计数</strong>，InnoDB 的 redo log 则能解决崩溃恢复问题，<strong>利用事务的原子性，将计数的记录 + 1 和插入一条数据放入到同一个事务</strong>可以解决逻辑不正确问题，推荐使用</li>
</ol> 
<p>count语法的性能对比，自上而下性能递增</p> 
<table>
<thead><tr>
<th>语法</th>
<th>底层原理</th>
</tr></thead>
<tbody>
<tr>
<td>count(字段）</td>
<td>遍历整张表，需要取值，判断 字段 != null</td>
</tr>
<tr>
<td>count(id)</td>
<td>遍历整张表，需要取ID，判断 id !=null，按行累加</td>
</tr>
<tr>
<td>count(1)</td>
<td>遍历整张表，不需要取值，返回的每一行放一个数字1，按行累加</td>
</tr>
<tr>
<td>count(*)</td>
<td>按行累加； 因为count(*) 和 count(1) 不取字段值，减少往 server层的数据返回，所以比其他count(字段)要返回值的性能较好</td>
</tr>
</tbody>
</table>
<h2>
<a id="7order_by_721"></a>7.order by机制</h2> 
<p>排序机制有两种，全字段排序和 rowid 排序，排序的选择依据于排序数据的<strong>单行长度</strong>，通过参数：max_length_for_sort_data 设置，单行长度小于这个值则选择全字段排序，大于这个值则选择rowid排序</p> 
<p>排序开始时，会初始化 <strong>sort_buffer</strong>（通过参数 sort_buffer_size 设置其大小），如果 sort buffer 的大小足够，那么排序就在内存中完成，否则就需要使用磁盘临时文件进行排序，在 sort buffer 中排好序然后把结果存入临时文件，最后合并成一个大的临时文件，采用<strong>归并排序算法</strong></p> 
<blockquote> 
 <p><strong>补充</strong>：如果结果集需要的有序列很少的话，则会使用优先队列算法，维护一个大根堆或小根堆，避免使用临时表以提升效率</p> 
</blockquote> 
<p><strong>全字段排序</strong></p> 
<ol>
<li> <p>通过索引将所需的字段<strong>全部</strong>读取到 sort_buffer 中</p> </li>
<li> <p>按照排序字段进行排序</p> </li>
<li> <p>将结果集返回给客户端</p> </li>
</ol> 
<p><strong>rowid排序</strong></p> 
<ol>
<li> <p>只将需要排序的字段和主键读取到 sort_buffer 中，并按照排序字段进行排序</p> </li>
<li> <p>按照排序后的顺序，取id进行<strong>回表</strong>取出想要获取的数据</p> </li>
<li> <p>将结果集返回给客户端</p> </li>
</ol> 
<p><strong>全字段排序 vs rowid 排序</strong></p> 
<table>
<thead><tr>
<th></th>
<th>全字段排序</th>
<th>rowid 排序</th>
</tr></thead>
<tbody>
<tr>
<td>优点</td>
<td>造成 sort_buffer 中存放不下很多数据，因为除了排序字段还存放其他字段，对 sort_buffer 的利用效率不高，当所需排序数据量很大时，会有很多的临时文件，排序性能也会很差</td>
<td>更好的利用内存的sort_buffer 进行排序操作，尽量减少对磁盘的访问</td>
</tr>
<tr>
<td>缺点</td>
<td>造成 sort_buffer 中存放不下很多数据，因为除了排序字段还存放其他字段，对 sort_buffer 的利用效率不高，当所需排序数据量很大时，会有很多的临时文件，排序性能也会很差</td>
<td>回表的操作是随机 IO，会造成大量的随机读，不一定就比全字段排序减少对磁盘的访问</td>
</tr>
</tbody>
</table>
<p><strong>Ung index优化</strong></p> 
<p>可以利用<strong>索引覆盖</strong>优化，取消回表，但相应的会付出维护联合索引的代价，二者需要权衡</p> 
<p><strong>order by rand()</strong></p> 
<p>这个语句需要 Using temporary 和 Using filesort，查询的执行代价比较大。所以，在设计的时候要尽量避开这种写法，随机数的计算应该放在业务中进行，让数据库只做读写数据，保持单一职责</p> 
<h2>
<a id="8_766"></a>8.查询优化</h2> 
<p>查询无返回的几种情况：</p> 
<ol>
<li>
<strong>等 MDL 锁</strong>，线程状态为 Waiting for table metadata lock，kill掉造成阻塞的线程即可</li>
<li>
<strong>等 flush</strong>，线程状态为 Waiting for table flush ，flush tables 会等待正在运行的所有语句执行结束，如何flush线程被阻塞，则其会阻塞所有请求，优化方案为解决掉阻塞 flush 的线程</li>
<li>
<strong>等行锁</strong>，解决掉长期占有行锁但不提交的事务</li>
</ol> 
<p>查询缓慢的几种情况：</p> 
<ol>
<li>
<strong>一致性读慢</strong>，事务A在执行过程中，其它事务对记录有很多次的更新，导致 undo log过大，事务A要用大量 undo log 才能拿到启动时的快照，优化方案是尽量不要使用长事务</li>
<li>上文提到的<strong>索引选择异常</strong>，应急方案就是给这个语句加上 force index 制定索引</li>
<li>
<strong>索引没有设计好</strong>，利用 Online DDL 机制执行 alter table 语句紧急创建索引</li>
</ol> 
<h2>
<a id="9_780"></a>9.短连接风暴</h2> 
<p>MySQL 建立连接的成本很高。除了正常的网络连接三次握手外，还需要做登录权限判断和获得这个连接的数据读写权限，连接数由参数 max_connections 控制，当连接超过了上限，数据库就会拒绝请求，对业务来说数据库不可用，而设置 max_connections 参数的目的是为了降低负载保护数据库，所以调高这个参数并不能很好的优化</p> 
<p>优化方案：</p> 
<ol>
<li>处理掉占着连接但是不工作的线程</li>
<li>减少连接过程的消耗，使用 –skip-grant-tables 参数重启数据库跳过权限校验阶段，但风险极高</li>
</ol> 
<h2>
<a id="10QPS__789"></a>10.QPS 突增问题</h2> 
<p>往往是由业务层面导致（此类问题一般使用中间件实现负载均衡），数据库层面的解决方案：</p> 
<ol>
<li>停掉业务，或者将客户端从数据库白名单中去掉，依赖于虚拟化白名单机制</li>
<li>使用管理员账号删除该用户，依赖于业务账号分离机制</li>
<li>查询重写，把压力最大的 SQL 语句直接重写成"select 1"返回，但会导致业务逻辑失败，优先级最低</li>
</ol> 
<h2>
<a id="11IO_797"></a>11.IO性能瓶颈</h2> 
<p>优化方案：</p> 
<ol>
<li>设置 binlog_group_commit_sync_delay 和 binlog_group_commit_sync_no_delay_count 参数，减少 binlog 的写盘次数。这个方法是基于“额外的故意等待”来实现的，因此可能会增加语句的响应时间，但没有丢失数据的风险</li>
<li>将 sync_binlog 设置为大于 1 的值（比较常见是 100~1000）。这样做的风险是，主机掉电时会丢 binlog 日志</li>
<li>将 innodb_flush_log_at_trx_commit 设置为 2。这样做的风险是，主机掉电的时候会丢数据</li>
</ol> 
<h2>
<a id="12_804"></a>12.读写分离优化</h2> 
<p>“在从库上会读到系统的一个过期状态”的现象，可以称之为“过期读”</p> 
<p>解决过期读的方案如下</p> 
<p><strong>强制走主库方案</strong></p> 
<p>将查询请求做分类，对于必须要拿到最新结果的请求，强制将其发到主库上，对于可以读到旧数据的请求，才将其发到从库上</p> 
<p><strong>sleep 方案</strong></p> 
<p>主库更新后，读从库之前先 sleep 一下。具体的方案就是，类似于执行一条 select sleep(1) 命令</p> 
<p><strong>判断主备无延迟方案</strong></p> 
<p>要确保备库无延迟，通常有三种做法:</p> 
<ol>
<li>每次从库执行查询请求前，先判断 seconds_behind_master 是否已经等于 0。如果还不等于 0 ，那就必须等到这个参数变为 0 才能执行查询请求</li>
<li>对比位点确保主备无延迟</li>
<li>对比 GTID 集合确保主备无延迟</li>
</ol> 
<p><strong>配合 semi-sync 方案</strong></p> 
<p>引入<strong>半同步复制</strong>，也就是 semi-sync replication</p> 
<p>semi-sync 做了这样的设计：</p> 
<ol>
<li>事务提交的时候，主库把 binlog 发给从库</li>
<li>从库收到 binlog 以后，发回给主库一个 ack，表示收到了</li>
<li>主库收到这个 ack 以后，才能给客户端返回“事务完成”的确认</li>
</ol> 
<p>也就是说，如果启用了 semi-sync，就表示所有给客户端发送过确认的事务，都确保了备库已经收到了这个日志</p> 
<p><strong>等主库位点方案</strong></p> 
<p>在从库上执行命令</p> 
<pre><code class="prism language-sql"><span class="token keyword">select</span> master_pos_wait<span class="token punctuation">(</span><span class="token keyword">file</span><span class="token punctuation">,</span> pos<span class="token punctuation">[</span><span class="token punctuation">,</span> timeout<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p>相当于主库上事务更新后，不知道从库执行情况，先在主库上找到位置，然后在从库上找，返回 0 和返回大于 0 都表示这个从库执行过这个事务了，可以在这个从库上select，没执行过等，超过N秒没有返回说明过期</p> 
<p><strong>等 GTID 方案</strong></p> 
<p>在从库上执行命令</p> 
<pre><code class="prism language-sql"> <span class="token keyword">select</span> wait_for_executed_gtid_set<span class="token punctuation">(</span>gtid_set<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p>相当于从库执行完事务后，将事务id发给主库，如果返回值是 0，则在这个从库执行查询语句，否则，到主库执行查询语句，超过N秒没有返回说明过期</p> 
<h2>
<a id="13_857"></a>13.误删修复</h2> 
<p><strong>使用 delete 语句误删数据行</strong></p> 
<p>可以用 Flashback 工具通过闪回把数据恢复回来，Flashback 恢复数据的原理，是修改 binlog 的内容，拿回原库重放。而能够使用这个方案的前提是，需要确保 <strong>binlog_format=row 和 binlog_row_image=FULL</strong></p> 
<p><strong>事前预防方案</strong>：</p> 
<ol>
<li>把 sql_safe_updates 参数设置为 on。如果忘记在 delete 或者 update 语句中写 where 条件，或者 where 条件里面没有包含索引字段的话，这条语句的执行就会报错</li>
<li>代码上线前，必须经过 SQL 审计</li>
</ol> 
<p>设置完 sql_safe_updates 后删除全表可以在语句后继加 where id&gt;=0 ，但是delete 全表是很慢的，需要生成回滚日志、写 redo、写 binlog。所以，从性能角度考虑，应该优先考虑使用 truncate table 或者 drop table 命令</p> 
<p><strong>使用 drop table 或者 truncate table 语句误删数据表或使用 drop database 语句误删数据库</strong></p> 
<p>在误删库/表情况下恢复数据，要求线上有定期的全量备份和实时备份binlog</p> 
<p>恢复流程：</p> 
<ol>
<li>取最近一次的全量备份恢复出一个临时库</li>
<li>取binlog日志中固定时间点之后的日志</li>
<li>把这些日志除了误删数据的语句外，全部应用到临时库</li>
</ol> 
<p>加速恢复的方案：</p> 
<ol>
<li>应用 binlog 时，指定误删库</li>
<li>新增临时实例，设置为备库，利用并行复制加快速度</li>
<li>当数据量特别大时，可以采用延时备份</li>
</ol> 
<p><strong>预防方案</strong>：</p> 
<ol>
<li>
<strong>账号分离</strong>，避免写错命令</li>
<li>
<strong>制定操作规范</strong>，避免写错要删除的表名<br> <img src="https://images2.imgbox.com/4b/aa/r6L4faUg_o.png" alt="在这里插入图片描述">
</li>
</ol> 
<p><strong>使用 rm 命令误删整个 MySQL 实例</strong></p> 
<p>对于一个有高可用机制的 MySQL 集群来说，最不怕的就是 rm 删除数据了。只要不是恶意地把整个集群删除，而只是删掉了其中某一个节点的数据的话，HA 系统就会开始工作，选出一个新的主库，从而保证整个集群的正常工作</p> 
<h1>
<a id="explain_899"></a>explain分析执行计划</h1> 
<p>在sql语句前面加explain可以分析sql语句的执行信息</p> 
<table>
<thead><tr>
<th>字段</th>
<th>含义</th>
</tr></thead>
<tbody>
<tr>
<td>id</td>
<td>select查询的序列号，是一组数字，表示的是查询中执行select子句或者是操作表的顺序。</td>
</tr>
<tr>
<td>select_type</td>
<td>表示 SELECT 的类型，常见的取值有 SIMPLE（简单表，即不使用表连接或者子查询）、PRIMARY（主查询，即外层的查询）、UNION（UNION 中的第二个或者后面的查询语句）、SUBQUERY（子查询中的第一个 SELECT）等</td>
</tr>
<tr>
<td>table</td>
<td>输出结果集的表</td>
</tr>
<tr>
<td>type</td>
<td>表示表的连接类型，性能由好到差的连接类型为( system —&gt; const -----&gt; eq_ref ------&gt; ref -------&gt; ref_or_null----&gt; index_merge —&gt; index_subquery -----&gt; range -----&gt; index ------&gt; all )</td>
</tr>
<tr>
<td>possible_keys</td>
<td>表示查询时，可能使用的索引</td>
</tr>
<tr>
<td>key</td>
<td>表示实际使用的索引</td>
</tr>
<tr>
<td>key_len</td>
<td>索引字段的长度</td>
</tr>
<tr>
<td>rows</td>
<td>扫描行的数量</td>
</tr>
<tr>
<td>extra</td>
<td>执行情况的说明和描述</td>
</tr>
</tbody>
</table>
<p><strong>id</strong></p> 
<p>id存在三种情况</p> 
<ul>
<li>id 相同表示加载表的顺序是从上到下</li>
<li>id 不同id值越大，优先级越高，越先被执行</li>
<li>id 有相同，也有不同，同时存在。id相同的可以认为是一组，从上往下顺序执行；在所有的组中，id的值越大，优先级越高，越先执行</li>
</ul> 
<p><strong>select_type</strong></p> 
<table>
<thead><tr>
<th>select_type</th>
<th>含义</th>
</tr></thead>
<tbody>
<tr>
<td>SIMPLE</td>
<td>简单的select查询，查询中不包含子查询或者UNION</td>
</tr>
<tr>
<td>PRIMARY</td>
<td>查询中若包含任何复杂的子查询，最外层查询标记为该标识</td>
</tr>
<tr>
<td>SUBQUERY</td>
<td>在SELECT 或 WHERE 列表中包含了子查询</td>
</tr>
<tr>
<td>DERIVED</td>
<td>在FROM 列表中包含的子查询，被标记为 DERIVED（衍生） MYSQL会递归执行这些子查询，把结果放在临时表中</td>
</tr>
<tr>
<td>UNION</td>
<td>若第二个SELECT出现在UNION之后，则标记为UNION ； 若UNION包含在FROM子句的子查询中，外层SELECT将被标记为 ： DERIVED</td>
</tr>
<tr>
<td>UNION RESULT</td>
<td>从UNION表获取结果的SELECT</td>
</tr>
</tbody>
</table>
<p><strong>type</strong></p> 
<p>type 显示的是访问类型，是较为重要的一个指标，可取值为：</p> 
<table>
<thead><tr>
<th>type</th>
<th>含义</th>
</tr></thead>
<tbody>
<tr>
<td>NULL</td>
<td>MySQL不访问任何表，索引，直接返回结果</td>
</tr>
<tr>
<td>system</td>
<td>表只有一行记录(等于系统表)，这是const类型的特例，一般不会出现</td>
</tr>
<tr>
<td>const</td>
<td>表示通过索引一次就找到了，const 用于比较primary key 或者 unique 索引。因为只匹配一行数据，所以很快。如将主键置于where列表中，MySQL 就能将该查询转换为一个常亮。const于将 “主键” 或 “唯一” 索引的所有部分与常量值进行比较</td>
</tr>
<tr>
<td>eq_ref</td>
<td>类似ref，区别在于使用的是唯一索引，使用主键的关联查询，关联查询出的记录只有一条。常见于主键或唯一索引扫描</td>
</tr>
<tr>
<td>ref</td>
<td>非唯一性索引扫描，返回匹配某个单独值的所有行。本质上也是一种索引访问，返回所有匹配某个单独值的所有行（多个）</td>
</tr>
<tr>
<td>range</td>
<td>只检索给定返回的行，使用一个索引来选择行。 where 之后出现 between ， &lt; , &gt; , in 等操作。</td>
</tr>
<tr>
<td>index</td>
<td>index 与 ALL的区别为 index 类型只是遍历了索引树， 通常比ALL 快， ALL 是遍历数据文件。</td>
</tr>
<tr>
<td>all</td>
<td>将遍历全表以找到匹配的行</td>
</tr>
</tbody>
</table>
<p>结果值从最好到最坏以此是：</p> 
<pre><code class="prism language-shell">NULL <span class="token operator">&gt;</span> system <span class="token operator">&gt;</span> const <span class="token operator">&gt;</span> eq_ref <span class="token operator">&gt;</span> ref <span class="token operator">&gt;</span> fulltext <span class="token operator">&gt;</span> ref_or_null <span class="token operator">&gt;</span> index_merge <span class="token operator">&gt;</span> unique_subquery <span class="token operator">&gt;</span> index_subquery <span class="token operator">&gt;</span> range <span class="token operator">&gt;</span> index <span class="token operator">&gt;</span> ALL

system <span class="token operator">&gt;</span> const <span class="token operator">&gt;</span> eq_ref <span class="token operator">&gt;</span> ref <span class="token operator">&gt;</span> range <span class="token operator">&gt;</span> index <span class="token operator">&gt;</span> ALL
</code></pre> 
<p><strong>extra</strong></p> 
<p>其他的额外的执行计划信息，在该列展示</p> 
<table>
<thead><tr>
<th>extra</th>
<th>含义</th>
</tr></thead>
<tbody>
<tr>
<td>using filesort</td>
<td>说明mysql会对数据使用一个外部的索引排序，而不是按照表内的索引顺序进行读取， 称为 “文件排序”, 效率低。</td>
</tr>
<tr>
<td>using temporary</td>
<td>使用了临时表保存中间结果，MySQL在对查询结果排序时使用临时表。常见于 order by 和 group by； 效率低</td>
</tr>
<tr>
<td>using index</td>
<td>表示相应的select操作使用了覆盖索引， 避免访问表的数据行， 效率不错。</td>
</tr>
</tbody>
</table>
                </div>
                
                

		</div>
	</article>
</main>




			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程小白.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://www.w3counter.com/tracker.js?id=150625"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>
	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>