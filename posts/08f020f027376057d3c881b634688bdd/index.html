<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<title>Stable Diffusion原理详解 - 编程小白</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程小白" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程小白</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Stable Diffusion原理详解</h1>
			
		</header>
		<div class="content post__content clearfix">
			


        
                <div id="content_views" class="markdown_views prism-tomorrow-night">
                    
                        
                    
                    <h1 align="center">Stable Diffusion原理详解</h1> 
<p>最近AI图像生成异常火爆，听说鹅厂都开始用AI图像生成做前期设定了，小厂更是直接用AI替代了原画师的岗位。这一张张丰富细腻、风格各异、以假乱真的AI生成图像，背后离不开<a href="https://stability.ai/blog/stable-diffusion-public-release">Stable Diffusion</a>算法。</p> 
<p>Stable Diffusion是<a href="stability.ai">stability.ai</a>开源的图像生成模型，可以说Stable Diffusion的发布将AI图像生成提高到了全新高度，其效果和影响不亚于Open AI发布ChatGPT。今天我们就一起学习一下Stable Diffusion的原理。</p> 
<p><img src="https://images2.imgbox.com/d0/d5/rDvehIci_o.jpg" alt="在这里插入图片描述"><br> </p>
<div class="toc">
 <h3>文章目录</h3>
 <ul><li>
<ul>
<li><a href="#_9">图像生成的发展</a></li>
<li><a href="#_25">扩散模型</a></li>
<li><a href="#Transformer_60">Transformer</a></li>
<li><a href="#Stable_Diffusion_66">Stable Diffusion</a></li>
<li>
<ul>
<li><a href="#Lantent_Space_72">潜在空间(Lantent Space)</a></li>
<li><a href="#Latent_Diffusion_84">Latent Diffusion</a></li>
<li>
<ul>
<li><a href="#_90">感知压缩</a></li>
<li><a href="#_99">语义压缩</a></li>
<li><a href="#_103">感知损失</a></li>
<li><a href="#_107">扩散损失</a></li>
<li><a href="#_129">条件扩散</a></li>
<li><a href="#_133">注意力机制</a></li>
<li><a href="#_137">文本-图像合成</a></li>
<li><a href="#_141">图像-图像合成</a></li>
</ul>
    </li>
<li><a href="#_145">整体架构</a></li>
</ul>
   </li>
<li><a href="#_155">总结</a></li>
</ul>
 </li></ul>
</div>
<p></p> 
<h2>
<a id="_9"></a>图像生成的发展</h2> 
<p>在Stable Diffusion诞生之前，计算机视觉和机器学习方面最重要的突破是 GAN（Generative Adversarial Networks 生成对抗网络）。GAN让超越训练数据已有内容成为可能，从而打开了一个全新领域——现在称之为生成建模。</p> 
<p>然而，在经历了一段蓬勃发展后，GAN开始暴露出一些瓶颈和弊病，大家倾注了很多心血努力解决对抗性方法所面临的一些瓶颈，但是鲜有突破，GAN由此进入平台期。GAN的主要问题在于：</p> 
<ul>
<li>图像生成缺乏多样性</li>
<li>模式崩溃</li>
<li>多模态分布学习困难</li>
<li>训练时间长</li>
<li>由于问题表述的对抗性，不容易训练</li>
</ul> 
<p>另外，还有一条基于似然（例如，马尔可夫随机场）的技术路线，尽管已经存在很久，但由于对每个问题的实施和制定都很复杂，因此未能产生重大影响。</p> 
<p>近几年，随着算力的增长，一些过去算力无法满足的复杂算法得以实现，其中有一种方法叫“扩散模型”——一种从气体扩散的物理过程中汲取灵感并试图在多个科学领域模拟相同现象的方法。该模型在图像生成领域展现了巨大的潜力，成为今天Stable Diffusion的基础。</p> 
<h2>
<a id="_25"></a>扩散模型</h2> 
<p>扩散模型是一种生成模型，用于生成与训练数据相似的数据。简单的说，扩散模型的工作方式是通过迭代添加高斯噪声来“破坏”训练数据，然后学习如何消除噪声来恢复数据。</p> 
<p>一个标准扩散模型有两个主要过程：<strong>正向扩散</strong>和<strong>反向扩散</strong>。</p> 
<p>在正向扩散阶段，通过逐渐引入噪声来破坏图像，直到图像变成完全随机的噪声。</p> 
<p>在反向扩散阶段，使用一系列马尔可夫链逐步去除预测噪声，从高斯噪声中恢复数据<sup class="footnote-ref"><a href="#fn1" id="fnref1">1</a></sup>。</p> 
<p><img src="https://images2.imgbox.com/ce/d6/5D90VRmf_o.png" alt="在这里插入图片描述"></p> 

 <small>通过缓慢添加（去除）噪声来生成样本的正向（反向）扩散过程的马尔可夫链(图片来源: Jonathan Ho, Ajay Jain, Pieter Abbeel. 2020)</small>

<br> 
<p>对于噪声的估计和去除，最常使用的是 U-Net。该神经网络的架构看起来像字母 U，由此得名。U-Net 是一个全连接卷积神经网络，这使得它对图像处理非常有用。U-Net的特点在于它能够将图像作为入口，并通过减少采样来找到该图像的低维表示，这使得它更适合处理和查找重要属性，然后通过增加采样将图像恢复回来。</p> 
<p><img src="https://images2.imgbox.com/f8/58/SWipN4d0_o.png" alt="img"></p> 

 <small>一个典型的U-Net架构实例</small>

<br> 
<p>具体的说，所谓去除噪声就是从时间帧 <span class="katex--inline"><span class="katex"><span class="katex-mathml">
    
     
      
       
        t
       
      
      
       t
      
     
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6151em"></span><span class="mord mathnormal">t</span></span></span></span></span> 向时间帧 <span class="katex--inline"><span class="katex"><span class="katex-mathml">
    
     
      
       
        t
       
       
        −
       
       
        1
       
      
      
       t-1
      
     
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6984em;vertical-align: -0.0833em"></span><span class="mord mathnormal">t</span><span class="mspace" style="margin-right: 0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right: 0.2222em"></span></span><span class="base"><span class="strut" style="height: 0.6444em"></span><span class="mord">1</span></span></span></span></span> 的变换，其中 <span class="katex--inline"><span class="katex"><span class="katex-mathml">
    
     
      
       
        t
       
      
      
       t
      
     
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6151em"></span><span class="mord mathnormal">t</span></span></span></span></span> 是 <span class="katex--inline"><span class="katex"><span class="katex-mathml">
    
     
      
       
        
         t
        
        
         0
        
       
      
      
       t_0
      
     
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.7651em;vertical-align: -0.15em"></span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em"><span class="" style="margin-left: 0em;margin-right: 0.05em"><span class="pstrut" style="height: 2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em"><span class=""></span></span></span></span></span></span></span></span></span></span> （没有噪声）到 <span class="katex--inline"><span class="katex"><span class="katex-mathml">
    
     
      
       
        
         t
        
        
         
          m
         
         
          a
         
         
          x
         
        
       
      
      
       t_{max}
      
     
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.7651em;vertical-align: -0.15em"></span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.1514em"><span class="" style="margin-left: 0em;margin-right: 0.05em"><span class="pstrut" style="height: 2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">ma</span><span class="mord mathnormal mtight">x</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em"><span class=""></span></span></span></span></span></span></span></span></span></span>（完全噪声）之间的任意时间帧。变换规则为：</p> 
<ol>
<li>输入时间帧 <span class="katex--inline"><span class="katex"><span class="katex-mathml">
     
      
       
        
         t
        
       
       
        t
       
      
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6151em"></span><span class="mord mathnormal">t</span></span></span></span></span> 的图像，并且在该时间帧上图像存在特定噪声；</li>
<li>使用 U-Net 预测总噪声量；</li>
<li>然后在时间帧 <span class="katex--inline"><span class="katex"><span class="katex-mathml">
     
      
       
        
         t
        
       
       
        t
       
      
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6151em"></span><span class="mord mathnormal">t</span></span></span></span></span> 的图像中去除总噪声的“一部分”，得到噪声较少的时间帧 <span class="katex--inline"><span class="katex"><span class="katex-mathml">
     
      
       
        
         t
        
        
         −
        
        
         1
        
       
       
        t-1
       
      
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6984em;vertical-align: -0.0833em"></span><span class="mord mathnormal">t</span><span class="mspace" style="margin-right: 0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right: 0.2222em"></span></span><span class="base"><span class="strut" style="height: 0.6444em"></span><span class="mord">1</span></span></span></span></span> 的图像。</li>
</ol> 
<p><img src="https://images2.imgbox.com/27/0e/JFLC1Cu0_o.png" alt="在这里插入图片描述"></p> 

 <small>向图片逐步增加/删除噪声</small>

<br> 
<p>从数学上讲，执行此上述方法 <span class="katex--inline"><span class="katex"><span class="katex-mathml">
    
     
      
       
        T
       
      
      
       T
      
     
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6833em"></span><span class="mord mathnormal" style="margin-right: 0.1389em">T</span></span></span></span></span> 次比尝试消除整个噪声更有意义。通过重复这个过程，噪声会逐渐被去除，我们会得到一个更“干净”的图像。比如对于带有噪声的图，我们通过在初始图像上添加完全噪声，然后再迭代地去除它来生成没有噪声的图像，效果比直接在原图上去除噪声要好。</p> 
<p>近几年，扩散模型在图像生成任务中表现出突出的性能，并在图像合成等多个任务中取代了GAN。由于扩散模型能够保持数据的语义结构，因此不会受到模式崩溃的影响。</p> 
<p>然而，实现扩散模型存在一些困难。因为所有马尔可夫状态都需要一直在内存中进行预测，这意味着内存中要一直保存多个大型深度网络的实例，从而导致扩散模型非常吃内存。此外，扩散模型可能会陷入图像数据中难以察觉的细粒度复杂性中，导致训练时间变得太长（几天到几个月）。矛盾的是，细粒度图像生成是扩散模型的主要优势之一，我们无法避免这个“甜蜜的烦恼”。由于扩散模型对计算要求非常高，训练需要非常大的内存和电量，这使得早前大多数研究人员无法在现实中实现该模型。</p> 
<h2>
<a id="Transformer_60"></a>Transformer</h2> 
<p>Transformer是来自 NLP 领域的非常著名的模型方法。Transformer在语言建模和构建对话式 AI 工具方面取得了巨大成功。 在视觉应用中，Transformer 表现出了泛化和自适应的优势，这使得它们非常适合通用学习。 它们比其他技术能够更好地捕捉文本甚至图像中的语义结构。 然而，Transformers 需要大量数据，并且与其他方法相比，在许多视觉领域的性能方面也面临着平台期。</p> 
<p>Transformer可以与扩散模型结合，通过Transformer的“词嵌入”可以将文本插入到模型中。这意味着将词Token化后，然后将这种文本表示添加到U-Net的输入（图像）中，经过每一层U-Net神经网络与图像一起进行变换。从第一次迭代开始到之后的每一次迭代都加入相同的文本，从而让文本“作为指南”生成图像，从有完整噪声的第一次迭代开始，然后进一步向下应用到整个迭代。</p> 
<h2>
<a id="Stable_Diffusion_66"></a>Stable Diffusion</h2> 
<p>扩散模型最大的问题是它的时间成本和经济成本都极其“昂贵”。Stable Diffusion的出现就是为了解决上述问题。如果我们想要生成一张 <span class="katex--inline"><span class="katex"><span class="katex-mathml">
    
     
      
       
        1024
       
       
        ×
       
       
        1024
       
      
      
       1024 times 1024
      
     
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.7278em;vertical-align: -0.0833em"></span><span class="mord">1024</span><span class="mspace" style="margin-right: 0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right: 0.2222em"></span></span><span class="base"><span class="strut" style="height: 0.6444em"></span><span class="mord">1024</span></span></span></span></span> 尺寸的图像，U-Net 会使用 <span class="katex--inline"><span class="katex"><span class="katex-mathml">
    
     
      
       
        1024
       
       
        ×
       
       
        1024
       
      
      
       1024 times 1024
      
     
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.7278em;vertical-align: -0.0833em"></span><span class="mord">1024</span><span class="mspace" style="margin-right: 0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right: 0.2222em"></span></span><span class="base"><span class="strut" style="height: 0.6444em"></span><span class="mord">1024</span></span></span></span></span> 尺寸的噪声，然后从中生成图像。这里做一步扩散的计算量就很大，更别说要循环迭代多次直到100%。一个解决方法是将大图片拆分为若干小分辨率的图片进行训练，然后再使用一个额外的神经网络来产生更大分辨率的图像（超分辨率扩散）。</p> 
<p>2021年发布的<a href="https://arxiv.org/abs/2112.10752">Latent Diffusion模型</a>给出了不一样的方法。 Latent Diffusion模型不直接在操作图像，而是在<strong>潜在空间</strong>中进行操作。通过将原始数据编码到更小的空间中，让U-Net可以在低维表示上添加和删除噪声。</p> 
<h3>
<a id="Lantent_Space_72"></a>潜在空间(Lantent Space)</h3> 
<p>潜在空间简单的说是对压缩数据的表示。所谓压缩指的是用比原始表示更小的数位来编码信息的过程。比如我们用一个颜色通道（黑白灰）来表示原来由RGB三原色构成的图片，此时每个像素点的颜色向量由3维变成了1维度。维度降低会丢失一部分信息，然而在某些情况下，降维不是件坏事。通过降维我们可以过滤掉一些不太重要的信息你，只保留最重要的信息。</p> 
<p>假设我们像通过全连接的卷积神经网络训练一个图像分类模型。当我们说模型在学习时，我们的意思是它在学习神经网络每一层的特定属性，比如边缘、角度、形状等……每当模型使用数据（已经存在的图像）学习时，都会将图像的尺寸先减小再恢复到原始尺寸。最后，模型使用解码器从压缩数据中重建图像，同时学习之前的所有相关信息。因此，空间变小，以便提取和保留最重要的属性。这就是潜在空间适用于扩散模型的原因。</p> 
<p><img src="https://images2.imgbox.com/04/49/YgMv6D1a_o.jpg" alt="Extricating the most important attributes by using convolutional neural networks"></p> 
<p><img src="https://images2.imgbox.com/e4/0b/fvbm7tTm_o.jpg" alt="Extricating the most important attributes by using convolutional neural networks"></p> 

 <small>利用卷积神经网络提取最重要的属性</small>
 
<h3>
<a id="Latent_Diffusion_84"></a>Latent Diffusion</h3> 
<p>“潜在扩散模型”（Latent Diffusion Model）将GAN的感知能力、扩散模型的细节保存能力和Transformer的语义能力三者结合，创造出比上述所有模型更稳健和高效的生成模型。与其他方法相比，Latent Diffusion不仅节省了内存，而且生成的图像保持了多样性和高细节度，同时图像还保留了数据的语义结构。</p> 
<p>任何生成性学习方法都有两个主要阶段：<strong>感知压缩</strong>和<strong>语义压缩</strong>。</p> 
<h4>
<a id="_90"></a>感知压缩</h4> 
<p>在感知压缩学习阶段，学习方法必须去除高频细节将数据封装到抽象表示中。此步骤对构建一个稳定、鲁棒的环境表示是必要的。GAN 擅长感知压缩，通过将高维冗余数据从像素空间投影到潜在空间的超空间来实现这一点。潜在空间中的潜在向量是原始像素图像的压缩形式，可以有效地代替原始图像。</p> 
<p>更具体地说，用自动编码器 (Auto Encoder) 结构捕获感知压缩。 自动编码器中的编码器将高维数据投影到潜在空间，解码器从潜在空间恢复图像。</p> 
<p><img src="https://images2.imgbox.com/e4/a9/0nP5dj37_o.jpg" alt="Final Stable diffusion architecture"></p> 

 <small>自动编码器和解码器构成感知压缩</small>

<br> 
<h4>
<a id="_99"></a>语义压缩</h4> 
<p>在学习的第二阶段，图像生成方法必须能够捕获数据中存在的语义结构。 这种概念和语义结构提供了图像中各种对象的上下文和相互关系的保存。 Transformer擅长捕捉文本和图像中的语义结构。 Transformer的泛化能力和扩散模型的细节保存能力相结合，提供了两全其美的方法，并提供了一种生成细粒度的高度细节图像的方法，同时保留图像中的语义结构。</p> 
<h4>
<a id="_103"></a>感知损失</h4> 
<p>潜在扩散模型中的自动编码器通过将数据投影到潜在空间来捕获数据的感知结构。论文作者使用一种特殊的损失函数来训练这种称为“感知损失”的自动编码器。该损失函数确保重建限制在图像流形内，并减少使用像素空间损失（例如 L1/L2 损失）时出现的模糊。</p> 
<h4>
<a id="_107"></a>扩散损失</h4> 
<p>扩散模型通过从正态分布变量中逐步去除噪声来学习数据分布。换句话说，扩散模型使用长度为 <span class="katex--inline"><span class="katex"><span class="katex-mathml">
    
     
      
       
        T
       
      
      
       T
      
     
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6833em"></span><span class="mord mathnormal" style="margin-right: 0.1389em">T</span></span></span></span></span> 的<em>反向马尔可夫链</em>。这也意味着扩散模型可以建模为时间步长为 <span class="katex--inline"><span class="katex"><span class="katex-mathml">
    
     
      
       
        t
       
       
        =
       
       
        1
       
       
        ,
       
       
        …
       
       
        ,
       
       
        T
       
      
      
       t =1,dots,T
      
     
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6151em"></span><span class="mord mathnormal">t</span><span class="mspace" style="margin-right: 0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em"></span></span><span class="base"><span class="strut" style="height: 0.8778em;vertical-align: -0.1944em"></span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em"></span><span class="minner">…</span><span class="mspace" style="margin-right: 0.1667em"></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em"></span><span class="mord mathnormal" style="margin-right: 0.1389em">T</span></span></span></span></span> 的一系列“T”去噪自动编码器。由下方公式中的 <span class="katex--inline"><span class="katex"><span class="katex-mathml">
    
     
      
       
        
         ϵ
        
        
         θ
        
       
      
      
       epsilon_theta
      
     
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.5806em;vertical-align: -0.15em"></span><span class="mord"><span class="mord mathnormal">ϵ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em"><span class="" style="margin-left: 0em;margin-right: 0.05em"><span class="pstrut" style="height: 2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0278em">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em"><span class=""></span></span></span></span></span></span></span></span></span></span>表示：</p> 
<p><span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml">
     
      
       
        
         
         
          
           
            
             L
            
            
             
              D
             
             
              M
             
            
           
           
            =
           
           
            
             E
            
            
             
              x
             
             
              ,
             
             
              ϵ
             
             
              ∼
             
             
              N
             
             
              (
             
             
              0
             
             
              ,
             
             
              1
             
             
              )
             
             
              ,
             
             
              t
             
            
           
           
            [
           
           
            ∣
           
           
            ∣
           
           
            ϵ
           
           
            −
           
           
            
             ϵ
            
            
             θ
            
           
           
            (
           
           
            
             x
            
            
             t
            
           
           
            ,
           
           
            t
           
           
            )
           
           
            ∣
           
           
            
             ∣
            
            
             2
            
            
             2
            
           
           
            ]
           
          
         
         
         
          
           (1)
          
         
        
       
       
         L_{DM} = mathbb{E}_{x, epsilon sim mathcal{N}(0, 1), t} Biglbrack||epsilon-epsilon_theta(x_t, t)||_2^2Bigrbrack tag{1} 
       
      
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8333em;vertical-align: -0.15em"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3283em"><span class="" style="margin-left: 0em;margin-right: 0.05em"><span class="pstrut" style="height: 2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0278em">D</span><span class="mord mathnormal mtight" style="margin-right: 0.109em">M</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em"></span></span><span class="base"><span class="strut" style="height: 1.8em;vertical-align: -0.65em"></span><span class="mord"><span class="mord mathbb">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3448em"><span class="" style="margin-left: 0em;margin-right: 0.05em"><span class="pstrut" style="height: 2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">ϵ</span><span class="mrel mtight">∼</span><span class="mord mathcal mtight" style="margin-right: 0.1474em">N</span><span class="mopen mtight">(</span><span class="mord mtight">0</span><span class="mpunct mtight">,</span><span class="mord mtight">1</span><span class="mclose mtight">)</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.3552em"><span class=""></span></span></span></span></span></span><span class="mord"><span class="delimsizing size2">[</span></span><span class="mord">∣∣</span><span class="mord mathnormal">ϵ</span><span class="mspace" style="margin-right: 0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right: 0.2222em"></span></span><span class="base"><span class="strut" style="height: 1.8em;vertical-align: -0.65em"></span><span class="mord"><span class="mord mathnormal">ϵ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em"><span class="" style="margin-left: 0em;margin-right: 0.05em"><span class="pstrut" style="height: 2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0278em">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em"><span class=""></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.2806em"><span class="" style="margin-left: 0em;margin-right: 0.05em"><span class="pstrut" style="height: 2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em"></span><span class="mord mathnormal">t</span><span class="mclose">)</span><span class="mord">∣</span><span class="mord"><span class="mord">∣</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.8641em"><span class="" style="margin-left: 0em;margin-right: 0.05em"><span class="pstrut" style="height: 2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span><span class="" style="margin-right: 0.05em"><span class="pstrut" style="height: 2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.247em"><span class=""></span></span></span></span></span></span><span class="mord"><span class="delimsizing size2">]</span></span></span><span class="tag"><span class="strut" style="height: 1.8em;vertical-align: -0.65em"></span><span class="mord text"><span class="mord">(</span><span class="mord"><span class="mord">1</span></span><span class="mord">)</span></span></span></span></span></span></span></p> 
<p>公式(1)给出了扩散模型的损失函数。在潜在扩散模型中，损失函数取决于潜在向量而不是像素空间。我们将像素空间元素<span class="katex--inline"><span class="katex"><span class="katex-mathml">
    
     
      
       
        x
       
      
      
       x
      
     
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.4306em"></span><span class="mord mathnormal">x</span></span></span></span></span>替换成潜在向量<span class="katex--inline"><span class="katex"><span class="katex-mathml">
    
     
      
       
        ε
       
       
        (
       
       
        x
       
       
        )
       
      
      
       varepsilon(x)
      
     
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em;vertical-align: -0.25em"></span><span class="mord mathnormal">ε</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span></span></span></span></span>，将t时间的状态<span class="katex--inline"><span class="katex"><span class="katex-mathml">
    
     
      
       
        
         x
        
        
         t
        
       
      
      
       x_t
      
     
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.5806em;vertical-align: -0.15em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.2806em"><span class="" style="margin-left: 0em;margin-right: 0.05em"><span class="pstrut" style="height: 2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em"><span class=""></span></span></span></span></span></span></span></span></span></span>替换为去噪U-Net在时间t的潜在状态<span class="katex--inline"><span class="katex"><span class="katex-mathml">
    
     
      
       
        
         z
        
        
         t
        
       
      
      
       z_t
      
     
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.5806em;vertical-align: -0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.044em">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.2806em"><span class="" style="margin-left: -0.044em;margin-right: 0.05em"><span class="pstrut" style="height: 2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em"><span class=""></span></span></span></span></span></span></span></span></span></span>，即可得到潜在扩散模型的损失函数，见公式(2)：</p> 
<p><span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml">
     
      
       
        
         
         
          
           
            
             L
            
            
             
              L
             
             
              D
             
             
              M
             
            
           
           
            :
           
           
            =
           
           
            
             E
            
            
             
              ε
             
             
              (
             
             
              x
             
             
              )
             
             
              ,
             
             
              ϵ
             
             
              ∼
             
             
              N
             
             
              (
             
             
              0
             
             
              ,
             
             
              1
             
             
              )
             
             
              ,
             
             
              t
             
            
           
           
            [
           
           
            ∣
           
           
            ∣
           
           
            ϵ
           
           
            −
           
           
            
             ϵ
            
            
             θ
            
           
           
            (
           
           
            
             z
            
            
             t
            
           
           
            ,
           
           
            t
           
           
            )
           
           
            ∣
           
           
            
             ∣
            
            
             2
            
            
             2
            
           
           
            ]
           
          
         
         
         
          
           (2)
          
         
        
       
       
         L_{LDM} := mathbb{E}_{varepsilon(x), epsilonsim mathcal{N}(0, 1), t} Biglbrack||epsilon-epsilon_theta(z_t, t)||_2^2Bigrbrack tag{2} 
       
      
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8333em;vertical-align: -0.15em"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3283em"><span class="" style="margin-left: 0em;margin-right: 0.05em"><span class="pstrut" style="height: 2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">L</span><span class="mord mathnormal mtight" style="margin-right: 0.0278em">D</span><span class="mord mathnormal mtight" style="margin-right: 0.109em">M</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2778em"></span><span class="mrel">:=</span><span class="mspace" style="margin-right: 0.2778em"></span></span><span class="base"><span class="strut" style="height: 1.8em;vertical-align: -0.65em"></span><span class="mord"><span class="mord mathbb">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3448em"><span class="" style="margin-left: 0em;margin-right: 0.05em"><span class="pstrut" style="height: 2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">ε</span><span class="mopen mtight">(</span><span class="mord mathnormal mtight">x</span><span class="mclose mtight">)</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">ϵ</span><span class="mrel mtight">∼</span><span class="mord mathcal mtight" style="margin-right: 0.1474em">N</span><span class="mopen mtight">(</span><span class="mord mtight">0</span><span class="mpunct mtight">,</span><span class="mord mtight">1</span><span class="mclose mtight">)</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.3552em"><span class=""></span></span></span></span></span></span><span class="mord"><span class="delimsizing size2">[</span></span><span class="mord">∣∣</span><span class="mord mathnormal">ϵ</span><span class="mspace" style="margin-right: 0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right: 0.2222em"></span></span><span class="base"><span class="strut" style="height: 1.8em;vertical-align: -0.65em"></span><span class="mord"><span class="mord mathnormal">ϵ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em"><span class="" style="margin-left: 0em;margin-right: 0.05em"><span class="pstrut" style="height: 2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0278em">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em"><span class=""></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.044em">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.2806em"><span class="" style="margin-left: -0.044em;margin-right: 0.05em"><span class="pstrut" style="height: 2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em"></span><span class="mord mathnormal">t</span><span class="mclose">)</span><span class="mord">∣</span><span class="mord"><span class="mord">∣</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.8641em"><span class="" style="margin-left: 0em;margin-right: 0.05em"><span class="pstrut" style="height: 2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span><span class="" style="margin-right: 0.05em"><span class="pstrut" style="height: 2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.247em"><span class=""></span></span></span></span></span></span><span class="mord"><span class="delimsizing size2">]</span></span></span><span class="tag"><span class="strut" style="height: 1.8em;vertical-align: -0.65em"></span><span class="mord text"><span class="mord">(</span><span class="mord"><span class="mord">2</span></span><span class="mord">)</span></span></span></span></span></span></span></p> 
<p>将公式(2)写成条件损失函数，得到公式(3)：</p> 
<p><span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml">
     
      
       
        
         
         
          
           
            
             L
            
            
             
              L
             
             
              D
             
             
              M
             
            
           
           
            :
           
           
            =
           
           
            
             E
            
            
             
              ε
             
             
              (
             
             
              x
             
             
              )
             
             
              ,
             
             
              y
             
             
              ,
             
             
              ϵ
             
             
              ∼
             
             
              N
             
             
              (
             
             
              0
             
             
              ,
             
             
              1
             
             
              )
             
             
              ,
             
             
              t
             
            
           
           
            [
           
           
            ∣
           
           
            ∣
           
           
            ϵ
           
           
            −
           
           
            
             ϵ
            
            
             θ
            
           
           
            (
           
           
            
             z
            
            
             t
            
           
           
            ,
           
           
            t
           
           
            )
           
           
            ,
           
           
            
             τ
            
            
             θ
            
           
           
            (
           
           
            y
           
           
            )
           
           
            ∣
           
           
            
             ∣
            
            
             2
            
            
             2
            
           
           
            ]
           
          
         
         
         
          
           (3)
          
         
        
       
       
         L_{LDM} := mathbb{E}_{varepsilon(x), y, epsilonsim mathcal{N}(0, 1), t} Biglbrack||epsilon-epsilon_theta(z_t, t),tau_theta(y)||_2^2 Bigrbrack tag{3} 
       
      
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8333em;vertical-align: -0.15em"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3283em"><span class="" style="margin-left: 0em;margin-right: 0.05em"><span class="pstrut" style="height: 2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">L</span><span class="mord mathnormal mtight" style="margin-right: 0.0278em">D</span><span class="mord mathnormal mtight" style="margin-right: 0.109em">M</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2778em"></span><span class="mrel">:=</span><span class="mspace" style="margin-right: 0.2778em"></span></span><span class="base"><span class="strut" style="height: 1.8em;vertical-align: -0.65em"></span><span class="mord"><span class="mord mathbb">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3448em"><span class="" style="margin-left: 0em;margin-right: 0.05em"><span class="pstrut" style="height: 2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">ε</span><span class="mopen mtight">(</span><span class="mord mathnormal mtight">x</span><span class="mclose mtight">)</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right: 0.0359em">y</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">ϵ</span><span class="mrel mtight">∼</span><span class="mord mathcal mtight" style="margin-right: 0.1474em">N</span><span class="mopen mtight">(</span><span class="mord mtight">0</span><span class="mpunct mtight">,</span><span class="mord mtight">1</span><span class="mclose mtight">)</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.3552em"><span class=""></span></span></span></span></span></span><span class="mord"><span class="delimsizing size2">[</span></span><span class="mord">∣∣</span><span class="mord mathnormal">ϵ</span><span class="mspace" style="margin-right: 0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right: 0.2222em"></span></span><span class="base"><span class="strut" style="height: 1.8em;vertical-align: -0.65em"></span><span class="mord"><span class="mord mathnormal">ϵ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em"><span class="" style="margin-left: 0em;margin-right: 0.05em"><span class="pstrut" style="height: 2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0278em">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em"><span class=""></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.044em">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.2806em"><span class="" style="margin-left: -0.044em;margin-right: 0.05em"><span class="pstrut" style="height: 2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em"></span><span class="mord mathnormal">t</span><span class="mclose">)</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.1132em">τ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em"><span class="" style="margin-left: -0.1132em;margin-right: 0.05em"><span class="pstrut" style="height: 2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0278em">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em"><span class=""></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right: 0.0359em">y</span><span class="mclose">)</span><span class="mord">∣</span><span class="mord"><span class="mord">∣</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.8641em"><span class="" style="margin-left: 0em;margin-right: 0.05em"><span class="pstrut" style="height: 2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span><span class="" style="margin-right: 0.05em"><span class="pstrut" style="height: 2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.247em"><span class=""></span></span></span></span></span></span><span class="mord"><span class="delimsizing size2">]</span></span></span><span class="tag"><span class="strut" style="height: 1.8em;vertical-align: -0.65em"></span><span class="mord text"><span class="mord">(</span><span class="mord"><span class="mord">3</span></span><span class="mord">)</span></span></span></span></span></span></span></p> 
<p>其中<span class="katex--inline"><span class="katex"><span class="katex-mathml">
    
     
      
       
        
         τ
        
        
         θ
        
       
       
        (
       
       
        y
       
       
        )
       
      
      
       tau_theta(y)
      
     
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em;vertical-align: -0.25em"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.1132em">τ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em"><span class="" style="margin-left: -0.1132em;margin-right: 0.05em"><span class="pstrut" style="height: 2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0278em">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em"><span class=""></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right: 0.0359em">y</span><span class="mclose">)</span></span></span></span></span>是条件<span class="katex--inline"><span class="katex"><span class="katex-mathml">
    
     
      
       
        y
       
      
      
       y
      
     
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.625em;vertical-align: -0.1944em"></span><span class="mord mathnormal" style="margin-right: 0.0359em">y</span></span></span></span></span>下的领域专用编码器（比如Transformer）。</p> 
<h4>
<a id="_129"></a>条件扩散</h4> 
<p>扩散模型是依赖于先验的条件模型。在图像生成任务中，先验通常是文本、图像或语义图。为了获得先验的潜在表示，需要使用转换器（例如 CLIP）将文本/图像嵌入到潜在向量<span class="katex--inline"><span class="katex"><span class="katex-mathml">
    
     
      
       
        τ
       
      
      
       tau
      
     
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.4306em"></span><span class="mord mathnormal" style="margin-right: 0.1132em">τ</span></span></span></span></span>中。因此，最终的损失函数不仅取决于原始图像的潜在空间，还取决于条件的潜在嵌入。</p> 
<h4>
<a id="_133"></a>注意力机制</h4> 
<p>潜在扩散模型的主干是具有稀疏连接的 U-Net 自动编码器，提供交叉注意力机制<sup class="footnote-ref"><a href="#fn2" id="fnref2">2</a></sup>。Transformer 网络将条件文本/图像编码为潜在嵌入，后者又通过交叉注意力层映射到 U-Net 的中间层。这个交叉注意力层实现了注意力 <span class="katex--inline"><span class="katex"><span class="katex-mathml">
    
     
      
       
        (
       
       
        Q
       
       
        ,
       
       
        K
       
       
        ,
       
       
        V
       
       
        )
       
       
        =
       
       
        s
       
       
        o
       
       
        f
       
       
        t
       
       
        m
       
       
        a
       
       
        x
       
       
        (
       
       
        Q
       
       
        K
       
       
        T
       
       
        /
       
       
        
         d
        
       
       
        )
       
       
        V
       
      
      
       (Q,K,V) = softmax(QKT/sqrt{d}) V
      
     
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em;vertical-align: -0.25em"></span><span class="mopen">(</span><span class="mord mathnormal">Q</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em"></span><span class="mord mathnormal" style="margin-right: 0.0715em">K</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em"></span><span class="mord mathnormal" style="margin-right: 0.2222em">V</span><span class="mclose">)</span><span class="mspace" style="margin-right: 0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em"></span></span><span class="base"><span class="strut" style="height: 1.1822em;vertical-align: -0.25em"></span><span class="mord mathnormal">so</span><span class="mord mathnormal" style="margin-right: 0.1076em">f</span><span class="mord mathnormal">t</span><span class="mord mathnormal">ma</span><span class="mord mathnormal">x</span><span class="mopen">(</span><span class="mord mathnormal">Q</span><span class="mord mathnormal" style="margin-right: 0.0715em">K</span><span class="mord mathnormal" style="margin-right: 0.1389em">T</span><span class="mord">/</span><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.9322em"><span class="svg-align"><span class="pstrut" style="height: 3em"></span><span class="mord" style="padding-left: 0.833em"><span class="mord mathnormal">d</span></span></span><span class=""><span class="pstrut" style="height: 3em"></span><span class="hide-tail" style="min-width: 0.853em;height: 1.08em">
           
            
           </span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.1078em"><span class=""></span></span></span></span></span><span class="mclose">)</span><span class="mord mathnormal" style="margin-right: 0.2222em">V</span></span></span></span></span>，其中 Q、K 和 V 是可学习的投影矩阵</p> 
<h4>
<a id="_137"></a>文本-图像合成</h4> 
<p>在 Python 实现中，我们可以使用使用 LDM v4 的最新官方实现来生成图像。 在文本到图像的合成中，潜在扩散模型使用预训练的 CLIP 模型<sup class="footnote-ref"><a href="#fn3" id="fnref3">3</a></sup>，该模型为文本和图像等多种模态提供基于Transformer的通用嵌入。 然后将Transformer模型的输出输入到称为“diffusers”的潜在扩散模型Python API，同时还可以设置一些参数（例如，扩散步数、随机数种子、图像大小等）。</p> 
<h4>
<a id="_141"></a>图像-图像合成</h4> 
<p>相同的方法同样适用于图像到图像的合成，不同的是需要输入样本图像作为参考图像。生成的图像在语义和视觉上与作为参考给出的图像相似。这个过程在概念上类似于基于样式的 GAN 模型，但它在保留图像的语义结构方面做得更好。</p> 
<h3>
<a id="_145"></a>整体架构</h3> 
<p>上面介绍了潜在扩散模型的各个主要技术部分，下面我们将它们合成一个整理，看一下潜在扩散模型的完整工作流程。</p> 
<p><img src="https://images2.imgbox.com/32/fd/18BqQEE5_o.png" alt="在这里插入图片描述"></p> 

 <small>潜在扩散模型的架构（图片来源：Rombach &amp; Blattmann, et al. 2022）</small>

<br> 
<p>上图中 <span class="katex--inline"><span class="katex"><span class="katex-mathml">
    
     
      
       
        x
       
      
      
       x
      
     
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.4306em"></span><span class="mord mathnormal">x</span></span></span></span></span> 表示输入图像，<span class="katex--inline"><span class="katex"><span class="katex-mathml">
    
     
      
       
        
         x
        
        
         ~
        
       
      
      
       tilde{x}
      
     
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6679em"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.6679em"><span class=""><span class="pstrut" style="height: 3em"></span><span class="mord mathnormal">x</span></span><span class=""><span class="pstrut" style="height: 3em"></span><span class="accent-body"><span class="mord">~</span></span></span></span></span></span></span></span></span></span></span> 表示生成的图像；<span class="katex--inline"><span class="katex"><span class="katex-mathml">
    
     
      
       
        ε
       
      
      
       varepsilon
      
     
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.4306em"></span><span class="mord mathnormal">ε</span></span></span></span></span> 是编码器，<span class="katex--inline"><span class="katex"><span class="katex-mathml">
    
     
      
       
        D
       
      
      
       cal{D}
      
     
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6833em"></span><span class="mord"><span class="mord"><span class="mord mathcal" style="margin-right: 0.0278em">D</span></span></span></span></span></span></span> 是解码器，二者共同构成了感知压缩；<span class="katex--inline"><span class="katex"><span class="katex-mathml">
    
     
      
       
        z
       
      
      
       z
      
     
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.4306em"></span><span class="mord mathnormal" style="margin-right: 0.044em">z</span></span></span></span></span> 是潜在向量；<span class="katex--inline"><span class="katex"><span class="katex-mathml">
    
     
      
       
        
         z
        
        
         T
        
       
      
      
       z_T
      
     
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.5806em;vertical-align: -0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.044em">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3283em"><span class="" style="margin-left: -0.044em;margin-right: 0.05em"><span class="pstrut" style="height: 2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.1389em">T</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em"><span class=""></span></span></span></span></span></span></span></span></span></span> 是增加噪声后的潜在向量；<span class="katex--inline"><span class="katex"><span class="katex-mathml">
    
     
      
       
        
         τ
        
        
         θ
        
       
      
      
       tau_theta
      
     
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.5806em;vertical-align: -0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.1132em">τ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em"><span class="" style="margin-left: -0.1132em;margin-right: 0.05em"><span class="pstrut" style="height: 2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0278em">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em"><span class=""></span></span></span></span></span></span></span></span></span></span> 是文本/图像的编码器（比如Transformer或CLIP），实现了语义压缩。</p> 
<h2>
<a id="_155"></a>总结</h2> 
<p>本文向大家介绍了图像生成领域最前沿的Stable Diffusion模型。本质上Stable Diffusion属于潜在扩散模型(Latent Diffusion Model)。潜在扩散模型在生成细节丰富的不同背景的高分辨率图像方面非常稳健，同时还保留了图像的语义结构。 因此，潜在扩散模型是图像生成即深度学习领域的一项重大进步。 Stable Diffusion只是将潜在扩散模型应用于高分辨率图像，同时使用 CLIP 作为文本编码器。</p> 
<p>说了这么多理论，想必大家已经迫不及待跃跃欲试了。别着急，后面我会手把手教大家搭建Stable Diffusion本地环境，让大家可以亲手体验Stable Diffusion的威力。<br> <img src="https://images2.imgbox.com/b7/88/ab56ovOF_o.png" alt="在这里插入图片描述"></p> 
<hr class="footnotes-sep"> 
<section class="footnotes"> 
 <ol class="footnotes-list">
<li id="fn1" class="footnote-item">
<p>Jonathan Ho, Ajay Jain, Pieter Abbeel, “<a href="https://arxiv.org/abs/2006.11239">Denoising Diffusion Probabilistic Models</a>”, 2020 <a href="#fnref1" class="footnote-backref">↩︎</a></p> </li>
<li id="fn2" class="footnote-item">
<p>Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin, “<a href="https://arxiv.org/abs/1706.03762">Attention Is All You Need</a>”, 2017 <a href="#fnref2" class="footnote-backref">↩︎</a></p> </li>
<li id="fn3" class="footnote-item">
<p>Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, Gretchen Krueger, Ilya Sutskever, “<a href="https://arxiv.org/abs/2103.00020">Learning Transferable Visual Models From Natural Language Supervision</a>”, 2021 <a href="#fnref3" class="footnote-backref">↩︎</a></p> </li>
</ol> 
</section>
                </div>
                
                

		</div>
	</article>
</main>




			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程小白.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://www.w3counter.com/tracker.js?id=150625"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>
	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>