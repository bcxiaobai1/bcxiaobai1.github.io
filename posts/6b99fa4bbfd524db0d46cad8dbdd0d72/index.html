<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<title>（超详细）快速上手分布式数据库——HBase - 编程小白</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程小白" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程小白</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">（超详细）快速上手分布式数据库——HBase</h1>
			
		</header>
		<div class="content post__content clearfix">
			


                <div id="content_views" class="htmledit_views">
                    <h1 id="HBase%E7%9A%84%E5%AE%89%E8%A3%85%E3%80%81%E5%91%BD%E4%BB%A4%E6%93%8D%E4%BD%9C%E5%92%8C%E5%9F%BA%E7%A1%80%E7%BC%96%E7%A8%8B">HBase的安装、命令操作和基础编程</h1> 
<p> <em>JunLeon——go big or go home</em></p> 
<hr>
<p style="text-align:center"><img alt="" src="https://images2.imgbox.com/e1/f0/F2hVN6Ah_o.jpg"></p> 
<p id="main-toc"><strong>目录</strong></p> 
<p id="HBase%E7%9A%84%E5%AE%89%E8%A3%85%E3%80%81%E5%91%BD%E4%BB%A4%E6%93%8D%E4%BD%9C%E5%92%8C%E5%9F%BA%E7%A1%80%E7%BC%96%E7%A8%8B-toc" style="margin-left:0px"><a href="#HBase%E7%9A%84%E5%AE%89%E8%A3%85%E3%80%81%E5%91%BD%E4%BB%A4%E6%93%8D%E4%BD%9C%E5%92%8C%E5%9F%BA%E7%A1%80%E7%BC%96%E7%A8%8B" title="HBase的安装、命令操作和基础编程">HBase的安装、命令操作和基础编程</a></p> 
<p id="%E4%B8%80%E3%80%81HBase%E7%9A%84%E6%A6%82%E8%BF%B0-toc" style="margin-left:0px"><a href="#%E4%B8%80%E3%80%81HBase%E7%9A%84%E6%A6%82%E8%BF%B0" title="一、HBase的概述">一、HBase的概述</a></p> 
<p id="1.%E4%BB%80%E4%B9%88%E6%98%AFHBase%EF%BC%9F-toc" style="margin-left:40px"><a href="#1.%E4%BB%80%E4%B9%88%E6%98%AFHBase%EF%BC%9F" title="1.什么是HBase？">1.什么是HBase？</a></p> 
<p id="2.HBase%E7%9A%84%E7%89%B9%E7%82%B9-toc" style="margin-left:40px"><a href="#2.HBase%E7%9A%84%E7%89%B9%E7%82%B9" title="2.HBase的特点">2.HBase的特点</a></p> 
<p id="3.HBase%E7%BB%84%E6%88%90%E9%83%A8%E5%88%86%E5%8F%8A%E6%95%B0%E6%8D%AE%E6%A8%A1%E5%9E%8B-toc" style="margin-left:40px"><a href="#3.HBase%E7%BB%84%E6%88%90%E9%83%A8%E5%88%86%E5%8F%8A%E6%95%B0%E6%8D%AE%E6%A8%A1%E5%9E%8B" title="3.HBase组成部分及数据模型">3.HBase组成部分及数据模型</a></p> 
<p id="%EF%BC%881%EF%BC%89HBase%E6%9E%B6%E6%9E%84%E7%9A%84%E7%BB%84%E4%BB%B6%E5%8F%8A%E5%85%B6%E4%BD%9C%E7%94%A8-toc" style="margin-left:80px"><a href="#%EF%BC%881%EF%BC%89HBase%E6%9E%B6%E6%9E%84%E7%9A%84%E7%BB%84%E4%BB%B6%E5%8F%8A%E5%85%B6%E4%BD%9C%E7%94%A8" title="（1）HBase架构的组件及其作用">（1）HBase架构的组件及其作用</a></p> 
<p id="%EF%BC%882%EF%BC%89HBase%E7%9A%84%E6%95%B0%E6%8D%AE%E6%A8%A1%E5%9E%8B-toc" style="margin-left:80px"><a href="#%EF%BC%882%EF%BC%89HBase%E7%9A%84%E6%95%B0%E6%8D%AE%E6%A8%A1%E5%9E%8B" title="（2）HBase的数据模型">（2）HBase的数据模型</a></p> 
<p id="%EF%BC%883%EF%BC%89%E8%A1%A8%E5%92%8CRegion-toc" style="margin-left:80px"><a href="#%EF%BC%883%EF%BC%89%E8%A1%A8%E5%92%8CRegion" title="（3）表和Region">（3）表和Region</a></p> 
<p id="4.HBase%E7%9A%84%E8%AF%BB%E5%86%99%E6%B5%81%E7%A8%8B-toc" style="margin-left:40px"><a href="#4.HBase%E7%9A%84%E8%AF%BB%E5%86%99%E6%B5%81%E7%A8%8B" title="4.HBase的读写流程">4.HBase的读写流程</a></p> 
<p id="5.HBase%E7%9A%84Compaction%E8%BF%87%E7%A8%8B-toc" style="margin-left:40px"><a href="#5.HBase%E7%9A%84Compaction%E8%BF%87%E7%A8%8B" title="5.HBase的Compaction过程">5.HBase的Compaction过程</a></p> 
<p id="%E4%BA%8C%E3%80%81%E5%9F%BA%E4%BA%8EHadoop%20HA%E9%9B%86%E7%BE%A4%E7%9A%84HBase%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE-toc" style="margin-left:0px"><a href="#%E4%BA%8C%E3%80%81%E5%9F%BA%E4%BA%8EHadoop%20HA%E9%9B%86%E7%BE%A4%E7%9A%84HBase%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE" title="二、基于Hadoop HA集群的HBase环境安装配置">二、基于Hadoop HA集群的HBase环境安装配置</a></p> 
<p id="1.%E4%B8%8B%E8%BD%BDHBase-toc" style="margin-left:40px"><a href="#1.%E4%B8%8B%E8%BD%BDHBase" title="1.下载HBase">1.下载HBase</a></p> 
<p id="2.%E8%A7%A3%E5%8E%8B%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE-toc" style="margin-left:40px"><a href="#2.%E8%A7%A3%E5%8E%8B%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE" title="2.解压安装配置">2.解压安装配置</a></p> 
<p id="%EF%BC%881%EF%BC%89%E4%B8%8A%E4%BC%A0%E5%88%B0%E8%99%9A%E6%8B%9F%E6%9C%BA%E4%B8%AD%E6%8C%87%E5%AE%9A%E7%9A%84opt%E7%9B%AE%E5%BD%95%E4%B8%8B-toc" style="margin-left:80px"><a href="#%EF%BC%881%EF%BC%89%E4%B8%8A%E4%BC%A0%E5%88%B0%E8%99%9A%E6%8B%9F%E6%9C%BA%E4%B8%AD%E6%8C%87%E5%AE%9A%E7%9A%84opt%E7%9B%AE%E5%BD%95%E4%B8%8B" title="（1）上传到虚拟机中指定的opt目录下">（1）上传到虚拟机中指定的opt目录下</a></p> 
<p id="%EF%BC%882%EF%BC%89%E8%A7%A3%E5%8E%8BHBase-toc" style="margin-left:80px"><a href="#%EF%BC%882%EF%BC%89%E8%A7%A3%E5%8E%8BHBase" title="（2）解压HBase">（2）解压HBase</a></p> 
<p id="%EF%BC%883%EF%BC%89%E9%85%8D%E7%BD%AE%E7%8E%AF%E5%A2%83%E5%8F%8A%E5%85%B6%E7%9B%B8%E5%85%B3%E5%B1%9E%E6%80%A7-toc" style="margin-left:80px"><a href="#%EF%BC%883%EF%BC%89%E9%85%8D%E7%BD%AE%E7%8E%AF%E5%A2%83%E5%8F%8A%E5%85%B6%E7%9B%B8%E5%85%B3%E5%B1%9E%E6%80%A7" title="（3）配置环境及其相关属性">（3）配置环境及其相关属性</a></p> 
<p id="3.%E5%90%AF%E5%8A%A8HBase%E9%9B%86%E7%BE%A4-toc" style="margin-left:40px"><a href="#3.%E5%90%AF%E5%8A%A8HBase%E9%9B%86%E7%BE%A4" title="3.启动HBase集群">3.启动HBase集群</a></p> 
<p id="4.%E6%9F%A5%E7%9C%8B%E8%BF%9B%E7%A8%8B%E5%8F%8AHBase%E9%9B%86%E7%BE%A4%E4%BF%A1%E6%81%AF-toc" style="margin-left:40px"><a href="#4.%E6%9F%A5%E7%9C%8B%E8%BF%9B%E7%A8%8B%E5%8F%8AHBase%E9%9B%86%E7%BE%A4%E4%BF%A1%E6%81%AF" title="4.查看进程及HBase集群信息">4.查看进程及HBase集群信息</a></p> 
<p id="%E4%B8%89%E3%80%81HBase%E7%9A%84Shell%E5%91%BD%E4%BB%A4-toc" style="margin-left:0px"><a href="#%E4%B8%89%E3%80%81HBase%E7%9A%84Shell%E5%91%BD%E4%BB%A4" title="三、HBase的Shell命令">三、HBase的Shell命令</a></p> 
<p id="1.%E5%9F%BA%E6%9C%ACShell%E5%91%BD%E4%BB%A4-toc" style="margin-left:40px"><a href="#1.%E5%9F%BA%E6%9C%ACShell%E5%91%BD%E4%BB%A4" title="1.基本Shell命令">1.基本Shell命令</a></p> 
<p id="2.DDL%E6%93%8D%E4%BD%9C%E5%91%BD%E4%BB%A4-toc" style="margin-left:40px"><a href="#2.DDL%E6%93%8D%E4%BD%9C%E5%91%BD%E4%BB%A4" title="2.DDL操作命令">2.DDL操作命令</a></p> 
<p id="3.DML%E6%93%8D%E4%BD%9C%E5%91%BD%E4%BB%A4-toc" style="margin-left:40px"><a href="#3.DML%E6%93%8D%E4%BD%9C%E5%91%BD%E4%BB%A4" title="3.DML操作命令">3.DML操作命令</a></p> 
<p id="4.%E8%BF%90%E8%A1%8CHBase%20Shell%E8%84%9A%E6%9C%AC-toc" style="margin-left:40px"><a href="#4.%E8%BF%90%E8%A1%8CHBase%20Shell%E8%84%9A%E6%9C%AC" title="4.运行HBase Shell脚本">4.运行HBase Shell脚本</a></p> 
<p id="%E5%9B%9B%E3%80%81HBase%E5%9F%BA%E7%A1%80%E7%BC%96%E7%A8%8B-toc" style="margin-left:0px"><a href="#%E5%9B%9B%E3%80%81HBase%E5%9F%BA%E7%A1%80%E7%BC%96%E7%A8%8B" title="四、HBase基础编程">四、HBase基础编程</a></p> 
<p id="1.HBase%20API-toc" style="margin-left:40px"><a href="#1.HBase%20API" title="1.HBase API">1.HBase API</a></p> 
<p id="2.HBase%20API%E7%BC%96%E7%A8%8B%E4%BB%A3%E7%A0%81%E6%BC%94%E7%A4%BA-toc" style="margin-left:40px"><a href="#2.HBase%20API%E7%BC%96%E7%A8%8B%E4%BB%A3%E7%A0%81%E6%BC%94%E7%A4%BA" title="2.HBase API编程代码演示">2.HBase API编程代码演示</a></p> 
<hr id="hr-toc">
<p></p> 
<p><strong>前言：</strong></p> 
<p>        学习HBase这个组件，可能很多人都有这个这个疑惑：HDFS和MySQL等都可做数据的持久化存储，那为什么还要学习这个HBase呢？而HBase的最终数据还是存储在HDFS中，那为什么还要使用HBase呢？HBase和HDFS又有什么关系呢？</p> 
<p>        HBase作为Hadoop的分布式数据库，基于Google发行的三篇论文之一——《BigData》研发的Hadoop生态组件之一。那我们为啥要用HBase呢？HBase在HDFS之上提供了<strong>高并发的随机写</strong>和<strong>支持实时查询</strong>，这是HDFS不具备的。</p> 
<p>        HDFS是分布式文件存储系统，HBase是分布式数据库，两者其实没有什么可比性。可能很多人对MySQL比较熟悉，MySQL的数据持久化就是将数据落地磁盘存储。简单理解就是可以把HBase当做是MySQL，把HDFS当做是硬盘。HBase只是一个NoSQL数据库，把数据存在HDFS上。</p> 
<h1 id="%E4%B8%80%E3%80%81HBase%E7%9A%84%E6%A6%82%E8%BF%B0">一、HBase的概述</h1> 
<h2 id="1.%E4%BB%80%E4%B9%88%E6%98%AFHBase%EF%BC%9F">1.什么是HBase？</h2> 
<p style="margin-left:.0001pt;text-align:justify">        HBase是高可靠性、高性能、面向列、可伸缩的分布式存储系统，是基于HDFS的分布式数据库，也是一种非关系型数据库。分布式数据库HBase是Hadoop生态系统的组件之一。HBase的运行依赖于Hadoop HDFS文件系统提供数据的持久化，依赖于Zookeeper提供集群的的同步与协调。HBase使用Zookeeper服务来进行节点管理以及表数据的定位。</p> 
<h2 id="2.HBase%E7%9A%84%E7%89%B9%E7%82%B9">2.HBase的特点</h2> 
<p>        (1)大：一个表可以有上亿行，上百万列。<br>         (2)面向列：面向列表（簇）的存储和权限控制，列（簇）独立检索。<br>         (3)稀疏：对于为空（NULL）的列，并不占用存储空间，因此，表可以设计的非常稀疏。<br>         (4)无模式：每一行都有一个可以排序的主键和任意多的列，列可以根据需要动态增加，同一张表中不同的行可以有截然不同的列。<br>         (5)数据多版本：每个单元中的数据可以有多个版本，默认情况下，版本号自动分配，版本号就是单元格插入时的时间戳。<br>         (6)数据类型单一：HBase中的数据都是字符串，没有类型。</p> 
<h2 id="3.HBase%E7%BB%84%E6%88%90%E9%83%A8%E5%88%86%E5%8F%8A%E6%95%B0%E6%8D%AE%E6%A8%A1%E5%9E%8B">3.HBase组成部分及数据模型</h2> 
<h3 id="%EF%BC%881%EF%BC%89HBase%E6%9E%B6%E6%9E%84%E7%9A%84%E7%BB%84%E4%BB%B6%E5%8F%8A%E5%85%B6%E4%BD%9C%E7%94%A8">（1）HBase架构的组件及其作用</h3> 
<p style="margin-left:.0001pt;text-align:justify">        HBase采用Master/slaves的主从服务器架构，由一个HMaster服务器和多个HRegionServer服务器组成。HBase采用Master/Slave架构，主要角色包括Master服务器（HMaster，管理节点）、Region服务器（HRegionServer，数据节点）、ZooKeeper服务器以及客户端。</p> 
<p style="margin-left:.0001pt;text-align:center"><img alt="" src="https://images2.imgbox.com/f1/8d/fY6NYAYW_o.jpg"></p> 
<p> 1．HMaster HMaster</p> 
<p>        HMaster HMaster是主节点，它主要负责HRegionServer的管理以及元数据的更改，包括以下内容：新HRegionServer的注册、表的增删改查、HRegionServer的负载均衡，Region（表的分区，存储在Region服务器上）的分布调整、Region分裂以及分裂后的Region分配,HRegionServer失效后的Region迁移等。</p> 
<p>        HMaster采用主备模式部署，集群启动时，通过竞争获得主HMaster角色。主HMaster只能有一个，备HMaster进程在集群运行期间处于休眠状态，不干涉任何集群事务。当主用Master故障时，备用Master将取代主用Master对外提供服务。</p> 
<p>2．HRegionServer</p> 
<p>        HRegionServer是HBase的从节点，它负责提供表数据读写等服务，是数据存储和计算单元。HRegionServer一般与HDFS集群的DataNode部署在一起，实现数据的存储功能。一台HRegionServer管理多个Region对象和一个HLog文件。</p> 
<p>        一个Region由一个或多个Store组成。每个Store存储该Region一个列族的数据。一个Store包含一个MemStore缓存以及若干StoreFile文件，MemStore缓存客户端向Region插入的数据，当HRegionServer中的MemStore大小达到配置的容量上限时，RegionServer会将MemStore中的数据刷新（Flush）到HDFS中。MemStore的数据刷新到HDFS后成为HFile，HFile定义了StoreFile在文件系统中的存储格式，它是当前HBase系统中StoreFile的具体实现。随着数据的插入，一个Store会产生多个StoreFile，当StoreFile的个数达到配置的最大值时，RegionServer会将多个StoreFile合并为一个大的StoreFile。</p> 
<p>        HLog日志是一种预写式日志（Write Ahead Log），用户更新数据时需要先写入HLog再写入MemStore，MemStore中的数据被刷新到StoreFile之后才会在HLog中清除对应的记录，这样的设计保证了当HRegionServer故障时，用户写入的数据不丢失，一台HRegionServer的所有Region共享同一个HLog。</p> 
<p>3．ZooKeeper</p> 
<p>        ZooKeeper为HBase集群各进程提供分布式协作服务。各HRegionServer将自己的信息注册到ZooKeeper中，HMaster据此感知各个HRegionServer的健康状态。</p> 
<p>        HBase还通过ZooKeeper实现HMaster的高可用。ZooKeeper存储HBase的如下信息：HBase元数据、HMaster地址。当HMaster主节点出现故障时，HMaster备用节点会通过ZooKeeper获取主HMaster存储的整个HBase集群状态信息，接管HMaster主节点的工作。</p> 
<p>4．Client</p> 
<p>        客户端通过HBase的元数据找到所需数据所在的HRegionServer进行访问（HBase的元数据存储在ZooKeeper中，因此客户端在做读取操作时不需要与HMaster进行通信，这样的设计减少了HMaster的负担），客户端会在缓存中维护访问过的Region位置信息，下次访问时就可以跳过向ZooKeeper寻址的过程。如果缓存中位置信息所指向的HRegionServer失效或Region已被迁移到其他服务器，客户端在查找不到该Region的情况下，会重新查询元数据以获取该Region的新地址。除了读取HRegionServer的信息外，客户端还可以与HMaster通信做表的修改。</p> 
<h3 id="%EF%BC%882%EF%BC%89HBase%E7%9A%84%E6%95%B0%E6%8D%AE%E6%A8%A1%E5%9E%8B">（2）HBase的数据模型</h3> 
<p>        HBase中，数据存储在由行和列组成的表中，HBase的表是稀疏的，多维映射的。HBase用键值对的方式存储数据。每个值都是未经解释的字符串，通过行键、列族、列限定符、时间戳等信息进行定位。</p> 
<p>1．表（Table）</p> 
<p>        HBase采取表的形式存储数据，表由行和列组成。</p> 
<p>2．行（Row）</p> 
<p>        HBase中的行由行键（RowKey）和若干列组成。行是通过行键按字典顺序进行排序的，因此行键的设计非常重要，好的行键设计可以将内容相关的行排列到相邻位置，方便查找和读取。以存储网页内容为例，将URL作为行键，如org.apache.www、org.apache.mail，可以将相邻子网页存储在相邻的位置。</p> 
<p>3．列族（Column Family）</p> 
<p>        一个表在水平方向上由一个或多个列族组成。一个列族可以由任意多个列组成，列族在表创建时就需要预先设定好。</p> 
<p>        列族是Region的物理存储单元。同一个Region下面的多个列族，位于不同的Store下面。</p> 
<p>        列族信息是表级别的配置。同一个表的多个Region，都拥有相同的列族信息（例如，都有两个列族，且不同Region的同一个列族配置信息相同）。不是每一行下的列族或列中都存储了信息，因此说HBase的表是稀疏的。</p> 
<p>4．列限定符（Column Qualifier）</p> 
<p>        列族中添加不同的列限定符可以对数据进行划分定位，列限定符以列族名作为前缀，用“：”连接后缀。例如以“content”为列族，那么列限定符则可以是“content：xxxx”。列限定符是列族下的一个标签，可以在写入数据时任意添加，支持动态扩展，无需预先定义列的数量和类型。</p> 
<p>5．单元格（Cell）</p> 
<p>        一个单元格保存了一个值的多个版本，单元格通过行键、列族和列限定符进行定位，每个版本对应一个时间戳。</p> 
<p>6．时间戳（TimeStamp）</p> 
<p>        HBase每个值都会带一个时间戳，时间戳标识了这个值的版本。默认情况下，在一个值发生变化（写入、更新、删除）时，所在的HRegionServer会自动为其创建一个时间戳。用户也可以在值发生变化时自定义时间戳。如果一个值有多个版本，在用户查询时默认返回最新的版本。HBase保存的版本数可以自定义，当超过设置的版本数时，新的版本会替换掉最早的版本。</p> 
<h3 id="%EF%BC%883%EF%BC%89%E8%A1%A8%E5%92%8CRegion">（3）表和Region</h3> 
<p>        一个HBase集群中维护着多张表，每张表可能包含非常多的行，在单台机器上无法全部存储，HBase会将一张数据表按行键的值范围横向划分为多个子表，实现分布式存储，如图5-1所示。这些子表，在HBase中被称作“Region”，Region是HBase分布式存储的基本单元。每一个Region都关联一个行键值的范围，即一个使用StartKey和EndKey描述的区间。事实上，每一个Region仅仅记录StartKey就可以了，因为它的EndKey就是下一个Region的StartKey。</p> 
<p>        每张表最开始值包含一个Region，随着表中数据的不断增大，Region中的行数超过一定阈值时就会分裂为两个新的Region。</p> 
<p>        Region分为元数据Region以及用户Region（User Region）两类。用户Region用于存储普通数据，元数据Region包括.META.表和-ROOT-表，用于存储Region的位置信息。.META.表记录了每一个用户Region的路由信息，用户可以通过.META.表查询到要访问的Region所在的HRegionServer，从而与其建立通信进行数据操作。.META.表的路由信息存储在-ROOT-表中，-ROOT-表不可被分割，只有一个Region。用户可以通过访问ZooKeeper服务器来获得-ROOT-表的位置。Region的划分如下图：</p> 
<p style="text-align:center"><img alt="" src="https://images2.imgbox.com/85/e7/vOUMOHEF_o.jpg"></p> 
<p>        从HBase0.96.0开始，-ROOT-表的设置已被移除，.META.表改名为hbase：meta，hbase：meta的位置信息直接保存在ZooKeeper中。</p> 
<h2 id="4.HBase%E7%9A%84%E8%AF%BB%E5%86%99%E6%B5%81%E7%A8%8B">4.HBase的读写流程</h2> 
<p>1．HBase的读流程</p> 
<p>        HBase的读流程如下： ·</p> 
<p>        客户端发起请求，与ZooKeeper服务器通信获取hbase：meta所在的HRegion Server，记为HRegionServer A；</p> 
<p>        访问HRegionServer A中的hbase：meta，hbase：meta中记载着各个User Region信息（行键范围，所在RegionServer等），通过行键查找hbase：meta获取所要读取的Region所在HRegionServer，记为HRegionServer B；</p> 
<p>        请求发送到HRegionServer B，HRegionServer B先查询MemStore，如果未查询到目标数据，则在HFile中查找； ·</p> 
<p>        查询到数据后返回到客户端。</p> 
<p>2．HBase的写流程</p> 
<p>        HBase的写流程如下： ·</p> 
<p>        客户端发起请求，与ZooKeeper服务器通信获取hbase：meta所在HRegionServer，记为HRegionServer A；</p> 
<p>        客户端访问HRegionServer A中的hbase：meta，hbase：meta中记载着每个User Region信息（行键范围，所在RegionServer），通过行键查找hbase：meta获取本次写入操作所涉及的HRegionServer（HBase写入操作可能会涉及多个HRegionServer，在写入前HBase会对数据进行分组，分组共两步：首先将所有的记录按RegionServer划分，然后将同一RegionServer所有的记录按Region划分。每个RegionServer上的数据会一起发送，这样发送的数据中，都是已经按照Region分好组了）；</p> 
<p>        客户端按RegionServer和Region将数据打包发送到对应的HRegionServer，RegionServer将数据写入对应的Region； ·客户端发送完待写数据后，会自动等待请求处理结果，如果客户端没有捕获到任何的异常，则认为所有数据写入成功。如果全部写入失败，或者部分写入失败，客户端能够获知详细的失败Key值列表。</p> 
<p>        如下图所示，HRegionServer在写入数据时，会先将数据写入HLog中，再将需要写入的数据暂时保存在对应Region的缓存MemStore中。这样一来可以减少数据直接写入磁盘带来的写入延迟，提高写入效率；另外数据先写入HLog可以避免HRegionServer故障时造成缓存数据的丢失。</p> 
<p style="text-align:center"><img alt="" src="https://images2.imgbox.com/21/b1/LfXPShlv_o.jpg">      </p> 
<p>        达到一定预设条件时，HBase会将MemStore中的数据写入磁盘生成HFlie文件，并清空MemStore及HLog中的对应记录，这个过程称为刷盘（Flush）。</p> 
<h2 id="5.HBase%E7%9A%84Compaction%E8%BF%87%E7%A8%8B">5.HBase的Compaction过程</h2> 
<p>        当随着时间的增长，业务数据不断写入到HBase集群中，HFile的数目会越来越多，那么针对同样的查询，需要同时打开的文件也就可能越来越多，从而增加了查询延时，降低查询效率。</p> 
<p>        当HFile文件过多时，HBase就会启动一个Compation的操作。Compaction的主要目的，是为了减少同一个Region同一个列族下面的小文件数目，从而提升读取的性能。</p> 
<p>        如下图所示，Compaction分为Minor、Major两类。</p> 
<p style="text-align:center"><img alt="" src="https://images2.imgbox.com/5e/69/HdRIiUj2_o.jpg"></p> 
<p>        Minor：小范围的Compaction。Minor Compation有最少和最大文件数目限制，默认最少选择3个HFile，最多10个，通常会选择一些连续时间范围的小文件进行合并。Minor Compaction选取文件时，遵循一定的算法。 </p> 
<p>        Major：Major Compaction会将一个Region中的某个ColumnFamily下面所有的HFile合并成一个HFile。HBase默认一天进行一次Major Compaction。Major Compaction过程中，会清理被删除的数据。</p> 
<h1 id="%E4%BA%8C%E3%80%81%E5%9F%BA%E4%BA%8EHadoop%20HA%E9%9B%86%E7%BE%A4%E7%9A%84HBase%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE">二、基于Hadoop HA集群的HBase环境安装配置</h1> 
<h2 id="1.%E4%B8%8B%E8%BD%BDHBase">1.下载HBase</h2> 
<blockquote> 
 <p>官网下载：<a href="https://archive.apache.org/dist/hbase/" title="Index of /dist/hbase">Index of /dist/hbase</a></p> 
 <p>版本：hbase-1.4.13-bin.tar.gz</p> 
</blockquote> 
<p> hadoop版本对应的HBase版本可以参考下表，自行选择下载：</p> 
<p><img alt="" height="469" src="https://images2.imgbox.com/82/2a/lTU6FoT8_o.png" width="969"> <strong>补充：</strong>我使用的是hadoop-2.7.3版本，故下载hbase-1.4.13的版本。</p> 
<h2 id="2.%E8%A7%A3%E5%8E%8B%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE">2.解压安装配置</h2> 
<p> 说明：该HBase环境是在基于Zookeeper的Hadoop HA的基础上搭建的。</p> 
<p>基于Zookeeper的Hadoop HA搭建请查看：<a href="https://blog.csdn.net/JunLeon/article/details/120689889" title="（超详细）基于Zookeeper的Hadoop HA集群的搭建_JunLeon的博客-CSDN博客">（超详细）基于Zookeeper的Hadoop HA集群的搭建_JunLeon的博客-CSDN博客</a></p> 
<h3 id="%EF%BC%881%EF%BC%89%E4%B8%8A%E4%BC%A0%E5%88%B0%E8%99%9A%E6%8B%9F%E6%9C%BA%E4%B8%AD%E6%8C%87%E5%AE%9A%E7%9A%84opt%E7%9B%AE%E5%BD%95%E4%B8%8B">（1）上传到虚拟机中指定的opt目录下</h3> 
<p>        可通过XShell或者其他远程连接工具上传，上传过程略</p> 
<h3 id="%EF%BC%882%EF%BC%89%E8%A7%A3%E5%8E%8BHBase">（2）解压HBase</h3> 
<pre><code class="language-bash">tar -zxvf /opt/hbase-1.4.13-bin.tar.gz -C /opt/   </code></pre> 
<h3 id="%EF%BC%883%EF%BC%89%E9%85%8D%E7%BD%AE%E7%8E%AF%E5%A2%83%E5%8F%8A%E5%85%B6%E7%9B%B8%E5%85%B3%E5%B1%9E%E6%80%A7">（3）配置环境及其相关属性</h3> 
<p>1.配置HBase的环境变量</p> 
<pre><code class="language-bash">vi  /etc/profile</code></pre> 
<p>在该文件的最后添加HBase的安装路径</p> 
<p><img alt="" height="139" src="https://images2.imgbox.com/ed/13/gs8136XT_o.png" width="1065"></p> 
<p> 使配置文件生效：</p> 
<pre><code class="language-bash">source /etc/profile</code></pre> 
<p>2.配置${HBASE_HOME}/conf/hbase-env.sh文件</p> 
<pre><code class="language-bash">vi ${HBASE_HOME}/conf/hbase-env.sh</code></pre> 
<p>在27行，配置jdk路径：</p> 
<p><img alt="" height="79" src="https://images2.imgbox.com/85/04/4LqmzGHw_o.png" width="747"></p> 
<p> 注释46、47行，如果使用jdk1.8，则需要注释掉</p> 
<p><img alt="" height="115" src="https://images2.imgbox.com/c5/c2/mR4cJc8J_o.png" width="1200"></p> 
<p> 128行，设置是否启动HBase自带的zookeeper</p> 
<p><img alt="" height="62" src="https://images2.imgbox.com/18/57/mmOLcxIp_o.png" width="917"></p> 
<p> 3.配置${HBASE_HOME}/conf/hbase-site.xml文件</p> 
<pre><code class="language-XML">&lt;configuration&gt;
	&lt;property&gt;
		&lt;!-- hbase存放数据目录。mycluster为hdfs-site.xml中dfs.nameservices的值 --&gt;
		&lt;name&gt;hbase.rootdir&lt;/name&gt;
		&lt;value&gt;hdfs://mycluster/data/hbase_db&lt;/value&gt;
	&lt;/property&gt;
	&lt;property&gt;
		&lt;!-- 是否分布式部署HBase --&gt;
		&lt;name&gt;hbase.cluster.distributed&lt;/name&gt;
		&lt;value&gt;true&lt;/value&gt;
	&lt;/property&gt;
	&lt;property&gt;
		&lt;name&gt;dfs.support.append&lt;/name&gt;
		&lt;value&gt;true&lt;/value&gt;
	&lt;/property&gt;
	&lt;property&gt;
		&lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt;
		&lt;value&gt;BigData01,BigData02,BigData03&lt;/value&gt;
	&lt;/property&gt;
	&lt;property&gt;
		&lt;!-- Zookooper配置、日志等的存储位置 --&gt;
		&lt;name&gt;hbase.zookeeper.property.datadir&lt;/name&gt;
		&lt;value&gt;/opt/zookeeper-3.4.12&lt;/value&gt;
	&lt;/property&gt;
	&lt;property&gt;
		&lt;name&gt;hbase.zookeeper.property.clientPort&lt;/name&gt;
		&lt;value&gt;2181&lt;/value&gt;
	&lt;/property&gt;
&lt;/configuration&gt;</code></pre> 
<p>4.配置${HBASE_HOME}/conf/regionservers文件</p> 
<pre><code class="language-XML">BigData01
BigData02
BigData03</code></pre> 
<h2 id="3.%E5%90%AF%E5%8A%A8HBase%E9%9B%86%E7%BE%A4">3.启动HBase集群</h2> 
<p>在开启HBase集群之前应先将HDFS和YARN节点开启</p> 
<pre><code class="language-bash">start-all.sh    # 在主节点上执行</code></pre> 
<p>再启动HBase集群节点</p> 
<pre><code class="language-bash">start-hbase.sh    # 在主节点上执行</code></pre> 
<h2 id="4.%E6%9F%A5%E7%9C%8B%E8%BF%9B%E7%A8%8B%E5%8F%8AHBase%E9%9B%86%E7%BE%A4%E4%BF%A1%E6%81%AF">4.查看进程及HBase集群信息</h2> 
<pre><code class="language-bash">jps    # 查看开启的守护进程</code></pre> 
<p> Web端访问：(在主机Master上执行)</p> 
<blockquote> 
 <p>IP:16010        例如：192.168.182.10:16010</p> 
</blockquote> 
<h1 id="%E4%B8%89%E3%80%81HBase%E7%9A%84Shell%E5%91%BD%E4%BB%A4">三、HBase的Shell命令</h1> 
<h2 id="1.%E5%9F%BA%E6%9C%ACShell%E5%91%BD%E4%BB%A4">1.基本Shell命令</h2> 
<p>（1）启动shell命令（进入HBase命令环境）</p> 
<pre><code class="language-bash">[root@BigData01 ~]# hbase shell</code></pre> 
<p> 如下图所示即进入HBase命令环境中：</p> 
<p><img alt="" height="307" src="https://images2.imgbox.com/3f/ed/Mrtpvj7p_o.png" width="1200"></p> 
<p>（2）查看HBase状态</p> 
<pre><code class="language-bash">hbase(main):001:0&gt; status</code></pre> 
<p>（3）查看版本</p> 
<pre><code class="language-bash">hbase(main):002:0&gt; version</code></pre> 
<p>（4）获得帮助</p> 
<pre><code class="language-bash">hbase(main):003:0&gt; help</code></pre> 
<p>（5）退出shell命令</p> 
<pre><code class="language-bash">hbase(main):004:0&gt; exit</code></pre> 
<h2 id="2.DDL%E6%93%8D%E4%BD%9C%E5%91%BD%E4%BB%A4">2.DDL操作命令</h2> 
<p>DDL即数据定义语言：</p> 
<p>（1）创建表</p> 
<pre><code class="language-bash">create  '表名','列族1','列族2'
# 例如：	create  ‘student’,’address’,’info’</code></pre> 
<p>（2）以列表的形式显示所有表</p> 
<pre><code class="language-bash">list</code></pre> 
<p>（3）查看表的结构</p> 
<pre><code class="language-bash">desc  '表名'
# 例如： desc  'student'</code></pre> 
<p>（4）修改表的结构</p> 
<pre><code class="language-bash">disable  '表名'     # 设置表为不可用的状态
alter  '表名',NAME＝&gt;'列族名'    # 添加列族
alter  '表名',NAME＝&gt;'cf3',METHOD＝&gt;'delete'   # 删除列族

# 例如：    
# disable  'student'   —— 设置student为不可用状态      
# alter  'student',NAME＝&gt;'cf3'  ——  添加列族cf3
# alter  'student',NAME＝&gt;'cf3',METHOD＝&gt;'delete'  ——  删除列族cf3
</code></pre> 
<p>（5）查询表是否存在</p> 
<pre><code class="language-bash">exists  '表名'
# 例如：    exists   'student'</code></pre> 
<p>（6）判断表是否可用或者不可用</p> 
<pre><code class="language-bash">is_eabled  '表名'    # 判断表是否可用
is_disabled  '表名'    # 判断表是否不可用
</code></pre> 
<p>（7）删除表</p> 
<pre><code class="language-bash">disable  '表名'     # 设置表为不可用的状态
drop  '表名'    # 删除指定表
</code></pre> 
<h2 id="3.DML%E6%93%8D%E4%BD%9C%E5%91%BD%E4%BB%A4">3.DML操作命令</h2> 
<p><strong>DML即数据操作语言：</strong></p> 
<blockquote> 
 <p>首先， 假设student 表的列族为address { province、city}、info { height、weight、birthday、telephone}、'row key' 为姓名(也可根据需要设学号为row key)</p> 
</blockquote> 
<p>（1）插入记录数据</p> 
<blockquote> 
 <p>格式：put  '表名','row key','列族:列','列的值'    </p> 
</blockquote> 
<pre><code class="language-bash">put  'student','zhangsan','address:province','guizhou'
put  'student','zhangsan','address:city','guiyang'
put  'student','zhangsan','info:height','180'
put  'student','zhangsan','info:birthday','2000-01-01'
put  'student','zhangsan','info:telephone','18888888888'</code></pre> 
<p>（2）获取一条数据</p> 
<blockquote> 
 <p>格式：get  '表名','row key'</p> 
</blockquote> 
<pre><code class="language-bash">get  'student','zhangsan'</code></pre> 
<p>（3）获取一个ID（row key）的一个列族所有数据</p> 
<blockquote> 
 <p>格式：get  '表名','row key','列族'</p> 
</blockquote> 
<pre><code class="language-bash">get  'student','zhangsan','info'
</code></pre> 
<p>（4）更新一条记录</p> 
<blockquote> 
 <p>格式：get  '表名','row key','列族:列'</p> 
</blockquote> 
<pre><code class="language-bash">get  'student','zhangsan','info:height'
</code></pre> 
<p>（5）更新一条数据</p> 
<blockquote> 
 <p>格式：put  '表名','row key','列族:列','列新的值'</p> 
</blockquote> 
<pre><code class="language-bash">put  'student','zhangsan','info:height','190'
</code></pre> 
<p>（6）读出表数据</p> 
<blockquote> 
 <p>scan  '表名'</p> 
</blockquote> 
<pre><code class="language-bash">scan  'student'</code></pre> 
<p>（7）查询表有多少行</p> 
<blockquote> 
 <p>count  '表名'</p> 
</blockquote> 
<pre><code class="language-bash">count  'student'</code></pre> 
<p>（8）将表清空</p> 
<blockquote> 
 <p>truncate  '表名'</p> 
</blockquote> 
<pre><code class="language-bash">truncate  'student'</code></pre> 
<p>（9）删除某ID（row key）的某列的值</p> 
<blockquote> 
 <p>格式：delete  '表名','row key','列族:列' </p> 
</blockquote> 
<pre><code class="language-bash">delete  'student','zhangsan','info:height'</code></pre> 
<h2 id="4.%E8%BF%90%E8%A1%8CHBase%20Shell%E8%84%9A%E6%9C%AC">4.运行HBase Shell脚本</h2> 
<p>可以将操作命令写入文件中，当成HBase Shell脚本，再在Linux shell命令下执行该脚本。</p> 
<p>比如：在Linux文件系统中创建一个脚本testHBaseData.sh，再在Linux Shell命令下执行：</p> 
<p>vi  testHBaseData.sh，在脚本文件中添加如下内容：</p> 
<blockquote> 
 <p>put  'student','lisi','address:province','guizhou'<br> put  'student','lisi','address:city','guiyang'<br> put  'student','lisi','info:height','185'<br> put  'student','lisi','info:birthday','1995-01-01'<br> put  'student','lisi','info:telephone','18899999999'</p> 
</blockquote> 
<p>执行脚本文件：</p> 
<pre><code class="language-bash">hbase shell testHbaseData.sh</code></pre> 
<h1 id="%E5%9B%9B%E3%80%81HBase%E5%9F%BA%E7%A1%80%E7%BC%96%E7%A8%8B">四、HBase基础编程</h1> 
<h2 id="1.HBase%20API">1.HBase API</h2> 
<p style="text-align:justify">（1）HBaseConfiguration类</p> 
<blockquote> 
 <p style="margin-left:.0001pt;text-align:justify">该类在hbase-common-1.4.13.jar 里，包名为org.apach.hadoop.hbase，该类是客户端必须使用的。 它从hbase-default.xml和hbase-site.xml文件中获取配置信息，编程时使用如下语句进行初始化配置文件：<br> Configuration  config  =  HBaseConfiguration.create();</p> 
</blockquote> 
<p style="text-align:justify">（2）ConnectionFactory类和Connection接口</p> 
<blockquote> 
 <p style="margin-left:.0001pt;text-align:justify">该类和接口在hbase-common-1.4.13.jar 里，包名为org.apach.hadoop.hbase.client，用来通过配置连接HBase 集群，即建立连接，提高连接接口。 编程时使用如下语句：<br> Connection  connection  =  ConnectionFactory.createConnection(config)</p> 
</blockquote> 
<p style="text-align:justify">（3）HBaseAdmin类和Admin接口</p> 
<blockquote> 
 <p style="margin-left:.0001pt;text-align:justify">该类和接口在hbase-client-1.4.13.jar 里，包名为org.apach.hadoop.hbase.client，封装了对数据表结构的操作的接口，提供的方法有：创建表、删除表、列出表项、使表有效或者无效、添加或者删除表列族成员。</p> 
</blockquote> 
<p style="text-align:justify">（4）HTableDescriptor类</p> 
<blockquote> 
 <p style="margin-left:.0001pt;text-align:justify">该类在hbase-client-1.4.13.jar 里，包名为org.apach.hadoop.hbase。HTableDescriptor类封装了表的相关属性及操作接口。</p> 
</blockquote> 
<p style="text-align:justify">（5）HColumnDescriptor类</p> 
<blockquote> 
 <p style="margin-left:.0001pt;text-align:justify">该类在hbase-client-1.4.13.jar 里，包名为org.apach.hadoop.hbase。HColumnDescriptor类维护列族的相关信息。</p> 
</blockquote> 
<p style="text-align:justify">（6）HTable类和Table接口</p> 
<blockquote> 
 <p style="margin-left:.0001pt;text-align:justify">该类和接口在hbase-client-1.4.13.jar 里，包名为org.apach.hadoop.hbase.client，HTable类与HBase表直接通信,编程时不推荐使用HTable 类， 建议直接使用Table 接口， 使用如下语句获得Table 接口变量:<br> TableName  tableName  =  TableName.valueOf("表名");<br> Table  table  =  connection.getTable(tableName);</p> 
</blockquote> 
<p style="text-align:justify">（7）Put类</p> 
<blockquote> 
 <p style="margin-left:.0001pt;text-align:justify">该类在hbase-client-1.4.13.jar 里，包名为org.apach.hadoop.hbase.client，Put类用来对单行数据的添加操作。</p> 
</blockquote> 
<p style="text-align:justify">（8）Get类</p> 
<blockquote> 
 <p style="margin-left:.0001pt;text-align:justify">该类在hbase-client-1.4.13.jar 里，包名为org.apach.hadoop.hbase.client，Get类用于获取单行数据的相关信息。</p> 
</blockquote> 
<p style="text-align:justify">（9）Scan类</p> 
<blockquote> 
 <p style="margin-left:.0001pt;text-align:justify">该类在hbase-client-1.4.13.jar 里，包名为org.apach.hadoop.hbase.client，用于对表进行检索</p> 
</blockquote> 
<p style="text-align:justify">（10）ResultScanner类</p> 
<blockquote> 
 <p style="text-align:justify">该类在hbase-client-1.4.13.jar 里，包名为org.apach.hadoop.hbase.client，该类提供了客户端获取值得接口。</p> 
</blockquote> 
<p style="text-align:justify">（11）Result类</p> 
<blockquote> 
 <p style="text-align:justify">该类在hbase-client-1.4.13.jar 里，包名为org.apach.hadoop.hbase.client</p> 
</blockquote> 
<p style="text-align:justify">（12）Delete类</p> 
<blockquote> 
 <p style="text-align:justify">该类在hbase-client-1.4.13.jar 里，包名为org.apach.hadoop.hbase.client</p> 
</blockquote> 
<p style="text-align:justify">（13）TableName类</p> 
<blockquote> 
 <p style="text-align:justify">该类在hbase-common-1.4.13.jar 里，包名为org.apach.hadoop.hbase</p> 
</blockquote> 
<p style="text-align:justify">（14）Cell类和CellUtil类</p> 
<blockquote> 
 <p style="text-align:justify">该类在hbase-common-1.4.13.jar 里，包名为org.apach.hadoop.hbase</p> 
</blockquote> 
<h2 id="2.HBase%20API%E7%BC%96%E7%A8%8B%E4%BB%A3%E7%A0%81%E6%BC%94%E7%A4%BA">2.HBase API编程代码演示</h2> 
<blockquote> 
 <p>下面通过示例介绍使用Java 语言编程来操作HBase 中的表及数据，编程时必需的最少<br> jar 包为hadoop-common-2.x.x.jar、hbase-common-1.4.13.jar、hbase-client-1.4.13.jar<br> ①打开Eclipse 编程工具,并建立Java工程MyHBaseUtil；</p> 
 <p><br> ②新建lib 目录, 将Hbase 编程所需的jar 包拷贝到lib 目录下, 并加入buildpath；</p> 
 <p><br> ③新建Class文件， 比如: HBASEUtil 类， 并在该类中编写针对HBase 操作的方法， 为<br> 了测试在本类中添加入口主方法main()， 使用HBASEUtil 操作数据；</p> 
 <p><br> ④将本工程导出生成jar 包文件(指定主类)， 导出生成jar 包文件的方法：<br> 选择Eclipse的菜单File→Export， 接着选Java 下的Jar File，点击“Next”， 勾选当前工程(比如:MyHBaseUtil)， 此时默认选中当前工程下的src和lib 目录,接下来勾选“Export all output folders for checked projects”，导出所有输出文件夹， 在选项Options中勾选“Compress the contents of the of JAR file” “ add directory entries”， 在“ Select the export destination:”中输入JAR file 存储位置及文件名(比如: MyHBaseUtil.jar)，最后点击“Finish”即可！</p> 
 <p>⑤ 将导出的jar 文件上传到服务器BigData01中，再使用命令：</p> 
 <pre><code class="language-bash">hadoop jar MyHBaseUtil.jar hadoop.hbase.HBaseUtil</code></pre> 
 <p>运行程序(需要保证已经启动运行了HBase集群)， 假设出现Zookeeper连接错误， 则将程序代码中注释下面几行：</p> 
 <p>        //conf.set("hbase.zookeeper.quorum", "BigData01:2181, BigData02:2181, BigData03:2181");<br>         //conf.set("hbase.zookeeper.quorum", "BigData01, BigData02, BigData03");<br>         //conf.set("hbase.zookeeper.property.clientPort", "2181");</p> 
</blockquote> 
<p>参考代码如下：</p> 
<pre><code class="language-java">package hadoop.hbase;

import java.io.IOException;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.hbase.HBaseConfiguration;
import org.apache.hadoop.hbase.HColumnDescriptor;
import org.apache.hadoop.hbase.HTableDescriptor;
import org.apache.hadoop.hbase.KeyValue;
import org.apache.hadoop.hbase.MasterNotRunningException;
import org.apache.hadoop.hbase.TableName;
import org.apache.hadoop.hbase.ZooKeeperConnectionException;
import org.apache.hadoop.hbase.client.Admin;
import org.apache.hadoop.hbase.client.Append;
import org.apache.hadoop.hbase.client.Delete;
import org.apache.hadoop.hbase.client.Get;
import org.apache.hadoop.hbase.client.HBaseAdmin;
import org.apache.hadoop.hbase.client.HTable;
import org.apache.hadoop.hbase.client.Increment;
import org.apache.hadoop.hbase.client.Put;
import org.apache.hadoop.hbase.client.Result;
import org.apache.hadoop.hbase.client.ResultScanner;
import org.apache.hadoop.hbase.client.Scan;
import org.apache.hadoop.hbase.client.Table;
import org.apache.hadoop.hbase.filter.CompareFilter.CompareOp;
import org.apache.hadoop.hbase.filter.Filter;
import org.apache.hadoop.hbase.filter.SingleColumnValueFilter;
import org.apache.hadoop.hbase.util.Bytes;

public class HBaseUtil {
	private static Configuration conf = null;
	static {
		conf = HBaseConfiguration.create();
		//conf.set("hbase.zookeeper.quorum", "BigData01:2181, BigData02:2181, BigData03:2181");
		//conf.set("hbase.zookeeper.quorum", "BigData01, BigData02, BigData03");
		//conf.set("hbase.zookeeper.property.clientPort", "2181");
		System.out.println("---Static Code Loaded. Configuration: " + conf.toString());
	}
	
	public static void main(String[] args) {
		String tableName = "goods"; 
		String[] familys = {"baseinfo", "otherinfo"};
		try {
			System.out.println("===Test Beginning: Creat table " + tableName);
			HBaseUtil.deleteTable(tableName);
			HBaseUtil.createTable(tableName, familys);
			HBaseUtil.addData(tableName, "000001", familys[0], "name", "创维电视机");
			HBaseUtil.getOneRow(tableName, "000001");
		} catch (IOException e) {
			e.printStackTrace();
		}
	}
	
	/**
	 * 创建表
	 * @param tableName
	 * @param familys
	 * @throws MasterNotRunningException
	 * @throws ZooKeeperConnectionException
	 * @throws IOException
	 */
	public static void createTable(String tableName, String[] familys) throws MasterNotRunningException, ZooKeeperConnectionException, IOException{
		HBaseAdmin admin = new HBaseAdmin(conf);
		if(admin.tableExists(tableName)){
			System.out.println("---CreateTable: table " + tableName + " already exists!");
		}else{
			HTableDescriptor tableDesc = new HTableDescriptor(tableName);
			for(int i=0; i&lt;familys.length; i++){
				tableDesc.addFamily(new HColumnDescriptor(familys[i]));
			}
			admin.createTable(tableDesc);
			System.out.println("---CreateTable: create table " + tableName + " success!");
		}
	}
	
	// 删除表
	public static void deleteTable(String tableName)
			throws MasterNotRunningException, ZooKeeperConnectionException, IOException {
		HBaseAdmin admin = new HBaseAdmin(conf);
		if (admin.tableExists(tableName)) {
			admin.disableTable(tableName);
			admin.deleteTable(tableName);
			System.out.println("---DeleteTable: delete table " + tableName + " success!");
		} else {
			System.out.println("---DeleteTable: " + tableName + " not exists!");
		}
	}

	/**
	 * 插入数据
	 * @param tableName
	 * @param rowKey
	 * @param family
	 * @param qualifier
	 * @param value
	 */
	public static void addData(String tableName, String rowKey, String family, String qualifier, String value){
		try {
			HTable table = new HTable(conf, tableName);
			Put put = new Put(Bytes.toBytes(rowKey));
			put.add(Bytes.toBytes(family), Bytes.toBytes(qualifier), Bytes.toBytes(value));
			table.put(put);
			System.out.println("insert record success!");
		} catch (IOException e) {
			// TODO Auto-generated catch block
			e.printStackTrace();
		}
	}
	
	/**
	 * 删除数据
	 * @param tableName
	 * @param rowKey
	 * @throws IOException 
	 */
	public static void deleteRow(String tableName, String rowKey) throws IOException{
		HTable table = new HTable(conf, tableName);
		Delete deleteRow = new Delete(rowKey.getBytes());
		table.delete(deleteRow);
		System.out.println("delete row " + rowKey + " success!");
	}
	
	/**
	 * 删除一行中某列
	 * @param tableName
	 * @param rowKey
	 * @param familyName
	 * @param columnName
	 * @throws IOException 
	 */
	public static void deleteColumn(String tableName, String rowKey, String familyName, String columnName) throws IOException{
		HTable table = new HTable(conf, tableName);
		Delete deleteColumn = new Delete(Bytes.toBytes(rowKey));
		deleteColumn.deleteColumn(Bytes.toBytes(familyName), Bytes.toBytes(columnName));
		table.delete(deleteColumn);
		System.out.println("delete " + rowKey + ":" + familyName + ":" + columnName + " success!");
	}
	
	/**
	 * 添加数据
	 * @param tableName
	 * @param rowKey
	 * @param family
	 * @param qualifier
	 * @param value
	 * @throws IOException 
	 */
	public static void appendData(String tableName, String rowKey, String family, String qualifier, String value) throws IOException {
		HTable table = new HTable(conf, tableName);
		Append append = new Append(Bytes.toBytes(rowKey));
		append.add(Bytes.toBytes(family), Bytes.toBytes(qualifier), Bytes.toBytes(value));
		table.append(append);
		System.out.println("append data success!");
	}
	
	/**
	 * 增长数据
	 * @param tableName
	 * @param rowKey
	 * @param family
	 * @param qualifier
	 * @param amount
	 * @throws IOException 
	 */
	public static void incrementData(String tableName, String rowKey, String family, String qualifier, long amount) throws IOException {
		HTable table = new HTable(conf, tableName);
		Increment increment = new Increment(Bytes.toBytes(rowKey));
		increment.addColumn(Bytes.toBytes(family), Bytes.toBytes(qualifier), amount);
		table.increment(increment);
		System.out.println("increment data success!");
	}
	
	/**
	 * 读取数据
	 * @param tableName
	 * @param rowKey
	 * @throws IOException
	 */
	public static void getOneRow(String tableName, String rowKey) throws IOException{
		HTable table = new HTable(conf, tableName);
		Get get = new Get(rowKey.getBytes());	//设置rowKey
		Result result = table.get(get);
		//打印结果
		for(KeyValue kv : result.raw()){
			System.out.println("trow: " + new String(kv.getRow()) + " ");
			System.out.println("tfamily: " + new String(kv.getFamily()) + " ");
			System.out.println("tqualifier: " + new String(kv.getQualifier()) + " ");
			System.out.println("ttimestamp: " + kv.getTimestamp() + " ");
			System.out.println("tvalue: " + new String(kv.getValue()) + " ");
		}
	}
	
	/**
	 * 扫描数据
	 * @param tableName
	 * @param startRow
	 * @param stopRow
	 * @throws IOException
	 */
	public static void scanRows(String tableName, String startRow, String stopRow) throws IOException{
		HTable table = new HTable(conf, tableName);
		//在scan中指定startRow和stopRow
		Scan scan = new Scan(startRow.getBytes(), stopRow.getBytes());
		ResultScanner resultS = table.getScanner(scan);
		//打印扫描结果
		for(Result result : resultS){
			for(KeyValue kv : result.raw()){
				System.out.println("trow: " + new String(kv.getRow()) + " ");
				System.out.println("tfamily: " + new String(kv.getFamily()) + " ");
				System.out.println("tqualifier: " + new String(kv.getQualifier()) + " ");
				System.out.println("ttimestamp: " + kv.getTimestamp() + " ");
				System.out.println("tvalue: " + new String(kv.getValue()) + " ");
			}
		}
	}
	
	public static void scanByFilter(String tableName, String family, String qualifier, String value) throws IOException{
		HTable table = new HTable(conf, tableName);
		Scan scan = new Scan();
		scan.addColumn(Bytes.toBytes(family), Bytes.toBytes(qualifier));
		Filter filter = new SingleColumnValueFilter(Bytes.toBytes(family), Bytes.toBytes(qualifier), CompareOp.EQUAL, Bytes.toBytes(value));
		//在scan中设置filter
		scan.setFilter(filter);
		ResultScanner resultS = table.getScanner(scan);
		//打印扫描结果
		for(Result result : resultS){
			System.out.println("row: " + new String(result.getRow()));
			for(KeyValue kv : result.raw()){
				System.out.println("tfamily: " + new String(kv.getFamily()));
				System.out.println("tqualifier: " + new String(kv.getQualifier()));
				System.out.println("ttimestamp: " + kv.getTimestamp() + " ");
				System.out.println("tvalue: " + new String(kv.getValue()));
			}
		}
	}

}
</code></pre> 
<p></p> 
<p>下一篇：数据仓库Hive的实战（超详细）</p> 
<p>如果你喜欢、对你有帮助，点赞+收藏，跟着军哥学知识……</p>
                </div>

		</div>
	</article>
</main>




			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程小白.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://www.w3counter.com/tracker.js?id=150625"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>
	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>