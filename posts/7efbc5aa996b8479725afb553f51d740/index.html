<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<title>大数据课程D4——hadoop的YARN - 编程小白</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程小白" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程小白</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">大数据课程D4——hadoop的YARN</h1>
			
		</header>
		<div class="content post__content clearfix">
			


        
                <div id="content_views" class="htmledit_views">
                    <p>文章作者邮箱：yugongshiye@sina.cn              地址：广东惠州</p> 
<p></p> 
<h1>
<a name="t0"></a><span style="color:#4da8ee"><strong> ▲ 本章节目的</strong></span>
</h1> 
<p>⚪ 了解YARN的概念和结构；</p> 
<p>⚪ 掌握YARN的资源调度流程；</p> 
<p>⚪ 了解Hadoop支持的资源调度器：FIFO、Capacity、Fair；</p> 
<p>⚪ 掌握YARN的完全分布式结构和常见问题；</p> 
<p>⚪ 掌握YARN的服役新节点操作；</p> 
<p></p> 
<h1><span style="color:#fe2c24">一、简介</span></h1> 
<h2><span style="color:#ff9900">1. 概述</span></h2> 
<div> 
 <p>1. Another Resource Negotiator - 迄今另一个资源调度器) - 负责任务管理和资源调度。</p> 
 <p>2. YARN是Hadoop2.X开始出现的，也是Hadoop2.X中最重要的特性之一。也正是因为YARN的出现，导致Hadoop1.X和Hadoop2.X不兼容。</p> 
 <p>3. 产生原因：</p> 
 <p>a. 内部原因：</p> 
 <p>Ⅰ. 在Hadoop1.X中，没有YARN的说法，此时MapReduce分为主进程JobTracker和从进程TaskTracker。JobTracker只允许存在1个，容易出现单点故障。</p> 
 <p>Ⅱ. JobTracker负责对外接收任务，接收到任务之后需要将任务拆分成子任务(MapTask和ReduceTask)。JobTracker拆分完任务之后，将子任务分配给从进程TaskTracker。JobTracker会监控每一个TaskTracker的执行情况。在官方文档中，每一个JobTracker最多能够管理4000个TaskTracker。如果TaskTracker数量过多，导致JobTracker的效率成别下降，甚至于导致JobTracker的崩溃。</p> 
 <p><span style="color:#4d4d4d">b. 外部原因：</span></p> 
 <p>Ⅰ. <span style="color:#4d4d4d">Hadoop产生的时候，市面上并没有太多的大数据框架，因此Hadoop在刚开始涉及的时候，只考虑MapReduce的资源调度问题。</span></p> 
 <p>Ⅱ. 后来随着大数据的发展，产生了越来越多的计算框架，很大一部分的框架都是围绕着Hadoop使用，因为Hadoop没有考虑其他框架的资源调度问题，所以这些计算框架就产生了资源调度冲突。</p> 
 <div> 
  <p>4. YARN的结构：</p> 
  <div> 
   <p>a. 主进程ResourceManager：</p> 
   <p>Ⅰ. 负责对外接收请求</p> 
   <p>Ⅱ. 负责管理NodeManager</p> 
   <p>Ⅲ. 负责管理ApplicationMaster</p> 
   <div> 
    <div> 
     <p>b. 从进程NodeManager：</p> 
     <div> 
      <div> 
       <p>Ⅰ. 执行任务。</p> 
       <p>Ⅱ. 负责管理本节点上的资源。</p> 
      </div> 
     </div> 
     <div> 
      <div> 
       <p>c. 辅助进程ApplicationMaster：负责管理具体的子任务。</p> 
      </div> 
     </div> 
     <h2 style="margin-left:.0001pt"><span style="color:#ff9900">2. 流程</span></h2> 
     <div> 
      <div> 
       <p>1. 当ResourceManager收到客户端提交的任务之后，会先将这个任务临时存储下来，等待NodeManager的心跳。</p> 
       <p>2. 当ResourceManager收到NodeManager的心跳之后，会在心跳响应中将Job任务返回给NodeManager。</p> 
       <p>3. NodeManager通过心跳响应之后，收到任务之后，就会在本节点内部开启一个ApplicationMaster进程，然后将Job任务交给这个ApplicationMaster处理。</p> 
       <p>4. ApplicationMaster收到任务之后，会将Job任务来进行拆分，拆分成子任务。例如，如果是一个MapReduce程序，那么拆分成MapTask和ReduceTask。</p> 
       <p>5. 拆分完成之后，ApplicationMaster会给ResourceManager发送请求申请资源。</p> 
       <p>6. ResourceManager收到请求之后，将请求交给内部组件ResourceScheduler处理。</p> 
       <p>7. ResourceScheduler收到请求之后，会将资源的描述封装成一个Container对象返回给ApplicationMaster。</p> 
       <p>8. ApplicationMaster收到资源之后，会对资源进行二次拆分，分配给具体的子任务，然后将子任务分配到不同的NodeManager上执行，并且ApplicationMaster还会监控这些子任务的执行。</p> 
       <p>9. 如果子任务执行失败，那么ApplicationMaster监控到之后，会自动的重启这个失败的子任务，或者会自动的将失败的子任务分配到其他的节点上重新执行。</p> 
       <p>10. 当Job任务结束之后，ApplicationMaster会ResourceManager发送请求，同时请求注销自己。</p> 
      </div> 
     </div> 
    </div> 
   </div> 
   <div> 
    <p style="margin-left:.0001pt"><img alt="" height="631" src="https://images2.imgbox.com/91/8b/dOuLAg7x_o.png" width="1200"></p> 
    <h2 style="margin-left:.0001pt"><span style="color:#ff9900">3. ResourceScheduler - 资源调度器</span></h2> 
    <div> 
     <div> 
      <p>1. 在Hadoop中，目前为止，支持3种资源调度器：FIFO(先进先出)，Capacity(资源容量)以及Fair(公平)。</p> 
      <p>2. FIFO(先进先出)：</p> 
      <p>a. 在Hadoop2.X中，默认使用是这个资源调度器，但是Hadoop3.X发生变化。</p> 
      <p>b. 底层会为维系唯一的队列，任务会先进入队列，然后从队列头获取任务，为这个任务分配资源。如果资源不充足的情况下，后入队的任务就会被阻塞。</p> 
      <p>3. Capacity(资源容量)：</p> 
      <p>a. 在Hadoop3.X中，默认使用的是这个资源调度器。</p> 
      <p>b. 这个资源调度器中，可以维系多个队列，每一个队列维系FIFO的规则。默认情况下，这个调度器中只有1个队列default。</p> 
      <p>c. 如果资源调度器中维系了多个队列，那么可以为每一个队列设置资源分配比。在提交任务的时候，可以将任务提交到不同的队列中。</p> 
      <p>4. Fair(公平资源)：</p> 
      <p>a. 在这个资源调取其中，也可以维系多个队列。</p> 
      <p>b. 这个队列中可以保证每一个在时间上是相对公平中 - 即任务在队列中是进行轮询的。</p> 
     </div> 
    </div> 
    <h1><span style="color:#fe2c24"> 二、完全分布式结构</span></h1> 
    <div> 
     <div style="margin-left:10.8pt"> 
      <h2 style="margin-left:0px"><span style="color:#ff9900">1. 结构</span></h2> 
      <p style="margin-left:0"><img alt="" height="702" src="https://images2.imgbox.com/4d/70/K4YlfDkS_o.png" width="748"></p> 
      <h2><span style="color:#ff9900"> 2. 常见问题</span></h2> 
      <p>1. 在第一次关闭Hadoop之前，先修改stop-dfs.sh和stop-yarn.sh中的内容。将start-dfs.sh中添加的内容放到stop-dfs.sh中，将start-yarn.sh中的内容放到stop-yarn.sh中。</p> 
      <p>2. 在Hadoop集群中，一定要先启动Zookeeper再启动Hadoop。</p> 
      <p>3. 以后再次启动Hadoop，只需要通过start-all.sh即可启动。</p> 
      <p>4. 在执行命令的时候，出现了Name or service not known或者UnknownHost之类的异常，那么先检查主机名是否写对；再检查/etc/hostname或者是/etc/hosts文件是否配置正确。</p> 
      <p>5. 在进行ssh的时候需要输入密码，需要重新进行免密。</p> 
      <p>6. 在执行命令的时候，出现了command not found，那么先检查命令是否配置正确；然后再检查/etc/profile中的环境变量是否配置正确；最后确定对/etc/profile文件修改之后是否进行了重新生效source。</p> 
      <p>7. 在格式化的时候，出现了HA is not enabled/HA is not available之类的异常，那么说明Hadoop和当前系统出现了兼容性问题 - 重装系统。</p> 
      <p>8. 如果执行命令的时候出现了IllegalArgument之类的异常，那么说明命令或者参数写错了。</p> 
      <p>9. 如果启动之后，发现缺少了QuorumPeerMain，那么Zookeeper启动失败。</p> 
      <p>10. 如果启动之后，发现缺少了NameNode/DataNode/JournalNode/ DFSZKFailoverController进程，可以试图通过hdfs --daemon start namenode/datanode/journalnode/zkfc来单独这个进程，例如hdfs --daemon start datanode。</p> 
      <p>11. 如果启动之后，发现缺少了ResourceManager/NodeManage进程，那么可以试图通过yarn --daemon start resourcemanager/nodemanager来单独启动这个进程，例如yarn --daemon start nodemanager。</p> 
      <p>12. 如果在启动的时候，出现process already running as xxx，那么先kill -9 xxx，然后再单独重新启动。</p> 
      <p>13. 在NameNode格式化的时候，如果格式化失败，那么改错之后，先删除掉/home/software/hadoop-3.1.3/tmp/dfs/name目录，再重新格式化。</p> 
      <h1><span style="color:#fe2c24">三、扩展</span></h1> 
      <h2><span style="color:#ff9900">1. 服役新节点</span></h2> 
      <p>1. 先修改新节点的主机名</p> 
      <div> 
       <p><span style="background-color:#d7d8d9">vim /etc/hostname</span></p> 
       <p><span style="background-color:#d7d8d9">#将主机名改为对应的名字，例如hadoop04</span></p> 
      </div> 
      <p>2. 进行主机名和IP的映射</p> 
      <div> 
       <p><span style="background-color:#d7d8d9">vim /etc/hosts</span></p> 
       <p><span style="background-color:#d7d8d9">#需要将所有云主机的IP和主机名都进行映射</span></p> 
       <p><span style="background-color:#d7d8d9">cd /etc/</span></p> 
       <p><span style="background-color:#d7d8d9">#远程拷贝给其他主机</span></p> 
       <p style="margin-left:0"><span style="background-color:#d7d8d9">scp -r hosts root@hadoop01:$PWD</span></p> 
       <p style="margin-left:0"><span style="background-color:#d7d8d9">scp -r hosts root@hadoop02:$PWD</span></p> 
       <p style="margin-left:0"><span style="background-color:#d7d8d9">scp -r hosts root@hadoop03:$PWD</span></p> 
      </div> 
      <p>3. 重启</p> 
      <div> 
       <span style="background-color:#d7d8d9">reboot</span> 
      </div> 
      <p>4. 配置免密码互通</p> 
      <div> 
       <p><span style="background-color:#d7d8d9">ssh-keygen</span></p> 
       <p><span style="background-color:#d7d8d9">ssh-copy-id root@hadoop01</span></p> 
       <p><span style="background-color:#d7d8d9">ssh hadoop01 --- 如果不需要密码，则输入logout</span></p> 
       <p><span style="background-color:#d7d8d9">ssh-copy-id root@hadoop02</span></p> 
       <p><span style="background-color:#d7d8d9">ssh hadoop02 --- 如果不需要密码，则输入logout</span></p> 
       <p><span style="background-color:#d7d8d9">ssh-copy-id root@hadoop03</span></p> 
       <p><span style="background-color:#d7d8d9">ssh hadoop03 --- 如果不需要密码，则输入logout</span></p> 
      </div> 
      <p>5. 所有的主机都需要和新添加的节点进行免密</p> 
      <div> 
       <p><span style="background-color:#d7d8d9">ssh-copy-id root@hadoop04</span></p> 
       <p><span style="background-color:#d7d8d9">ssh hadoop04 --- 如果不需要密码，则输入logout</span></p> 
      </div> 
      <p>6. 从其他节点拷贝一个Hadoop安装目录到第四个节点上</p> 
      <div> 
       <p><span style="background-color:#d7d8d9">cd /home/software/</span></p> 
       <p><span style="background-color:#d7d8d9">scp -r hadoop-3.1.3 root@hadoop04:$PWD</span></p> 
      </div> 
      <p>7. 新添加的节点上，进入Hadoop的安装目录，然后删除对应的目录</p> 
      <div> 
       <p><span style="background-color:#d7d8d9">cd /home/software/hadoop-3.1.3/</span></p> 
       <p><span style="background-color:#d7d8d9">rm -rf tmp</span></p> 
       <p><span style="background-color:#d7d8d9">rm -rf logs/</span></p> 
      </div> 
      <p>8. 新节点配置环境变量</p> 
      <div> 
       <p><span style="background-color:#d7d8d9">vim /etc/profile</span></p> 
       <p><span style="background-color:#d7d8d9">#在文件末尾添加</span></p> 
       <p style="margin-left:0"><span style="background-color:#d7d8d9">export HADOOP_HOME=/home/software/hadoop-3.1.3</span></p> 
       <p style="margin-left:0"><span style="background-color:#d7d8d9">export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin</span></p> 
       <p style="margin-left:0"><span style="background-color:#d7d8d9">#保存退出，重新生效</span></p> 
       <p style="margin-left:0"><span style="background-color:#d7d8d9">source /etc/profile</span></p> 
      </div> 
      <p>9. 启动DataNode</p> 
      <div> 
       <span style="background-color:#d7d8d9">hdfs --daemon start datanode</span> 
      </div> 
      <p>10. 启动YARN</p> 
      <div> 
       <span style="background-color:#d7d8d9">yarn --daemon start nodemanager</span> 
      </div> 
      <h2><span style="color:#ff9900">2. Federation HDFS - 联邦HDFS</span></h2> 
     </div> 
    </div> 
   </div> 
  </div> 
 </div> 
 <div> 
  <div> 
   <div> 
    <div> 
     <div> 
      <p>1. 当前HDFS架构的弊端：</p> 
      <p>a. NameNode会将元数据维系在内存中。实际开发中，一台服务器大概能腾出50G左右的内存给NameNode来使用，也就意味着一台服务器大概能存储3亿~4亿条元数据，经过计算，意味着NameNode所管理的集群大概能够存储12~15PB的数据。但是在现在的开发中，很多大型企业的数据量已经超过上百PB，原始的NameNode架构就不能满足这个需求。</p> 
      <p>b. NameNode无法做到程序的隔离。所有的元数据都维系在一个NameNode上，意味着如果某一个任务占用的资源比较多，那么就会影响其他在进行的任务。</p> 
      <p>c. 所有的请求都只能访问这唯一的一个NameNode，此时NameNode的并发量就成了整个HDFS的并发瓶颈。</p> 
      <p>2. 在联邦HDFS中，可以利用多个节点同时作为NameNode对外接收请求，在请求之前，需要将HDFS中的路径于NameNode之间来进行映射。每一个路径必须对应某一个NameNode。</p> 
      <p>3. 在联邦HDFS中，所有的请求不再集中于某一个节点上而是分散到不同的节点上，从而提高了集群的并发量的上限。</p> 
      <p>4. 因为不同路径分别对应了不同的节点，此时某一个节点上资源被过多的占用，例如节点的磁盘的IO资源占用比较多，并不会影响其他的节点的读写。</p> 
      <p>5. 因为利用多个NameNode来实现功能，此时元数据也不再集中于一个节点上，而是分散到多个节点上，大大的提高了集群的数据量容纳的上限。</p> 
      <p>6. 在联邦HDFS中，要求所有的NameNode的BlockPoolID必须一致。</p> 
     </div> 
    </div> 
   </div> 
  </div> 
 </div> 
 <div></div> 
 <div></div> 
 <div></div> 
 <div></div> 
 <div></div> 
 <div></div> 
 <div></div> 
 <div></div> 
</div>
                </div>

		</div>
	</article>
</main>




			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程小白.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://www.w3counter.com/tracker.js?id=150625"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>
	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>