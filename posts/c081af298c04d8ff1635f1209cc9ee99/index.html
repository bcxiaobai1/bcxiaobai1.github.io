<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<title>MATLAB环境下基于深度学习的JPEG图像去块（Image Deblocking） - 编程小白</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程小白" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程小白</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">MATLAB环境下基于深度学习的JPEG图像去块（Image Deblocking）</h1>
			
		</header>
		<div class="content post__content clearfix">
			


                <div id="content_views" class="htmledit_views">
                    <p><strong>之前主要研究现代信号处理，深度学习嘛，一个大号/深层的，现代的，黑箱的，信号/图像处理器，所以，作为一个研究现代信号处理的，顺便搞些深度学习也是顺理成章的。本文程序运行环境为MATLAB R2018A。</strong></p> 
<p><strong>代码如下</strong></p> 
<p><a href="https://mianbaoduo.com/o/bread/mbd-Y5mYkplp" title="?正在为您运送作品详情">?正在为您运送作品详情</a></p> 
<p>本文简要讲解如何训练一个经典的降噪卷积神经网络 （DnCNN），并使用DnCNN网络减少JPEG压缩伪影（compresaion artifact）。</p> 
<p>本文讲解如何从头开始训练一个 DnCNN 网络，建议使用计算能力为 3.0 或更高版本的支持 CUDA 的 NVIDIA GPU，同时需要并行计算工具箱）。</p> 
<p>图像压缩可以减少图像内存，JPEG 图像格式采用了一种功能强大的压缩方法，该方法使用所谓的<strong>质量因子quality factor</strong>来指定压缩量。降低quality值会导致更高的压缩比和更小的内存占用，但会牺牲图像的视觉质量。JPEG 压缩是有损的，这意味着压缩过程会导致图像丢失信息。对于 JPEG 图像，信息丢失显示为图像中的所谓的<strong>块效应blocking artifacts</strong> 。如下图所示，高压缩比会导致更多的信息丢失和更强的<strong>块效应</strong>。具有高频的纹理区域（如草地和云）看起来模糊不清，而锐利的边缘，如房子的屋顶和灯塔顶部的护栏，表现出所谓的振铃效应(ringing artifacts)。</p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/4a/26/lrvJrPtU_o.png"></p> 
<p>JPEG图像去块（deblocking ）是减弱JPEG 图像中压缩伪影的过程，目前存在几种JPEG图像去块方法，包括深度学习。本例讲解一种基于深度学习的方法，尝试将 JPEG 压缩伪影的影响降至最低。</p> 
<p><strong>DnCNN网络</strong></p> 
<p>本例使用一种早已提出的<strong>深度前馈卷积神经网络</strong>DnCNN，DnCNN主要是为了消除图像中的噪声而设计的。但是，也可以训练 DnCNN 以消除 JPEG 压缩伪影或提高图像的分辨率。</p> 
<p>DnCNN 网络经过训练，可根据彩色图像的亮度检测残差图像。图像的亮度通道 Y 通过红色、绿色和蓝色像素值的线性组合来表示每个像素的亮度。作为对比，图像的两个色度通道Cb和Cr是红色，绿色和蓝色像素值的不同线性组合。DnCNN仅使用亮度通道进行训练，因为人类感知对亮度变化比颜色变化更敏感。</p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/f5/b7/h5NXnhFO_o.png"></p> 
<p>为了描述方便，直接上英文</p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/52/f4/YkzH8mSP_o.png"></p> 
<p>一旦DnCNN网络学会如何估计残差图像，就可以通过将残差图像加入到压缩后的亮度通道，然后将图像转换回RGB色彩空间以重建压缩JPEG图像的无失真版本。</p> 
<p><strong>训练数据</strong></p> 
<p>IAPR TC-12 数据集包含 20，000 张自然图像，包括人物，动物，城市等，约1.8 GB，本文为了简便，将使用 IAPR TC-12 数据集的一小部分数据来训练网络，所有图像均为 32 位 JPEG 彩色图像。</p> 
<p>训练图像的数量</p> 
<pre><code>numel(trainImages.Files)</code></pre> 
<p>ans = 251</p> 
<p><strong>准备训练数据</strong></p> 
<p>读取原始图像，创建文件夹，以正确组织训练数据</p> 
<p>指定用于渲染图像压缩伪影的quality值，quality值在 [0， 100] 范围内。较小的quality值将导致高压缩比和更强的压缩伪影，因此对较小的quality值使用更密集的采样。</p> 
<pre><code>JPEGQuality = [5:5:40 50 60 70 80];</code></pre> 
<p>写入原始和压缩后的训练图像。</p> 
<pre><code>files = dir([originalFileLocation filesep '*.jpg']);
imNumber = 1;
for fileIndex = 1:size(files,1)
 fname = [originalFileLocation filesep files(fileIndex).name];
 im = imread(fname);
 if size(im,3) == 3
 im = rgb2gray(im);
 end
 for index = 1:length(JPEGQuality)
 imwrite(im,[uncompressedFileLocation filesep num2str(imNumber) '.jpg'],'JPEG','Quality',100)
 imwrite(im,[compressedFileLocation filesep num2str(imNumber) '.jpg'],'JPEG','Quality',JPEGQuality(index))
 imNumber = imNumber + 1;
 end
end</code></pre> 
<p><strong>定义用于训练的Mini-Batch Datastore</strong></p> 
<p>mini-batch datastore 用于将训练数据输送到网络，本例自定义一个mini-batch datastore方法，称作JPEGimagePatchDatastore。 JPEGimagePatchDatastore从失真的输入图像中提取图形块，并从原始图像中的相应图形块中计算目标残差。图像块为网络输入，残差为网络输出。每个mini-batch包含 128 个大小为 50 x 50 像素的图形块。在训练期间，只会从每个图像中提取一个mini-batch，并且将从图像中的随机位置提取所有块。</p> 
<pre><code>batchSize = 128;
patchSize = 50;
batchesPerImage = 1;
exts = {'.jpg'};
imdsUncompressed = imageDatastore(uncompressedFileLocation,'FileExtensions',exts);
imdsCompressed = imageDatastore(compressedFileLocation,'FileExtensions',exts);
ds = JPEGimagePatchDatastore(imdsUncompressed,imdsCompressed,...
 'MiniBatchSize',batchSize,...
 'PatchSize',patchSize,...
 'BatchesPerImage',batchesPerImage);</code></pre> 
<p>执行读取操作</p> 
<pre><code>inputBatch = read(ds);
summary(inputBatch)</code></pre> 
<p><strong>设置DnCNN层</strong></p> 
<p>使用 dnCNNLayers 函数创建DnCNN 网络层，默认情况下，网络深度（卷积层数）为 20。</p> 
<pre><code>layers = dnCNNLayers()</code></pre> 
<p><strong>设置训练参数</strong></p> 
<p>使用具有动量 （SGDM） 优化的随机梯度下降训练网络，使用trainingOptions函数指定 SDGM 的超参数。</p> 
<pre><code>maxEpochs = 30;
initLearningRate = 0.1;
l2reg = 0.0001;
batchSize = 128;
options = trainingOptions('sgdm',...
 'Momentum',0.9,...
 'InitialLearnRate',initLearningRate,...
 'LearnRateSchedule','piecewise',...
 'GradientThresholdMethod','absolute-value',...
 'GradientThreshold',0.005,...
 'L2Regularization',l2reg,...
 'MiniBatchSize',batchSize,...
 'MaxEpochs',maxEpochs,...
 'Plots','training-progress');</code></pre> 
<p><strong>训练网络</strong></p> 
<p>配置完训练参数后，使用trainNetwork函数训练DnCNN网络</p> 
<p>在 <em>NVIDIA Titan X</em> 上进行训练大约需要 40 个小时。</p> 
<pre><code> [net, info] = trainNetwork(ds,layers,options); </code></pre> 
<p>现在可以使用 DnCNN 网络从新图像中移除JPEG 压缩伪影。</p> 
<p>使用 DnCNN 执行 JPEG图像去块的步骤如下：</p> 
<p>· 创建具有三种不同quality值的 JPEG 压缩伪影的示例图像。</p> 
<p>· 使用 DnCNN 网络去除压缩伪影。</p> 
<p>· 直观地比较去块前后的图像。</p> 
<p>· 通过量化压缩和去块后图像与未失真参考图像的相似性来评估其质量。</p> 
<p><strong>创建具有块效应Blocking Artifacts的示例图像</strong></p> 
<p>创建示例图像以评估DnCNN 网络的JPEG 图像去块的结果。测试数据集 testImages 包含21张未失真的图像。</p> 
<pre><code>exts = {'.jpg','.png'};
fileNames = {'sherlock.jpg','car2.jpg','fabric.png','greens.jpg','hands1.jpg','kobi.png',...
    'lighthouse.png','micromarket.jpg','office_4.jpg','onion.png','pears.png','yellowlily.jpg',...
    'indiancorn.jpg','flamingos.jpg','sevilla.jpg','llama.jpg','parkavenue.jpg',...
    'peacock.jpg','car1.jpg','strawberries.jpg','wagon.jpg'};
filePath = [fullfile(matlabroot,'toolbox','images','imdata') filesep];
filePathNames = strcat(filePath,fileNames);
testImages = imageDatastore(filePathNames,'FileExtensions',exts);
</code></pre> 
<p>显示测试图像</p> 
<pre><code>montage(testImages)</code></pre> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/ef/34/YQXfiHJV_o.png"></p> 
<p>选择一张图像用于JPEG图像去块的参考图像</p> 
<pre><code>indx = 7; % 图像索引
Ireference = readimage(testImages,indx);
imshow(Ireference)
title('Uncompressed Reference Image')</code></pre> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/ba/21/KuD0xvv2_o.png"></p> 
<p>创建三个JPEG quality值分别为 10、20 和 50 的压缩测试图像。</p> 
<pre><code>imwrite(Ireference,fullfile(tempdir,'testQuality10.jpg'),'Quality',10);
imwrite(Ireference,fullfile(tempdir,'testQuality20.jpg'),'Quality',20);
imwrite(Ireference,fullfile(tempdir,'testQuality50.jpg'),'Quality',50);</code></pre> 
<p><strong>预处理压缩图像</strong></p> 
<p>将压缩图像读入工作区。</p> 
<pre><code>I10 = imread(fullfile(tempdir,'testQuality10.jpg'));
I20 = imread(fullfile(tempdir,'testQuality20.jpg'));
I50 = imread(fullfile(tempdir,'testQuality50.jpg'));</code></pre> 
<p>展示图像</p> 
<pre><code>montage({I50,I20,I10},'Size',[1 3])
title('JPEG-Compressed Images with Quality Factor: 50, 20 and 10 (left to right)')</code></pre> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/66/d0/6Mya9rlZ_o.png"></p> 
<p>DnCNN仅使用图像的亮度通道进行训练，因为人类感知对亮度变化比颜色变化更敏感。使用 rgb2ycbcr函数将 JPEG 压缩图像从 RGB 色彩空间转换为 YCbCr 色彩空间。</p> 
<pre><code>I10ycbcr = rgb2ycbcr(I10);
I20ycbcr = rgb2ycbcr(I20);
I50ycbcr = rgb2ycbcr(I50);</code></pre> 
<p><strong>应用DnCNN网络</strong></p> 
<p>为了执行网络的前向传播，使用 denoiseImage 函数，此函数使用完全相同的训练和测试过程对图像进行去噪。可将 JPEG 压缩伪影去看做一种图像噪声。</p> 
<pre><code>I10y_predicted = denoiseImage(I10ycbcr(:,:,1),net);
I20y_predicted = denoiseImage(I20ycbcr(:,:,1),net);
I50y_predicted = denoiseImage(I50ycbcr(:,:,1),net);</code></pre> 
<p>色度通道不需要处理。将deblocked的亮度通道与原始色度通道连接起来，以获得YCbCr色彩空间中的deblocked图像。</p> 
<pre><code>I10ycbcr_predicted = cat(3,I10y_predicted,I10ycbcr(:,:,2:3));
I20ycbcr_predicted = cat(3,I20y_predicted,I20ycbcr(:,:,2:3));
I50ycbcr_predicted = cat(3,I50y_predicted,I50ycbcr(:,:,2:3));</code></pre> 
<p>利用 Ycbcr2rgb 函数将去块后的 YCbCr 图像转换到RGB 颜色空间。</p> 
<pre><code>I10_predicted = ycbcr2rgb(I10ycbcr_predicted);
I20_predicted = ycbcr2rgb(I20ycbcr_predicted);
I50_predicted = ycbcr2rgb(I50ycbcr_predicted);</code></pre> 
<p>展示去块后的图像</p> 
<pre><code>montage({I50_predicted,I20_predicted,I10_predicted},'Size',[1 3])
title('Deblocked Images with Quality Factor: 50, 20 and 10 (left to right)')</code></pre> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/29/92/lIQrK1l5_o.png"></p> 
<p>为了在视觉上更好地理解效果的提升，使用格式为 [<em>x</em> <em>y</em> <em>width</em> <em>height</em>]的向量roi来指定感兴趣区域 （ROI）， x 和 y 为ROI的坐标，<em>width和height</em>为ROI的宽度和高度。</p> 
<pre><code>roi = [30 440 100 80];</code></pre> 
<p>显示结果</p> 
<pre><code>i10 = imcrop(I10,roi);
i20 = imcrop(I20,roi);
i50 = imcrop(I50,roi);
montage({i50 i20 i10},'Size',[1 3])
title('Patches from JPEG-Compressed Images with Quality Factor: 50, 20 and 10 (left to right)')</code></pre> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/9c/31/EfuPiAuk_o.png"></p> 
<p>将去块后的图像裁剪到此 ROI，并显示结果</p> 
<pre><code>i10predicted = imcrop(I10_predicted,roi);
i20predicted = imcrop(I20_predicted,roi);
i50predicted = imcrop(I50_predicted,roi);
montage({i50predicted,i20predicted,i10predicted},'Size',[1 3])
title('Patches from Deblocked Images with Quality Factor: 50, 20 and 10 (left to right)')</code></pre> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/1b/c3/z47kUEPb_o.png"></p> 
<p><strong>定量比较</strong></p> 
<p>通过4个指标量化区块后的图像的质量，可以使用 displayJPEGResults 函数来计算quality值为 10、20 和 50 的压缩图像和去块后的图像指标。</p> 
<p>· Structural Similarity Index (SSIM). SSIM assesses the visual impact of three characteristics of an image: luminance, contrast and structure, against a reference image. The closer the SSIM value is to 1, the better the test image agrees with the reference image. Here, the reference image is the undistorted original image, Ireference, before JPEG compression.</p> 
<p>· Peak signal-to-noise ratio (PSNR). The larger the PNSR value, the stronger the signal compared to the distortion.</p> 
<p>· Naturalness Image Quality Evaluator (NIQE). NIQE measures perceptual image quality using a model trained from natural scenes. Smaller NIQE scores indicate better perceptual quality.</p> 
<p>· Blind/Referenceless Image Spatial Quality Evaluator (BRISQUE). BRISQUE measures perceptual image quality using a model trained from natural scenes with image distortion. Smaller BRISQUE scores indicate better perceptual quality.</p> 
<p>displayJPEGResults(Ireference,I10,I20,I50,I10_predicted,I20_predicted,I50_predicted)</p> 
<p>------------------------------------------</p> 
<p>SSIM Comparison</p> 
<p>===============</p> 
<p>I10: 0.90624 I10_predicted: 0.91286</p> 
<p>I20: 0.94904 I20_predicted: 0.95444</p> 
<p>I50: 0.97238 I50_predicted: 0.97482</p> 
<p>------------------------------------------</p> 
<p>PSNR Comparison</p> 
<p>===============</p> 
<p>I10: 26.6046 I10_predicted: 27.0793</p> 
<p>I20: 28.8015 I20_predicted: 29.3378</p> 
<p>I50: 31.4512 I50_predicted: 31.8584</p> 
<p>------------------------------------------</p> 
<p>NIQE Comparison</p> 
<p>===============</p> 
<p>I10: 7.0989 I10_predicted: 3.9334</p> 
<p>I20: 4.5065 I20_predicted: 3.0699</p> 
<p>I50: 2.8866 I50_predicted: 2.4109</p> 
<p>NOTE: Smaller NIQE score signifies better perceptual quality</p> 
<p>------------------------------------------</p> 
<p>BRISQUE Comparison</p> 
<p>==================</p> 
<p>I10: 52.2731 I10_predicted: 38.9688</p> 
<p>I20: 45.5237 I20_predicted: 30.9583</p> 
<p>I50: 27.7386 I50_predicted: 24.3889</p> 
<p>NOTE: Smaller BRISQUE score signifies better perceptual quality</p> 
<p>总结</p> 
<p>本文演示如何构建和训练 DnCNN 网络，然后使用该网络减少图像中的 JPEG 压缩伪影，步骤如下：</p> 
<p>1.准备训练数据。</p> 
<p>2.通过以不同压缩比的JPEG文件创建训练图像。</p> 
<p>3.定义 JPEGimagePatchDatastore数据存储，以从输入压缩图像中提取图像块，并从原始图像中的相应块中计算目标残差，JPEGimagePatchDatastore数据存储用于将训练数据输入到网络。</p> 
<p>4.构建DnCNN 网络层。</p> 
<p>5.设置训练参数。</p> 
<p>6.使用 trainNetwork训练网络。</p> 
<p>在训练 DnCNN 网络或加载预训练的 DnCNN 网络后，本例以3个不同的quality值压缩测试图像，然后使用该网络去除压缩伪影。</p> 
<p>参考文献</p> 
<p>[1] Zhang, K., W. Zuo, Y. Chen, D. Meng, and L. Zhang, "Beyond a Gaussian Denoiser: Residual Learning of Deep CNN for Image Denoising." IEEE® Transactions on Image Processing. Feb 2017.</p> 
<p>[2] Grubinger, M., P. Clough, H. Müller, and T. Deselaers. "The IAPR TC-12 Benchmark: A New Evaluation Resource for Visual Information Systems." Proceedings of the OntoImage 2006 Language Resources For Content-Based Image Retrieval. Genoa, Italy. Vol. 5, May 2006, p. 10.</p>
                </div>

		</div>
	</article>
</main>




			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程小白.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://www.w3counter.com/tracker.js?id=150625"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>
	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>