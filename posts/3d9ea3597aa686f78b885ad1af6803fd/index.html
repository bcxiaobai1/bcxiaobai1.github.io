<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<title>动手学习VGG16 - 编程小白</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程小白" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程小白</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">动手学习VGG16</h1>
			
		</header>
		<div class="content post__content clearfix">
			


                <div id="content_views" class="markdown_views prism-atom-one-dark">
                    
                        
                    
                    <h2>
<a id="VGG__0"></a>VGG 论文</h2> 
<p><a href="https://arxiv.org/abs/1409.1556">《Very Deep Convolutional Networks for Large-Scale Image Recognition》</a><br> 论文地址：https://arxiv.org/abs/1409.1556</p> 
<h2>
<a id="VGG_3"></a>使用重复元素的网络(VGG)</h2> 
<p>以学习VGG的收获、VGG16的复现二大部分，简述VGG16网络。</p> 
<h1>
<a id="__VGG_5"></a>一. 学习VGG的收获</h1> 
<ol><li>VGG网络明确指出并实践证明了，<strong>浅而大的卷积核不如深而小的卷积核</strong>。<br> 假设卷积块a、b的输入输出维度相同（不妨设维度=C），其中卷积块a（1个7 * 7的卷积层），卷积块b（由3个3 * 3的卷积层组成）。</li></ol> 
<blockquote> 
 <p>特征方面：不论h、w是否发生改变，对于卷积块a都只能得到浅层的特征（轮廓），而卷积块b能得到深层的特征（轮廓，波纹，花边等等）。当h、w发生改变的时候，卷积块a和卷积块b都具有相同的感受野。<br> 参数方面：卷积块a的参数Pa = 7 * 7 * C^2 = 49 * C^2，卷积块b的参数Pb = 3 * (3 * 3 * C^2) = 3 * 9 * C^2 = 27 * C^2，明显 Pa &gt; Pb。</p> 
</blockquote> 
<ol start="2"><li> <p>图片的尺度N（h * w）决定了VGG网络的性能，<strong>多尺度N训练</strong>有助于提升VGG网络的性能。</p> <p>VGG网络结构图如下所示。<br> <img src="https://images2.imgbox.com/ab/05/AKJPpIFJ_o.png" alt="在这里插入图片描述"></p> </li></ol> 
<p>VGG16网络由5个卷积块和1个全连接块组成，每个卷积块后接一个步幅为2的2 * 2的最大池化层，根据图片卷积后的尺寸计算公式：</p> 
<p><span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml">
     
      
       
        
         
          h
         
         
          ′
         
        
        
         =
        
        
         (
        
        
         h
        
        
         −
        
        
         F
        
        
         +
        
        
         2
        
        
         P
        
        
         )
        
        
         /
        
        
         S
        
        
         +
        
        
         1
        
       
       
         h' = (h-F+2P)/S+1 
       
      
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.801892em;vertical-align: 0em"></span><span class="mord"><span class="mord mathdefault">h</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.801892em"><span class="" style="margin-right: 0.05em"><span class="pstrut" style="height: 2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.277778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em"></span></span><span class="base"><span class="strut" style="height: 1em;vertical-align: -0.25em"></span><span class="mopen">(</span><span class="mord mathdefault">h</span><span class="mspace" style="margin-right: 0.222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right: 0.222222em"></span></span><span class="base"><span class="strut" style="height: 0.76666em;vertical-align: -0.08333em"></span><span class="mord mathdefault" style="margin-right: 0.13889em">F</span><span class="mspace" style="margin-right: 0.222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.222222em"></span></span><span class="base"><span class="strut" style="height: 1em;vertical-align: -0.25em"></span><span class="mord">2</span><span class="mord mathdefault" style="margin-right: 0.13889em">P</span><span class="mclose">)</span><span class="mord">/</span><span class="mord mathdefault" style="margin-right: 0.05764em">S</span><span class="mspace" style="margin-right: 0.222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.222222em"></span></span><span class="base"><span class="strut" style="height: 0.64444em;vertical-align: 0em"></span><span class="mord">1</span></span></span></span></span></span><br> <span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml">
     
      
       
        
         
          w
         
         
          ′
         
        
        
         =
        
        
         (
        
        
         w
        
        
         −
        
        
         F
        
        
         +
        
        
         2
        
        
         P
        
        
         )
        
        
         /
        
        
         S
        
        
         +
        
        
         1
        
       
       
         w' = (w-F+2P)/S+1 
       
      
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.801892em;vertical-align: 0em"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.02691em">w</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.801892em"><span class="" style="margin-right: 0.05em"><span class="pstrut" style="height: 2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.277778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em"></span></span><span class="base"><span class="strut" style="height: 1em;vertical-align: -0.25em"></span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right: 0.02691em">w</span><span class="mspace" style="margin-right: 0.222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right: 0.222222em"></span></span><span class="base"><span class="strut" style="height: 0.76666em;vertical-align: -0.08333em"></span><span class="mord mathdefault" style="margin-right: 0.13889em">F</span><span class="mspace" style="margin-right: 0.222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.222222em"></span></span><span class="base"><span class="strut" style="height: 1em;vertical-align: -0.25em"></span><span class="mord">2</span><span class="mord mathdefault" style="margin-right: 0.13889em">P</span><span class="mclose">)</span><span class="mord">/</span><span class="mord mathdefault" style="margin-right: 0.05764em">S</span><span class="mspace" style="margin-right: 0.222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.222222em"></span></span><span class="base"><span class="strut" style="height: 0.64444em;vertical-align: 0em"></span><span class="mord">1</span></span></span></span></span></span></p> 
<p>其中输入图片的尺度W(h, w)，Filter大小(卷积层或池化层的卷积核大小) F * F，步幅 S，填充 P，输出图片的尺度N(h’, w’)。<br> VGG16网的输入图片的尺度必须为32的整数倍。由于组成VGG16的卷积块都是由数个步幅为1，填充为1的3 * 3的卷积层组成，不会改变图片的尺度。对于卷积块后接步幅为2的2 * 2最大池化层，图片的尺度缩小为原尺度的1/2，有5个步幅为2的2 * 2最大池化层，因此图片的尺度缩小为原尺度的(1/2)^5=1/32。</p> 
<blockquote> 
 <p>不妨设输入图片的尺度为N，采用多尺度（N-32, N, N+32）可以显著提升VGG16网络的性能。</p> 
</blockquote> 
<h1>
<a id="__VGG16_30"></a>二. VGG16网络的复现</h1> 
<ol><li>数据预处理<br> VGG网络采用极为简单的处理方式，RGB三通道分别减去样本RGB三通道的均值。</li></ol> 
<p>样本数量较少时</p> 
<pre><code class="prism language-python"><span class="token triple-quoted-string string">"""
path 为文件路径的前缀
folders 为一个字典（类别kind，列表list），其中列表内存放着图片名
"""</span>
<span class="token comment"># 样本数量较少</span>
<span class="token keyword">import</span> cv2
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
means    <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">]</span>
stdevs   <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">]</span>
img_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>

<span class="token keyword">for</span> string <span class="token keyword">in</span> folders<span class="token punctuation">:</span>
	path_next <span class="token operator">=</span> path <span class="token operator">+</span> <span class="token string">"\"</span> <span class="token operator">+</span> string
    <span class="token keyword">for</span> <span class="token builtin">file</span> <span class="token keyword">in</span> folders<span class="token punctuation">[</span>string<span class="token punctuation">]</span><span class="token punctuation">:</span>
    	<span class="token builtin">file</span> <span class="token operator">=</span> path_next <span class="token operator">+</span> <span class="token string">"\"</span> <span class="token operator">+</span> <span class="token builtin">file</span>
    	<span class="token comment">#opencv 读入的矩阵是BGR</span>
        img <span class="token operator">=</span> cv2<span class="token punctuation">.</span>imread<span class="token punctuation">(</span><span class="token builtin">file</span><span class="token punctuation">)</span>
        img <span class="token operator">=</span> img<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>newaxis<span class="token punctuation">]</span>
        <span class="token comment"># print(img.shape)</span>
        <span class="token comment"># img.shape = (h, w, 3, 1)</span>
        img_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>img<span class="token punctuation">)</span>

imgs <span class="token operator">=</span> np<span class="token punctuation">.</span>concatenate<span class="token punctuation">(</span>img_list<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">)</span>
<span class="token comment"># print(imgs.shape)</span>
<span class="token comment"># imgs.shape = (h, w, 3, n)</span>
imgs <span class="token operator">=</span> imgs<span class="token punctuation">.</span>astype<span class="token punctuation">(</span>np<span class="token punctuation">.</span>float32<span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token punctuation">(</span><span class="token number">255</span><span class="token punctuation">.</span><span class="token punctuation">)</span>

<span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
	pixels    <span class="token operator">=</span> imgs<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> i<span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">.</span>ravel<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 拉成一行</span>
	<span class="token comment"># pixels.shape = (h*w*n, )</span>
    means<span class="token punctuation">[</span>i<span class="token punctuation">]</span>  <span class="token operator">+=</span> np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>pixels<span class="token punctuation">)</span>
    stdevs<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">+=</span> np<span class="token punctuation">.</span>std<span class="token punctuation">(</span>pixels<span class="token punctuation">)</span>

<span class="token comment"># BGR --&gt; RGB ， CV读取的需要转换，PIL读取的不用转换</span>
<span class="token comment"># 也可以这么思考，opencv读取的是BGR，PIL读取的是RGB，如果交叉使用则需要使用。</span>
means<span class="token punctuation">.</span>reverse<span class="token punctuation">(</span><span class="token punctuation">)</span>
stdevs<span class="token punctuation">.</span>reverse<span class="token punctuation">(</span><span class="token punctuation">)</span>

</code></pre> 
<p>样本数量过多时</p> 
<blockquote> 
 <p>样本数量过多时，采用《概率论与数理统计》中的参数估计的方法。<br> 对于样本x1,x2,x3,…,xn,期望u1,u2,u3,…,un，方差 v1^2, v2^2, v3^2,…, vn^2，都来源于同一个样本X采用随机取样得到。<br> 不妨设 u1,u2,u3,…,un的均值为u，v1^2, v2^2, v3^2,…, vn^2的均值为v。<br> NX = x1+x2+x3+…+xn<br> E(NX) = u1+u2+u3+…+un = n<em>u<br> D(NX) = v1^2 + v2^2 + v3^2 +…+ vn^2 = n</em>v^2<br> X = NX/n = (x1+x2+x3+…+xn)/n<br> E(X) = E(NX)/n = u<br> D(X) = D(NX)/(n*n) = v^2/n<br> 样本X的期望为u，标准差为v/sqrt(n)。</p> 
</blockquote> 
<pre><code class="prism language-python"><span class="token comment"># 样本数量过多</span>
<span class="token keyword">import</span> cv2
<span class="token keyword">import</span> random
<span class="token keyword">import</span> math
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np

means    <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">]</span>
stdevs   <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">]</span>
<span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1000</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    img_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>

    <span class="token keyword">for</span> string <span class="token keyword">in</span> folders<span class="token punctuation">:</span>
        path_next <span class="token operator">=</span> path <span class="token operator">+</span> <span class="token string">"\"</span> <span class="token operator">+</span> string
        <span class="token keyword">for</span> <span class="token builtin">file</span> <span class="token keyword">in</span> folders<span class="token punctuation">[</span>string<span class="token punctuation">]</span><span class="token punctuation">:</span>
            random_num <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>uniform<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># np.random.uniform(0,1) 0-1之间按照均匀分布采样</span>
            <span class="token keyword">if</span> random_num <span class="token operator">&lt;</span> <span class="token number">0.001</span><span class="token punctuation">:</span>
                <span class="token builtin">file</span> <span class="token operator">=</span> path_next <span class="token operator">+</span> <span class="token string">"\"</span> <span class="token operator">+</span> <span class="token builtin">file</span>
                img <span class="token operator">=</span> cv2<span class="token punctuation">.</span>imread<span class="token punctuation">(</span><span class="token builtin">file</span><span class="token punctuation">)</span>
                <span class="token comment">#opencv 读入的矩阵是BGR</span>
                img <span class="token operator">=</span> img<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>newaxis<span class="token punctuation">]</span>
                <span class="token comment"># print(img.shape)</span>
                <span class="token comment"># img.shape = (h, w, 3, 1)</span>
                img_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>img<span class="token punctuation">)</span>
    
    imgs <span class="token operator">=</span> np<span class="token punctuation">.</span>concatenate<span class="token punctuation">(</span>img_list<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">)</span>
    <span class="token comment">#print(imgs.shape)</span>
    <span class="token comment"># imgs.shape = (h, w, 3, n)</span>
    imgs <span class="token operator">=</span> imgs<span class="token punctuation">.</span>astype<span class="token punctuation">(</span>np<span class="token punctuation">.</span>float32<span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token punctuation">(</span><span class="token number">255</span><span class="token punctuation">.</span><span class="token punctuation">)</span>

    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        pixels    <span class="token operator">=</span> imgs<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> i<span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">.</span>ravel<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 拉成一行</span>
        <span class="token comment"># print(pixels.shape)</span>
        <span class="token comment"># pixels.shape = (h*w*n, )</span>
        means<span class="token punctuation">[</span>i<span class="token punctuation">]</span>  <span class="token operator">+=</span> np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>pixels<span class="token punctuation">)</span>
        stdevs<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">+=</span> np<span class="token punctuation">.</span>std<span class="token punctuation">(</span>pixels<span class="token punctuation">)</span>
        
    <span class="token comment">#if (epoch+1)%100 == 0:</span>
        <span class="token comment">#print("normMean = {}".format(means))</span>
        <span class="token comment">#print("normStd = {}".format(stdevs))</span>

<span class="token comment"># BGR --&gt; RGB ， CV读取的需要转换，PIL读取的不用转换</span>
<span class="token comment"># 也可以这么思考，opencv读取的是BGR，PIL读取的是RGB，如果交叉使用则需要使用。</span>
means<span class="token punctuation">.</span>reverse<span class="token punctuation">(</span><span class="token punctuation">)</span>
stdevs<span class="token punctuation">.</span>reverse<span class="token punctuation">(</span><span class="token punctuation">)</span>

use_means  <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">]</span>
use_stdevs <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">]</span>
<span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    use_means<span class="token punctuation">[</span>i<span class="token punctuation">]</span>  <span class="token operator">=</span> means<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">/</span> <span class="token number">1000</span> 
	use_stdevs<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> stdevs<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">/</span> math<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span><span class="token number">1000</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>use_means<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>use_stdevs<span class="token punctuation">)</span>
</code></pre> 
<ol start="2"><li>参数控制</li></ol> 
<pre><code class="prism language-python">batch_size <span class="token operator">=</span> <span class="token number">8</span>            <span class="token comment"># 每次喂入的数据量，batch_size可以根据电脑的配置调整</span>
lr         <span class="token operator">=</span> <span class="token number">0.01</span>         <span class="token comment"># 学习率</span>
step_size  <span class="token operator">=</span> <span class="token number">1</span>            <span class="token comment"># 每n个epoch更新一次学习率，数据集过大因此调小</span>
epoch_num  <span class="token operator">=</span> <span class="token number">50</span>           <span class="token comment"># 总迭代次数</span>
num_print  <span class="token operator">=</span> <span class="token number">1120</span>         <span class="token comment"># 每n次batch打印一次，数据集过大因此调大</span>
num_check  <span class="token operator">=</span> <span class="token number">1</span>            <span class="token comment"># 每n个epoch验证一次模型，若效果更优则保存模型，数据集过大因此调小</span>
</code></pre> 
<ol start="3"><li>数据集构建</li></ol> 
<pre><code class="prism language-python"><span class="token triple-quoted-string string">"""
train_path 为一个字典（类别kind，列表list），其中列表内存放着图片的绝对路径
"""</span>

<span class="token keyword">import</span> torch
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>autograd <span class="token keyword">import</span> Variable
<span class="token keyword">from</span> torchvision <span class="token keyword">import</span> transforms
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> Dataset<span class="token punctuation">,</span> DataLoader
<span class="token keyword">import</span> cv2

<span class="token comment"># 独立设置尺寸，有利于VGG网络的多尺度训练</span>
size <span class="token operator">=</span> <span class="token number">224</span>

<span class="token comment"># 均值和标准差均是按照VGG论文设置的，减去样本均值，标准差设置为1。</span>
transform <span class="token operator">=</span> transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                transforms<span class="token punctuation">.</span>Normalize<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">0.5142455680072308</span><span class="token punctuation">,</span> <span class="token number">0.4990353952050209</span><span class="token punctuation">,</span> <span class="token number">0.5186490820050239</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">1.0</span><span class="token punctuation">,</span> <span class="token number">1.0</span><span class="token punctuation">,</span> <span class="token number">1.0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
                               <span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token comment"># -----------------ready the dataset--------------------------</span>
<span class="token keyword">def</span> <span class="token function">default_loader</span><span class="token punctuation">(</span>path<span class="token punctuation">,</span> img_size<span class="token punctuation">)</span><span class="token punctuation">:</span>
    img <span class="token operator">=</span> cv2<span class="token punctuation">.</span>imread<span class="token punctuation">(</span>path<span class="token punctuation">)</span>
    <span class="token keyword">if</span> img_size <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
        img <span class="token operator">=</span> cv2<span class="token punctuation">.</span>resize<span class="token punctuation">(</span>img<span class="token punctuation">,</span><span class="token punctuation">(</span>img_size<span class="token punctuation">,</span>img_size<span class="token punctuation">)</span><span class="token punctuation">,</span>interpolation<span class="token operator">=</span>cv2<span class="token punctuation">.</span>INTER_NEAREST<span class="token punctuation">)</span>
    <span class="token keyword">return</span> img

<span class="token keyword">class</span> <span class="token class-name">MyDataset</span><span class="token punctuation">(</span>Dataset<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># 构造函数</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> path<span class="token punctuation">,</span> transform<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> target_transform<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> loader<span class="token operator">=</span>default_loader<span class="token punctuation">,</span> img_size <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        imgs <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        <span class="token keyword">for</span> classification <span class="token keyword">in</span> path<span class="token punctuation">:</span>
            <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>path<span class="token punctuation">[</span>classification<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                img_path  <span class="token operator">=</span> path<span class="token punctuation">[</span>classification<span class="token punctuation">]</span><span class="token punctuation">[</span>i<span class="token punctuation">]</span>
                img_label <span class="token operator">=</span> labels<span class="token punctuation">[</span>classification<span class="token punctuation">]</span>
                imgs<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">(</span>img_path<span class="token punctuation">,</span><span class="token builtin">int</span><span class="token punctuation">(</span>img_label<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment">#imgs中包含有图像路径和标签</span>
        self<span class="token punctuation">.</span>path             <span class="token operator">=</span> path
        self<span class="token punctuation">.</span>imgs             <span class="token operator">=</span> imgs
        self<span class="token punctuation">.</span>transform        <span class="token operator">=</span> transform
        self<span class="token punctuation">.</span>target_transform <span class="token operator">=</span> target_transform
        self<span class="token punctuation">.</span>loader           <span class="token operator">=</span> loader
        self<span class="token punctuation">.</span>img_size         <span class="token operator">=</span> img_size
        
    <span class="token comment"># hash_map建立</span>
    <span class="token keyword">def</span> <span class="token function">__getitem__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> index<span class="token punctuation">)</span><span class="token punctuation">:</span>
        img_path<span class="token punctuation">,</span> img_label <span class="token operator">=</span> self<span class="token punctuation">.</span>imgs<span class="token punctuation">[</span>index<span class="token punctuation">]</span>
        <span class="token comment"># 调用 opencv 打开图片</span>
        img <span class="token operator">=</span> self<span class="token punctuation">.</span>loader<span class="token punctuation">(</span>img_path<span class="token punctuation">,</span>self<span class="token punctuation">.</span>img_size<span class="token punctuation">)</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>transform <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            img <span class="token operator">=</span> self<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>img<span class="token punctuation">)</span>
        img_label <span class="token operator">-=</span> <span class="token number">1</span>
        <span class="token keyword">return</span> img<span class="token punctuation">,</span> img_label
    
    <span class="token keyword">def</span> <span class="token function">__len__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> <span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>imgs<span class="token punctuation">)</span>

train_data        <span class="token operator">=</span> MyDataset<span class="token punctuation">(</span>train_path<span class="token punctuation">,</span> transform<span class="token operator">=</span>transform<span class="token punctuation">,</span> img_size<span class="token operator">=</span>size<span class="token punctuation">)</span>
verification_data <span class="token operator">=</span> MyDataset<span class="token punctuation">(</span>verification_path<span class="token punctuation">,</span> transform<span class="token operator">=</span>transform<span class="token punctuation">,</span> img_size<span class="token operator">=</span>size<span class="token punctuation">)</span>
test_data         <span class="token operator">=</span> MyDataset<span class="token punctuation">(</span>test_path<span class="token punctuation">,</span> transform<span class="token operator">=</span>transform<span class="token punctuation">,</span> img_size<span class="token operator">=</span>size<span class="token punctuation">)</span>

<span class="token comment">#train_data 、verification_data和test_data包含多有的训练、验证与测试数据，调用DataLoader批量加载</span>
train_loader        <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>dataset<span class="token operator">=</span>train_data<span class="token punctuation">,</span> batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
verification_loader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>dataset<span class="token operator">=</span>verification_data<span class="token punctuation">,</span> batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
test_loader         <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>dataset<span class="token operator">=</span>test_data<span class="token punctuation">,</span> batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
</code></pre> 
<ol start="4"><li>VGG16网络构建</li></ol> 
<pre><code class="prism language-python"><span class="token keyword">import</span> torch
<span class="token keyword">from</span> torch <span class="token keyword">import</span> optim
<span class="token keyword">import</span> torchvision
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">from</span> torchvision<span class="token punctuation">.</span>utils <span class="token keyword">import</span> make_grid
<span class="token keyword">import</span> time
</code></pre> 
<p>关于多尺度训练的问题，有两个思路。<br> 思路1：采用模型加载函数<strong>model.load_state_dict(torch.load(PATH), strict=False)</strong>。在加载部分模型参数进行预训练的时候，很可能会碰到键不匹配的情况（模型权重都是按键值对的形式保存并加载回来的）。因此，无论是缺少键还是多出键的情况，都可以通过在load_state_dict()函数中设定strict参数为False来忽略不匹配的键。（不推荐）<br> 思路2：参照《动手学深度学习》的卷积神经网络NiN、GoogLeNet、ResNet、DenseNet等网络，对VGG16网络的全连接块进行魔改，采用卷积块temp代替全连接块的思路。卷积块temp由2个1 * 1的卷积层及1个全局平均池化层组成，最后接2(其中1层为塑造类别的全连接层)个全连接层。</p> 
<p>思路1代码实现</p> 
<pre><code class="prism language-python"><span class="token keyword">from</span> torch <span class="token keyword">import</span> nn
<span class="token keyword">from</span> torchsummary <span class="token keyword">import</span> summary

<span class="token keyword">class</span> <span class="token class-name">VGG16Net</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>VGG16Net<span class="token punctuation">,</span>self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        
        <span class="token comment"># 第一层，2个卷积层和1个最大池化层</span>
        self<span class="token punctuation">.</span>layer1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
            <span class="token comment"># 输入3通道，卷积核3*3，输出64通道（如224*224*3的样本图片，（224+2*1-3）/1+1=224,输出224*224*64）</span>
            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span>padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            
            <span class="token comment"># 输入64通道，卷积核3*3，输出64通道（输入224*224*64，卷积3*3*64*64，输出224*224*64）</span>
            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span>padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            
            <span class="token comment"># 输入224*224*64，输出112*112*64</span>
            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span>stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
        <span class="token punctuation">)</span>
        
        <span class="token comment"># 第二层，2个卷积层和1个最大池化层</span>
        self<span class="token punctuation">.</span>layer2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
            <span class="token comment"># 输入64通道，卷积核3*3，输出128通道</span>
            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">128</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span>padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            
            <span class="token comment"># 输入128通道，卷积核3*3，输出128通道</span>
            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span><span class="token number">128</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span>padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            
            <span class="token comment"># 输入112*112*128，输出56*56*128</span>
            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span>stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
        <span class="token punctuation">)</span>
        
        <span class="token comment"># 第三层，3个卷积层和1个最大池化层</span>
        self<span class="token punctuation">.</span>layer3 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
            <span class="token comment"># 输入128通道，卷积核3*3，输出256通道</span>
            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span><span class="token number">256</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span>padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            
            <span class="token comment"># 输入256通道，卷积核3*3，输出256通道</span>
            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span><span class="token number">256</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span>padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            
            <span class="token comment"># 输入256通道，卷积核3*3，输出256通道</span>
            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span><span class="token number">256</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span>padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            
            <span class="token comment">#输入56*56*256，输出28*28*256</span>
            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span>stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
        <span class="token punctuation">)</span>
        
        <span class="token comment"># 第四层，3个卷积层和1个最大池化层</span>
        self<span class="token punctuation">.</span>layer4 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
            <span class="token comment"># 输入256通道，卷积核3*3，输出512通道</span>
            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span><span class="token number">512</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span>padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            
            <span class="token comment"># 输入512通道，卷积核3*3，输出512通道</span>
            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span><span class="token number">512</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span>padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            
            <span class="token comment"># 输入512通道，卷积核3*3，输出512通道</span>
            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span><span class="token number">512</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span>padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            
            <span class="token comment">#输入28*28*512，输出14*14*256</span>
            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span>stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
        <span class="token punctuation">)</span>
        
        <span class="token comment"># 第五层，3个卷积层和1个最大池化层</span>
        self<span class="token punctuation">.</span>layer5 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
            <span class="token comment"># 输入512通道，卷积核3*3，输出512通道</span>
            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span><span class="token number">512</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span>padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            
            <span class="token comment"># 输入512通道，卷积核3*3，输出512通道</span>
            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span><span class="token number">512</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span>padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            
            <span class="token comment"># 输入512通道，卷积核3*3，输出512通道</span>
            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span><span class="token number">512</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span>padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            
            <span class="token comment">#输入14*14*512，输出7*7*256</span>
            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span>stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
        <span class="token punctuation">)</span>
        <span class="token comment"># VGG16--13个卷积层</span>
        self<span class="token punctuation">.</span>conv_layer <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
            self<span class="token punctuation">.</span>layer1<span class="token punctuation">,</span>
            self<span class="token punctuation">.</span>layer2<span class="token punctuation">,</span>
            self<span class="token punctuation">.</span>layer3<span class="token punctuation">,</span>
            self<span class="token punctuation">.</span>layer4<span class="token punctuation">,</span>
            self<span class="token punctuation">.</span>layer5
        <span class="token punctuation">)</span>
        
        <span class="token comment"># VGG16--3个全连接层</span>
        self<span class="token punctuation">.</span>fc <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
            <span class="token triple-quoted-string string">"""
            多尺度训练，代表训练3次
            分别把第一个全连接层，设置成如下
            A、nn.Linear(512 * 6 * 6, 4096)
            B、nn.Linear(512 * 8 * 8, 4096)
            C、nn.Linear(512 * 7 * 7, 4096)
            保证C为最后一次训练即可。
            """</span>
            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">512</span> <span class="token operator">*</span> <span class="token number">7</span> <span class="token operator">*</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">4096</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token comment"># 随机丢弃50%的神经元</span>
            
            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">4096</span><span class="token punctuation">,</span> <span class="token number">4096</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token comment"># 随机丢弃50%的神经元</span>
            
            
            <span class="token triple-quoted-string string">"""
            第一种方法
            nn.Linear(4096, n)
            shape = (-1, n)，n表示类别的数量
            第二种方法如下，在VGG16后接1个全连接层
            """</span>
            
            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">4096</span><span class="token punctuation">,</span> <span class="token number">1000</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token comment"># 后接1个全连接层，shape = (-1, n)，n表示类别的数量</span>
            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">1000</span><span class="token punctuation">,</span> <span class="token number">29</span><span class="token punctuation">)</span>
            
            
        <span class="token punctuation">)</span>
    
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>conv_layer<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> x<span class="token punctuation">.</span>view<span class="token punctuation">(</span>x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>fc<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token keyword">return</span> x
<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">"__main__"</span><span class="token punctuation">:</span> 
    device <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">'cuda'</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">'cpu'</span><span class="token punctuation">)</span>
    vgg_model<span class="token operator">=</span>VGG16Net<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
    summary<span class="token punctuation">(</span>vgg_model<span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">224</span><span class="token punctuation">,</span><span class="token number">224</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment">#打印网络结构</span>
</code></pre> 
<p>思路2代码实现</p> 
<pre><code class="prism language-python"><span class="token keyword">from</span> torch <span class="token keyword">import</span> nn
<span class="token keyword">from</span> torchsummary <span class="token keyword">import</span> summary

<span class="token keyword">class</span> <span class="token class-name">VGG16Net</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>VGG16Net<span class="token punctuation">,</span>self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        
        <span class="token comment"># 第一层，2个卷积层和1个最大池化层</span>
        self<span class="token punctuation">.</span>layer1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
            <span class="token comment"># 输入3通道，卷积核3*3，输出64通道（如224*224*3的样本图片，（224+2*1-3）/1+1=224,输出224*224*64）</span>
            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span>padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            
            <span class="token comment"># 输入64通道，卷积核3*3，输出64通道（输入224*224*64，卷积3*3*64*64，输出224*224*64）</span>
            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span>padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            
            <span class="token comment"># 输入224*224*64，输出112*112*64</span>
            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span>stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
        <span class="token punctuation">)</span>
        
        <span class="token comment"># 第二层，2个卷积层和1个最大池化层</span>
        self<span class="token punctuation">.</span>layer2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
            <span class="token comment"># 输入64通道，卷积核3*3，输出128通道</span>
            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">128</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span>padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            
            <span class="token comment"># 输入128通道，卷积核3*3，输出128通道</span>
            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span><span class="token number">128</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span>padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            
            <span class="token comment"># 输入112*112*128，输出56*56*128</span>
            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span>stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
        <span class="token punctuation">)</span>
        
        <span class="token comment"># 第三层，3个卷积层和1个最大池化层</span>
        self<span class="token punctuation">.</span>layer3 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
            <span class="token comment"># 输入128通道，卷积核3*3，输出256通道</span>
            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span><span class="token number">256</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span>padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            
            <span class="token comment"># 输入256通道，卷积核3*3，输出256通道</span>
            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span><span class="token number">256</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span>padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            
            <span class="token comment"># 输入256通道，卷积核3*3，输出256通道</span>
            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span><span class="token number">256</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span>padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            
            <span class="token comment">#输入56*56*256，输出28*28*256</span>
            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span>stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
        <span class="token punctuation">)</span>
        
        <span class="token comment"># 第四层，3个卷积层和1个最大池化层</span>
        self<span class="token punctuation">.</span>layer4 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
            <span class="token comment"># 输入256通道，卷积核3*3，输出512通道</span>
            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span><span class="token number">512</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span>padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            
            <span class="token comment"># 输入512通道，卷积核3*3，输出512通道</span>
            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span><span class="token number">512</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span>padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            
            <span class="token comment"># 输入512通道，卷积核3*3，输出512通道</span>
            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span><span class="token number">512</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span>padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            
            <span class="token comment">#输入28*28*512，输出14*14*256</span>
            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span>stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
        <span class="token punctuation">)</span>
        
        <span class="token comment"># 第五层，3个卷积层和1个最大池化层</span>
        self<span class="token punctuation">.</span>layer5 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
            <span class="token comment"># 输入512通道，卷积核3*3，输出512通道</span>
            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span><span class="token number">512</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span>padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            
            <span class="token comment"># 输入512通道，卷积核3*3，输出512通道</span>
            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span><span class="token number">512</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span>padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            
            <span class="token comment"># 输入512通道，卷积核3*3，输出512通道</span>
            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span><span class="token number">512</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span>padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            
            <span class="token comment">#输入14*14*512，输出7*7*256</span>
            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span>stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
        <span class="token punctuation">)</span>
        
        <span class="token comment"># 魔改VGG16--第六层</span>
        self<span class="token punctuation">.</span>layer6 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
            
            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">4096</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">4096</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            
            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">4096</span><span class="token punctuation">,</span> <span class="token number">4096</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">4096</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
            
        <span class="token punctuation">)</span>
        
        <span class="token comment"># VGG16--15个卷积层</span>
        self<span class="token punctuation">.</span>conv_layer <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
            self<span class="token punctuation">.</span>layer1<span class="token punctuation">,</span>
            self<span class="token punctuation">.</span>layer2<span class="token punctuation">,</span>
            self<span class="token punctuation">.</span>layer3<span class="token punctuation">,</span>
            self<span class="token punctuation">.</span>layer4<span class="token punctuation">,</span>
            self<span class="token punctuation">.</span>layer5<span class="token punctuation">,</span>
            self<span class="token punctuation">.</span>layer6
        <span class="token punctuation">)</span>
        
        <span class="token comment"># VGG16--1个全连接层</span>
        self<span class="token punctuation">.</span>fc <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">4096</span><span class="token punctuation">,</span> <span class="token number">1000</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token comment"># 随机丢弃50%的神经元</span>
            
            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">1000</span><span class="token punctuation">,</span> <span class="token number">29</span><span class="token punctuation">)</span>
            
        <span class="token punctuation">)</span>
    
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>conv_layer<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token comment"># 全局平均池化层</span>
        x <span class="token operator">=</span> nn<span class="token punctuation">.</span>functional<span class="token punctuation">.</span>adaptive_avg_pool2d<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        x <span class="token operator">=</span> x<span class="token punctuation">.</span>view<span class="token punctuation">(</span>x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>fc<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token keyword">return</span> x
<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">"__main__"</span><span class="token punctuation">:</span> 
    device <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">'cuda'</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">'cpu'</span><span class="token punctuation">)</span>
    vgg_model<span class="token operator">=</span>VGG16Net<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
    summary<span class="token punctuation">(</span>vgg_model<span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">224</span><span class="token punctuation">,</span><span class="token number">224</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment">#打印网络结构</span>
</code></pre> 
<ol start="5"><li>模型训练</li></ol> 
<pre><code class="prism language-python"><span class="token comment"># VGG16</span>
device <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">"cuda:0"</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">"cpu"</span><span class="token punctuation">)</span>
model  <span class="token operator">=</span> VGG16Net<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
</code></pre> 
<pre><code class="prism language-python"><span class="token comment"># 调参</span>
<span class="token comment"># 交叉熵</span>
criterion <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span> 
<span class="token comment"># 迭代器</span>
optimizer <span class="token operator">=</span> optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>lr<span class="token punctuation">,</span> momentum<span class="token operator">=</span><span class="token number">0.8</span><span class="token punctuation">,</span> weight_decay<span class="token operator">=</span><span class="token number">0.001</span><span class="token punctuation">)</span>
<span class="token comment"># 更新学习率</span>
schedule  <span class="token operator">=</span> optim<span class="token punctuation">.</span>lr_scheduler<span class="token punctuation">.</span>StepLR<span class="token punctuation">(</span>optimizer<span class="token punctuation">,</span> step_size<span class="token operator">=</span>step_size<span class="token punctuation">,</span> gamma<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">,</span> last_epoch<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
</code></pre> 
<pre><code class="prism language-python"><span class="token comment"># 训练</span>

<span class="token comment"># 损失图</span>
loss_list         <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
start             <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>
correct_optimal   <span class="token operator">=</span> <span class="token number">0.0</span>

<span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>epoch_num<span class="token punctuation">)</span><span class="token punctuation">:</span>
    
    model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>
    running_loss <span class="token operator">=</span> <span class="token number">0.0</span>
    <span class="token keyword">for</span> i<span class="token punctuation">,</span> <span class="token punctuation">(</span>inputs<span class="token punctuation">,</span> labels<span class="token punctuation">)</span> <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>train_loader<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 从train_loader中取出64个数据</span>
        inputs<span class="token punctuation">,</span> labels <span class="token operator">=</span> inputs<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">,</span> labels<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
        <span class="token comment"># 梯度清零</span>
        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
        
        <span class="token comment"># 模型训练</span>
        outputs <span class="token operator">=</span> model<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>
        <span class="token comment">#print(outputs.shape)</span>
        
        <span class="token comment"># 反向传播</span>
        loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span>labels<span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
        
        running_loss <span class="token operator">+=</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
        
        <span class="token keyword">if</span> <span class="token punctuation">(</span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">%</span> num_print <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'[%d epoch, %d]  loss:%.6f'</span> <span class="token operator">%</span><span class="token punctuation">(</span>epoch<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">,</span> i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">,</span> running_loss<span class="token operator">/</span>num_print<span class="token punctuation">)</span><span class="token punctuation">)</span>
            loss_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>running_loss<span class="token operator">/</span>num_print<span class="token punctuation">)</span>
            running_loss <span class="token operator">=</span> <span class="token number">0.0</span>
    
    <span class="token comment"># 打印学习率及确认学习率是否进行更新</span>
    lr_1 <span class="token operator">=</span> optimizer<span class="token punctuation">.</span>param_groups<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'lr'</span><span class="token punctuation">]</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"learn_rate: %.15f"</span><span class="token operator">%</span>lr_1<span class="token punctuation">)</span>
    schedule<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
    
    <span class="token comment"># 验证模式</span>
    <span class="token keyword">if</span> <span class="token punctuation">(</span>epoch<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">%</span> num_check <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
        <span class="token comment"># 不需要梯度更新</span>
        model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
        correct <span class="token operator">=</span> <span class="token number">0.0</span>
        total   <span class="token operator">=</span> <span class="token number">0</span>
        <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"=======================check======================="</span><span class="token punctuation">)</span>
            <span class="token keyword">for</span> inputs<span class="token punctuation">,</span> labels <span class="token keyword">in</span> verification_loader<span class="token punctuation">:</span>
                <span class="token comment"># 从train_loader中取出batch_size个数据</span>
                inputs<span class="token punctuation">,</span> labels <span class="token operator">=</span> inputs<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">,</span> labels<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
                
                <span class="token comment"># 模型验证</span>
                outputs <span class="token operator">=</span> model<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>
                pred    <span class="token operator">=</span> outputs<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token comment">#返回每一行中最大值的索引</span>
                total   <span class="token operator">=</span> total <span class="token operator">+</span> inputs<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
                correct <span class="token operator">=</span> correct <span class="token operator">+</span> torch<span class="token punctuation">.</span>eq<span class="token punctuation">(</span>pred<span class="token punctuation">,</span> labels<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
            
        
        correct <span class="token operator">=</span> <span class="token number">100</span> <span class="token operator">*</span> correct<span class="token operator">/</span>total
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Accuracy of the network on the 19850 verification images:%.2f %%"</span> <span class="token operator">%</span>correct <span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"==================================================="</span><span class="token punctuation">)</span>
        
        <span class="token comment"># 模型保存</span>
        <span class="token keyword">if</span> correct <span class="token operator">&gt;</span> correct_optimal<span class="token punctuation">:</span>
            PATH <span class="token operator">=</span> <span class="token string">"VVG\VGG16 model_"</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>epoch<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">"_"</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>correct<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">".pth"</span>
            torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>model<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'VGG/VGG16_%03d-correct%.3f.pth'</span> <span class="token operator">%</span> <span class="token punctuation">(</span>epoch <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span> correct<span class="token punctuation">)</span><span class="token punctuation">)</span>
            correct_optimal <span class="token operator">=</span> correct

end<span class="token operator">=</span>time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"time:{}"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>end<span class="token operator">-</span>start<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<ol start="6"><li>绘制损失图</li></ol> 
<pre><code class="prism language-python"><span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt

x <span class="token operator">=</span> <span class="token punctuation">[</span> i<span class="token operator">+</span><span class="token number">1</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>loss_list<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">]</span>

<span class="token comment"># plot函数作图</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>x<span class="token punctuation">,</span> loss_list<span class="token punctuation">)</span>  

<span class="token comment"># show函数展示出这个图，如果没有这行代码，则程序完成绘图，但看不到</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>  
</code></pre> 
<p>损失图如下，其中5个单位代表1次epoch。<br> <img src="https://images2.imgbox.com/00/56/VKfYmNE8_o.png" alt="在这里插入图片描述"><br> 7. 模型检验</p> 
<pre><code class="prism language-python"><span class="token comment"># 检验模式，不需要梯度更新</span>
model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
correct <span class="token operator">=</span> <span class="token number">0.0</span>
total   <span class="token operator">=</span> <span class="token number">0</span>
<span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"=======================check======================="</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> inputs<span class="token punctuation">,</span> labels <span class="token keyword">in</span> test_loader<span class="token punctuation">:</span>
        <span class="token comment"># 从train_loader中取出batch_size个数据</span>
        inputs<span class="token punctuation">,</span> labels <span class="token operator">=</span> inputs<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">,</span> labels<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
                
        <span class="token comment"># 模型检验</span>
        outputs <span class="token operator">=</span> model<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>
        pred    <span class="token operator">=</span> outputs<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token comment">#返回每一行中最大值的索引</span>
        total   <span class="token operator">=</span> total <span class="token operator">+</span> inputs<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
        correct <span class="token operator">=</span> correct <span class="token operator">+</span> torch<span class="token punctuation">.</span>eq<span class="token punctuation">(</span>pred<span class="token punctuation">,</span> labels<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
            
        
    correct <span class="token operator">=</span> <span class="token number">100</span> <span class="token operator">*</span> correct<span class="token operator">/</span>total
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Accuracy of the network on the 25907 test images:%.2f %%"</span> <span class="token operator">%</span>correct <span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"==================================================="</span><span class="token punctuation">)</span>
</code></pre> 
<p>最后祝各位永远怀着一颗怀疑的心，时刻仰望理论，不止于纸上谈兵，把想法付诸于实践，并不断思考。</p>
                </div>
                
                

		</div>
	</article>
</main>




			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程小白.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://www.w3counter.com/tracker.js?id=150625"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>
	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>