<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<title>Hadoop期末复习城科专用 - 编程小白</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程小白" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程小白</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Hadoop期末复习城科专用</h1>
			
		</header>
		<div class="content post__content clearfix">
			


                <div id="content_views" class="markdown_views prism-atom-one-dark">
                    
                        
                    
                    <h1>
<a id="Hadoop_0"></a>Hadoop期末复习城科专用</h1> 
<p>根据老师给出的知识点范围整理，<strong>有的知识点太长了，就标了一部分黑色字体，把黑色字体记住答上也应该能得分</strong>，其余的方便记忆理清思路，列出来的全是给的知识点范围，<strong>如果觉得长了，可以自行省略背</strong>。<br> 有需要.md文件的同学可以加Q2660593526<br> 论述题最后一个就不写了<br> </p>
<div class="toc">
 <h3>目录</h3>
 <ul>
<li><a href="#Hadoop_0">Hadoop期末复习城科专用</a></li>
<li>
<ul>
<li><a href="#Hadoop_9">一、Hadoop集群</a></li>
<li>
<ul>
<li><a href="#_11">概念解释：</a></li>
<li><a href="#1Yarn_13">1.Yarn</a></li>
<li><a href="#_17">简答题</a></li>
<li><a href="#1Hadoop6_19">1.Hadoop集群6个核心配置文件以及它的作用</a></li>
<li><a href="#2Hadoop_30">2.Hadoop集群部署方式以及各方式使用场景</a></li>
<li><a href="#3Hadoop_38">3.Hadoop版本的区别</a></li>
<li><a href="#4_45">4.大数据的意义（围绕这个写就行）</a></li>
</ul>
   </li>
<li><a href="#HDFS_49">二、HDFS</a></li>
<li>
<ul>
<li><a href="#_51">概念解释：</a></li>
<li><a href="#1NameNode_53">1.NameNode</a></li>
<li><a href="#2Secondary_NameNode_57">2.Secondary NameNode</a></li>
<li><a href="#3DataNode_61">3.DataNode</a></li>
<li><a href="#4_65">4.元数据</a></li>
<li><a href="#5Block_68">5.Block（数据块）</a></li>
<li><a href="#_71">简答题：</a></li>
<li><a href="#1HDFSHDFS53_73">1.HDFS文件上传流程（HDFS写数据原理，详细看书53页，感觉没必要）</a></li>
<li><a href="#2NameNode_95">2.NameNode管理分布式文件系统的命名空间</a></li>
<li><a href="#3HDFS_BlockMapReduce_split_99">3.HDFS Block与MapReduce split之间的联系</a></li>
</ul>
   </li>
<li><a href="#MapReduce_110">三、MapReduce</a></li>
<li>
<ul>
<li><a href="#1_112">1.核心思想及概念</a></li>
<li><a href="#2MapReduce_122">2.MapReduce工作过程（可以只背这部分黑色的）</a></li>
<li><a href="#3Shuffle_155">3.Shuffle工作流程（可以只背这部分黑色的）</a></li>
<li>
<ul><li>
<ul>
<li><a href="#1Map_157">1.Map阶段</a></li>
<li><a href="#2Reduce_169">2.Reduce阶段</a></li>
</ul>
    </li></ul>
    </li>
<li><a href="#_177">组件</a></li>
<li>
<ul>
<li><a href="#4InputFormat_179">4.InputFormat组件</a></li>
<li><a href="#5Mapper_186">5.Mapper组件</a></li>
<li><a href="#6Reducer_190">6.Reducer组件</a></li>
<li><a href="#7Partitoner_194">7.Partitoner组件</a></li>
<li><a href="#8Combiner_198">8.Combiner组件</a></li>
</ul>
    </li>
<li><a href="#9JobTracker_204">9.JobTracker</a></li>
<li><a href="#10TaskTracker_212">10.TaskTracker：</a></li>
</ul>
   </li>
<li><a href="#Zookeeper_221">四、Zookeeper</a></li>
<li>
<ul>
<li><a href="#_223">概念解释：</a></li>
<li><a href="#1zookeeper_225">1.zookeeper</a></li>
<li><a href="#2Znode_229">2.Znode</a></li>
<li><a href="#_233">简答题：</a></li>
<li><a href="#3Zookeeper107_235">3.Zookeeper集群选举机制（书上107,如果能理清就可以看，建议不看）</a></li>
<li>
<ul>
<li><a href="#_251">全新集群选举：</a></li>
<li><a href="#_262">非全新集群选举：</a></li>
</ul>
    </li>
<li><a href="#4Watch_274">4.Watch机制</a></li>
</ul>
   </li>
<li><a href="#Hive_285">五、Hive</a></li>
<li>
<ul>
<li><a href="#_287">概念解释：</a></li>
<li><a href="#1Hive_289">1.Hive</a></li>
<li><a href="#2HQL_293">2.HQL</a></li>
<li><a href="#3_297">3.星状模型</a></li>
<li><a href="#4_303">4.雪花模型</a></li>
<li><a href="#5_308">5.桶表</a></li>
<li><a href="#_312">简答题</a></li>
<li><a href="#6Hive_314">6.Hive的特点是什么</a></li>
</ul>
   </li>
<li><a href="#Flume_319">六、Flume</a></li>
<li>
<ul>
<li><a href="#_321">概念解释</a></li>
<li><a href="#1Source_323">1.Source</a></li>
<li><a href="#2Channel_327">2.Channel</a></li>
<li><a href="#3Sink_331">3.Sink</a></li>
<li><a href="#4Flume_335">4.Flume拦截器</a></li>
<li><a href="#_339">简答题</a></li>
<li><a href="#5Flume_341">5.Flume的工作原理</a></li>
</ul>
   </li>
<li><a href="#Azkaban_345">七、Azkaban</a></li>
<li>
<ul>
<li><a href="#_347">概念解释：</a></li>
<li><a href="#Azkaban_349">Azkaban</a></li>
</ul>
   </li>
<li><a href="#Sqoop_353">八、Sqoop</a></li>
<li>
<ul>
<li><a href="#_355">概念解释：</a></li>
<li><a href="#Sqoop_357">Sqoop</a></li>
</ul>
   </li>
<li><a href="#_361">论述题</a></li>
<li>
<ul>
<li><a href="#1HDFS_363">1.HDFS不适合应用的场景有哪些</a></li>
<li><a href="#Sqoop_369">Sqoop导入导出数据的工作原理是什么</a></li>
<li><a href="#2Hadoop_374">2.基于Hadoop的大数据分析过程与传统数据分析相比特点有哪些，有何不同</a></li>
<li><a href="#3_380">3.大数据研究的意义是什么，理由。</a></li>
<li><a href="#4Hadoop_384">4.Hadoop的组件有哪些，结构分别是什么，特点是什么</a></li>
<li>
<ul>
<li><a href="#_386">四大组件：</a></li>
<li>
<ul>
<li><a href="#MapReduce_388">MapReduce</a></li>
<li><a href="#HDFS_394">HDFS</a></li>
<li><a href="#Yarn_400">Yarn</a></li>
<li><a href="#Others_406">Others(其他工具类)</a></li>
</ul>
    </li>
</ul>
    </li>
<li><a href="#5HadoopHadoop_410">5.Hadoop集群的特点是什么，分布式系统给Hadoop带来什么特性</a></li>
<li>
<ul>
<li><a href="#_412">集群特点</a></li>
<li><a href="#_420">分布式系统特性</a></li>
<li>
<ul>
<li><a href="#_422">优点：</a></li>
<li><a href="#_430">缺点：</a></li>
</ul>
    </li>
</ul>
    </li>
<li><a href="#6Hadoop_436">6.总结Hadoop集群部署的过程，分为哪些步骤</a></li>
<li><a href="#7Hadoop_456">7.与普通集群相比，Hadoop高可用集群有哪些特殊之处，两者有何不同</a></li>
<li>
<ul>
<li><a href="#_458">普通集群</a></li>
<li><a href="#Hadoop7_465">Hadoop集群（详情见书第7页，具体内容可以背点）</a></li>
</ul>
   </li>
</ul>
  </li>
</ul>
 </li>
</ul>
</div>
<p></p> 
<h2>
<a id="Hadoop_9"></a>一、Hadoop集群</h2> 
<h3>
<a id="_11"></a>概念解释：</h3> 
<h3>
<a id="1Yarn_13"></a>1.Yarn</h3> 
<p>Yarn是Hadoop2.0中的资源管理器，它可为上层应用提供统一的资源管理和调度，它的引入为集群在利用率、资源统一管理和数据共享等方面带来巨大好处。</p> 
<h3>
<a id="_17"></a>简答题</h3> 
<h3>
<a id="1Hadoop6_19"></a>1.Hadoop集群6个核心配置文件以及它的作用</h3> 
<table>
<thead><tr>
<th>配置文件</th>
<th>功能描述</th>
</tr></thead>
<tbody>
<tr>
<td>hadoop-env.sh</td>
<td>配置Hadoop运行所需的环境变量</td>
</tr>
<tr>
<td>yarn-env.sh</td>
<td>配置Yarn运行所需环境变量</td>
</tr>
<tr>
<td>core-site.xml</td>
<td>Hadoop核心全局配置文件，可在其他配置文件中引用该文件</td>
</tr>
<tr>
<td>hdfs-site.xml</td>
<td>HDFS配置文件，继承core-site.xml配置文件</td>
</tr>
<tr>
<td>mapred-site.xml</td>
<td>MapReduce配置文件，继承core-site.xml配置文件</td>
</tr>
<tr>
<td>yarn-site.xml</td>
<td>YARN配置文件，继承core-site.xml文件</td>
</tr>
</tbody>
</table>
<h3>
<a id="2Hadoop_30"></a>2.Hadoop集群部署方式以及各方式使用场景</h3> 
<p>（1）独立模式：又称单例模式，在该模式下，无须运行任何守护进程，所有的程序都在单个JVM上执行，</p> 
<p>（2）伪分布模式：Hadoop程序的守护进程运行在一台主机节点上，通常使用伪分布式模式来调试Hadoop分布式程序的代码，以及程序执行是否正确，伪分布式模式是完全分布式模式的一个特例。</p> 
<p>（3）完全分布式模式：Hadoop的守护进程分别运行在由多个主机搭建的集群上，不同节点担任不同的角色，在实际工作应用开发中，通常使用该模式构建企业级Hadoop系统。</p> 
<h3>
<a id="3Hadoop_38"></a>3.Hadoop版本的区别</h3> 
<p>借用尚硅谷一张图</p> 
<p><img src="https://images2.imgbox.com/a4/58/BEC5dQPw_o.png" alt="在这里插入图片描述"></p> 
<h3>
<a id="4_45"></a>4.大数据的意义（围绕这个写就行）</h3> 
<p>研究大数据，最重要的意义在于预测。因为数据从根本上来讲，是对过去和现在的归纳和总结，其本身不具备趋势和方向性的特征，但是可以应用大数据去了解事物发展的客观规律、了解人类行为，并且能够帮助我们改变过去的思维方式，建立新的数据思维模式，从而对未来进行预测和推测。</p> 
<h2>
<a id="HDFS_49"></a>二、HDFS</h2> 
<h3>
<a id="_51"></a>概念解释：</h3> 
<h3>
<a id="1NameNode_53"></a>1.NameNode</h3> 
<p><strong>NameNode是HDFS集群的主服务器，通常称为名称节点或主节点</strong>。一旦NameNode关闭，就无法访问Hadoop集群。<strong>NameNode主要以元数据的形式进行管理和存储，用于维护文件系统名称并管理客户端对文件的访问;NameNode记录对文件系统名称的空间或其属性的任何更改操作</strong>；HDFS负责整个数据集群的管理，并且在配置文件中，可以设置备份数量，这些信息都由NameNode存储。</p> 
<h3>
<a id="2Secondary_NameNode_57"></a>2.Secondary NameNode</h3> 
<p>HDFS中提供了Secondary NameNode(辅助名称节点)，它并不是要取代NameNode也不是NameNode的备份，<strong>它的职责是周期性地把NameNode中地EditLog日志文件合并到FsImage镜像文件中，从而减小EditLog日志文件大小，缩短集群重启时间，保证了HDFS系统地完整性</strong>。</p> 
<h3>
<a id="3DataNode_61"></a>3.DataNode</h3> 
<p>DataNode是HDFS集群中的从服务器，通常称为数据节点。<strong>文件系统存储文件的方式是将文件切分成多个数据块，这些数据块实际上是存在DataNode节点上</strong>的，因此DataNode机器需要配置大量磁盘空间。它与NameNode不断地保持通信，<strong>DataNode在客户端或者NameNode地调度下，存储并检索数据块，对数据块进行创建、删除等操作</strong>，并且定期向NameNode发送所存储地数据块列表，每当DataNode启动时，它将负责把持有地数据块列表发送到NameNode集群中。</p> 
<h3>
<a id="4_65"></a>4.元数据</h3> 
<p><strong>元数据从类型上可分为三种信息形式，一是维护HDFS中文件和目录的信息</strong>，如文件名、目录名、父目录信息、文件大小、创建时间、修改时间等；<strong>二是记录文件内容</strong>，存储相关信息，如文件分块情况、副本个数、每个副本所在的DataNode信息等；<strong>三是用来记录HDFS中所有DataNode的信息</strong>，用于DataNode管理。</p> 
<h3>
<a id="5Block_68"></a>5.Block（数据块）</h3> 
<p><strong>每个磁盘都有默认的数据块大小，这是磁盘进行数据读/写的最小单位，HDFS同样也有块的概念，它是抽象的块，而非整个文件作为存储单元，默认大小为128M，且备份3份，每个块尽可能的存储于不同的DataNode中</strong>。按块存储的好处主要是屏蔽了文件大小。提供数据的容错性和可用性。</p> 
<h3>
<a id="_71"></a>简答题：</h3> 
<h3>
<a id="1HDFSHDFS53_73"></a>1.HDFS文件上传流程（HDFS写数据原理，详细看书53页，感觉没必要）</h3> 
<p>配个尚硅谷的流程图，理解一下<br> <img src="https://images2.imgbox.com/57/88/QQOsCsye_o.png" alt="在这里插入图片描述"></p> 
<p>（1）客户端向NameNode请求上传文件，NameNode检查目标文件是否已存在，父目录是否存在。</p> 
<p>（2）NameNode返回是否可以上传。</p> 
<p>（3）客户端请求第一个 Block上传到哪几个DataNode服务器上。</p> 
<p>（4）NameNode返回3个DataNode节点，分别为dn1、dn2、dn3。</p> 
<p>（5）客户端通过FSDataOutputStream模块请求dn1上传数据，dn1收到请求会继续调用dn2，然后dn2调用dn3，将这个通信管道建立完成。</p> 
<p>（6）dn1、dn2、dn3逐级应答客户端。</p> 
<p>（7）客户端开始往dn1上传第一个Block（先从磁盘读取数据放到一个本地内存缓存），以Packet为单位，dn1收到一个Packet就会传给dn2，dn2传给dn3；dn1每传一个packet会放入一个应答队列等待应答。</p> 
<p>（8）当一个Block传输完成之后，客户端再次请求NameNode上传第二个Block的服务器。（重复执行3-7步）。</p> 
<h3>
<a id="2NameNode_95"></a>2.NameNode管理分布式文件系统的命名空间</h3> 
<p><strong>NameNode内部以元数据的形式，维护着两个文件，分别是FsImage镜像文件和EditLog日志文</strong>件。其中，FsImage镜像文件用于存储整个文件系统命名空间的信息，EditLog日志文件用于持久化记录文件系统元数据发生的变化。<strong>当NameNode启动的时候，FsImage镜像文件就会被加载到内存中，然后对内存里的数据执行记录的操作，以确保内存所保留的数据处于最新状态</strong>，这样就加快了元数据的读取和更新操作。</p> 
<h3>
<a id="3HDFS_BlockMapReduce_split_99"></a>3.HDFS Block与MapReduce split之间的联系</h3> 
<ul>
<li><strong>split是MapReduce里的概念，是切片的概念，split是逻辑切片 ；而block是hdfs中切块的大小，block是物理切块；</strong></li>
<li><strong>split的大小在默认的情况下和HDFS的block切块大小一致，为了是MapReduce处理的时候减少由于split和block之间大小不一致，可能会完成多余的网络之间的传输。</strong></li>
</ul> 
<p>如果blockSize小于maxSize &amp;&amp; blockSize 大于 minSize之间，那么split就是blockSize；</p> 
<p>如果blockSize小于maxSize &amp;&amp; blockSize 小于 minSize之间，那么split就是minSize；</p> 
<p>如果blockSize大于maxSize &amp;&amp; blockSize 大于 minSize之间，那么split就是maxSize；</p> 
<h2>
<a id="MapReduce_110"></a>三、MapReduce</h2> 
<h3>
<a id="1_112"></a>1.核心思想及概念</h3> 
<p><strong>”分而治之“</strong>：<strong>把一个复杂的问题，按照一定的“分解”方法分为等价的规模较小的若干部分，然后逐个解决</strong></p> 
<p>MapReduce作为一种分布式计算模型，它主要解决海量数据的计算问题。使用MapReduce分析海量数据时，每个MapReduce程序被初始化为一个工作任务，<strong>每个工作任务可以分为Map和Reduce两个阶段</strong>，具体介绍如下：</p> 
<ul>
<li> <p>Map阶段：负责将任务分解，即把复杂的任务分解成若干个“简单的任务”来并行处理，但前提是这些任务没有必然的依赖关系，可以单独执行任务</p> </li>
<li> <p>Reduce阶段：负责将任务合并，即把Map阶段的结果进行全局汇总</p> </li>
</ul> 
<h3>
<a id="2MapReduce_122"></a>2.MapReduce工作过程（可以只背这部分黑色的）</h3> 
<ol>
<li> <p>分片、格式化数据源<br> <strong>（对数据进行分片和格式化）</strong></p> <p>输入Map阶段的数据源，必须经过分片和格式化操作。<br> <strong>分片操作</strong>:指的是将源文件划分为大小相等的小数据块(Hadoop 2. x中默认128MB) ,也就是分片(split),Hadoop会为每一个分片构建一个Map任务，并由该任务运行自定义的map()函数，从而处理分片里的每一-条记录。</p> <p><strong>格式化操作</strong>:将划分好的分片(split)格式化为键值对&lt;key,value&gt;形式的数据其中,key代表偏移量,value代表每一-行内容。</p> </li>
<li> <p>执行MapTask<br> <strong>(处理任务，并将任务处理结果写入内存缓冲区，若缓冲区将满则写入磁盘)</strong></p> <p>每个Map任务都有一个内存缓冲区(缓冲区大小100MB)，输入的分片(split)数据经过Map任务处理后的中间结果会写入内存缓冲区中。如果写入的数据达到内存缓冲的阈值(80MB),会启动一个线程将内存中的溢出数据写入磁盘，同时不影响map中间结果继续写入缓冲区。<br> 在溢写过程中,MapReduce框架会对key进行排序，如果中间结果比较大,会形成多个溢写文件,最后的缓冲区数据也会全部溢写入磁盘形成一个溢写文件，如果是多个溢写文件，则最后合并所有的溢写文件为-一个文件。</p> </li>
<li> <p>执行Shuffle过程<br> <strong>（将MapTask处理结果发给ReduceTask，并对数据进行分区和排序）</strong></p> <p>MapReduce工作过程中，Map阶段处理的数据如何传递给Reduce 阶段，这是MapReduce框架中关键的一个过程,这个过程叫作Shuffle. Shuffle 会将MapTask输出的处理结果数据分发给ReduceTask,并在分发的过程中,对数据按key进行分区和排序。</p> </li>
<li> <p>执行ReduceTask<br> <strong>(逻辑处理并输出)</strong></p> <p>输入ReduceTask的数据流是&lt;key, {value list}&gt;形式,用户可以自定义reduce()方法进行逻辑处理，最终以&lt;key,value&gt;的形式输出。</p> </li>
<li> <p>写入文件<br> <strong>（将结果写入文件）</strong></p> <p>MapReduce框架会自动把ReduceTask生成的&lt; key, value&gt;传入OutputFormat的write方法,实现文件的写入操作。</p> </li>
</ol> 
<h3>
<a id="3Shuffle_155"></a>3.Shuffle工作流程（可以只背这部分黑色的）</h3> 
<h5>
<a id="1Map_157"></a>1.Map阶段</h5> 
<p>（1）MapTask处理的结果会暂且放入一个内存缓冲区（默认大小100MB）内，当缓冲区快要溢出时（达到80%），会在本地文件系统创建一个溢出文件，将该缓冲区的数据写入这个文件。(<strong>若MapTask缓冲区将要溢出，则把缓冲区数据写入本地溢出文件</strong>)</p> 
<p>（2）写入磁盘前，线程会根据ReduceTask的数量将数据分区，一个Reduce任务对应一个分区的数据。这样做目的是为了避免有些ruduce任务分配大量数据，而有些reduce任务分到很少的数据，甚至没有分到数据的尴尬局面（<strong>将数据进行分区</strong>）</p> 
<p>（3）分完数据后，会对每个分区的数据进行排序，如果此时设置了Combiner，将排序后的结果进行Combine操作，这样做目的时尽可能少地执行数据写入磁盘的操作。(<strong>对分区数据进行排序，进行Combine操作</strong>)</p> 
<p>（4）当Map任务输出最后一个记录时，可能有很多溢出文件，这时需要将这些文件合并，合并过程中不断地进行排序和Combine操作，其目的有两个：一是尽量减少每次写入磁盘的数据量；二是尽量减少下一复制阶段网络传输的数据量。最后合并成一个已分区且排序的文件(<strong>对溢出文件进行合并，合并时进行排序和Combine操作</strong>)</p> 
<p>（5）将分区数据复制给对应的Reduce任务。</p> 
<h5>
<a id="2Reduce_169"></a>2.Reduce阶段</h5> 
<p>（1）Reduce会接受到不同map任务传来的数据，并且每个map传来的数据都是有序的。如果Reduce阶段接受到的数据量相当小，则直接存储在内存中，如果数据量超过了该缓冲区大小的一定比例，则对数据合并后溢写到磁盘中。<strong>（Reduce接受到的数据量小，存在内存中，否则将数据合并后存在磁盘）</strong></p> 
<p>（2）随着溢写文件的增多，后台线程会将它们合并成一个更大的有序的文件，这样做是为了给后面的合并节省时间。（<strong>后台线程会将溢出文件合并成一个大的有序的文件</strong>）</p> 
<p>（3）合并的过程中产生了许多中间文件（写入磁盘了），但MapReduce会让写入磁盘的数据尽可能地少，并且最后一次合并地结果没有写入磁盘，而是直接输入到reduce函数。</p> 
<h3>
<a id="_177"></a>组件</h3> 
<h4>
<a id="4InputFormat_179"></a>4.InputFormat组件</h4> 
<p>InputFormat组件主要用于描述输入数据的格式，它提供一下两个功能。</p> 
<ul>
<li>数据切分：按照某个策略将输入数据切分成若干个分片，以便确定MapTask个数以及对应的分片。</li>
<li>为Mapper提供输入数据：给定某个分片，将其解析成一个一个的key/value键值对。</li>
</ul> 
<h4>
<a id="5Mapper_186"></a>5.Mapper组件</h4> 
<p><strong>MapReduce程序会根据输入文件产生多个map任务</strong>。Hadoop提供的Mapper类是实现Map任务的一个抽象类，该基类提供了一个map()方法，默认情况下，Mapper类中的map方法是没有做任何处理的。如果想自定义map()方法，只需要继承Mapper类并重写map()方法即可。</p> 
<h4>
<a id="6Reducer_190"></a>6.Reducer组件</h4> 
<p><strong>Map过程输出的键值对，将由Reducer组件进行合并处理</strong>。Hadoop提供了一个抽象类Reducer，<strong>当用户调用Reducer类时，会直接调用Reducer类里的run()方法，该方法中定义了setup()，reduce()，cleanup()三个方法的执行顺序：setup-&gt;reduce-&gt;clean</strong>u<strong>p</strong>。默认情况下，setup()和cleanup()方法内部不做任何处理，reduce()方法是处理数据的核心方法，该方法接受Map阶段输出的键值对数据，对传入的键值对数据进行处理，并产生最终某种形式的结果并输出。</p> 
<h4>
<a id="7Partitoner_194"></a>7.Partitoner组件</h4> 
<p><strong>Partitioner组件可以让Map对Key进行分区，从而根据不同的key分发到不同的Reduce中去处理，其目的是将key均匀分布在ReduceTask上</strong>。Hadoop自带一个默认的分区类HashPartitioner，它继承了Partitioner类，并提供了一个getPartition方法。如果想自定义一个Partitioner组件，需要继承Partitioner类并重写getPartition()方法。重写getPartitioner方法时，通常做法是使用hash函数对文件数量进行分区，即通过hash操作，获得一个非负整数的hash码，然后用当前作业的reduce节点数进行驱魔运算，从而实现数据均匀分布在ReduceTask的目的。</p> 
<h4>
<a id="8Combiner_198"></a>8.Combiner组件</h4> 
<p>在Map阶段输出可能会产生大量相同的数据，势必会降低Reduce聚合阶段的执行效率。<strong>Combiner组件的作用就是对Map阶段的输出的重复数据先做一次合并计算，然后把新的(key,value)作为Reduce阶段的输入</strong>。如果想自定义Combiner，需要继承Reducer类，并且重写reduce()方法。</p> 
<h3>
<a id="9JobTracker_204"></a>9.JobTracker</h3> 
<ul>
<li>概述：<strong>JobTracker是一个后台服务进程，启动之后，会一直监听并接收来自各个TaskTracker发送的心跳信息，包括资源使用情况和任务运行情况等信息。</strong>
</li>
<li>JobTracker的主要功能：<br> 1.<strong>作业控制</strong>：在hadoop中每个应用程序被表示成一个作业，每个作业又被分成多个任务，JobTracker的作业控制模块则负责作业的分解和状态监控。<br> *最重要的是状态监控：主要包括TaskTracker状态监控、作业状态监控和任务状态监控。主要作用：容错和为任务调度提供决策依据。<br> 2.<strong>资源管理</strong>。</li>
</ul> 
<h3>
<a id="10TaskTracker_212"></a>10.TaskTracker：</h3> 
<ul>
<li>TaskTracker概述：<strong>TaskTracker是JobTracker和Task之间的桥梁：一方面，从JobTracker接收并执行各种命令：运行任务、提交任务、杀死任务等；另一方面，将本地节点上各个任务的状态通过心跳周期性汇报给JobTracker。TaskTracker与JobTracker和Task之间采用了RPC协议进行通信。</strong>
</li>
<li>TaskTracker的功能：<br> 1.<strong>汇报心跳</strong>：Tracker周期性将所有节点上各种信息通过心跳机制汇报给JobTracker。这些信息包括两部分：<br> 机器级别信息：节点健康情况、资源使用情况等。<br> 任务级别信息：任务执行进度、任务运行状态等。<br> 2.<strong>执行命令</strong>：JobTracker会给TaskTracker下达各种命令，主要包括：<strong>启动任务</strong>(LaunchTaskAction)、<strong>提交任务</strong>(CommitTaskAction)、<strong>杀死任务</strong>(KillTaskAction)、<br> <strong>杀死作业</strong>(KillJobAction)和<strong>重新初始化</strong>(TaskTrackerReinitAction)。</li>
</ul> 
<h2>
<a id="Zookeeper_221"></a>四、Zookeeper</h2> 
<h3>
<a id="_223"></a>概念解释：</h3> 
<h3>
<a id="1zookeeper_225"></a>1.zookeeper</h3> 
<p><strong>zookeeper是一个分布式协调服务的开源框架，本质上是一个分布式的小文件存储系统，提供基于类似文件系统的目录树方式的数据存储，并且可以对树中的节点进行有效管理，从而用来维护和监控存储的数据的状态变化</strong>。通过监控这些数据状态的变化，从而达到基于数据的集群管理。如同一命名服务、分布式配置管理、分布式消息队列、分布式锁、分布式协调等功能。</p> 
<h3>
<a id="2Znode_229"></a>2.Znode</h3> 
<p>**Zookeeper是由节点组成的树，树中的每个节点被称为Znode树中每个节点被称为都可以拥有子节点。每一个Znode默认能够存储1MB的数据，每个Znode都可以通过其路径唯一标识。**Zookeeper数据模型中的每个Znode都是由3部分组成，分别是stat（状态信息，描述Znode的版本，权限信息等组成）、data（与该Znode关联的数据）和Children（该Znode下的子节点）。</p> 
<h3>
<a id="_233"></a>简答题：</h3> 
<h3>
<a id="3Zookeeper107_235"></a>3.Zookeeper集群选举机制（书上107,如果能理清就可以看，建议不看）</h3> 
<p>这个很多，实在背不下来就写这个黑体，黑体下面就别看了</p> 
<p><strong>Zookeeper选举机制有两种类型，分别为全新集群选举和非全新集群选举。全新集群选举是新搭建起来的，没有数据ID和逻辑时钟的数据影响集群的选举；非全新集群选举时是优中选优，保证Leader是Zookeeper集群中数据最完整、最可靠的一台服务器。</strong></p> 
<p>首先明白几个概念：</p> 
<p>服务器ID：每个服务器都有不同的ID，假设我们有服务器1，服务器2，服务器3，数字编号越大当选leader的权重越大。</p> 
<p>选举状态：每个Zookerper服务器都有4种状态，分别为竞选状态（LOOKING）、随从状态（FOLLOWING,同步leader状态，参与投票），观察状态（OBSERVING,同步leader状态，不参与投票）和领导者状态（LEADING）。</p> 
<p>数据ID：代表服务器中存放的最新数据版本号，值越大说明数据越新。</p> 
<p>逻辑时钟：投票次数。起始值为0，每投完一次票，这个数据就会增加。然后与接收到其他服务器返回的投票信息中的数值相比较，根据不同的值做出不同判断。</p> 
<h4>
<a id="_251"></a>全新集群选举：</h4> 
<p>假设现在有5台服务器均没有数据，它们的编号分别是1，2，3，4，5，按编号依次启动。过程如下：</p> 
<ol>
<li>服务器 1 启动，给自己投票，然后发投票信息给其他服务器，由于其他服务器没有启动，所以它收不到反馈信息，但是由于投票还没有到达半数（服务器 1 怎么知道一共有多少台服务器参与选举呢， 那是因为在zk配置文件中配置了集群信息，所有配置了3888端口的服务器均会参与投票，假设这5台都参与投票，则超过半数应为至少3台服务器参与投票。），所以服务器 1 的状态一直处于 LOOKING。</li>
<li>服务器 2 启动， 给自己投票，然后与其他服务投票信息交换结果， 由于服务器 2 的编号大于服务器 1， 所以服务器 2 胜出，但是由于投票仍未到达半数，所以服务器 2 同样处于 LOOKING 状态。</li>
<li>服务器 3 启动， 给自己投票，然后与其他服务投票信息交换结果， 由于服务器 3 的编号大于服务器 2，1，所以服务器 3胜出， 并且此时投票数正好大于半数， 所以选举结束，服务器 3 处于LEADING 状态， 服务器 1， 服务器 2 处于 FOLLOWING 状态。</li>
<li>服务器 4 启动， 给自己投票， 同时与之前的服务器 1 ，2，3交换信息，尽管服务器 4 的编号最大，但之前服务器 3 已经胜出，所以服务器 4 只能处于 FOLLOWING 状态。</li>
<li>服务器 5 启动， 同上。FOLLOWING状态。</li>
<li>整个zookeeper集群启动以后，领导者就使用2888端口向从属机开始通信。</li>
</ol> 
<h4>
<a id="_262"></a>非全新集群选举：</h4> 
<p>对于运行正常的zookeeper集群，中途有机器down掉，需要重新选举时，选举过程就需要加入数据ID、服务器ID、和逻辑时钟。</p> 
<p>这样选举就变成：</p> 
<ol>
<li>逻辑时钟小的选举结果被忽略，重新投票；（除去选举次数不完整的服务器）</li>
<li>统一逻辑时钟后，数据id大的胜出；（选出数据最新的服务器）</li>
<li>数据id相同的情况下，服务器id大的胜出。（数据相同的情况下， 选择服务器id最大，即权重最大的服务器）</li>
</ol> 
<h3>
<a id="4Watch_274"></a>4.Watch机制</h3> 
<p><strong>在ZooKeeper中，引入了Watch机制来实现这种分布式的通知功能。ZooKeeper允许客户端向服务端注册一个Watch监听，当服务端的一些事件触发了这个Watch，那么就会向指定客户端发送一个事件通知，来实现分布式的通知功能。</strong></p> 
<p>特点：</p> 
<ul>
<li>一次性触发</li>
<li>事件封装</li>
<li>异步发送</li>
<li>先注册再触发</li>
</ul> 
<h2>
<a id="Hive_285"></a>五、Hive</h2> 
<h3>
<a id="_287"></a>概念解释：</h3> 
<h3>
<a id="1Hive_289"></a>1.Hive</h3> 
<p>Hive是建立在Hadoop文件系统上的数据仓库，它提供了一系列工具，能够对存储再HDFS中的数据进行数据提取、转换和加载，这是一种可以存储、查询和分析存储再Hadoop中的大规模数据的工具</p> 
<h3>
<a id="2HQL_293"></a>2.HQL</h3> 
<p><strong>Hive定义了简单的类SQL查询语言，称为HQL，它可以将结构化的数据文件映射为一张数据表，允许熟悉SQL的用户查询数据，也允许熟悉MapReduce的开发者开发自定义的mapper和reducer来处理复杂的分析工作</strong>，相对于Java代码编写的MapReduce来说，Hive的优势更明显。</p> 
<h3>
<a id="3_297"></a>3.星状模型</h3> 
<p>在数据仓库建模中，形状模型是维度建模中的一种选择方式。<strong>星状模型是由一个事实表和维度表组合而成，并且以事实表为中心，所有的维度表直接与事实表相连</strong>。如下图所示，所有的维度表都直接连接到事实表中，作为事实表与维度表连接的外键，因此维度表和事实表是有关联的，然而，维度表与维度表并没有直接相连，因此，<strong>维度表之间是并没有关联的</strong>。<br> <img src="https://images2.imgbox.com/ce/72/pEqNFwAe_o.png" alt="在这里插入图片描述"></p> 
<h3>
<a id="4_303"></a>4.雪花模型</h3> 
<p><strong>雪花模型也是维度建模的另一种选择，它是对星状模型的拓展，如下图所示，雪花模型的维度表可以拥有其他的维度表，并且维度表与维度表之间相互关联的</strong>。因此，雪花模型相比星状模型更规范一些。但是，由于雪花模型需要关联多层的维度表，因此，<strong>性能也比星状模型要低</strong>，所以一般不是很常用。<br> <img src="https://images2.imgbox.com/d7/f9/gXtx2Rnt_o.png" alt="在这里插入图片描述"></p> 
<h3>
<a id="5_308"></a>5.桶表</h3> 
<p>简单来说，桶表就是把“大表”分成了“小表”。把表或者分区组织成桶表的目的主要是为了获得更高的查询效率，尤其是抽象查询更为便捷。桶表是Hive数据模型的最小单元，数据加载到桶表时，会对字段的值进行Hash取值，然后除以桶个数得到余数进行分桶，保证每个桶中都有数据，在物理上，每个桶表就是表或分区的一个文件。</p> 
<h3>
<a id="_312"></a>简答题</h3> 
<h3>
<a id="6Hive_314"></a>6.Hive的特点是什么</h3> 
<ul>
<li>可扩展：Hive可以自由的扩展集群的规模，一般情况下不需要重启服务。</li>
<li>延展性：Hive支持用户自定义函数，用户可以根据自己的需求来实现自己的函数。</li>
<li>容错：良好的容错性，节点出现问题SQL仍可完成执行。</li>
</ul> 
<h2>
<a id="Flume_319"></a>六、Flume</h2> 
<h3>
<a id="_321"></a>概念解释</h3> 
<h3>
<a id="1Source_323"></a>1.Source</h3> 
<p>Source（数据采集器）：用于源数据的采集，然后将采集到的数据写入到Channel并流向Sink。</p> 
<h3>
<a id="2Channel_327"></a>2.Channel</h3> 
<p>Channel（缓冲通道）：<strong>底层是一个缓冲队列，对Source中的数据进行缓存，将数据高效，准确地写入Sink</strong>，待数据全部到达Sink后，Flume就会删除该缓存通道中的数据</p> 
<h3>
<a id="3Sink_331"></a>3.Sink</h3> 
<p>Sink（接收器）：接受并汇集向Sink的所有数据，根据需求，可以直接进行集中式存储，也可以继续作为数据源传入其他远程服务器或者Source中。</p> 
<h3>
<a id="4Flume_335"></a>4.Flume拦截器</h3> 
<p>主要用于实现对Flume系统数据流中event的修改操作，常用的Flume拦截器有 时间拦截器、静态拦截器和查询和替换拦截器</p> 
<h3>
<a id="_339"></a>简答题</h3> 
<h3>
<a id="5Flume_341"></a>5.Flume的工作原理</h3> 
<p>Flume的核心是把数据源（如 Web Server）通过数据采集器（Source）收集过来，再将收集的数据通过缓冲通道（Channel）汇集到指定的接收器(Sink)。</p> 
<h2>
<a id="Azkaban_345"></a>七、Azkaban</h2> 
<h3>
<a id="_347"></a>概念解释：</h3> 
<h3>
<a id="Azkaban_349"></a>Azkaban</h3> 
<p>开源的一个批量工作流任务调度器，用于在一个工作流内以一个特定的顺序运行运行一组工作和流程。定义了一种KV文件格式来建立任务之间的依赖关系，并提供一个易于使用的UI维护和跟踪工作流</p> 
<h2>
<a id="Sqoop_353"></a>八、Sqoop</h2> 
<h3>
<a id="_355"></a>概念解释：</h3> 
<h3>
<a id="Sqoop_357"></a>Sqoop</h3> 
<p>–是一款开源工具，主要用于在Hadoop和关系型数据库或大型机器之间传输数据，可以使用Sqoop工具将数据从关系数据库系统导入Hadoop分布式文件系统中，或者将Hadoop中的数据转换导出到关系数据库管理系统</p> 
<h2>
<a id="_361"></a>论述题</h2> 
<h3>
<a id="1HDFS_363"></a>1.HDFS不适合应用的场景有哪些</h3> 
<ul>
<li>
<strong>不能做到低延迟数据访问</strong>：由于hadoop针对高数据吞吐量做了优化，牺牲了获取数据的延迟，所以对于低延迟访问数据的业务需求不适合HDFS。</li>
<li>
<strong>不适合大量的小文件存储</strong> ：对于Hadoop系统，小文件通常定义为远小于HDFS的数据块大小（128MB）的文件，由于每个文件都会产生各自的元数据，Hadoop通过NameNode来存储这些信息，若小文件过多，容易导致NameNode存储出现瓶颈。</li>
<li>
<strong>不支持用户的并行写</strong>：HDFS目前不支持并发多用户的写操作，写操作只能在文件末尾追加数据。</li>
</ul> 
<h3>
<a id="Sqoop_369"></a>Sqoop导入导出数据的工作原理是什么</h3> 
<ul>
<li>
<strong>导入原理</strong>：Sqoop使用JDBC检查打入的数据表，检索出表中的所有列及列的SQL数据类型，并将这些SQL类型映射为JAVA数据类型，在转换后的MapReduce应用中使用这些对应的Java类型来保存字段的值，Sqoop的代码生成器使用这些信息来创建对象表的类，用于保存从表中抽取的记录。</li>
<li>
<strong>导出原理</strong>：在导出数据之前Sqoop会根据数据库连接字符串来选择一个导出方法，对于大部分系统来说，Sqoop会选择JDBC。Sqoop会根据目标表的定义生成一个Java类，这个生成的类能够从文本中解析出记录数据，并能够向表中插入类型合适的值，然后启动一个MapReduce作业，从HDFS中读取源数据文件，使用生成的类解析出记录，并且执行选定的导出方法</li>
</ul> 
<h3>
<a id="2Hadoop_374"></a>2.基于Hadoop的大数据分析过程与传统数据分析相比特点有哪些，有何不同</h3> 
<ol>
<li>成本降低，能用PC机，就不用大型机和高端存储</li>
<li>软件容错硬件故障视为常态，通过软件保证可靠性</li>
<li>简化并行分布式计算，无须控制节点同步和数据交换</li>
</ol> 
<h3>
<a id="3_380"></a>3.大数据研究的意义是什么，理由。</h3> 
<p>研究大数据，最重要的意义在于预测。因为数据从根本上来讲，是对过去和现在的归纳和总结，其本身不具备趋势和方向性的特征，但是可以应用大数据去了解事物发展的客观规律、了解人类行为，并且能够帮助我们改变过去的思维方式，建立新的数据思维模式，从而对未来进行预测和推测。</p> 
<h3>
<a id="4Hadoop_384"></a>4.Hadoop的组件有哪些，结构分别是什么，特点是什么</h3> 
<h4>
<a id="_386"></a>四大组件：</h4> 
<h5>
<a id="MapReduce_388"></a>MapReduce</h5> 
<p>结构：由一个JobTracker和多个DateNode组成。</p> 
<p>特点：“分而治之”，将海量数据分解成多个任务进行处理。</p> 
<h5>
<a id="HDFS_394"></a>HDFS</h5> 
<p>结构：由一个NameNode和多个DataNode组成</p> 
<p>特点：高容错性的数据备份机制</p> 
<h5>
<a id="Yarn_400"></a>Yarn</h5> 
<p>结构：由ResourceManager和ApplicationMaster实现</p> 
<p>特点：通用</p> 
<h5>
<a id="Others_406"></a>Others(其他工具类)</h5> 
<p>特点：提供服务，提供API</p> 
<h3>
<a id="5HadoopHadoop_410"></a>5.Hadoop集群的特点是什么，分布式系统给Hadoop带来什么特性</h3> 
<h4>
<a id="_412"></a>集群特点</h4> 
<ul>
<li>扩容能力强</li>
<li>成本低</li>
<li>高效率</li>
<li>可靠性</li>
<li>高容错性</li>
</ul> 
<h4>
<a id="_420"></a>分布式系统特性</h4> 
<h5>
<a id="_422"></a>优点：</h5> 
<ul>
<li>高容错</li>
<li>流式数据访问</li>
<li>支持超大文件</li>
<li>高数据吞吐量</li>
<li>可构建在廉价机器上</li>
</ul> 
<h5>
<a id="_430"></a>缺点：</h5> 
<ul>
<li>高延迟</li>
<li>不适合小文件存取场景</li>
<li>不适合并发写入</li>
</ul> 
<h3>
<a id="6Hadoop_436"></a>6.总结Hadoop集群部署的过程，分为哪些步骤</h3> 
<ol>
<li>JDK安装</li>
<li>Hadoop安装</li>
<li>Hadoop集群配置</li>
</ol> 
<p>​ (1) 在hadoop-env.sh文件中<strong>配置JAVA_HOME参数</strong></p> 
<p>​ (2) 在core-site.xml文件中<strong>配置HDFS地址、端口号以及临时文件目录</strong></p> 
<p>​ (3) 在hdfs-site.xml文件中<strong>设置NameNode和DataNode两大进程</strong></p> 
<p>​ (4) 在mapred-site.xml文件中<strong>指定MapReduce运行时框架</strong></p> 
<p>​ (5) 在yarn-site.xml文件中<strong>指定YARN集群管理者</strong></p> 
<p>​ (6) 修改slaves文件<strong>记录从节点主机名</strong></p> 
<p>​ (7) <strong>将配置文件分发到子节点</strong></p> 
<h3>
<a id="7Hadoop_456"></a>7.与普通集群相比，Hadoop高可用集群有哪些特殊之处，两者有何不同</h3> 
<h4>
<a id="_458"></a>普通集群</h4> 
<ul>
<li>并发量差</li>
<li>容错性差(不具有高可用性)</li>
</ul> 
<p>注：不具有高可用性的意思是，比如当用户访问时，服务器后台因为一些原因导致服务器崩溃，用户就能直接看到错误页面，服务器也因为错误从而停止运行(宕机)，这就叫做不具有高可用性。</p> 
<h4>
<a id="Hadoop7_465"></a>Hadoop集群（详情见书第7页，具体内容可以背点）</h4> 
<ul>
<li>扩容能力强</li>
<li>成本低</li>
<li>高效率</li>
<li>可靠性</li>
<li>高容错性</li>
</ul>
                </div>
                
                

		</div>
	</article>
</main>




			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程小白.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://www.w3counter.com/tracker.js?id=150625"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>
	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>