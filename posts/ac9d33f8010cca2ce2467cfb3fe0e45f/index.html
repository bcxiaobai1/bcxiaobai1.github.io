<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<title>基于深度学习的水果检测与识别系统（Python界面版，YOLOv5实现） - 编程小白</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程小白" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程小白</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">基于深度学习的水果检测与识别系统（Python界面版，YOLOv5实现）</h1>
			
		</header>
		<div class="content post__content clearfix">
			


        
                <div id="content_views" class="markdown_views prism-tomorrow-night">
                    
                        
                    
                    <p><font face="微软雅黑">摘要：本博文介绍了一种基于深度学习的水果检测与识别系统，使用YOLOv5算法对常见水果进行检测和识别，实现对图片、视频和实时视频中的水果进行准确识别。博文详细阐述了算法原理，同时提供Python实现代码、训练数据集，以及基于PyQt的UI界面。通过YOLOv5实现对图像中存在的多个水果目标进行识别分类，用户可以在界面中选择各种水果图片、视频进行检测识别。本文旨在为相关领域的研究人员和新入门的朋友提供一个参考，完整代码资源文件请转至文末的下载链接。本文结构如下：</font></p> 
<p></p> 
<div class="toc"> 
 <h3>文章目录</h3> 
 <ul>
<li><a href="#font_face_size5font_13"><font face="华文行楷" size="5">前言</font></a></li>
<li><a href="#font_face_size51_font_27"><font face="华文行楷" size="5">1. 系统界面演示效果</font></a></li>
<li><a href="#font_face_size52_font_49"><font face="华文行楷" size="5">2. 算法原理介绍</font></a></li>
<li><a href="#font_face_size53_font_66"><font face="华文行楷" size="5">3. 数据集与预处理</font></a></li>
<li><a href="#font_face_size55_font_83"><font face="华文行楷" size="5">5. 系统实现</font></a></li>
<li>
<ul>
<li><a href="#font_face_size551_Pythonfont_85"><font face="楷体" size="5">5.1 Python实现</font></a></li>
<li><a href="#font_face_size552_PyQtfont_190"><font face="楷体" size="5">5.2 PyQt界面设计</font></a></li>
</ul> 
  </li>
<li><a href="#font_face_size56_font_221"><font face="华文行楷" size="5">6. 实验结果与分析</font></a></li>
<li><a href="#font_face_size5__colorff4500font_242"><font face="华文行楷" size="5" color="#ff4500">下载链接</font></a></li>
<li><a href="#font_face_size5font_286"><font face="华文行楷" size="5">结束语</font></a></li>
<li><a href="#font_face_size5font_291"><font face="华文行楷" size="5">参考文献</font></a></li>
</ul> 
</div> 
<p></p> 
<p></p> 
<div class="csdn-video-box"> 
  
 <p>水果检测与识别系统功能演示与介绍（YOLOv5+PyQt5+UI界面）</p> 
</div> 
<p></p> 
<p><a href="#i1"><font face="楷体" size="5">➷点击跳转至文末所有涉及的<strong>完整代码文件</strong>下载页☇</font></a></p> 
<hr> 
<h1>
<a id="font_face_size5font_13"></a><font face="华文行楷" size="5">前言</font>
</h1> 
<p><font face="微软雅黑">        近年来，随着全球经济的发展，水果消费市场规模不断扩大，水果种类也日益丰富。水果检测与识别技术在农业生产、仓储物流、超市零售等领域具有重要的应用价值。传统的水果检测与识别方法主要依赖于人工识别，这种方法在一定程度上受到人力成本、识别效率和准确性等方面的限制。因此，开发一种高效、准确的自动化水果检测与识别系统具有重要的研究意义和实际价值。（<strong>本文的参考文献请见文末</strong>）</font></p> 
<p><font face="微软雅黑">        计算机视觉作为人工智能的一个重要分支，在目标检测和识别方面取得了显著的研究进展。特别是深度学习技术的发展，极大地推动了计算机视觉在水果检测与识别领域的应用。许多研究人员已经尝试利用深度学习技术进行水果检测与识别，取得了一定的成果[1]。然而，当前的研究仍然存在一定的局限性，如算法复杂度高、实时性差等问题。</font></p> 
<p><font face="微软雅黑">        在计算机视觉领域，已有多种深度学习算法被应用于目标检测和识别任务。例如，R-CNN[2]、Fast R-CNN[3]、Faster R-CNN[4]、SSD[5]、RetinaNet[6]等。这些算法在一定程度上提高了目标检测的准确性和速度。然而，这些算法仍然存在一定的局限性，如计算复杂度高、实时性差等。为了解决这些问题，研究人员提出了YOLO（You Only Look Once）算法[7]，该算法采用端到端的训练方式，能够在保持较高检测准确性的同时实现实时检测。YOLO算法自2016年首次提出以来，经历了多次改进，如YOLOv2[8]、YOLOv3[9]、YOLOv4[10]等，每个版本都在前一个版本的基础上提高了检测准确性和速度。针对水果检测与识别任务，有研究人员尝试将深度学习技术应用于该领域。例如，使用Faster R-CNN进行苹果检测[11]，采用Mask R-CNN实现对葡萄的实例分割[12]，以及利用SSD进行柑橘检测[13]等。这些研究表明深度学习技术在水果检测与识别任务上具有很大的前景。</font></p> 
<p><font face="微软雅黑">        在本博文中，我们提出了一种基于深度学习的水果检测与识别系统，该系统采用YOLOv5算法对常见水果进行检测和识别，实现对图片、视频和实时视频中的水果进行准确识别。YOLOv5[14]作为YOLO系列算法的最新版本，在保持实时性的同时，进一步提高了检测准确性。与其他目标检测算法相比，YOLOv5具有较高的性能和较低的计算复杂度，因此适合应用于水果检测与识别任务。</font></p> 
<p><font face="微软雅黑">        本文的主要贡献包括：（1）介绍了一种基于YOLOv5的水果检测与识别系统；（2）详细描述了算法原理，提供了Python实现代码以及训练数据集；（3）展示了基于PyQt的UI界面设计，并分析了训练和评估结果等实验。本文旨在为相关领域的研究人员和新入门的朋友提供一个参考。</font></p> 
<hr> 
<h1>
<a id="font_face_size51_font_27"></a><font face="华文行楷" size="5">1. 系统界面演示效果</font>
</h1> 
<p><font face="微软雅黑">        在本节中，我们将展示系统的界面效果。通过演示界面效果，可以帮助读者更好地理解整个水果检测与识别系统的工作流程，同时也有利于展示系统的功能和易用性。下面我们将通过图片和描述来展示系统的界面效果，本系统具有以下主要功能：</font></p> 
<p><font face="微软雅黑">（1）用户登录注册：支持用户进行注册和登录。</font></p> 
<p><img src="https://images2.imgbox.com/61/dc/WbkbWwg7_o.png" alt="在这里插入图片描述" width="400"></p> 
<p><font face="微软雅黑">（2）选择图片识别：用户可以上传单张图片进行水果检测与识别，系统将识别出图片中的水果并显示相应的类别和置信度。</font></p> 
<p><img src="https://images2.imgbox.com/29/22/VbSvY6GJ_o.png" alt="在这里插入图片描述" width="600"></p> 
<p><font face="微软雅黑">（3）视频识别：用户可以上传视频文件进行水果检测与识别，系统将实时识别视频中的水果并显示相应的类别和置信度。</font></p> 
<p><img src="https://images2.imgbox.com/fc/46/PGn9kFVk_o.png" alt="在这里插入图片描述" width="600"></p> 
<p><font face="微软雅黑">（4）摄像头识别：用户可以使用摄像头进行实时水果检测与识别，系统将捕捉摄像头图像并实时识别出水果，显示相应的类别和置信度。</font></p> 
<p><img src="https://images2.imgbox.com/d7/54/8Z3Hkh8x_o.png" alt="在这里插入图片描述" width="600"><br> <font face="微软雅黑">（5）更换模型和修改文字图标：用户可以点击右侧的模型选择按钮更换不同的模型，对于界面中的文字和图标的修改请参考文末的介绍。</font></p> 
<hr> 
<h1>
<a id="font_face_size52_font_49"></a><font face="华文行楷" size="5">2. 算法原理介绍</font>
</h1> 
<p><font face="微软雅黑">        本系统采用了基于深度学习的目标检测算法YOLOv5，该算法是YOLO系列算法的最新版本，相比于YOLOv3和YOLOv4，YOLOv5在检测精度和速度上都有很大的提升。YOLOv5算法的核心思想是将目标检测问题转化为一个回归问题。YOLOv5使用一种称为“Anchor Free”的方法来代替传统目标检测算法中的Anchor框，通过直接预测物体中心点的坐标来代替Anchor框。此外，YOLOv5还引入了一种称为SPP(Spatial Pyramid Pooling)的特征提取方法，这种方法可以在不增加计算量的情况下，有效地提取多尺度特征，提高检测性能。</font></p> 
<p><font face="微软雅黑">        在YOLOv5中，首先将输入图像通过骨干网络进行特征提取，得到一系列特征图。然后，通过对这些特征图进行处理，将其转化为一组检测框和相应的类别概率分数，即每个检测框所属的物体类别以及该物体的置信度。YOLOv5中的特征提取网络使用CSPNet(Cross Stage Partial Network)结构，它将输入特征图分为两部分，一部分通过一系列卷积层进行处理，另一部分直接进行下采样，最后将这两部分特征图进行融合。这种设计使得网络具有更强的非线性表达能力，可以更好地处理目标检测任务中的复杂背景和多样化物体。</font></p> 
<p><img src="https://images2.imgbox.com/71/b2/OlWmwaOp_o.png" alt="在这里插入图片描述" width="700"></p> 
<p><font face="微软雅黑">        在YOLOv5中，每个检测框由其左上角坐标(x,y)、宽度(w)、高度(h)和置信度(confidence)组成。同时，每个检测框还会预测C个类别的概率得分，即分类得分(ci)，每个类别的得分之和等于1。因此，每个检测框最终被表示为一个(C+5)维的向量。在训练阶段，YOLOv5使用交叉熵损失函数来优化模型。损失函数由定位损失、置信度损失和分类损失三部分组成，其中定位损失和置信度损失采用了Focal Loss和IoU Loss等优化方法，能够有效地缓解正负样本不平衡和目标尺寸变化等问题。&lt;/font</font></p> 
<p><font face="微软雅黑">         YOLOv5网络结构是由Input、Backbone、Neck、Prediction组成。Yolov5的Input部分是网络的输入端，采用Mosaic数据增强方式，对输入数据随机裁剪，然后进行拼接。Backbone是Yolov5提取特征的网络部分，特征提取能力直接影响整个网络性能。YOLOv5的Backbone相比于之前Yolov4提出了新的Focus结构。Focus结构是将图片进行切片操作，将W（宽）、H（高）信息转移到了通道空间中，使得在没有丢失任何信息的情况下，进行了2倍下采样操作。博主觉得YOLOv5不失为一种目标检测的高性能解决方案，能够以较高的准确率对海洋动物进行分类与定位。当然现在YOLOv6、YOLOv7、YOLOv8等算法也在不断提出和改进，等其代码版本成熟后博主也会再设计本系统的算法，敬请期待。</font></p> 
<p><img src="https://images2.imgbox.com/08/86/BstG6g4q_o.png" alt="在这里插入图片描述" width="500"></p> 
<hr> 
<h1>
<a id="font_face_size53_font_66"></a><font face="华文行楷" size="5">3. 数据集与预处理</font>
</h1> 
<p><font face="微软雅黑">        在水果识别领域有一些数据集如<a href="https://www.sciencedirect.com/science/article/pii/S0168169920300624">Perez-Borrero I, Marin-Santos D, Gegundez-Arias M E, et al. A fast and accurate deep learning method for strawberry instance segmentation[J]. Computers and Electronics in Agriculture, 2020, 178: 105736</a>，如下图所示。</font></p> 
<p><img src="https://images2.imgbox.com/af/d4/SEEsb1M7_o.png" alt="在这里插入图片描述" width="400"><br> <font face="微软雅黑">        还有<a href="https://github.com/laboroai/LaboroTomato">Laboro Tomato</a>数据集，也可参考这篇文章<a href="https://www.sciencedirect.com/science/article/pii/S0168169922008250#b0090">Real-time fruit detection using deep neural networks on CPU (RTFD): An edge AI application</a>，包括介绍和算法都可以参考。</font></p> 
<p><img src="https://images2.imgbox.com/35/39/uqF9aJ5J_o.png" alt="在这里插入图片描述" width="500"></p> 
<p><font face="微软雅黑">        本系统使用的水果检测数据集Fruit Detection Dataset，手动标注了包含苹果、香蕉、火龙果、番石榴、橙子、梨、菠萝、释迦果等8个类别的水果，共计3030张图片。该数据集中每个类别的水果都有大量的旋转和不同的光照条件，有助于训练出更加鲁棒的检测模型。本文实验的水果检测识别数据集包含训练集2424张图片，验证集303张图片，测试集303张图片，选取部分数据部分样本数据集如图所示。</font></p> 
<p><img src="https://images2.imgbox.com/b6/15/OHRt6y00_o.jpg" alt="在这里插入图片描述" width="400"><br> <font face="微软雅黑">        由于YOLOv5算法对输入图片大小有限制，需要将所有图片调整为相同的大小。为了在不影响检测精度的情况下尽可能减小图片的失真，我们将所有图片调整为640x640的大小，并保持原有的宽高比例。此外，为了增强模型的泛化能力和鲁棒性，我们还使用了数据增强技术，包括随机旋转、缩放、裁剪和颜色变换等，以扩充数据集并减少过拟合风险。</font></p> 
<hr> 
<h1>
<a id="font_face_size55_font_83"></a><font face="华文行楷" size="5">5. 系统实现</font>
</h1> 
<h2>
<a id="font_face_size551_Pythonfont_85"></a><font face="楷体" size="5">5.1 Python实现</font>
</h2> 
<p><font face="微软雅黑">        本系统的深度学习模型使用PyTorch实现，基于YOLOv5算法进行目标检测。在训练阶段，我们使用了预训练模型作为初始模型进行训练，然后通过多次迭代优化网络参数，以达到更好的检测性能。在训练过程中，我们采用了学习率衰减和数据增强等技术，以增强模型的泛化能力和鲁棒性。</font></p> 
<p><font face="微软雅黑">        在测试阶段，我们使用了训练好的模型来对新的图片、视频和实时视频流进行检测。通过设置阈值，将置信度低于阈值的检测框过滤掉，最终得到检测结果。同时，我们还可以将检测结果保存为图片或视频格式，以便进行后续分析和应用。本系统基于YOLOv5算法，使用PyTorch实现。代码中用到的主要库包括PyTorch、NumPy、OpenCV、PyQt等。实现过程中，我们首先需要导入所需的库和模块：</font></p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> argparse
<span class="token keyword">import</span> random

<span class="token keyword">import</span> cv2
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> torch

<span class="token keyword">from</span> models<span class="token punctuation">.</span>experimental <span class="token keyword">import</span> attempt_load
<span class="token keyword">from</span> utils<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> letterbox
<span class="token keyword">from</span> utils<span class="token punctuation">.</span>general <span class="token keyword">import</span> non_max_suppression<span class="token punctuation">,</span> check_img_size<span class="token punctuation">,</span> scale_coords
<span class="token keyword">from</span> utils<span class="token punctuation">.</span>torch_utils <span class="token keyword">import</span> time_synchronized<span class="token punctuation">,</span> select_device
</code></pre> 
<p><font face="微软雅黑">        然后，我们需要定义一些函数，其中predict()函数用于实现图片的预测推理；cv_imread()函数用于读取图片；plot_one_box()函数用于绘制预测框。</font></p> 
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">predict</span><span class="token punctuation">(</span>img<span class="token punctuation">)</span><span class="token punctuation">:</span>
    img <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>img<span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
    img <span class="token operator">=</span> img<span class="token punctuation">.</span>half<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">if</span> half <span class="token keyword">else</span> img<span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    img <span class="token operator">/=</span> <span class="token number">255.0</span>
    <span class="token keyword">if</span> img<span class="token punctuation">.</span>ndimension<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">3</span><span class="token punctuation">:</span>
        img <span class="token operator">=</span> img<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>

    t1 <span class="token operator">=</span> time_synchronized<span class="token punctuation">(</span><span class="token punctuation">)</span>
    pred <span class="token operator">=</span> model<span class="token punctuation">(</span>img<span class="token punctuation">,</span> augment<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
    pred <span class="token operator">=</span> non_max_suppression<span class="token punctuation">(</span>pred<span class="token punctuation">,</span> opt<span class="token punctuation">.</span>conf_thres<span class="token punctuation">,</span> opt<span class="token punctuation">.</span>iou_thres<span class="token punctuation">,</span> classes<span class="token operator">=</span>opt<span class="token punctuation">.</span>classes<span class="token punctuation">,</span>
                               agnostic<span class="token operator">=</span>opt<span class="token punctuation">.</span>agnostic_nms<span class="token punctuation">)</span>
    t2 <span class="token operator">=</span> time_synchronized<span class="token punctuation">(</span><span class="token punctuation">)</span>
    InferNms <span class="token operator">=</span> <span class="token builtin">round</span><span class="token punctuation">(</span><span class="token punctuation">(</span>t2 <span class="token operator">-</span> t1<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>

    <span class="token keyword">return</span> pred<span class="token punctuation">,</span> InferNms


<span class="token keyword">def</span> <span class="token function">cv_imread</span><span class="token punctuation">(</span>filePath<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># 读取图片</span>
    cv_img <span class="token operator">=</span> cv2<span class="token punctuation">.</span>imdecode<span class="token punctuation">(</span>np<span class="token punctuation">.</span>fromfile<span class="token punctuation">(</span>filePath<span class="token punctuation">,</span> dtype<span class="token operator">=</span>np<span class="token punctuation">.</span>uint8<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>

    <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>cv_img<span class="token punctuation">.</span>shape<span class="token punctuation">)</span> <span class="token operator">&gt;</span> <span class="token number">2</span><span class="token punctuation">:</span>
        <span class="token keyword">if</span> cv_img<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span> <span class="token operator">&gt;</span> <span class="token number">3</span><span class="token punctuation">:</span>
            cv_img <span class="token operator">=</span> cv_img<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token number">3</span><span class="token punctuation">]</span>
    <span class="token keyword">return</span> cv_img


<span class="token keyword">def</span> <span class="token function">plot_one_box</span><span class="token punctuation">(</span>img<span class="token punctuation">,</span> x<span class="token punctuation">,</span> color<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> line_thickness<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># Plots one bounding box on image img</span>
    tl <span class="token operator">=</span> line_thickness <span class="token keyword">or</span> <span class="token builtin">round</span><span class="token punctuation">(</span><span class="token number">0.002</span> <span class="token operator">*</span> <span class="token punctuation">(</span>img<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">+</span> img<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">2</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">1</span>  <span class="token comment"># line/font thickness</span>
    color <span class="token operator">=</span> color <span class="token keyword">or</span> <span class="token punctuation">[</span>random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">255</span><span class="token punctuation">)</span> <span class="token keyword">for</span> _ <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
    c1<span class="token punctuation">,</span> c2 <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token builtin">int</span><span class="token punctuation">(</span>x<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token builtin">int</span><span class="token punctuation">(</span>x<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token builtin">int</span><span class="token punctuation">(</span>x<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token builtin">int</span><span class="token punctuation">(</span>x<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    cv2<span class="token punctuation">.</span>rectangle<span class="token punctuation">(</span>img<span class="token punctuation">,</span> c1<span class="token punctuation">,</span> c2<span class="token punctuation">,</span> color<span class="token punctuation">,</span> thickness<span class="token operator">=</span>tl<span class="token punctuation">,</span> lineType<span class="token operator">=</span>cv2<span class="token punctuation">.</span>LINE_AA<span class="token punctuation">)</span>
    <span class="token keyword">if</span> label<span class="token punctuation">:</span>
        tf <span class="token operator">=</span> <span class="token builtin">max</span><span class="token punctuation">(</span>tl <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>  <span class="token comment"># font thickness</span>
        t_size <span class="token operator">=</span> cv2<span class="token punctuation">.</span>getTextSize<span class="token punctuation">(</span>label<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> fontScale<span class="token operator">=</span>tl <span class="token operator">/</span> <span class="token number">3</span><span class="token punctuation">,</span> thickness<span class="token operator">=</span>tf<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
        c2 <span class="token operator">=</span> c1<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">+</span> t_size<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> c1<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">-</span> t_size<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">-</span> <span class="token number">3</span>
        cv2<span class="token punctuation">.</span>rectangle<span class="token punctuation">(</span>img<span class="token punctuation">,</span> c1<span class="token punctuation">,</span> c2<span class="token punctuation">,</span> color<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> cv2<span class="token punctuation">.</span>LINE_AA<span class="token punctuation">)</span>  <span class="token comment"># filled</span>
        cv2<span class="token punctuation">.</span>putText<span class="token punctuation">(</span>img<span class="token punctuation">,</span> label<span class="token punctuation">,</span> <span class="token punctuation">(</span>c1<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> c1<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">-</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> tl <span class="token operator">/</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">225</span><span class="token punctuation">,</span> <span class="token number">255</span><span class="token punctuation">,</span> <span class="token number">255</span><span class="token punctuation">]</span><span class="token punctuation">,</span> thickness<span class="token operator">=</span>tf<span class="token punctuation">,</span> lineType<span class="token operator">=</span>cv2<span class="token punctuation">.</span>LINE_AA<span class="token punctuation">)</span>


<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>
    img_path <span class="token operator">=</span> <span class="token string">"./UI_rec/test_/b-1459-_jpg.rf.06e32fd1fbee5a10c776e1e63237904f.jpg"</span>
    image <span class="token operator">=</span> cv_imread<span class="token punctuation">(</span>img_path<span class="token punctuation">)</span>
    image <span class="token operator">=</span> cv2<span class="token punctuation">.</span>resize<span class="token punctuation">(</span>image<span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">850</span><span class="token punctuation">,</span> <span class="token number">500</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    img0 <span class="token operator">=</span> image<span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token punctuation">)</span>
    img <span class="token operator">=</span> letterbox<span class="token punctuation">(</span>img0<span class="token punctuation">,</span> new_shape<span class="token operator">=</span>imgsz<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
    img <span class="token operator">=</span> np<span class="token punctuation">.</span>stack<span class="token punctuation">(</span>img<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span>
    img <span class="token operator">=</span> img<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>  <span class="token comment"># BGR to RGB, to 3x416x416</span>
    img <span class="token operator">=</span> np<span class="token punctuation">.</span>ascontiguousarray<span class="token punctuation">(</span>img<span class="token punctuation">)</span>

    pred<span class="token punctuation">,</span> useTime <span class="token operator">=</span> predict<span class="token punctuation">(</span>img<span class="token punctuation">)</span>

    det <span class="token operator">=</span> pred<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
    p<span class="token punctuation">,</span> s<span class="token punctuation">,</span> im0 <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token string">''</span><span class="token punctuation">,</span> img0
    <span class="token keyword">if</span> det <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span> <span class="token keyword">and</span> <span class="token builtin">len</span><span class="token punctuation">(</span>det<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment"># 如果有检测信息则进入</span>
        det<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token number">4</span><span class="token punctuation">]</span> <span class="token operator">=</span> scale_coords<span class="token punctuation">(</span>img<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">,</span> det<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">,</span> im0<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">round</span><span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 把图像缩放至im0的尺寸</span>
        number_i <span class="token operator">=</span> <span class="token number">0</span>  <span class="token comment"># 类别预编号</span>
        detInfo <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        <span class="token keyword">for</span> <span class="token operator">*</span>xyxy<span class="token punctuation">,</span> conf<span class="token punctuation">,</span> cls <span class="token keyword">in</span> <span class="token builtin">reversed</span><span class="token punctuation">(</span>det<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment"># 遍历检测信息</span>
            c1<span class="token punctuation">,</span> c2 <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token builtin">int</span><span class="token punctuation">(</span>xyxy<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token builtin">int</span><span class="token punctuation">(</span>xyxy<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token builtin">int</span><span class="token punctuation">(</span>xyxy<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token builtin">int</span><span class="token punctuation">(</span>xyxy<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            <span class="token comment"># 将检测信息添加到字典中</span>
            detInfo<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">[</span>names<span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">(</span>cls<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span>c1<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> c1<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> c2<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> c2<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">'%.2f'</span> <span class="token operator">%</span> conf<span class="token punctuation">]</span><span class="token punctuation">)</span>
            number_i <span class="token operator">+=</span> <span class="token number">1</span>  <span class="token comment"># 编号数+1</span>

            label <span class="token operator">=</span> <span class="token string">'%s %.2f'</span> <span class="token operator">%</span> <span class="token punctuation">(</span>names<span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">(</span>cls<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span> conf<span class="token punctuation">)</span>

            <span class="token comment"># 画出检测到的目标物</span>
            plot_one_box<span class="token punctuation">(</span>image<span class="token punctuation">,</span> xyxy<span class="token punctuation">,</span> label<span class="token operator">=</span>label<span class="token punctuation">,</span> color<span class="token operator">=</span>colors<span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">(</span>cls<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token comment"># 实时显示检测画面</span>
    cv2<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span><span class="token string">'Stream'</span><span class="token punctuation">,</span> image<span class="token punctuation">)</span>
    <span class="token comment"># if cv2.waitKey(1) &amp; 0xFF == ord('q'):</span>
    <span class="token comment">#     break</span>
    c <span class="token operator">=</span> cv2<span class="token punctuation">.</span>waitKey<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span> <span class="token number">0xff</span>
</code></pre> 
<p><font face="微软雅黑">        在这段Python代码中，我们首先定义了一个名为predict的函数，用于对输入的图像进行检测和分类。该函数输入一个图像，先将其转化为PyTorch Tensor，然后对图像进行预测和非极大值抑制，得到预测结果和推理时间。接下来我们定义了cv_imread函数，用于读取图片。cv_imread函数通过OpenCV库的imdecode函数读取图片，并将其转化为NumPy数组，然后返回该数组。接着我们定义了plot_one_box函数，该函数用于在图像上画出检测框和类别标签，其中函数参数中包括了待画出的图像、检测框坐标、类别标签、颜色等。</font></p> 
<p><font face="微软雅黑">        最后，在if <strong>name</strong> == ‘<strong>main</strong>’:语句中，我们首先读取一张测试图片，并将其调整为合适的大小，然后将其输入到predict函数中进行检测和分类，得到检测结果和推理时间。接着，我们通过遍历检测结果，将检测到的目标物的信息添加到detInfo列表中，然后调用plot_one_box函数，将目标物的检测框和类别标签画在图像上。最后通过OpenCV库的imshow函数将结果图像实时显示在屏幕上。</font></p> 
<p><font face="微软雅黑">        这部分代码是我们整个系统实现的关键部分，通过修改和集成该部分代码同样可以实现对输入视频和实时摄像头画面的实时检测和分类，并且可以通过界面将结果显示给用户，提高了系统的实用性。</font></p> 
<h2>
<a id="font_face_size552_PyQtfont_190"></a><font face="楷体" size="5">5.2 PyQt界面设计</font>
</h2> 
<p><font face="微软雅黑">        PyQt是Python语言的GUI编程解决方案之一，可以快速地为Python程序创建GUI应用。在本文中，我们使用PyQt库创建一个图形化界面，为用户提供简单易用的交互界面，实现用户选择图片、视频或实时视频进行目标检测。这里介绍系统的GUI设计和开发过程，包括主窗口的设计、UI控件的布局以及信号槽的连接。</font></p> 
<p><font face="微软雅黑">        在本系统中，使用PyQt5库设计了可视化的GUI界面，主要包括以下六个模块：</font></p> 
<p>（1）图片检测模块：用户可以选择本地的一张图片进行检测，检测结果将在界面中实时显示。用户也可以选择多张图片进行批量检测，并将结果记录保存到本地。<br> （2）视频检测模块：用户可以选择本地的一个视频进行检测，检测结果将在界面中实时显示。用户也可以选择多个视频进行批量检测，并将结果记录保存到本地。<br> （3）实时检测模块：用户可以启动摄像头进行实时检测，检测结果将在界面中实时显示。<br> （4）更换模型模块：用户可以选择不同的预训练模型进行检测，系统提供了多种不同的预训练模型供用户选择。<br> （5）结果记录回看模块：用户可以查看历史检测结果，并对检测结果进行搜索和筛选。<br> （6）其他模块：界面中还包括了一些辅助模块，如登录注册、设置等。</p> 
<p><font face="微软雅黑">        我们使用Qt Designer设计图形界面，然后使用PyQt将设计好的UI文件转换为Python代码。图形界面中包含多个UI控件，例如：菜单栏、工具栏、标签、按钮等。通过PyQt中的信号槽机制，可以使得UI控件与程序逻辑代码相互连接。</font></p> 
<p><img src="https://images2.imgbox.com/5b/87/5hzSiP2j_o.png" alt="在这里插入图片描述" width="800"></p> 
<p><font face="微软雅黑">        界面设计使用了Qt Designer工具，通过拖拽组件的方式进行布局，同时也可以通过代码进行动态添加和修改。在界面的设计过程中，我们主要使用了以下几个组件：</font></p> 
<p>（1）QLabel：用于显示文字和图片。<br> （2）QToolButton：用于实现按钮功能。<br> （3）QComboBox：用于实现下拉框功能，供用户选择预训练模型。<br> （4）QFileDialog：用于选择本地的图片和视频。<br> （5）QTableWidget：用于展示历史检测结果，并提供搜索和筛选功能。</p> 
<p><font face="微软雅黑">        为了使得界面更加美观和易于操作，我们还可以自定义控件样式，例如在系统中使用的按钮等，都进行了样式的调整。具体实现方式是通过QSS文件，使用CSS语法进行样式定义。</font></p> 
<p><font face="微软雅黑">        在图形界面的实现过程中，我们还需要使用Python中的OpenCV库实现视频的读取和显示。使用OpenCV可以快速实现视频的读取、播放和保存等操作，并且可以与PyQt进行结合，实现更为高效的图像和视频处理。下面我们给出系统GUI的示例图：</font></p> 
<p><img src="https://images2.imgbox.com/a1/57/ycInt76M_o.png" alt="在这里插入图片描述" width="700"></p> 
<hr> 
<h1>
<a id="font_face_size56_font_221"></a><font face="华文行楷" size="5">6. 实验结果与分析</font>
</h1> 
<p><font face="微软雅黑">        在实验结果与分析部分，我们不仅通过精度和召回率等指标来评估模型的性能，还通过损失曲线和PR曲线来分析训练过程</font></p> 
<p><font face="微软雅黑">        我们使用了前面介绍的水果检测数据集进行训练，该数据集包含多种不同的水果类别，包括苹果、香蕉、橙子、西瓜等，共计8个类别。我们使用了YOLOv5算法，训练了300个epochs，训练过程截图如下。</font></p> 
<p><img src="https://images2.imgbox.com/bb/28/vHezDt0Q_o.png" alt="在这里插入图片描述" width="600"></p> 
<p><font face="微软雅黑">        在训练过程中，我们使用tensorboard记录了模型在训练集和验证集上的损失曲线。从图6-1中可以看出，随着训练次数的增加，模型的训练损失和验证损失都逐渐降低，说明模型不断地学习到更加精准的特征。</font></p> 
<p><img src="https://images2.imgbox.com/e4/4b/kPREGv6t_o.png" alt="在这里插入图片描述" width="700"><br> <font face="微软雅黑">        在训练结束后，我们对模型在测试集上进行了评估，得到了以下结果。下图展示了我们训练的YOLOv5模型在测试集上的PR曲线。可以看到，模型在不同类别上都取得了较高的召回率和精确率，整体表现良好。</font></p> 
<p><img src="https://images2.imgbox.com/54/18/CQ0Extvn_o.png" alt="在这里插入图片描述" width="400"></p> 
<p><font face="微软雅黑">        综上，我们训练的YOLOv5模型在水果检测数据集上表现良好，具有较高的检测精度和鲁棒性，可以在实际场景中应用。</font></p> 
<p><font face="微软雅黑">        博主对整个系统进行了详细测试，最终开发出一版流畅得到清新界面，就是博文演示部分的展示，完整的UI界面、测试图片视频、代码文件，以及Python离线依赖包（方便安装运行，也可自行配置环境），均已打包上传，感兴趣的朋友可以通过下载链接获取。</font></p> 
<hr> 
<h1>
<a id="font_face_size5__colorff4500font_242"></a><font face="华文行楷" size="5" color="#ff4500">下载链接</font>
</h1> 
<p><font face="Times New Roman">    若您想获得博文中涉及的实现完整全部程序文件（包括测试图片、视频，<font face="Times New Roman"><em>py, UI</em></font>文件等，如下图），这里已打包上传至博主的面包多平台，见可参考博客与视频，已将所有涉及的文件同时打包到里面，点击即可运行，完整文件截图如下：</font></p> 
<p><img src="https://images2.imgbox.com/0c/6e/86tCJxkF_o.png" alt="在这里插入图片描述" width="700"></p> 
<p><font face="Times New Roman">    在文件夹下的资源显示如下，下面的链接中也给出了Python的离线依赖包，读者可在正确安装Anaconda和Pycharm软件后，复制离线依赖包至项目目录下进行安装，离线依赖的使用详细演示也可见本人B站视频：<a href="https://www.bilibili.com/video/BV1Hg4y1t78v/">win11从头安装软件和配置环境运行深度学习项目</a>、<a href="https://www.bilibili.com/video/BV1Vo4y1k7sR/">Win10中使用pycharm和anaconda进行python环境配置教程</a>。</font></p> 
<p><img src="https://images2.imgbox.com/eb/62/dlTNxtXp_o.png" alt="在这里插入图片描述" width="500"></p> 
<p><span id="i1"></span></p> 
<p><font face="微软雅黑"><strong>注意</strong>：该代码采用Pycharm+Python3.8开发，经过测试能成功运行，运行界面的主程序为runMain.py和LoginUI.py，测试图片脚本可运行testPicture.py，测试视频脚本可运行testVideo.py。为确保程序顺利运行，请按照requirements.txt配置Python依赖包的版本。<strong>Python版本：3.8</strong></font>，请勿使用其他版本，详见requirements.txt文件；</p> 
<p><font face="微软雅黑">完整资源中包含数据集及训练代码，环境配置与界面中文字、图片、logo等的修改方法请见视频，<strong>项目完整文件下载请见参考博客文章里面，或参考视频的简介处给出</strong>：➷➷➷</font></p> 
<p><strong>参考博客文章：</strong><a href="https://zhuanlan.zhihu.com/p/626198529">https://zhuanlan.zhihu.com/p/626198529</a></p> 
<p><strong>参考视频演示：</strong><a href="https://www.bilibili.com/video/BV1rT411h7dY/">https://www.bilibili.com/video/BV1rT411h7dY/</a></p> 
<p><strong>离线依赖库下载链接</strong>：<a href="https://pan.baidu.com/s/1hW9z9ofV1FRSezTSj59JSg?pwd=oy4n">https://pan.baidu.com/s/1hW9z9ofV1FRSezTSj59JSg?pwd=oy4n</a> （提取码：oy4n ）</p> 
<hr> 
<p><font face="微软雅黑"><strong>界面中文字、图标和背景图修改方法：</strong></font></p> 
<p><font face="微软雅黑">        在Qt Designer中可以彻底修改界面的各个控件及设置，然后将ui文件转换为py文件即可调用和显示界面。如果只需要修改界面中的文字、图标和背景图的，可以直接在ConfigUI.config文件中修改，步骤如下：</font><br> <font face="微软雅黑">        （1）打开UI_rec/tools/ConfigUI.config文件，若乱码请选择GBK编码打开。</font><br> <font face="微软雅黑">        （2）如需修改界面文字，只要选中要改的字符替换成自己的就好。</font><br> <font face="微软雅黑">        （3）如需修改背景、图标等，只需修改图片的路径。例如，原文件中的背景图设置如下：</font></p> 
<pre><code class="prism language-powershell">mainWindow = :<span class="token operator">/</span>images/icons/back-image<span class="token punctuation">.</span>png
</code></pre> 
<p><font face="微软雅黑">        可修改为自己的名为background2.png图片（位置在UI_rec/icons/文件夹中），可将该项设置如下即可修改背景图：</font></p> 
<pre><code class="prism language-powershell">mainWindow = <span class="token punctuation">.</span><span class="token operator">/</span>icons/background2<span class="token punctuation">.</span>png
</code></pre> 
<hr> 
<h1>
<a id="font_face_size5font_286"></a><font face="华文行楷" size="5">结束语</font>
</h1> 
<p><font face="Times New Roman">        由于博主能力有限，博文中提及的方法即使经过试验，也难免会有疏漏之处。希望您能热心指出其中的错误，以便下次修改时能以一个更完美更严谨的样子，呈现在大家面前。同时如果有更好的实现方法也请您不吝赐教。</font></p> 
<hr> 
<h1>
<a id="font_face_size5font_291"></a><font face="华文行楷" size="5">参考文献</font>
</h1> 
<p>[1] Bargoti, S., &amp; Underwood, J. P. (2017). Image segmentation for fruit detection and yield estimation in apple orchards. Journal of Field Robotics, 34(6), 1039-1060.<br> [2] Girshick, R., Donahue, J., Darrell, T., &amp; Malik, J. (2014). Rich feature hierarchies for accurate object detection and semantic segmentation. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 580-587).<br> [3] Girshick, R. (2015). Fast R-CNN. In Proceedings of the IEEE international conference on computer vision (pp. 1440-1448).<br> [4] Ren, S., He, K., Girshick, R., &amp; Sun, J. (2015). Faster R-CNN: Towards real-time object detection with region proposal networks. In Advances in neural information processing systems (pp. 91-99).<br> [5] Liu, W., Anguelov, D., Erhan, D., Szegedy, C., Reed, S., Fu, C. Y., &amp; Berg, A. C. (2016, October). SSD: Single shot multibox detector. In European conference on computer vision (pp. 21-37). Springer, Cham.<br> [6] Lin, T. Y., Goyal, P., Girshick, R., He, K., &amp; Dollár, P. (2017). Focal loss for dense object detection. In Proceedings of the IEEE international conference on computer vision (pp. 2980-2988).<br> [7] Redmon, J., Divvala, S., Girshick, R., &amp; Farhadi, A. (2016). You only look once: Unified, real-time object detection. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 779-788).<br> [8] Redmon, J., &amp; Farhadi, A. (2017). YOLO9000: Better, faster, stronger. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 7263-7271).<br> [9] Redmon, J., &amp; Farhadi, A. (2018). YOLOv3: An incremental improvement. arXiv preprint arXiv:1804.02767.<br> [10] Bochkovskiy, A., Wang, C. Y., &amp; Liao, H. Y. M. (2020). YOLOv4: Optimal speed and accuracy of object detection. arXiv preprint arXiv:2004.10934.<br> [11] Sa, I., Ge, Z., Dayoub, F., Upcroft, B., Perez, T., &amp; McCool, C. (2016). DeepFruits: A fruit detection system using deep neural networks. Sensors, 16(8), 1222.<br> [12] Rahnemoonfar, M., &amp; Sheppard, C. (2017). Deep count: Fruit counting based on deep simulated learning. Sensors, 17(4), 905.<br> [13] Chakraborty S K, Subeesh A, Dubey K, et al. Development of an optimally designed real-time automatic citrus fruit grading–sorting​ machine leveraging computer vision-based adaptive deep learning model[J]. Engineering Applications of Artificial Intelligence, 2023, 120: 105826.<br> [14] Jocher, G., Stoken, A., Borovec, J., Bendahan, R. A., Puig, D., Tokozume, Y., … &amp; Guan, H. (2021). Ultralytics/yolov5: v5.0-YOLOv5-PyTorch.</p>
                </div>
                
                

		</div>
	</article>
</main>




			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程小白.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://www.w3counter.com/tracker.js?id=150625"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>
	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>