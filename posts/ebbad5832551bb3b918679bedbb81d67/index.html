<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<title>机器学习：基于PyTorch搭建神经网络 - 编程小白</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程小白" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程小白</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">机器学习：基于PyTorch搭建神经网络</h1>
			
		</header>
		<div class="content post__content clearfix">
			


                <div id="content_views" class="htmledit_views">
                    <h2><span style="color:#4da8ee">1，PyTorch安装</span></h2> 
<h3><span style="color:#4da8ee">1.1，不需切换版本</span></h3> 
<blockquote> 
 <p><span style="color:#fe2c24"><strong>前往PyTorch官网，找到对应自己显卡版本的PyTorch安装命令。</strong></span></p> 
 <p style="text-align:center"><img alt="" height="430" src="https://images2.imgbox.com/3e/cc/v0FIfK8u_o.png" width="929"></p> 
 <p><span style="color:#fe2c24"><strong>PyTorch只对CUDA版本有要求，对于cudnn没有要求，甚至不需要安装。</strong></span><span style="color:#0d0016"><strong>查看方式如下：</strong></span></p> 
 <p style="text-align:center"><img alt="" height="230" src="https://images2.imgbox.com/f0/8c/MO1goqk2_o.png" width="558"></p> 
 <p style="text-align:center"><img alt="" height="379" src="https://images2.imgbox.com/00/a6/fCY9Du4H_o.png" width="400"></p> 
</blockquote> 
<h3><span style="color:#4da8ee">1.2，切换CUDA版本</span></h3> 
<blockquote> 
 <p><strong>前往NVIDA官网（<a href="https://developer.nvidia.cn/cuda-toolkit-archive" title="CUDA Toolkit Archive | NVIDIA Developer">CUDA Toolkit Archive | NVIDIA Developer</a>）下载指定版本。</strong></p> 
 <p><strong>安装路径自定义，其他的默认，最后还需要在系统变量中添加如下内容：</strong></p> 
 <p style="text-align:center"><img alt="" height="114" src="https://images2.imgbox.com/9d/8f/RcAbTcvn_o.png" width="392"></p> 
 <p><span style="color:#fe2c24"><strong>验证方式：</strong></span></p> 
 <p style="text-align:center"><img alt="" height="102" src="https://images2.imgbox.com/9b/85/yePWldcD_o.png" width="466"></p> 
</blockquote> 
<h2><span style="color:#4da8ee">2，PyTorch基础知识</span></h2> 
<h3><span style="color:#4da8ee">2.1，构造Tensor</span></h3> 
<blockquote> 
 <p><strong>Tensor是PyTorch中用来存储多维矩阵数据的数据结构，和NumPy中的naddary比较类似，<span style="color:#fe2c24">但Tensor能够使用GPU来加速运算。</span></strong></p> 
 <p><span style="color:#fe2c24"><strong>在PyTorch中构造Tensor方式有很多：</strong></span></p> 
 <pre><code>#生成随机Tensor
import torch
x = torch.Tensor(2, 3)
print(x)
================================================
tensor([[-7.5173e-01,  9.3731e-38, -1.5563e-04],
        [ 9.3731e-38, -4.4988e-05,  9.3731e-38]])</code></pre> 
 <pre><code>#利用list构造Tensor
import torch
x = torch.Tensor([1,2,3])
print(x)
y = torch.Tensor([[1,2,3],[6,5,4]])
print(y)
===================================
tensor([1., 2., 3.])
tensor([[1., 2., 3.],
        [6., 5., 4.]])</code></pre> 
 <pre><code>import torch
#随机元素值0~1之间矩阵
x= torch.rand(3,3)
print(x)
#元素全部为0的矩阵
x= torch.zeros(3,3)
print(x)
#元素全部为1的矩阵
x= torch.ones(3,3)
print(x)
==================================
tensor([[0.3766, 0.8037, 0.7080],
        [0.9064, 0.4387, 0.0712],
        [0.0787, 0.1682, 0.7385]])
tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]])
tensor([[1., 1., 1.],
        [1., 1., 1.],
        [1., 1., 1.]])</code></pre> 
 <p><span style="color:#fe2c24"><strong>获取一个Tensor的大小：</strong></span></p> 
 <pre><code>x = torch.ones(3, 3)
print(x.size())
====================
torch.Size([3, 3])</code></pre> 
</blockquote> 
<h3><span style="color:#4da8ee">2.2，Tensor操作</span></h3> 
<blockquote> 
 <p><strong>在PyTorch中我们可以方便地进行一些数学运算和矩阵操作，比如矩阵可以直接乘以一个数字，再加上另外一个矩阵：</strong></p> 
 <pre><code>x=torch.ones(2,3)
y=torch.ones(2,3)*2
print(x+y)
print(torch.add(x,y))
print(x.add_(y))
print(x*y)</code></pre> 
 <p><strong><span style="color:#fe2c24">PS：</span>add_()会原地修改Tensor x的值。在PyTorch中，任何原地修改Tensor内容的操作都会在方法名后加一个下划线作为后缀，例如：x.copy_(y)、x.t_()，这些都会改变x的值。</strong></p> 
</blockquote> 
<blockquote> 
 <p><strong>Tensor也支持NumPy中各种<span style="color:#fe2c24">切片操作</span>，比如操作矩阵的某一列：</strong></p> 
 <pre><code>x = torch.ones(3, 3)
x[:, 1] = x[:, 1] + 2
print(x)
====================
tensor([[3., 3., 3.],
        [1., 1., 1.],
        [1., 1., 1.]])
</code></pre> 
</blockquote> 
<blockquote> 
 <p><strong>另外，可以使用torch.view()来<span style="color:#fe2c24">改变矩阵的形状</span>（同NumPy中的reshape）：</strong></p> 
 <pre><code>x = torch.ones(3, 3)
x=x.view(1,9)
print(x)
==============================================
tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1.]])</code></pre> 
</blockquote> 
<h3><span style="color:#4da8ee">2.3，Tensor和NumPy array间的转化</span></h3> 
<blockquote> 
 <p><strong>Torch的Tensor和NumPy的array可以非常方便地进行<span style="color:#fe2c24">相互转化</span>。但是需要注意的是，它们会共享内存的地址，所以修改其中一个会导致另外一个也发生改变。</strong></p> 
 <pre><code>import torch
x = torch.ones(2, 3)
print(x)
y = x.numpy()
print(y)
x.add_(2)
print(y)
z = torch.from_numpy(y)
print(z)
========================
tensor([[1., 1., 1.],
        [1., 1., 1.]])
[[1. 1. 1.]
 [1. 1. 1.]]
[[3. 3. 3.]
 [3. 3. 3.]]
tensor([[3., 3., 3.],
        [3., 3., 3.]])</code></pre> 
</blockquote> 
<h3><span style="color:#4da8ee">2.4，Autograd：自动梯度</span></h3> 
<blockquote> 
 <p><strong>在任何深度学习框架中，<span style="color:#fe2c24">都需要一个计算误差的梯度并进行反向传播的机制，这对于构建神经网络模型至关重要。</span>在PyTorch中，这个机制是由Autograd包实现的，其中提供了对Tensor上的所有操作进行自动求导操作。</strong></p> 
 <p><span style="color:#956fe7"><strong>Variale类是Autograd包中最核心的一个类，它包装了一个Tensor，并且支持几乎所有定义在Tensor上的操作。我们可以通过.data属性访问原始的Tensor。</strong></span></p> 
 <pre><code>import torch
from torch.autograd import Variable
x = Variable(torch.ones(2, 2) * 2, requires_grad=True)
print(x)
print(x.data)
=====================================================
tensor([[2., 2.],
        [2., 2.]], requires_grad=True)
tensor([[2., 2.],
        [2., 2.]])</code></pre> 
 <p><span style="color:#956fe7"><strong>我们传入了一个Tensor，并设置requires_grad参数为True。只有一个Variable的requires_grad为True，我们才能求出关于它的梯度。</strong></span></p> 
 <pre><code>x = Variable(torch.ones(2, 2) * 2, requires_grad=True)
y = 2 * (x * x) + 5 * x
print(y)
=============================
tensor([[18., 18.],
        [18., 18.]], grad_fn=&lt;AddBackward0&gt;)</code></pre> 
 <p><span style="color:#956fe7"><strong><img alt="y" class="mathcode" src="https://images2.imgbox.com/c4/c7/vwamAN6c_o.gif"> 可以看作一个关于<img alt="x" class="mathcode" src="https://images2.imgbox.com/88/8e/I7IYC52T_o.gif">的函数，它关于 <img alt="x" class="mathcode" src="https://images2.imgbox.com/88/8e/I7IYC52T_o.gif"> 的梯度 <img alt="frac{dy}{dx}" class="mathcode" src="https://images2.imgbox.com/43/66/39vP8NF6_o.gif"> 的表达式我们可以通过计算得到：<img alt="4x+5" class="mathcode" src="https://latex.codecogs.com/gif.latex?4x&amp;plus;5"></strong>。<strong>现在<img alt="x" class="mathcode" src="https://images2.imgbox.com/88/8e/I7IYC52T_o.gif">中的每一个元素值都是 <img alt="2" class="mathcode" src="https://images2.imgbox.com/19/48/9d7VGJEQ_o.gif">，将其带入 <img alt="4x+5" class="mathcode" src="https://latex.codecogs.com/gif.latex?4x&amp;plus;5"> 得到值 <img alt="13" class="mathcode" src="https://images2.imgbox.com/76/b7/fZFHHBB8_o.gif">。</strong></span></p> 
 <pre><code>import torch
from torch.autograd import Variable
x = Variable(torch.ones(2, 2) * 2, requires_grad=True)
y = 2 * (x * x) + 5 * x
y=y.sum()
y.backward()
print(x.grad)
=====================
tensor([[13., 13.],
        [13., 13.]])</code></pre> 
 <p><span style="color:#0d0016"><strong>在PyTorch中，当我们计算完成之后，</strong></span><span style="color:#fe2c24"><strong>可以通过调用.backward()方法来自动计算梯度。</strong></span><span style="color:#0d0016"><strong>现在我们需要计算的是y关于x的梯度，所以我们调用y.backward()。而计算得到的梯度会存储到Variable x的.grad属性中。</strong></span></p> 
</blockquote> 
<h2><span style="color:#4da8ee">3，PyTorch中搭建神经网络</span></h2> 
<h3><span style="color:#4da8ee">3.1，定义神经网络</span></h3> 
<blockquote> 
 <p><strong>在PyTorch中，神经网络的构件主要使用torch.nn包。我们定义的神经网络需要继承内置的nn.Module类，nn.Module类给我们提供了很多定义好的功能，一般情况下我们只需要定义自己的网络模型结构及前向方法。</strong></p> 
 <pre><code>import torch
import torch.nn.functional as F
import torch.nn as nn


class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()  # 定义一个神经网络
        self.conv1 = nn.Conv2d(3, 6, 5)  # 两个卷积层，三个全连接层
        self.conv2 = nn.Conv2d(6, 16, 5)  # 输入3个通道，输出6个通道，卷积核5*5
        self.fc1 = nn.Linear(16 * 5 * 5, 120)  # 输入84维，输出10维
        self.fc2 = nn.Linear(120, 84)
        self.fc3 = nn.Linear(84, 10)

    # 在init中我们值定义了搭建网络的层，但没有真正定义网络的结构
    # 真正的输入输出关系是在forward()方法中定义的，控制数据在网络中的流动方式
    def forward(self, x):
        x = F.max_pool2d(F.relu(self.conv1(x)), 2)  # 激活函数ReLU，先经过一个卷积层，然后一个全连接层
        x = F.max_pool2d(F.relu(self.conv2(x)), 2)
        x = x.view(-1, 16 * 5 * 5)
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = self.fc3(x)
        return x</code></pre> 
 <p><strong><span style="color:#fe2c24">PS：</span>torch.nn中要求输入的数据是一个mini-batch，因为我们的图像数据（CIFAR-10）本身是3维的，所以forward()的输入x是4维的，在经过两个卷积层之后还是4维的Tensor，所以在输入后面的全连接层之前我们先使用.view()方法将其转化为2维的Tensor。</strong></p> 
 <p><strong>这样就定义好了我们自己的神经网络，接下来我们可以<span style="color:#fe2c24">创建这个神经网络的实例，并打印出来。</span></strong></p> 
 <pre><code>if __name__ == '__main__':
    net = Net()
    print(net)  #神经网络结果
============================
Net(
  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))
  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=400, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=84, bias=True)
  (fc3): Linear(in_features=84, out_features=10, bias=True)
)</code></pre> 
</blockquote> 
<blockquote> 
 <p><strong>神经网络模型中可以训练的参数由net.parameters()返回，在我们刚才定义的网络中，共有10个参数，分别对应于5个层的<span style="color:#fe2c24">weight参数和bias参数（权重和偏执）</span>。比如前面两个分别是第1个卷积层conv1的weight参数和bias参数，我们可以通过打印出来的参数的size确定这一点。</strong></p> 
 <pre><code>params = list(net.parameters())
print(len(params))
print(params[0].size())
print(params[1].size())
===============================
10
torch.Size([6, 3, 5, 5])
torch.Size([6])
</code></pre> 
 <p><strong>我们也可以直接通过层和参数的名字访问具体的参数，比如net.conv1.weight是第一个卷积层conv1的weight参数。另外，我们可以看到，<span style="color:#fe2c24">这些模型参数的requires_grad是默认的True，这意味着后面可以计算关于这些参数的梯度并用梯度来更新这些参数。</span></strong></p> 
 <p><strong>当然，<span style="color:#fe2c24">如果我们想要固定网络中的某些层的参数不更新，那么可以设置这部分网络对应的参数的requires_grad为False，</span>这样在方向求梯度过程中就不会计算这些参数对应的梯度了。</strong></p> 
 <pre><code>print(net.conv1.weight.size())
print(net.conv1.bias.size())
print(net.conv1.weight.requires_grad)
=====================================
torch.Size([6, 3, 5, 5])
torch.Size([6])
True
</code></pre> 
 <p><strong>定义好了神经网络，让我们来看一下如何调用这个神经网络获取输出。前面提到的，我们这边需要的输入数据是4维的。同时，在PyTorch里神经网络的输入样本作为示例。有了输入数据之后，可以直接将其传入神经网络得到输出，实际上调用我们定义的net.forward()方法。可以看到，神经网络的输出也是一个Variable，共有10维，和我们预期的一致。</strong></p> 
 <pre><code>input = Variable(torch.rand(1,3,32,32))
output = net(input)
print(output)
================================================================================
tensor([[ 0.1417,  0.0634, -0.0652, -0.0445,  0.0899,  0.0334,  0.0029, -0.0582,
          0.0845,  0.1239]], grad_fn=&lt;AddmmBackward&gt;)</code></pre> 
</blockquote> 
<h3><span style="color:#4da8ee">3.2，训练神经网络</span></h3> 
<blockquote> 
 <p><strong>要训练神经网络，<span style="color:#fe2c24">我们首先需要定义一个损失函数，我们训练的目的就是通过调整神经网络模型的参数来最小化这个损失函数。</span>1个损失函数输入神经网络的预测输出和样本真实标签，然后返回1个值评测输出距离真实标签的远近程度。在torch.nn包中，有很多定义好的损失函数，比如nn.MSELoss、nn.L1Loss、nn.CrossEntropyLoss等。<span style="color:#fe2c24">因为我们是在训练1个多分类模型，所以使用交叉熵损失函数nn.CrossEntropyLoss。</span></strong></p> 
 <pre><code>criterion = nn.CrossEntropyLoss()</code></pre> 
 <p><strong>假设刚才随机生成的按个输入样本input为例，假设它对应的真实标签是4，而我们刚才已经得到了它通过神经网络之后的输出output，那么我们就可以直接把它们输入刚才选择的损失函数计算得到loss。需要注意，损失函数的输入outpur和label都要求是Variable，输出loss也是一个Variable。</strong></p> 
 <pre><code>if __name__ == '__main__':
    net = Net()
    criterion = nn.CrossEntropyLoss()
    input = Variable(torch.rand(1, 3, 32, 32))
    output = net(input)
    print(output)
    label = Variable(torch.LongTensor([4]))
    print(label)
    loss = criterion(output,label)
    print(loss)
================================================================================
tensor([[ 0.1201,  0.0682,  0.0639,  0.0945, -0.0587,  0.0728,  0.0730,  0.1388,
         -0.0845,  0.1373]], grad_fn=&lt;AddmmBackward&gt;)
tensor([4])
tensor(2.4264, grad_fn=&lt;NllLossBackward&gt;)</code></pre> 
</blockquote> 
<blockquote> 
 <p><strong>在定义玩损失函数之后，我们还需要<span style="color:#fe2c24">最小化这个损失函数是准备采用的优化方法。</span>这时候我们需要用到torch.optim包，里面已经实现了各种常用的优化方法，比如SGD、Nesterov-SGD、Adam、RMSProp等，一般我们从中选择就可以了。我们选择带动量的随机梯度下降法，并将需要训练的模型参数作为第一个参数传入，同时设定学习速率参数lr=0.001，动量参数momentun=0.9。</strong></p> 
 <pre><code>import torch.optim as optim
optimizer = optim.SGD(net.parameters(),lr=0.001,momentum=0.9)</code></pre> 
 <p><strong>定义好损失函数和优化方法，我们就可以训练更新神经网络的参数了。在更新之前，我们先挑一个参数看一下：</strong></p> 
 <pre><code>print(net.conv1.bias)
==============================
Parameter containing:
tensor([ 0.0416, -0.0456, -0.0261,  0.0349, -0.0015, -0.0484],
       requires_grad=True)</code></pre> 
 <p><strong>参数训练更新主要包含两步，<span style="color:#fe2c24">首先我们调用loss.backward()自动计算loss关于所有可训练参数的梯度，然后执行optimizer.step()，根据上一步计算得到的梯度更新参数。</span>需要注意，在调用backward()计算梯度之前，我们一般需要先调用optimizer.zero_grad()将所有参数的梯度置为0，因为backward()计算得到的梯度是积累到原有的梯度之上的。</strong></p> 
 <pre><code>if __name__ == '__main__':
    net = Net()
    print(net.conv1.bias)
    criterion = nn.CrossEntropyLoss()  # 损失函数
    input = Variable(torch.rand(1, 3, 32, 32))
    output = net(input)
    print(output)
    label = Variable(torch.LongTensor([4]))
    loss = criterion(output, label)
    print(loss)
    optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)
    optimizer.zero_grad()
    loss.backward() #计算梯度
    optimizer.step()
    print(net.conv1.bias)
===========================================
Parameter containing:
tensor([ 0.0580,  0.0789,  0.0258, -0.0612, -0.0216,  0.0890],
       requires_grad=True)
tensor([[-0.0903, -0.0205,  0.0408, -0.0373,  0.0255,  0.0164,  0.1519,  0.1117,
         -0.1146, -0.0415]], grad_fn=&lt;AddmmBackward&gt;)
tensor(2.2844, grad_fn=&lt;NllLossBackward&gt;)
Parameter containing:
tensor([ 0.0580,  0.0789,  0.0258, -0.0613, -0.0216,  0.0891],
       requires_grad=True)</code></pre> 
 <p><span style="color:#fe2c24"><strong>由于样本集就一个样本，并且没有迭代循环，故该变量极小。</strong></span></p> 
</blockquote> 
<h3><span style="color:#4da8ee">3.3，在CIFAR-10数据集上进行训练和测试</span></h3> 
<blockquote> 
 <p><strong>首先我们需要获取CIFAR-10数据集，并对数据进行必要的预处理。有一个torchvision包已经为我们收好了各种常用的图像数据集，比如：Imagenet、CIFAR-10、MNIST等，并提供了非常方便的加载和预处理的功能。</strong></p> 
 <pre><code>import torch.utils.data
import torchvision
import torchvision.transforms as transforms
transform = transforms.Compose(
    [transforms.ToTensor(),transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))]
)
transform = transforms.Compose(
    [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]
)
trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)
trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,shuffle=True, num_workers=0)  # windows 下线程参数设为 0 安全
testset = torchvision.datasets.CIFAR10(root='./data', train=False,download=True, transform=transform)
testloader = torch.utils.data.DataLoader(testset, batch_size=4,shuffle=False, num_workers=0)

classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')
</code></pre> 
 <p><strong>我们来看几张 CIFAR10 的图片样例， 分别是 <code>frog、cat、deer、frog，</code> 32 X 32 的像素，看起来是有些模糊。</strong></p> 
 <pre><code>import matplotlib.pyplot as plt
import numpy as np
# functions to show an image
def imshow(img):
    img = img / 2 + 0.5  # unnormalize
    npimg = img.numpy()
    plt.imshow(np.transpose(npimg, (1, 2, 0)))
    plt.show()
# get some random training images
dataiter = iter(trainloader)
images, labels = dataiter.next()
# show images
imshow(torchvision.utils.make_grid(images))
# print labels
print(' '.join('%5s' % classes[labels[j]] for j in range(4)))
</code></pre> 
 <p style="text-align:center"><img alt="" height="480" src="https://images2.imgbox.com/ba/1d/WsZOLIly_o.png" width="640"></p> 
</blockquote> 
<blockquote> 
 <p><strong>数据准备好之后，我们就可以开始真正的训练了。我们会多次遍历训练数据集，每次取出一个mini-batch（设置为4）的数据，根据mini-batch的数据执行更新神经网络。</strong></p> 
 <p><span style="color:#fe2c24"><strong>构建神经网络：</strong></span></p> 
 <pre><code>import torch.nn as nn
import torch.nn.functional as F


class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.conv1 = nn.Conv2d(3, 6, 5)
        self.pool = nn.MaxPool2d(2, 2)
        self.conv2 = nn.Conv2d(6, 16, 5)
        self.fc1 = nn.Linear(16 * 5 * 5, 120)
        self.fc2 = nn.Linear(120, 84)
        self.fc3 = nn.Linear(84, 10)

    def forward(self, x):
        x = self.pool(F.relu(self.conv1(x)))
        x = self.pool(F.relu(self.conv2(x)))
        x = x.view(-1, 16 * 5 * 5)
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = self.fc3(x)
        return x
</code></pre> 
 <p><span style="color:#fe2c24"><strong>定义损失函数及优化器：</strong></span></p> 
 <pre><code>criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)</code></pre> 
 <p><span style="color:#fe2c24"><strong>训练模型：</strong></span></p> 
 <ul>
<li><span style="color:#956fe7"><strong>先通过 <code>optimizer.zero_grad()</code> 把梯度清理干净，防止受之前遗留梯度的影响。</strong></span></li>
<li><span style="color:#956fe7"><strong><code>outputs = net(inputs)</code>, 把图片数据送到网络里面，得到预测结果。</strong></span></li>
<li><span style="color:#956fe7"><strong><code>loss = criterion(outputs, labels)</code>, 计算当前 batch 的损失值。</strong></span></li>
<li><span style="color:#956fe7"><strong><code>loss.backward()</code>，执行链式求导，计算梯度。</strong></span></li>
<li><span style="color:#956fe7"><strong><code>optimizer.step()</code>，通过4中计算出来的梯度，更新每个可训练权重。</strong></span></li>
</ul>
 <pre><code>net = Net()
criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)

for epoch in range(5):

    running_loss = 0.0
    for i, data in enumerate(trainloader, 0):
        inputs, labels = data
        inputs, labels = Variable(inputs), Variable(labels)
        optimizer.zero_grad()
        outputs = net(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        running_loss += loss.item()
        if i % 6000 == 5999:
            print('[%d, %5d] loss: %.3f' %
                  (epoch + 1, i + 1, running_loss / 6000))
            running_loss = 0.0

print('Finished Training')</code></pre> 
 <p style="text-align:center"><img alt="" height="338" src="https://images2.imgbox.com/0e/23/nnR22Nu0_o.png" width="623"></p> 
 <p><strong>可以看到，随着训练过程的推进，损失函数在慢慢变小，说明神经网络的输出在慢慢接近真实标签。</strong></p> 
 <p><strong><span style="color:#fe2c24">模型验证：</span>我们在测试集上看一下模型预测的准确率，在预测时，我们将模型输出的10个值中最大的那个对应的类别作为模型的预测类别，</strong></p> 
 <pre><code># 测试模型
correct = 0
total = 0
for data in testloader:
    images, labels = data
    outputs = net(Variable(images))
    # 返回可能性最大的索引 -&gt; 输出标签
    _, predicted = torch.max(outputs, 1)
    total += labels.size(0)
    correct += (predicted == labels).sum()

print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))
==============================================
Accuracy of the network on the 10000 test images: 62 %</code></pre> 
 <p><strong>考虑到一共有10个类别，如果预测一个类别，准确期望在0.1，我们结果为62%，说明经过训练的网络确实学到了一些东西。下面计算我们的神经网络在<span style="color:#fe2c24">每个类别上的分类准确率：</span></strong></p> 
 <pre><code>class_correct = list(0. for i in range(10))
class_total = list(0. for i in range(10))
for data in testloader:
    images, labels = data
    outputs = net(Variable(images))
    _, predicted = torch.max(outputs.data, 1)
    c = (predicted == labels).squeeze()
    for i in range(4):  # mini-batch's size = 4
        label = labels[i]
        class_correct[label] += c[i]
        class_total[label] += 1

for i in range(10):
    print('Accuracy of %5s : %2d %%' % (
        classes[i], 100 * class_correct[i] / class_total[i]
    ))
=========================================
Accuracy of plane : 69 %
Accuracy of   car : 66 %
Accuracy of  bird : 58 %
Accuracy of   cat : 35 %
Accuracy of  deer : 54 %
Accuracy of   dog : 56 %
Accuracy of  frog : 70 %
Accuracy of horse : 73 %
Accuracy of  ship : 71 %
Accuracy of truck : 67 %</code></pre> 
</blockquote> 
<h3><span style="color:#4da8ee">3.4，模型的保存和加载</span></h3> 
<blockquote> 
 <p><strong><span style="color:#0d0016">神经网络的训练往往是比较耗时的，特别是在模型比较复杂、数据量比较大的时候，所以我们经常会希望将训练好的模型保存到文件供以后使用。这时我们可以调用网络的state_dict()方法，该方法会以字典的形式返回模型的所有参数。字典的key是模型参数的名字，字典的value是存储对应参数具体数值的Tensor。</span></strong></p> 
 <pre><code>print(net.state_dict().keys())
print(net.state_dict()['conv1.bias'])
============================================================================
odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])
tensor([ 0.0970, -0.3732, -0.6456, -0.3526,  0.4653, -0.4466])</code></pre> 
 <p><strong>接下来我们可以进一步使用torch.save()将state_dict()返回的模型参数保存到文件之后需要使用的时候，可以先用torch.load()从文件中读取模型参数，再用load_state_dict()方法将参数加载到神经网络模型中。</strong></p> 
 <pre><code>torch.save(net.state_dict(), './data/' + 'model.pt')
net.load_state_dict(torch.load('./data/' + 'model.pt'))</code></pre> 
</blockquote> 
<h3><span style="color:#4da8ee">3.5，代码</span></h3> 
<blockquote> 
 <pre><code>import torch.utils.data
import torchvision
import torchvision.transforms as transforms
import matplotlib.pyplot as plt
import numpy as np
import torch
import torch.nn.functional as F
import torch.nn as nn
from torch.autograd import Variable
import torch.optim as optim

transform = transforms.Compose(
    [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]
)
trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)
trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True, num_workers=0)  # windows 下线程参数设为 0 安全
testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)
testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=False, num_workers=0)

classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')


class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()  # 定义一个神经网络
        self.conv1 = nn.Conv2d(3, 6, 5)  # 两个卷积层，三个全连接层
        self.conv2 = nn.Conv2d(6, 16, 5)  # 输入3个通道，输出6个通道，卷积核5*5
        self.fc1 = nn.Linear(16 * 5 * 5, 120)  # 输入84维，输出10维
        self.fc2 = nn.Linear(120, 84)
        self.fc3 = nn.Linear(84, 10)

    # 在init中我们值定义了搭建网络的层，但没有真正定义网络的结构
    # 真正的输入输出关系是在forward()方法中定义的，控制数据在网络中的流动方式
    def forward(self, x):
        x = F.max_pool2d(F.relu(self.conv1(x)), 2)  # 激活函数ReLU，先经过一个卷积层，然后一个全连接层
        x = F.max_pool2d(F.relu(self.conv2(x)), 2)
        x = x.view(-1, 16 * 5 * 5)
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = self.fc3(x)
        return x


net = Net()
criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)
# 训练模型
# for epoch in range(5):
#
#     running_loss = 0.0
#     for i, data in enumerate(trainloader, 0):
#         inputs, labels = data
#         inputs, labels = Variable(inputs), Variable(labels)
#         optimizer.zero_grad()
#         outputs = net(inputs)
#         loss = criterion(outputs, labels)
#         loss.backward()
#         optimizer.step()
#         running_loss += loss.item()
#         if i % 6000 == 5999:
#             print('[%d, %5d] loss: %.3f' %
#                   (epoch + 1, i + 1, running_loss / 6000))
#             running_loss = 0.0

print('Finished Training')
# 保存训练好的模型
#torch.save(net.state_dict(), './data/' + 'model.pt')
net.load_state_dict(torch.load('./data/' + 'model.pt'))
print(net.state_dict().keys())
print(net.state_dict()['conv1.bias'])

# 测试模型
# correct = 0
# total = 0
# for data in testloader:
#     images, labels = data
#     outputs = net(Variable(images))
#     # 返回可能性最大的索引 -&gt; 输出标签
#     _, predicted = torch.max(outputs, 1)
#     total += labels.size(0)
#     correct += (predicted == labels).sum()
#
# print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))
# class_correct = list(0. for i in range(10))
# class_total = list(0. for i in range(10))
# for data in testloader:
#     images, labels = data
#     outputs = net(Variable(images))
#     _, predicted = torch.max(outputs.data, 1)
#     c = (predicted == labels).squeeze()
#     for i in range(4):  # mini-batch's size = 4
#         label = labels[i]
#         class_correct[label] += c[i]
#         class_total[label] += 1
#
# for i in range(10):
#     print('Accuracy of %5s : %2d %%' % (
#         classes[i], 100 * class_correct[i] / class_total[i]
#     ))
</code></pre> 
</blockquote>
                </div>

		</div>
	</article>
</main>




			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程小白.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://www.w3counter.com/tracker.js?id=150625"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>
	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>