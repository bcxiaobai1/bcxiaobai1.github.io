<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<title>泰坦尼克号沉船数据分析与可视化、数据建模与分类预测【Python | 机器学习-Sklearn】 - 编程小白</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程小白" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程小白</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">泰坦尼克号沉船数据分析与可视化、数据建模与分类预测【Python | 机器学习-Sklearn】</h1>
			
		</header>
		<div class="content post__content clearfix">
			


        
                <div id="content_views" class="htmledit_views">
                    <h1>泰坦尼克号沉船数据之美——起于悲剧，止于浪漫</h1> 
<p>前言：泰坦尼克号，不只是卡梅隆导演的经典电影，它是一个真实存在的悲剧，也是电影的故事背景与题材。作为一个IT人，分析事实还得看数据，了解到泰坦尼克号沉船幸存者多为老人、小孩和妇女，而牺牲者多为年轻的男士，这样的历史数据，让我感受到了人性之美与善，七夕，我们一起来分析一下这一悲壮与浪漫的数据吧～</p> 
<p>本文内容包含了泰坦尼克号沉船<strong>数据分析与可视化、数据建模与分类预测</strong>。</p> 
<p>现有 titanic.csv 数据集。该数据集记录了泰坦尼克轮船上的乘客信息。使用 scikit-learn 对该数据集进行分析，探究生存率和哪些因素有关(性别,年龄,是否有伴侣,票价,舱位等级,包间,出发地点)。</p> 
<p>关键步骤：</p> 
<p>1、把数据随机分成训练集和测试集两类。</p> 
<p>2、构造特征向量。（注意：如果所选特征是非数值特征，需要将其转成数值。）</p> 
<p>3、分别训练判定树、KNN、SVC和朴素贝叶斯四种模型，对测试数据进行预测。</p> 
<p>4、使用混淆矩阵对分类器的分类结果进行评估，比较。</p> 
<p>5** 绘制ROC曲线。</p> 
<h3>获取资源：</h3> 
<p>百度网盘：<a href="https://pan.baidu.com/s/1qsY70lqwmgWnMn-A81NOaw" title="https://pan.baidu.com/s/1qsY70lqwmgWnMn-A81NOaw">https://pan.baidu.com/s/1qsY70lqwmgWnMn-A81NOaw</a> <br>     提取码：<em>wsdc</em></p> 
<p>演示环境：Python 3、Jupyter notebook</p> 
<p>涉及技术：scikit-learn 分类 + seaborn + matplotlib + pandas +numpy</p> 
<h3 id="%E6%93%8D%E4%BD%9C%E6%AD%A5%E9%AA%A4%EF%BC%9A">操作步骤：</h3> 
<p>导入数据集预处理、特征工程、模型训练和模型对比所需的库</p> 
<div> 
 <pre><code class="language-python">import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from pylab import *
import seaborn as sns

from sklearn import model_selection, preprocessing, naive_bayes, metrics, svm
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn import ensemble, tree

# 忽略警告提示
import warnings
warnings.filterwarnings('ignore')</code></pre> 
</div> 
<p><strong>1. 数据预处理</strong></p> 
<p><strong>1.1 导入数据</strong></p> 
<div> 
 <pre><code class="language-python">data = pd.read_csv('titanic.csv')
print(data.shape)
data.sample(5)</code></pre> 
</div> 
<p>输出：(891, 15)</p> 
<p><img alt="" height="224" src="https://images2.imgbox.com/41/eb/Yo6iLNIg_o.png" width="1058">​</p> 
<p><strong>1.2 处理缺失值</strong></p> 
<div> 
 <pre><code class="language-python">data.isnull().sum()</code></pre> 
</div> 
<p>输出：</p> 
<hr> 
<pre>survived         0
pclass           0
sex              0
age            177
sibsp            0
parch            0
fare             0
embarked         2
class            0
who              0
adult_male       0
deck           688
embark_town      2
alive            0
alone            0
dtype: int64</pre> 
<hr> 
<p>缺失值分析：</p> 
<p>age、deck、embarked、embark_town 存在缺失值，需要处理。（1）age 对生存率有影响，不能忽略，用平均值填充；（2）总共有 891 条信息，deck 有 688 个缺失值，因此剔除 deck 这个分类标签；（3）embarked、embark_town 缺失值较少，都为 2 个，随机取其中一个数据填充。</p> 
<div> 
 <pre><code class="language-python">data['age']=data['age'].fillna(data['age'].median())
del data['deck']
data['embarked']=data['embarked'].fillna('S')
data['embark_town']=data['embark_town'].fillna('Southampton')

data.isnull().sum()</code></pre> 
</div> 
<p>输出：</p> 
<hr> 
<pre>survived       0
pclass         0
sex            0
age            0
sibsp          0
parch          0
fare           0
embarked       0
class          0
who            0
adult_male     0
embark_town    0
alive          0
alone          0
dtype: int64</pre> 
<hr> 
<p><strong>1.3 观察数据</strong></p> 
<p><strong>1.3.1 全体成员的生存情况</strong></p> 
<div> 
 <pre><code class="language-python">survived = data['survived'].value_counts().to_frame().reset_index().rename(columns={'index': 'label', 'survived': 'counts'})

#计算存活率
survived_rate = round(342/891, 2)
survived['rate'] = [1-survived_rate, survived_rate]
survived</code></pre> 
</div> 
<p>输出：</p> 
<p><img alt="" height="117" src="https://images2.imgbox.com/4d/cf/MpQlXi3j_o.png" width="186">​</p> 
<p>数据描述：存活 的有 342 人，遇难 的有 549 人。</p> 
<div> 
 <pre><code class="language-python">mpl.rcParams['axes.unicode_minus'] = False     #处理无法显示中文的问题
mpl.rcParams['font.sans-serif'] = ['SimHei']  

fig=plt.figure(1,figsize=(6,6))
ax1=fig.add_subplot(1,1,1)  
label=['遇难','存活']
color=['#C23531','#F5DEB3']
explode=0.05,0.05  #扇区间隔

patches,l_text,p_text = ax1.pie(survived.rate,labels=label,colors=color,startangle=90,autopct='%1.0f%%',explode=explode,shadow=True)
for t in l_text:
    t.set_size(20)
for t in p_text:
    t.set_size(20)
ax1.set_title('全体成员的生存情况', fontsize=20) </code></pre> 
</div> 
<p>输出：</p> 
<p><img alt="" height="269" src="https://images2.imgbox.com/98/d8/sziginah_o.png" width="296">​</p> 
<p><strong> 1.3.2 乘客的各属性分布情况</strong></p> 
<div> 
 <pre><code class="language-python">fig = plt.figure(figsize=(15,10))
fig.set(alpha=0.3)  # 设定图表颜色alpha参数(透明度)

plt.subplot2grid((2,3),(0,0))
data.survived.value_counts().plot(kind='bar')
plt.title("获救情况 (1为获救)")
plt.ylabel("人数")

plt.subplot2grid((2,3),(0,1))
data.pclass.value_counts().plot(kind="bar")
plt.ylabel("人数")
plt.title("乘客等级分布")

plt.subplot2grid((2,3),(0,2))
plt.scatter(data.survived, data.age)
plt.ylabel("年龄")
plt.grid(b=True, which='major', axis='y')
plt.title("按年龄看获救分布 (1为获救)")

plt.subplot2grid((2,3),(1,0), colspan=2)
data.age[data.pclass == 1].plot(kind='kde')
data.age[data.pclass == 2].plot(kind='kde')
data.age[data.pclass == 3].plot(kind='kde')
plt.xlabel("年龄")
plt.ylabel("密度")
plt.title("各等级的乘客年龄分布")
plt.legend(('头等舱', '2等舱','3等舱'),loc='best')

plt.subplot2grid((2,3),(1,2))
data.embarked.value_counts().plot(kind='bar')
plt.title("各登船口岸上船人数")
plt.ylabel("人数")
plt.show()</code></pre> 
</div> 
<p>输出： </p> 
<p><img alt="" height="774" src="https://images2.imgbox.com/d8/6c/u6vIoju5_o.png" width="1162">​</p> 
<p><strong>1.3.3 特征之间的相关性</strong></p> 
<div> 
 <pre><code class="language-python">sns.heatmap(data.corr(),annot=True,cmap='RdYlGn',linewidths=0.2)
fig=plt.gcf()
fig.set_size_inches(10,8)
plt.show()</code></pre> 
</div> 
<p>输出： </p> 
<p><img alt="" height="664" src="https://images2.imgbox.com/fa/90/zDES4D1f_o.png" width="780">​</p> 
<p><strong> 1.3.4 连续值特征（年龄、船票费用）对生存结果的影响</strong></p> 
<div> 
 <pre><code class="language-python">fig = plt.figure(figsize=(15,4))

plt.subplot2grid((2,2),(0,0))
data.age[data.survived == 0].plot(kind='box', vert=False, patch_artist=True, notch = True, color='#C23531', fontsize=15)
plt.grid(linestyle="--", alpha=0.8)
plt.title("遇难", fontsize=15)

plt.subplot2grid((2,2),(0,1))
data.fare[data.survived == 0].plot(kind='box', vert=False, patch_artist=True, notch = True, color='#C23531', fontsize=15)
plt.grid(linestyle="--", alpha=0.8)
plt.title("遇难", fontsize=15)

plt.subplot2grid((2,2),(1,0))
data.age[data.survived == 1].plot(kind='box', vert=False, patch_artist=True, notch = True, color='#F5DEB3', fontsize=15)
plt.grid(linestyle="--", alpha=0.8)
plt.xlabel("存活", fontsize=15)

plt.subplot2grid((2,2),(1,1))
data.fare[data.survived == 1].plot(kind='box', vert=False, patch_artist=True, notch = True, color='#F5DEB3', fontsize=15)
plt.grid(linestyle="--", alpha=0.8)
plt.xlabel("存活", fontsize=15)</code></pre> 
</div> 
<p>输出：<img alt="" height="387" src="https://images2.imgbox.com/5b/76/zc7MMAIh_o.png" width="1146">​</p> 
<p><strong> 1.3.5 乘客等级、性别对生存结果的影响（从年龄的分布看）</strong></p> 
<div> 
 <pre><code class="language-python">mpl.rcParams.update({'font.size': 14})
fig,axes=plt.subplots(2,2,figsize=(18, 12))
sns.violinplot("pclass","age", hue="survived", data=data, palette='autumn',ax=axes[0][0]).set_title('Pclass and Age vs Survived')
sns.swarmplot(x="pclass", y="age",hue="survived", data=data,palette='autumn',ax=axes[1][0]).legend(loc='upper right').set_title('survived')
sns.violinplot("sex","age", hue="survived", data=data, palette='winter', ax=axes[0][1]).set_title('Sex and Age vs Survived')
sns.swarmplot(x="sex", y="age",hue="survived", data=data,palette='winter',ax=axes[1][1]).legend(loc='upper right').set_title('survived')</code></pre> 
</div> 
<p>输出：  </p> 
<p><img alt="" height="871" src="https://images2.imgbox.com/49/8a/4FhEFhDg_o.png" width="1200">​</p> 
<p><strong>1.3.6 乘客等级、性别对生存结果的影响（从船票费用的分布看）</strong></p> 
<div> 
 <pre><code class="language-python">fig,axes=plt.subplots(2,2,figsize=(18, 12))
sns.violinplot("pclass","fare", hue="survived", data=data, palette='autumn',ax=axes[0][0]).set_title('Pclass and Age vs Survived')
sns.stripplot("pclass", "fare",hue="survived", data=data,palette='autumn',ax=axes[1][0]).legend(loc='upper right').set_title('survived')
sns.violinplot("sex","fare", hue="survived", data=data, palette='winter', ax=axes[0][1]).set_title('Sex and Age vs Survived')
sns.stripplot("sex", "fare",hue="survived", data=data,palette='winter',ax=axes[1][1]).legend(loc='upper right').set_title('survived')</code></pre> 
</div> 
<p>输出：  </p> 
<p><img alt="" height="839" src="https://images2.imgbox.com/dd/b6/o2EBhUcV_o.png" width="1200">​</p> 
<p id="2.-特征工程"><strong>2. 特征工程</strong></p> 
<p><strong>2.1 Feature Preprocessing——标签编码预处理</strong></p> 
<p>在所有标签中，survived 是分类标签，其余的 14 个变量是分类特征。 由于特征和标签的值存在非结构化类型，因此需要进行特征工程处理，即进行字符串编码处理。</p> 
<div> 
 <pre><code class="language-python">data.info()</code></pre> 
</div> 
<p>输出：</p> 
<hr> 
<pre>&lt;class 'pandas.core.frame.DataFrame'&gt;
RangeIndex: 891 entries, 0 to 890
Data columns (total 14 columns):
 #   Column       Non-Null Count  Dtype  
---  ------       --------------  -----  
 0   survived     891 non-null    int64  
 1   pclass       891 non-null    int64  
 2   sex          891 non-null    object 
 3   age          891 non-null    float64
 4   sibsp        891 non-null    int64  
 5   parch        891 non-null    int64  
 6   fare         891 non-null    float64
 7   embarked     891 non-null    object 
 8   class        891 non-null    object 
 9   who          891 non-null    object 
 10  adult_male   891 non-null    bool   
 11  embark_town  891 non-null    object 
 12  alive        891 non-null    object 
 13  alone        891 non-null    bool   
dtypes: bool(2), float64(2), int64(4), object(6)
memory usage: 85.4+ KB</pre> 
<hr> 
<p>初始化编码器</p> 
<div> 
 <pre><code class="language-python">le = preprocessing.LabelEncoder()
for col in data.columns:
    data[col] = le.fit_transform(data[col])
data.head()
data.to_csv('Preprocessing_Titanic.csv')</code></pre> 
</div> 
<p><strong>2.2 去除多余的的标签</strong></p> 
<p>名字对生存率几乎没有影响，所以删除 who 标签</p> 
<div> 
 <pre><code class="language-python">del data['who']</code></pre> 
</div> 
<p>去掉意思表达一样的标签</p> 
<div> 
 <pre><code class="language-python">data_ = data.T.drop_duplicates().T
print('去重前：', len(data.columns))
print('去重后：', len(data_.columns))

for a in data.columns:
    if a not in data_.columns:
        for b in data_.columns:
            if list(data[b].values) == list(data[a].values):
                print(f'重复标签: {a} 和 {b}')
data = data_</code></pre> 
</div> 
<p>输出：</p> 
<hr> 
<pre>去重前： 13
去重后： 10
重复标签: class 和 pclass
重复标签: embark_town 和 embarked
重复标签: alive 和 survived
</pre> 
<hr> 
<div> 
 <pre><code class="language-python">data.head()</code></pre> 
</div> 
<p>输出： </p> 
<p><img alt="" height="231" src="https://images2.imgbox.com/88/08/B2HDu3dG_o.png" width="641">​</p> 
<p><strong>2.3 可视化探索各个特征的分布情况</strong></p> 
<div> 
 <pre><code class="language-python">result_plot = data.hist(bins=50, figsize=(14, 12))</code></pre> 
</div> 
<p>输出：</p> 
<p><img alt="" height="879" src="https://images2.imgbox.com/1b/33/Md117BXY_o.png" width="1096">​</p> 
<p> 由上面的可视化情况来看，不需要对特征进行标准化处理。</p> 
<div> 
 <pre><code class="language-python"># 对数据进行标准化
# X = StandardScaler().fit_transform(X)</code></pre> 
</div> 
<p><strong>2.4 10折交叉验证分割数据集，9份做训练，1份做测试 ，确保训练和测试数据无交集</strong></p> 
<div> 
 <pre><code class="language-python">X = data.iloc[:, 1:]
y = data.iloc[:, 0]

x_train, x_test, y_train, y_test = train_test_split(X, y,test_size=0.1,shuffle=True,random_state=20)

print(x_train.shape)
print(x_test.shape)
print(y[:5])
X[:5]</code></pre> 
</div> 
<p>输出：</p> 
<hr> 
<pre>(801, 9)
(90, 9)
0    0
1    1
2    1
3    1
4    0
Name: survived, dtype: int64</pre> 
<hr> 
<p><img alt="" height="220" src="https://images2.imgbox.com/a4/97/sm2kkcv6_o.png" width="570">​</p> 
<p id="3.-建立模型训练及评估函数"><strong>3. 建立模型训练及评估函数</strong></p> 
<p><strong>3.1 建模</strong></p> 
<div> 
 <pre><code class="language-python">model, train_score, test_score, roc_auc = [], [], [], []  # 存储相关模型信息，以便后续分析

def train_model(classifier, x_train, y_train, x_test):
    lr = classifier  # 初始化
    lr.fit(x_train, y_train)  # 训练
    y_pred_lr = lr.predict(x_test)  # 预测

    if '.' in str(classifier):
        model_name = str(classifier).split('(')[0].split('Classifier')[0].split('.')[1]
        print('n{:=^60}'.format(model_name))
    else:
        model_name = str(classifier).split('(')[0].split('Classifier')[0]
        print('n{:=^60}'.format(model_name))
    model.append(model_name)
        
    # 性能评估
    print('n&gt;&gt;&gt;在训练集上的表现：', lr.score(x_train, y_train))
    print('n&gt;&gt;&gt;在测试集上的表现：', metrics.accuracy_score(y_test, y_pred_lr))
    print('n&gt;&gt;&gt;预测的 Roc_auc：%.4f' % metrics.roc_auc_score(y_test, y_pred_lr))
    print('n&gt;&gt;&gt;混淆矩阵'),show_confusion_matrix(metrics.confusion_matrix(y_test,y_pred_lr))
    
    train_score.append(lr.score(x_train, y_train))
    test_score.append(metrics.accuracy_score(y_test, y_pred_lr))
    roc_auc.append(metrics.roc_auc_score(y_test, y_pred_lr))</code></pre> 
</div> 
<p><strong>3.2 绘制误分类矩阵函数</strong></p> 
<div> 
 <pre><code class="language-python">def show_confusion_matrix(cnf_matrix):
    plt.matshow(cnf_matrix,cmap=plt.cm.YlGn,alpha=0.7)
    ax=plt.gca()
    ax.set_xlabel('Predicted Label',fontsize=16)
    ax.set_xticks(range(0,len(survived.label)))
    ax.set_xticklabels(survived.label,rotation=45)
    ax.set_ylabel('Actual Label',fontsize=16,rotation=90)
    ax.set_yticks(range(0,len(survived.label)))
    ax.set_yticklabels(survived.label)
    ax.xaxis.set_label_position('top')
    ax.xaxis.tick_top()
    for row in range(len(cnf_matrix)):
        for col in range(len(cnf_matrix[row])):
            ax.text(col,row,cnf_matrix[row][col],va='center',ha='center',fontsize=16)
    plt.show()</code></pre> 
</div> 
<p><strong>3.3 绘制ROC曲线函数</strong></p> 
<div> 
 <pre><code class="language-python">def show_roc_line(classifier, x_train, y_train):  
    y_train_prob=classifier.predict_proba(x_train)
    y_pred_prob=y_train_prob[:,1]                             #正例率 
    fpr,tpr,thresholds=metrics.roc_curve(y_train,y_pred_prob) #计算ROC曲线
    auc=metrics.auc(fpr,tpr)                                  #计算AUC 
    plt.plot(fpr,tpr,lw=2,label='ROC curve (area={:.2f})'.format(auc))
    plt.plot([0,1],[0,1],'r--')
    plt.xlim([-0.01, 1.02])
    plt.ylim([-0.01, 1.02])
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic')
    plt.legend(loc='lower right')
    plt.show() </code></pre> 
</div> 
<p id="4.-训练预测"><strong>4. 训练预测</strong></p> 
<p><strong>(1) Decision Tree 模型</strong></p> 
<div> 
 <pre><code class="language-python">classifier = tree.DecisionTreeClassifier()
train_model(classifier, x_train, y_train, x_test)  #建模</code></pre> 
</div> 
<p>输出：</p> 
<p><img alt="" height="573" src="https://images2.imgbox.com/c2/1e/MQUmguvL_o.png" width="594">​</p> 
<p> 可视化特征重要性权重</p> 
<div> 
 <pre><code class="language-python">labels = X.columns
importances = classifier.feature_importances_   # 获取特征权重值
indices = np.argsort(importances)[::-1]# 打印特征等级

features = [labels[i] for i in indices]
weights = [importances[i] for i in indices]

print("Feature ranking:")
for f in range(len(features)):
    print("%d. %s (%f)" % (f + 1, features[f], weights[f]))# 绘制随机森林的特征重要性
    
plt.figure()
plt.title("Feature importances")
plt.bar(features, np.array(weights), color='r')
plt.xticks(rotation=90)
plt.title('Feature Weights')
plt.show()</code></pre> 
</div> 
<p><img alt="" height="661" src="https://images2.imgbox.com/69/6e/F8FgertI_o.png" width="524">​</p> 
<p> 数据分析：从上面的可视化图可以看出，对生存率影响大的特征只有 4 个：fare(船票费用)、adult_male(成年男性)、age(年龄)、pclass(乘客等级)。</p> 
<p><strong>(2) KNN模型</strong></p> 
<div> 
 <pre><code class="language-python">classifier = KNeighborsClassifier(n_neighbors=20)
train_model(classifier, x_train, y_train, x_test)  
show_roc_line(classifier, x_train, y_train)</code></pre> 
</div> 
<p>输出：</p> 
<p><img alt="" height="926" src="https://images2.imgbox.com/52/fe/F4iGkZkV_o.png" width="602">​</p> 
<p> (3) SVC模型</p> 
<div> 
 <pre><code class="language-python">classifier = svm.SVC()
train_model(classifier, x_train, y_train, x_test)</code></pre> 
</div> 
<p>输出：</p> 
<p><img alt="" height="574" src="https://images2.imgbox.com/5f/76/wock4bW8_o.png" width="587">​</p> 
<p><strong> (4) 朴素贝叶斯</strong></p> 
<div> 
 <pre><code class="language-python">classifier = naive_bayes.GaussianNB()
train_model(classifier, x_train, y_train, x_test)  #建模</code></pre> 
</div> 
<p>输出：</p> 
<p><img alt="" height="559" src="https://images2.imgbox.com/3e/15/KBFt5rPn_o.png" width="560">​</p> 
<p></p> 
<div> 
 <pre><code class="language-python">show_roc_line(classifier, x_train, y_train)  #绘制ROC曲线</code></pre> 
</div> 
<p>输出： </p> 
<p><img alt="" height="362" src="https://images2.imgbox.com/6e/37/0OEGDg9K_o.png" width="510">​</p> 
<p><strong> 5. 性能比较</strong></p> 
<p>比较不同模型之间的性能情况</p> 
<div> 
 <pre><code class="language-python">df = pd.DataFrame()
df['model'] = model
df['Roc_auc'] = roc_auc
df['train_score'] = train_score
df['test_score'] = test_score
df</code></pre> 
</div> 
<p>输出：</p> 
<p><img alt="" height="190" src="https://images2.imgbox.com/c9/0e/Pq7Rp6ax_o.png" width="402">​</p> 
<p>【评判标准：AUC(Area under Curve)，Roc曲线下的面积，介于0.1和1之间。Auc作为数值可以直观的评价分类器的好坏，值越大越好。】</p> 
<p>从上面的结果可以看出，朴素贝叶斯(GaussianNB)的 Roc_auc 分值最高，预测结果最好，说明朴素贝叶斯比较适合泰坦尼克号问题的分类。</p> 
<p>特别的，对于 DecisionTree 的训练和预测结果，可以看出训练集拟合非常好，但是测试集拟合较差，说明过拟合了，需要调参：</p> 
<div> 
 <pre><code class="language-python">param = [{'criterion':['gini'],'max_depth': np.arange(20,50,10),'min_samples_leaf':np.arange(2,8,2),
          'min_impurity_decrease':np.linspace(0.1,0.9,10)},
         {'criterion':['gini','entropy']},
         {'min_impurity_decrease':np.linspace(0.1,0.9,10)}]
clf = GridSearchCV(tree.DecisionTreeClassifier(),param_grid=param,cv=10)
clf.fit(x_train,y_train)
print('最优参数:', clf.best_params_)
print('最好成绩:', clf.best_score_)</code></pre> 
</div> 
<p>输出：</p> 
<hr> 
<pre>最优参数: {'criterion': 'gini', 'max_depth': 20, 'min_impurity_decrease': 0.1, 'min_samples_leaf': 2}
最好成绩: 0.7839814814814815</pre> 
<hr> 
<p>按最优参数生成决策树</p> 
<div> 
 <pre><code class="language-python">model = tree.DecisionTreeClassifier(criterion= 'gini', max_depth=20, min_impurity_decrease=0.1, min_samples_leaf= 2)
model.fit(x_train, y_train)
y_pred = model.predict(x_test)
print('train score:', clf.score(x_train, y_train))
print('test score:', clf.score(x_test, y_test))
print("查准率：", metrics.precision_score(y_test,y_pred))
print('召回率:',metrics.recall_score(y_test,y_pred))
print('f1分数:', metrics.f1_score(y_test,y_pred)) #二分类评价标准</code></pre> 
</div> 
<p>输出：</p> 
<hr> 
<pre>train score: 0.784019975031211
test score: 0.8333333333333334
查准率： 0.7647058823529411
召回率: 0.7878787878787878
f1分数: 0.7761194029850745</pre> 
<hr> 
<p>从上面的分值来看，按最优参数生成决策树的预测结果比较理想，但还是比朴素贝叶斯(GaussianNB)的预测分值差一些，比其他模型的预测分值好。</p> 
<p></p> 
<p><strong>【最后，祝大家七夕快乐，顺便记得给我点个赞~~~~】</strong></p> 
<p><strong>【同时，欢迎留言、讨论~~~】</strong></p> 
<p></p> 
<p></p>
                </div>

		</div>
	</article>
</main>




			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程小白.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://www.w3counter.com/tracker.js?id=150625"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>
	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>