<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<title>基于pytorch使用LSTM进行虎年春联生成 - 编程小白</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程小白" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程小白</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">基于pytorch使用LSTM进行虎年春联生成</h1>
			
		</header>
		<div class="content post__content clearfix">
			


                <div id="content_views" class="markdown_views prism-atom-one-dark">
                    
                        
                    
                    <p>先看看我摘录的一些结果吧</p> 
<p>七字春联，开头两个字分别为 虎年、虎气、春节</p> 
<p>虎年啸虎春虎虎<br> 虎气伏虎牛龙龙</p> 
<p>虎年虎虎展啸风<br> 春节啸春虎风虎</p> 
<p>虎年虎啸啸千啸<br> 春节萝啸气风春</p> 
<p>虎年啸浩一讯欢<br> 春节回旧鹤绣舞</p> 
<p>虎年啸一着有处<br> 春节回一福舞福</p> 
<p>虎年啸月翼业来<br> 春节回旧精绣福</p> 
<p>我语文水平不太行，乍一眼看感觉还是满高级的。</p> 
<p>训练数据 春联.csv</p> 
<pre><code class="prism language-python"><span class="token number">0</span>
龙腾虎啸
腊尽春回
高崖伏虎啸
茅庐卧龙飞
虎啸风声远
龙腾海浪高
龙引千江水
虎越万重山
密林藏伏虎
萝峰染晴云
山月流古雪
风虎浴清泉
事事都如意
虎虎有生气
云中熊虎将
天上凤凰儿
百尺飞泉鸣震谷
一声长啸势惊天
丙部琳琅春馥郁
寅宾璀灿日光华
长白虎啸林中日
江南猿啼岭上风
赤县奔腾如虎跃
神州崛起似龙飞
丑旧寅新宏图展
牛归虎跃春意浓
丑去寅来千里锦
牛奔虎啸九州春
丑去寅来人益健
牛奔虎跃春愈新
春风浩荡神州绿
虎气升腾岳麓雄
春风着意随人愿
虎气生威壮国魂
春光春色源春意
虎将虎年扬虎威
春节乍闻春有喜
虎年乐见虎生风
春雷巨响山河动
月夜旋风草木飞
春晓寅回人起舞
岁祯虎啸物昭苏
电闪金光夸五色
雷鸣巨吼动千山
憨厚忠诚牛品德
高昂奋勇虎精神
虎步奔腾开胜景
春风浩荡展鸿图
虎踞龙盘今胜昔
花得鸟语旧更新
虎踞龙盘今胜昔
莺歌燕舞呈吉祥
虎年赢得春风意
喜讯唤来燕子情
虎气顿生年属虎
春风常驻户迎春
虎气频催翻旧景
春风浩荡著新篇
虎添双翼前程远
国展宏图事业新
虎啸大山山献宝
龙腾祖国国扬威
虎啸密林凤万壑
鹤眠苍松月千岩
虎啸青山千里锦
风拂绿柳万家春
虎啸一声山海动
龙腾三界吉祥来
虎跃龙腾生紫气
风调雨顺兆丰年
虎跃龙腾兴骏业
莺歌燕舞羡鹏程
虎跃神州千业旺
春临盛世万民欢
花事才逢花好日
虎年更有虎威风
黄牛虽去精神在
猛虎初来气象新
江山秀丽春增色
事业辉煌虎更威
江山一统腾龙日
岁月三春入虎年
皆称飞虎一身胆
不负英雄千古名
金牛昂首高歌去
玉虎迎春敛福来
金牛辞岁寒风尽
白虎迎春喜气来
金牛辞岁千仓满
玉虎迎春百业兴
金牛奋蹄奔大道
乳虎添翼舞新春
金牛奋蹄开锦绣
乳虎添翼会风云
金牛送旧千家乐
玉虎迎新万户欢
龙腾虎跃人间景
鸟语花香天地春
绿野春深禾涌碧
神州虎啸青山来
门庭虎踞平安岁
柳浪莺歌锦绣春
门浴春风梅吐艳
户生虎气鸟争鸣
年逢寅虎群情奋
岁别丑牛大地春
牛肥马壮丰收岁
虎跃龙腾大有年
牛肥马壮家家富
虎跃龙腾处处春
牛奋千程荣盛世
虎驮五福贺新春
牛奋四蹄开锦绣
虎添双翼会风云
牛耕绿野千仓满
虎啸青山万木荣
牛耕沃野扬长去
虎啸群山大步来
千载难逢新世纪
万民谱写虎春秋
乾元启运三阳泰
斗丙回寅万户春
人逢盛世精神壮
虎跃奇峰气势雄
人间喜庆康平世
虎岁承欢幸福春
人民气魄如龙虎
祖国江山似画图
人入虎年鼓虎劲
门添春色发春辉
人添志气虎添翼
雪舞丰年燕舞春
人效黄牛心自贵
岁朝寅虎劲更高
山明水秀风光丽
虎跃龙腾日月新
生气联吟欣虎虎
留春伴读奋年年
四海龙腾抒壮志
千山虎啸振雄风
四海三江春气息
千家万户虎精神
四海笙歌迎虎岁
九州英杰跃鹏程
唯大英雄能伏虎
是真俊杰敢擒龙
啸一声惊天动地
睁双眼照耀乾坤
新年捷报虎添翼
大路朝阳马奋蹄
兴伟业仍须牛劲
展宏图更壮虎威
一代英豪生虎气
三春杨柳动莺歌
英雄气概如龙虎
祖国江山似画图
英雄时代英雄业
龙虎精神龙虎年
莺歌燕舞新春日
虎跃龙腾大治年
迎春节莺歌遍地
兴中华虎劲冲天
云喷笔花腾虎豹
雨翻墨浪走蛟龙
宅后青山金虎踞
门前绿水玉龙盘
致富脱贫添虎翼
开山治水展鹏程
丙穴鱼生人间改岁
寅方斗指天下皆春
春风浩荡花香鸟语
岁月峥嵘虎跃龙腾
虎跃龙腾九州焕彩
风调雨顺五谷丰登
牛奔福地普天献瑞
虎卧华堂满院生辉
势如破竹人欢马叫
安若泰山虎踞龙盘
紫气东来江山如画
红旗招展龙虎扬威
祖国富强神龙活虎
人民幸福舞燕飞莺
白虎替青牛招财进宝
黄莺鸣翠柳辞旧迎新
虎跃龙腾创人间奇迹
莺歌燕舞描大地春光
虎跃龙腾有天皆丽日
花香鸟语无地不春风
花团锦簇江山添异彩
虎啸龙吟华夏壮神威
金牛辞旧携凯歌而去
乳虎迎春带捷报新来
瑞雪兆丰年年年大吉
丑牛接寅虎虎虎生威
岁月逢春山河添锦绣
人民思治龙虎振精神
效虎豪吟放怀歌富岁
闻鸡起舞挥笔颂春光
祖国腾飞大鹏振羽翼
宏图再展乳虎显神通
庆虎岁把酒高吟虎跃曲
祝丰年扶犁又唱丰收谣
迎虎年敢逐改革拦路虎
送牛岁勇当奉献老黄牛
迎新春处处呈文明气象
入虎岁人人当改革先锋
虎跃龙腾碧海黄山妆玉宇
莺歌燕舞春风旭日蔚神州
虎跃龙腾华夏人民多俊杰
莺歌燕舞阳春山水尽朝晖
牛耕广野丑年犁出文明路
虎跃深山寅岁图开舜尧天
岁步寅年喜庆团圆同把酒
珠还合浦欢歌一统共迎春
喜庆牛年两制先迎香港还
欢歌兔岁亿民再赞澳门归
栽竹栽松竹隐凤凰松隐鹤
培山培水山藏虎豹水藏龙
丑岁建奇功香港回归昌国运
寅年兴大业宏图展现壮情怀
虎年喜虎劲攻关夺隘皆如虎
春节焕春光绣水描山总是春
牛年虽过去牛劲更增多奉献
虎岁喜临门虎威大振有精神
寅时入虎年十亿人民振虎劲
佳节描春色九州大地荡春潮
忆旧岁牛劲冲霄汉神鞭一指神州巨变
看今朝虎威壮中华众志成城经济腾飞

</code></pre> 
<p>滑动窗口设置为2，即两个字符预测下一个字符，滑动预测5个字符。<br> 但是还是存在较大问题，因为我是直接将所有的对联都拼接起来然后滑动选取训练数据和标签，而不是每句滑动选取，这样就导致会串，但是懒得切了，就这样吧。</p> 
<p>完整代码</p> 
<pre><code class="prism language-python"><span class="token comment"># coding: utf-8</span>
<span class="token keyword">import</span> torch
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span> OneHotEncoder
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F


<span class="token keyword">class</span> <span class="token class-name">lstm_model</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> vocab<span class="token punctuation">,</span> hidden_size<span class="token punctuation">,</span> num_layers<span class="token punctuation">,</span> dropout<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>lstm_model<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>vocab <span class="token operator">=</span> vocab  <span class="token comment"># 字符数据集</span>
        <span class="token comment"># 索引，字符</span>
        self<span class="token punctuation">.</span>int_char <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>i<span class="token punctuation">:</span> char <span class="token keyword">for</span> i<span class="token punctuation">,</span> char <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>vocab<span class="token punctuation">)</span><span class="token punctuation">}</span>
        self<span class="token punctuation">.</span>char_int <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>char<span class="token punctuation">:</span> i <span class="token keyword">for</span> i<span class="token punctuation">,</span> char <span class="token keyword">in</span> self<span class="token punctuation">.</span>int_char<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span>
        <span class="token comment"># 对字符进行one-hot encoding</span>
        self<span class="token punctuation">.</span>encoder <span class="token operator">=</span> OneHotEncoder<span class="token punctuation">(</span>sparse<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">.</span>fit<span class="token punctuation">(</span>vocab<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>hidden_size <span class="token operator">=</span> hidden_size
        self<span class="token punctuation">.</span>num_layers <span class="token operator">=</span> num_layers

        <span class="token comment"># lstm层</span>
        self<span class="token punctuation">.</span>lstm <span class="token operator">=</span> nn<span class="token punctuation">.</span>LSTM<span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>vocab<span class="token punctuation">)</span><span class="token punctuation">,</span> hidden_size<span class="token punctuation">,</span> num_layers<span class="token punctuation">,</span> batch_first<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> dropout<span class="token operator">=</span>dropout<span class="token punctuation">)</span>

        <span class="token comment"># 全连接层</span>
        self<span class="token punctuation">.</span>linear <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>hidden_size<span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>vocab<span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> sequence<span class="token punctuation">,</span> hs<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        out<span class="token punctuation">,</span> hs <span class="token operator">=</span> self<span class="token punctuation">.</span>lstm<span class="token punctuation">(</span>sequence<span class="token punctuation">,</span> hs<span class="token punctuation">)</span>  <span class="token comment"># lstm的输出格式（batch_size, sequence_length, hidden_size）</span>
        output <span class="token operator">=</span> self<span class="token punctuation">.</span>linear<span class="token punctuation">(</span>out<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment"># linear的输出格式，(batch_size * sequence_length, vocab_size)</span>
        <span class="token keyword">return</span> output<span class="token punctuation">,</span> hs

    <span class="token keyword">def</span> <span class="token function">onehot_encode</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> data<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>data<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">onehot_decode</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> data<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>encoder<span class="token punctuation">.</span>inverse_transform<span class="token punctuation">(</span>data<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">label_encode</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> data<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span>self<span class="token punctuation">.</span>char_int<span class="token punctuation">[</span>ch<span class="token punctuation">]</span> <span class="token keyword">for</span> ch <span class="token keyword">in</span> data<span class="token punctuation">]</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">label_decode</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> data<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span>self<span class="token punctuation">.</span>int_char<span class="token punctuation">[</span>ch<span class="token punctuation">]</span> <span class="token keyword">for</span> ch <span class="token keyword">in</span> data<span class="token punctuation">]</span><span class="token punctuation">)</span>


<span class="token keyword">def</span> <span class="token function">get_batches</span><span class="token punctuation">(</span>data<span class="token punctuation">,</span> batch_size<span class="token punctuation">,</span> seq_len<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">'''
    :param data: 源数据，输入格式(num_samples, num_features)
    :param batch_size: batch的大小
    :param seq_len: 序列的长度（精度）
    :return: （batch_size, seq_len, num_features）
    '''</span>
    num_features <span class="token operator">=</span> data<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>
    num_chars <span class="token operator">=</span> batch_size <span class="token operator">*</span> seq_len  <span class="token comment"># 一个batch_size的长度</span>

    num_batches <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>floor<span class="token punctuation">(</span>data<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">/</span> num_chars<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># 计算出有多少个batches</span>

    need_chars <span class="token operator">=</span> num_batches <span class="token operator">*</span> num_chars  <span class="token comment"># 计算出需要的总字符量</span>

    targets <span class="token operator">=</span> np<span class="token punctuation">.</span>vstack<span class="token punctuation">(</span><span class="token punctuation">(</span>data<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">.</span>A<span class="token punctuation">,</span> data<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>A<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># 可能版本问题，取成numpy比较好reshape</span>

    inputs <span class="token operator">=</span> data<span class="token punctuation">[</span><span class="token punctuation">:</span>need_chars<span class="token punctuation">]</span><span class="token punctuation">.</span>A<span class="token punctuation">.</span>astype<span class="token punctuation">(</span><span class="token string">"int"</span><span class="token punctuation">)</span>  <span class="token comment"># 从原始数据data中截取所需的字符数量need_words</span>

    train_data <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span>inputs<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">-</span> seq_len<span class="token punctuation">,</span> seq_len<span class="token punctuation">,</span> num_features<span class="token punctuation">)</span><span class="token punctuation">)</span>
    train_label <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span>inputs<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">-</span> seq_len<span class="token punctuation">,</span> num_features<span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> inputs<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">-</span> seq_len<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        train_data<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> inputs<span class="token punctuation">[</span>i<span class="token punctuation">:</span>i<span class="token operator">+</span>seq_len<span class="token punctuation">]</span>
        train_label<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> inputs<span class="token punctuation">[</span>i<span class="token operator">+</span>seq_len<span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>

    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> inputs<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">-</span> seq_len<span class="token punctuation">,</span>  batch_size<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">if</span> i <span class="token operator">+</span> batch_size <span class="token operator">&gt;</span> inputs<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">-</span> seq_len<span class="token punctuation">:</span>
            <span class="token keyword">break</span>
        x <span class="token operator">=</span> train_data<span class="token punctuation">[</span>i<span class="token punctuation">:</span>i<span class="token operator">+</span>batch_size<span class="token punctuation">]</span>
        y <span class="token operator">=</span> train_label<span class="token punctuation">[</span>i<span class="token punctuation">:</span>i<span class="token operator">+</span>batch_size<span class="token punctuation">]</span>
        <span class="token keyword">yield</span> x<span class="token punctuation">,</span> y


<span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span>model<span class="token punctuation">,</span> data<span class="token punctuation">,</span> batch_size<span class="token punctuation">,</span> seq_len<span class="token punctuation">,</span> epochs<span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">,</span> valid<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    device <span class="token operator">=</span> <span class="token string">'cuda'</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">'cpu'</span>

    model <span class="token operator">=</span> model<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
    optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>lr<span class="token punctuation">)</span>
    criterion <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token keyword">if</span> valid <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
        data <span class="token operator">=</span> model<span class="token punctuation">.</span>onehot_encode<span class="token punctuation">(</span>data<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        valid <span class="token operator">=</span> model<span class="token punctuation">.</span>onehot_encode<span class="token punctuation">(</span>valid<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        data <span class="token operator">=</span> model<span class="token punctuation">.</span>onehot_encode<span class="token punctuation">(</span>data<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    train_loss <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    val_loss <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>

    <span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>
        hs <span class="token operator">=</span> <span class="token boolean">None</span>  <span class="token comment"># hs等于hidden_size隐藏层节点</span>
        train_ls <span class="token operator">=</span> <span class="token number">0.0</span>
        val_ls <span class="token operator">=</span> <span class="token number">0.0</span>
        <span class="token keyword">for</span> x<span class="token punctuation">,</span> y <span class="token keyword">in</span> get_batches<span class="token punctuation">(</span>data<span class="token punctuation">,</span> batch_size<span class="token punctuation">,</span> seq_len<span class="token punctuation">)</span><span class="token punctuation">:</span>
            optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
            x <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
            out<span class="token punctuation">,</span> hs <span class="token operator">=</span> model<span class="token punctuation">(</span>x<span class="token punctuation">,</span> hs<span class="token punctuation">)</span>
            hs <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token punctuation">[</span>h<span class="token punctuation">.</span>data <span class="token keyword">for</span> h <span class="token keyword">in</span> hs<span class="token punctuation">]</span><span class="token punctuation">)</span>
            y <span class="token operator">=</span> y<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>model<span class="token punctuation">.</span>vocab<span class="token punctuation">)</span><span class="token punctuation">)</span>
            y <span class="token operator">=</span> model<span class="token punctuation">.</span>onehot_decode<span class="token punctuation">(</span>y<span class="token punctuation">)</span>
            y <span class="token operator">=</span> model<span class="token punctuation">.</span>label_encode<span class="token punctuation">(</span>y<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            y <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>y<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">long</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>

            loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>out<span class="token punctuation">,</span> y<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
            optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
            train_ls <span class="token operator">+=</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>

        <span class="token keyword">if</span> valid <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
            hs <span class="token operator">=</span> <span class="token boolean">None</span>
            <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                <span class="token keyword">for</span> x<span class="token punctuation">,</span> y <span class="token keyword">in</span> get_batches<span class="token punctuation">(</span>valid<span class="token punctuation">,</span> batch_size<span class="token punctuation">,</span> seq_len<span class="token punctuation">)</span><span class="token punctuation">:</span>
                    x <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>  <span class="token comment"># x为一组测试数据，包含batch_size * seq_len个字</span>
                    out<span class="token punctuation">,</span> hs <span class="token operator">=</span> model<span class="token punctuation">(</span>x<span class="token punctuation">,</span> hs<span class="token punctuation">)</span>

                    <span class="token comment"># out.shape输出为tensor[batch_size * seq_len, vocab_size]</span>
                    hs <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token punctuation">[</span>h<span class="token punctuation">.</span>data <span class="token keyword">for</span> h <span class="token keyword">in</span> hs<span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment"># 更新参数</span>

                    y <span class="token operator">=</span> y<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>model<span class="token punctuation">.</span>vocab<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># y.shape为(128,100,43)，因此需要转成两维，每行就代表一个字了，43为字典大小</span>
                    y <span class="token operator">=</span> model<span class="token punctuation">.</span>onehot_decode<span class="token punctuation">(</span>y<span class="token punctuation">)</span>  <span class="token comment"># y标签即为测试数据各个字的下一个字，进行one_hot解码，即变为字符</span>
                    <span class="token comment"># 但是此时y 是[[..],[..]]形式</span>
                    y <span class="token operator">=</span> model<span class="token punctuation">.</span>label_encode<span class="token punctuation">(</span>y<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># 因此需要去掉一维才能成功解码</span>
                    <span class="token comment"># 此时y为[12...]成为一维的数组，每个代表自己字典里对应字符的字典序</span>
                    y <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>y<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">long</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>

                    <span class="token comment"># 这里y和y.squeeze()出来的东西一样，可能这里没啥用，不太懂</span>
                    loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>out<span class="token punctuation">,</span> y<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># 计算损失值</span>
                    val_ls <span class="token operator">+=</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>

            val_loss<span class="token punctuation">.</span>append<span class="token punctuation">(</span>np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>val_ls<span class="token punctuation">)</span><span class="token punctuation">)</span>
        train_loss<span class="token punctuation">.</span>append<span class="token punctuation">(</span>np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>train_ls<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"val_loss"</span><span class="token punctuation">,</span> val_ls<span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"train_loss:"</span><span class="token punctuation">,</span> train_ls<span class="token punctuation">)</span>

    plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>train_loss<span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">"train_loss"</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>val_loss<span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">"val loss"</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">"loop vs epoch"</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>

    model_name <span class="token operator">=</span> <span class="token string">"lstm_model.net"</span>

    <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>model_name<span class="token punctuation">,</span> <span class="token string">'wb'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>  <span class="token comment"># 训练完了保存模型</span>
        torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>model<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> f<span class="token punctuation">)</span>


<span class="token keyword">def</span> <span class="token function">predict</span><span class="token punctuation">(</span>vocab_size<span class="token punctuation">,</span> model<span class="token punctuation">,</span> char<span class="token punctuation">,</span> top_k<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> hidden_size<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    device <span class="token operator">=</span> <span class="token string">'cuda'</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">'cpu'</span>
    model<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
    model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 固定参数</span>
    <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        char <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span>char<span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment"># 输入一个字符，预测下一个字是什么，先转成numpy</span>
        char <span class="token operator">=</span> char<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>  <span class="token comment"># 变成二维才符合编码规范</span>
        char_encoding <span class="token operator">=</span> model<span class="token punctuation">.</span>onehot_encode<span class="token punctuation">(</span>char<span class="token punctuation">)</span><span class="token punctuation">.</span>A  <span class="token comment"># 对char进行编码，取成numpy比较方便reshape</span>
        char_encoding <span class="token operator">=</span> char_encoding<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> vocab_size<span class="token punctuation">)</span><span class="token comment"># 转成模型输入格式 </span>

        char_tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>char_encoding<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>  <span class="token comment"># 转成tensor</span>
        char_tensor <span class="token operator">=</span> char_tensor<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>

        out<span class="token punctuation">,</span> hidden_size <span class="token operator">=</span> model<span class="token punctuation">(</span>char_tensor<span class="token punctuation">,</span> hidden_size<span class="token punctuation">)</span>  <span class="token comment"># 放入模型进行预测，out为结果</span>

        probs <span class="token operator">=</span> F<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>out<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 计算预测值,即所有字符的概率</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span>probs<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>

        <span class="token keyword">if</span> top_k <span class="token keyword">is</span> <span class="token boolean">None</span><span class="token punctuation">:</span>  <span class="token comment"># 选择概率最大的top_k个</span>
            indices <span class="token operator">=</span> np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>vocab_size<span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            probs<span class="token punctuation">,</span> indices <span class="token operator">=</span> probs<span class="token punctuation">.</span>topk<span class="token punctuation">(</span>top_k<span class="token punctuation">)</span>
            indices <span class="token operator">=</span> indices<span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>
        probs <span class="token operator">=</span> probs<span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>

        char_index <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>choice<span class="token punctuation">(</span>indices<span class="token punctuation">,</span> p<span class="token operator">=</span>probs<span class="token operator">/</span>probs<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># 随机选择一个字符索引作为预测值</span>
        char <span class="token operator">=</span> model<span class="token punctuation">.</span>int_char<span class="token punctuation">[</span>char_index<span class="token punctuation">]</span>  <span class="token comment"># 通过索引找出预测字符</span>

    <span class="token keyword">return</span> char<span class="token punctuation">,</span> hidden_size


<span class="token keyword">def</span> <span class="token function">sample</span><span class="token punctuation">(</span>vocab_size<span class="token punctuation">,</span> seq_len<span class="token punctuation">,</span> model<span class="token punctuation">,</span> length<span class="token punctuation">,</span>sentence<span class="token punctuation">,</span> top_k<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    hidden_size <span class="token operator">=</span> <span class="token boolean">None</span>
    new_sentence <span class="token operator">=</span> <span class="token punctuation">[</span>char <span class="token keyword">for</span> char <span class="token keyword">in</span> sentence<span class="token punctuation">]</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>length<span class="token punctuation">)</span><span class="token punctuation">:</span>

        next_char<span class="token punctuation">,</span> hidden_size <span class="token operator">=</span> predict<span class="token punctuation">(</span>vocab_size<span class="token punctuation">,</span> model<span class="token punctuation">,</span> new_sentence<span class="token punctuation">[</span><span class="token operator">-</span>seq_len<span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">,</span> top_k<span class="token operator">=</span>top_k<span class="token punctuation">,</span> hidden_size<span class="token operator">=</span>hidden_size<span class="token punctuation">)</span>

        new_sentence<span class="token punctuation">.</span>append<span class="token punctuation">(</span>next_char<span class="token punctuation">)</span>
    <span class="token keyword">return</span> <span class="token string">""</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>new_sentence<span class="token punctuation">)</span>


<span class="token keyword">def</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    hidden_size <span class="token operator">=</span> <span class="token number">512</span>
    num_layers <span class="token operator">=</span> <span class="token number">4</span>
    batch_size <span class="token operator">=</span> <span class="token number">128</span>
    seq_len <span class="token operator">=</span> <span class="token number">2</span>
    epochs <span class="token operator">=</span> <span class="token number">30</span>
    lr <span class="token operator">=</span> <span class="token number">0.0001</span>

    f <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">"春联.csv"</span><span class="token punctuation">)</span>
    f <span class="token operator">=</span> f<span class="token punctuation">[</span><span class="token string">"0"</span><span class="token punctuation">]</span>
    text <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span>f<span class="token punctuation">)</span>
    text <span class="token operator">=</span> <span class="token string">"."</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>text<span class="token punctuation">)</span><span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">"."</span><span class="token punctuation">,</span> <span class="token string">""</span><span class="token punctuation">)</span>
    vocab <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token builtin">sorted</span><span class="token punctuation">(</span><span class="token builtin">set</span><span class="token punctuation">(</span>text<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># 建立字典</span>
    vocab_size <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>vocab<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"vocab_size"</span><span class="token punctuation">,</span> vocab_size<span class="token punctuation">)</span>


    val_len <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>floor<span class="token punctuation">(</span><span class="token number">0.2</span> <span class="token operator">*</span> <span class="token builtin">len</span><span class="token punctuation">(</span>text<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># 划分训练测试集</span>
    trainset <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token builtin">list</span><span class="token punctuation">(</span>text<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token operator">-</span>val_len<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    validset <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token builtin">list</span><span class="token punctuation">(</span>text<span class="token punctuation">[</span><span class="token operator">-</span>val_len<span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    model <span class="token operator">=</span> lstm_model<span class="token punctuation">(</span>vocab<span class="token punctuation">,</span> hidden_size<span class="token punctuation">,</span> num_layers<span class="token punctuation">)</span>  <span class="token comment"># 模型实例化</span>
    train<span class="token punctuation">(</span>model<span class="token punctuation">,</span> trainset<span class="token punctuation">,</span> batch_size<span class="token punctuation">,</span> seq_len<span class="token punctuation">,</span> epochs<span class="token punctuation">,</span> lr<span class="token operator">=</span>lr<span class="token punctuation">,</span> valid<span class="token operator">=</span>validset<span class="token punctuation">)</span>  <span class="token comment"># 训练模型</span>
    model<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">"lstm_model.net"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># 调用保存的模型</span>
    new_text1 <span class="token operator">=</span> sample<span class="token punctuation">(</span>vocab_size<span class="token punctuation">,</span> seq_len<span class="token punctuation">,</span> model<span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token string">"虎年"</span><span class="token punctuation">,</span> top_k<span class="token operator">=</span><span class="token number">7</span><span class="token punctuation">)</span>  <span class="token comment"># 预测模型，生成100个字符,预测时选择概率最大的前5个</span>
    new_text2 <span class="token operator">=</span> sample<span class="token punctuation">(</span>vocab_size<span class="token punctuation">,</span> seq_len<span class="token punctuation">,</span> model<span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token string">"春节"</span><span class="token punctuation">,</span> top_k<span class="token operator">=</span><span class="token number">7</span><span class="token punctuation">)</span>  <span class="token comment"># 预测模型，生成100个字符,预测时选择概率最大的前5个</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>new_text1<span class="token punctuation">)</span>  <span class="token comment"># 输出预测文本</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>new_text2<span class="token punctuation">)</span>


<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">"__main__"</span><span class="token punctuation">:</span>
    main<span class="token punctuation">(</span><span class="token punctuation">)</span>

</code></pre>
                </div>
                
                

		</div>
	</article>
</main>




			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程小白.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://www.w3counter.com/tracker.js?id=150625"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>
	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>