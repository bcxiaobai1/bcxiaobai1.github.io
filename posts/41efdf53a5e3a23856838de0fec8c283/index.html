<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<title>实验四 贝叶斯分类器（模式识别与机器学习） - 编程小白</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程小白" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程小白</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">实验四 贝叶斯分类器（模式识别与机器学习）</h1>
			
		</header>
		<div class="content post__content clearfix">
			


        
                <div id="content_views" class="htmledit_views">
                    <p id="main-toc"><strong>目录</strong></p> 
<p id="-toc" style="margin-left:40px"></p> 
<p id="%E5%AE%9E%E9%AA%8C%E4%B8%80%C2%A0%20%E7%A6%BB%E6%95%A3%E5%9E%8B%E6%95%B0%E6%8D%AE%E7%9A%84%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB-toc" style="margin-left:40px"><a href="#%E5%AE%9E%E9%AA%8C%E4%B8%80%C2%A0%20%E7%A6%BB%E6%95%A3%E5%9E%8B%E6%95%B0%E6%8D%AE%E7%9A%84%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB">实验一  离散型数据的朴素贝叶斯分类</a></p> 
<p id="%C2%A0%E5%AE%9E%E9%AA%8C%E6%AD%A5%E9%AA%A4%EF%BC%9A-toc" style="margin-left:80px"><a href="#%C2%A0%E5%AE%9E%E9%AA%8C%E6%AD%A5%E9%AA%A4%EF%BC%9A"> 实验步骤：</a></p> 
<p id="%C2%A0NBtrain.m-toc" style="margin-left:80px"><a href="#%C2%A0NBtrain.m"> NBtrain.m</a></p> 
<p id="NBtest.m-toc" style="margin-left:80px"> <a href="#NBtest.m">NBtest.m</a></p> 
<p id="main.m-toc" style="margin-left:80px"> <a href="#main.m">main.m</a></p> 
<p id="%E5%AE%9E%E9%AA%8C%E4%BA%8C%C2%A0%20%E8%BF%9E%E7%BB%AD%E5%9E%8B%E6%95%B0%E6%8D%AE%E7%9A%84%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB-toc" style="margin-left:40px"><a href="#%E5%AE%9E%E9%AA%8C%E4%BA%8C%C2%A0%20%E8%BF%9E%E7%BB%AD%E5%9E%8B%E6%95%B0%E6%8D%AE%E7%9A%84%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB">实验二  连续型数据的朴素贝叶斯分类</a></p> 
<p id="%E5%AE%9E%E9%AA%8C%E6%AD%A5%E9%AA%A4-toc" style="margin-left:80px"><a href="#%E5%AE%9E%E9%AA%8C%E6%AD%A5%E9%AA%A4">实验步骤</a>:</p> 
<p id="%C2%A0naiveBayestrain.m-toc" style="margin-left:80px"><a href="#%C2%A0naiveBayestrain.m"> naiveBayestrain.m</a></p> 
<p id="navieBayestest.m-toc" style="margin-left:80px"><a href="#navieBayestest.m">navieBayestest.m</a></p> 
<p id="main.m-toc" style="margin-left:80px"><a href="#main.m">main.m</a></p> 
<hr id="hr-toc">
<p></p> 
<h2 id="%E5%AE%9E%E9%AA%8C%E4%B8%80%C2%A0%20%E7%A6%BB%E6%95%A3%E5%9E%8B%E6%95%B0%E6%8D%AE%E7%9A%84%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB" style="margin-left:0in;text-align:justify">
<span style="color:#000000">实验</span><span style="color:#000000">一  </span><span style="color:#000000">离散型数据</span><span style="color:#000000">的朴素</span><span style="color:#000000">贝叶斯分类</span>
</h2> 
<p><span style="color:#000000">       </span><span style="color:#ff0000">data</span><span style="color:#000000">数据集中含有</span><span style="color:#000000">625</span><span style="color:#000000">个样本，每个样本第</span><span style="color:#000000">1</span><span style="color:#000000">列为类别；</span><span style="color:#000000">2~5</span><span style="color:#000000">列为各样</span><span style="color:#000000">本的属性。</span></p> 
<p>                                                            <img alt="" height="456" src="https://images2.imgbox.com/a1/4f/Tn7HY30P_o.png" width="115"></p> 
<h3 id="%C2%A0%E5%AE%9E%E9%AA%8C%E6%AD%A5%E9%AA%A4%EF%BC%9A"> 实验步骤：</h3> 
<blockquote> 
 <p style="margin-left:0in;text-align:left"><span style="color:#000000">①</span> <span style="color:#000000">准备阶段。</span></p> 
 <p style="margin-left:0in;text-align:left">          <span style="color:#000000">将数据集进行划分：训练集和测试集。</span></p> 
 <p style="margin-left:0in;text-align:left"><span style="color:#000000">②</span> <span style="color:#000000">构建分类器，进行数据训练。</span></p> 
 <p style="margin-left:0in;text-align:left">          <span style="color:#000000">将数据集进行划分：训练集和测试集。</span></p> 
 <p style="margin-left:0in;text-align:left"><span style="color:#000000">          计算条件概率：根据每类中各属性取值的概率</span></p> 
 <p style="margin-left:0in;text-align:left"><span style="color:#000000">③</span> <span style="color:#000000">数据测试。</span></p> 
 <p style="margin-left:0in;text-align:left"><span style="color:#000000">        计算每个测试样本在其各属性下的条件概率；</span></p> 
 <p style="margin-left:0in;text-align:left"><span style="color:#000000">        计算测试样本对于各类别的判别概率；</span></p> 
</blockquote> 
<h3 id="%C2%A0NBtrain.m"><strong> NBtrain.m</strong></h3> 
<pre><code>

function [y1,y_1,y2,y_2,y3,y_3] = NBtrain(train_data,train_label,m1)  
% returen:
% y1 y2 y3 先验概率
% y_1,y_2,y_3   在第 ? 类的情况下，第i个属性取值为j的概率估计值


%三类样本数量分别记为count1,count2,count3
count1=0;
count2=0;
count3=0;

%  数据总共 3 个类别，4 个属性， 5 个取值。 

%count_1(i,j)表示在第一类(y=1)的情况下，第i个属性是j的样本个数
count_1=zeros(4,5);
%count_2(i,j)表示在第二类(y=2)的情况下，第i个属性是j的样本个数
count_2=zeros(4,5);
%count_3(i,j)表示在第三类(y=3)的情况下，第i个属性是j的样本个数
count_3=zeros(4,5);

%训练集样本数量 m1 = 562
for i=1:m1
    
    x=train_data(i,:);
    if train_label(i)==1
        count1=count1+1;
        for j=1:4    %指示第j个属性
            for k=1:5    %第j个属性为哪个值
                if x(j)==k
                    
                    %===========填空:对当前类别中第j个属性第k个值得个数进行统计=============
                    count_1(j,k)=count_1(j,k)+1 ; 
                    %====================================================================
                    
                    break;
                end
            end
        end
    elseif train_label(i)==2
        count2=count2+1;
        for j=1:4    %指示第j个属性
            for k=1:5    %第j个属性为哪个值
                if x(j)==k
                    
                    %===========填空:对当前类别中第j个属性第k个值得个数进行统计=============
                    count_2(j,k)=count_2(j,k)+1 ;
                    %====================================================================
                    
                    break;
                end
            end
        end
    else count3=count3+1;
        for j=1:4    %指示第j个属性
            for k=1:5    %第j个属性为哪个值
                if x(j)==k
                    
                    %===========填空:对当前类别中第j个属性第k个值得个数进行统计=============
                    count_3(j,k)=count_3(j,k)+1 ;
                    %====================================================================
                    
                    break;
                end
            end
        end
    end
    
end

%分别计算三类概率y1=p(y=1)、y2=p(y=2)、y3=p(y=3)的估计值

%=========填空：计算每类的先验概率================
y1=count1/m1 ;
y2=count2/m1 ;
y3=count3/m1 ;
%===============================================

%y_1(i,j)表示在第一类(y=1)的情况下，第i个属性取值为j的概率估计值
%y_2(i,j)表示在第二类(y=2)的情况下，第i个属性取值为j的概率估计值
%y_3(i,j)表示在第三类(y=3)的情况下，第i个属性取值为j的概率估计值
for i=1:4
    for j=1:5
        
        %=========填空：计算每类中每个属性的取值概率，即在第C类中第i个属性为k的条件概率=============
        y_1(i,j)= count_1(i,j)/count1 ;
        y_2(i,j)= count_2(i,j)/count2 ;
        y_3(i,j)= count_3(i,j)/count3;
        %====================================================================================
        
    end
end

</code></pre> 
<h3 id="NBtest.m">NBtest.m</h3> 
<pre><code>function class_label = NBtest(test_data,y1,y_1,y2,y_2,y3,y_3,m2)
% y1 y2 y3  [1 1] 先验概率
% y_1,y_2,y_3  [4 5]  在第 ? 类的情况下，第i个属性取值为j的概率估计值

class_label = [];
for i=1:m2
    xx=test_data(i,:);
    
    %==========填空：计算样本对于每类而言的后验概率=====================
    p1= y1 * y_1(1,xx(1)) * y_1(2,xx(2))*y_1(3,xx(3)) * y_1(4,xx(4));
    p2= y2 * y_2(1,xx(1)) * y_2(2,xx(2))*y_2(3,xx(3)) * y_2(4,xx(4));
    p3= y3 * y_3(1,xx(1)) * y_3(2,xx(2))*y_3(3,xx(3)) * y_3(4,xx(4));
    %============================================================    
     
    if p1&gt;p2&amp;&amp;p1&gt;p3
        class_label(i) = 1;
    end
    if p2&gt;p1&amp;&amp;p2&gt;p3
        class_label(i) = 2;
    end
    if p3&gt;p1&amp;&amp;p3&gt;p2
        class_label(i) = 3;
    end
    
end</code></pre> 
<h3 id="main.m">main.m</h3> 
<pre><code>clear;
clc;
ex=importdata('data.txt');  %读入文件
X=ex.data;
Y = ex.rowheaders;
Y = grp2idx(Y);       %将类别B，R，L化为1，2，3
m=size(X);  %数据大小

%训练集，测试集划分
ii=1;%用来标识测试集的序号
jj=1;%用来标识训练集的序号


%我们把所有数字序号末尾为1的留作测试集，其他未训练集
for i = 1:m
    if mod(i,10)==1
        %%将数字序号末尾为1的留作测试集，其他未训练集
        test_data(ii,:)=X(i,:);
        test_label(ii)=Y(i);
        ii=ii+1;
    else
        train_data(jj,:)=X(i,:);
        train_label(jj)=Y(i);
        jj=jj+1;
    end
    
end

m1=jj-1;  %训练集样本数量562
m2=ii-1;  %测试集样本数量63

%y1、y2、y3表示每类的先验概率
%y_1(i,j)表示在第一类(y=1)的情况下，第i个属性取值为j的概率估计值
%y_2(i,j)表示在第二类(y=2)的情况下，第i个属性取值为j的概率估计值
%y_3(i,j)表示在第三类(y=3)的情况下，第i个属性取值为j的概率估计值

[y1,y_1,y2,y_2,y3,y_3] = NBtrain(train_data,train_label,m1);    %完善训练函数

test_class = NBtest(test_data,y1,y_1,y2,y_2,y3,y_3,m2);             %完善测试函数

accuracy =length(find(test_label==test_class))/length(test_label)
cMat2 = confusionmat(test_label,test_class ) 




</code></pre> 
<h2 style="margin-left:0in;text-align:justify"></h2> 
<h2 id="%E5%AE%9E%E9%AA%8C%E4%BA%8C%C2%A0%20%E8%BF%9E%E7%BB%AD%E5%9E%8B%E6%95%B0%E6%8D%AE%E7%9A%84%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB" style="margin-left:0in;text-align:justify"><span style="color:#000000">实验二  连续型数据的朴素贝叶斯分类</span></h2> 
<p><span style="color:#ff0000">fisheriris</span><span style="color:#000000">数据</span><span style="color:#000000">集中有</span><span style="color:#000000">150</span><span style="color:#000000">朵花的数据：</span></p> 
<p>•<span style="color:#0070c0"><strong>meas</strong></span><span style="color:#000000">给</span><span style="color:#000000">出了每朵花的</span><span style="color:#000000">4</span><span style="color:#000000">个</span><span style="color:#000000">属性：花萼</span><span style="color:#000000">长度，花萼宽度，花瓣长度，花瓣</span><span style="color:#000000">宽度。</span></p> 
<p>•<span style="color:#0070c0"><strong>species</strong></span><span style="color:#000000">说</span><span style="color:#000000">明了每朵花的</span><span style="color:#000000">种类：</span><span style="color:#000000">山</span><span style="color:#000000">鸢尾</span><span style="color:#000000">Setosa</span><span style="color:#000000">，杂色鸢尾</span><span style="color:#000000">Versicolour</span><span style="color:#000000">、弗吉尼亚</span><span style="color:#000000">鸢尾</span><span style="color:#000000">Virginica</span><span style="color:#000000">。</span></p> 
<p><img alt="" height="133" src="https://images2.imgbox.com/26/3d/ChURpcCr_o.png" width="676"></p> 
<h3 id="%E5%AE%9E%E9%AA%8C%E6%AD%A5%E9%AA%A4"><span style="color:#0d0016">实验步骤：</span></h3> 
<blockquote> 
 <p> •<span style="color:#000000"><strong>数据训练</strong></span></p> 
 <p><span style="color:#000000"><strong>        </strong>1. </span><span style="color:#000000">计算先验概率：每类样本占总样本数的比例；</span></p> 
 <p style="margin-left:0in;text-align:justify"><span style="color:#000000">        2. 根据概率密度函数，计算各类样本中各属性取值的均值和</span><span style="color:#000000">方差。</span></p> 
 <p style="margin-left:0in;text-align:justify">•<span style="color:#000000"><strong>数据测试</strong></span></p> 
 <p style="margin-left:0in;text-align:justify"><span style="color:#000000"><strong>        </strong>1. </span><span style="color:#000000">计算条件概率：根据</span><span style="color:#000000">训练集的均值</span><span style="color:#000000">与</span><span style="color:#000000">方差，计算训练样本</span><span style="color:#000000">的条件概率；</span></p> 
 <p style="margin-left:0in;text-align:justify"><span style="color:#000000">        2. 计算测试样本对于类别的判别</span><span style="color:#000000">概率。</span></p> 
</blockquote> 
<h3 id="%C2%A0naiveBayestrain.m"> naiveBayestrain.m</h3> 
<pre><code>function [label_priorP,mu,sigma] = navieBayestrain(meas,specise)
% means    = 150 * 4
% specise  = 150 * 1

trainData = meas';  %训练数据集       4 *150
trainLabel = specise';  %训练类别集   1 * 150
classNum = length(unique(trainLabel));  %类别数  3

label_priorP = zeros(1,classNum);  %类别的先验概率    1*3


%将trainSet按类别分组，然后分别对每类的数据求出每个属性的均值mu(Ak,Ci)和样本标准差sigma(Ak,Ci)
%mu(Ak,Ci),sigma(Ak,Ci)表示第Ci类数据集的属性Ak对应的均值和样本标准差

groupedSet = cell(1,classNum); %空的分组数据集矩阵   1*3 3个块

%  eg
%   C = {1,2,3;
%     'text',rand(5,10,2),{11; 22; 33}}
%   C=2×3 cell array
%    {[   1]}    {[          2]}    {[     3]}
%    {'text'}    {5x10x2 double}    {3x1 cell}

%mu、sigma中每列为对应类的均值列向量和标准差向量,size(trainSet,1)-1表示样本的属性数att_number
%mu(attNum,classNum),sigma(attnum,classNum)分别是第classNum类的第attNum个属性的均值和标准差

mu = zeros(size(trainData,1),classNum);  % 4*3
sigma = zeros(size(trainData,1),classNum); % 4*3

trainLabel = grp2idx(trainLabel);
% 分类过程，返回所有的分类索引

trainLabel =trainLabel';
for sampleNum = 1:size(trainLabel,2)      %size(trainLabel,2)为训练样本数
    
    label = trainLabel(1,sampleNum);
    
    %=====================================================================%
     %填空，计算每类样本的个数
    label_priorP(1,label) = label_priorP(1,label)+1;
    %=====================================================================%
    groupedSet{1,label} = [groupedSet{1,label} trainData(:,sampleNum)];
end
%=====================================================================%
     %填空，计算每类的先验概率
     label_priorP =label_priorP ./sampleNum;
%=====================================================================%


%对于每一类 计算某类每个属性的均值和样本标准差

for label = 1:classNum  % 迭代每一类
    b = groupedSet{label}; %  4*50
    
%=====================================================================%
     %填空，计算每类中每个属性的均值和标准差
     %第label个均值列向量；计算每类中每个属性的均值
      mu(:,label) = mean(b,2);  
     %第label个标准差列向量；计算每类中每个属性的标准差；按行求标准差
      sigma(:,label) = std(b,0,2);
%=====================================================================%

end
</code></pre> 
<h3 id="navieBayestest.m">navieBayestest.m</h3> 
<pre><code>function testClass = navieBayestest(meas,label_priorP,mu,sigma,classNum)

%  mu  sigma  4*3 行属性 * 列类别

testClass = [];
testData = meas' ; %测试数据集；testData每列代表一个样本 4 * 150

test_number = size(testData,2);%测试集样本数
attr_number = size(testData,1);%测试集维数；每个样本的属性个数

for testNum = 1:test_number  % 循环测试样本
    X = testData(:,testNum);    %当前测试样本     4 * 1
%    prob = label_priorP;%先验概率    
%  for label = 1:classNum  % 3类
%         for k = 1:attr_number  % 4属性
%      %填空：计算每类的条件概率与后验概率
%      
%      %计算条件概率
%      %此时prob已为后验概率
%              Pxk = 1/ (sigma(k,label)*sqrt(2 * pi) )* exp(-((X(k,1)-mu(k,label))^2 )/(2*sigma(k,label)^2));
%              prob(1,label) =prob(1,label) * Pxk;  
%         end    
%          %Pxk=1;
%     end
  
    
    %% 考核：请在对数条件下实现方案一
%=====================================================================%
    prob = label_priorP;%先验概率
    %%计算测试样本对于每类的后验概率
    for label = 1:classNum  % 3类
        for k = 1:attr_number  % 4属性
%=====================================================================%
     %填空：计算每类的条件概率与后验概率
     
     %计算条件概率
     %此时prob已为后验概率
             Pxk = -log(sigma(k,label))-((X(k,1)-mu(k,label))^2 /(2 * sigma(k,label)^2));
             prob(1,label) =prob(1,label)+Pxk; 
%=====================================================================%
        end
        
    end
%=====================================================================%
 
    [value index] = max(prob);
    testClass = [testClass index];
end</code></pre> 
<h3>main.m</h3> 
<pre><code>clc;
clear all;
tic
load fisheriris
% plotmatrix(meas)

% meas 给出了每朵花的4个属性
% species 说明了每朵花的种类
[label_priorP,mu,sigma] = navieBayestrain(meas,species);%需完成函数 navieBayestrain()内的填空


classNum = length(unique(species));  %类别数
testLabel = grp2idx(species);
testLabel =testLabel';

testClass = navieBayestest(meas,label_priorP,mu,sigma,classNum);%需完成函数 navieBayestest()内的填空

%识别率
accuracy=length(find(testLabel==testClass))/length(testLabel)
cMat2 = confusionmat(testLabel,testClass ) 
toc</code></pre> 
<p></p>
                </div>

		</div>
	</article>
</main>




			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程小白.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://www.w3counter.com/tracker.js?id=150625"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>
	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>