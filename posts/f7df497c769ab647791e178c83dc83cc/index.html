<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<title>TFT时间序列预测 - 编程小白</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程小白" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程小白</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">TFT时间序列预测</h1>
			
		</header>
		<div class="content post__content clearfix">
			


                <div id="content_views" class="markdown_views prism-atom-one-dark">
                    
                        
                    
                    <pre><code class="prism language-python"><span class="token keyword">from</span> torch <span class="token keyword">import</span> nn
<span class="token keyword">import</span> math
<span class="token keyword">import</span> torch
<span class="token keyword">import</span> ipdb
</code></pre> 
<pre><code class="prism language-python"><span class="token keyword">class</span> <span class="token class-name">GLU</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment">#Gated Linear Unit</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>input_size<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>GLU<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>fc1<span class="token operator">=</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>input_size<span class="token punctuation">,</span>input_size<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>fc2<span class="token operator">=</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>input_size<span class="token punctuation">,</span>input_size<span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>sigmoid<span class="token operator">=</span>nn<span class="token punctuation">.</span>Sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        sig<span class="token operator">=</span>self<span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span>self<span class="token punctuation">.</span>fc1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>
        x<span class="token operator">=</span>self<span class="token punctuation">.</span>fc2<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token keyword">return</span> torch<span class="token punctuation">.</span>mul<span class="token punctuation">(</span>sig<span class="token punctuation">,</span>x<span class="token punctuation">)</span>

<span class="token keyword">class</span> <span class="token class-name">TimeDistributed</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment">## Takes any module and stacks the time dimension with the batch dimenison of inputs before apply the module</span>
    <span class="token comment">## From: https://discuss.pytorch.org/t/any-pytorch-function-can-work-as-keras-timedistributed/1346/4</span>
    <span class="token comment"># 模块化用来改变输入大小,考虑到直接用Linear层对多维数据处理可能出问题，单独处理</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> module<span class="token punctuation">,</span> batch_first<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>TimeDistributed<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>module <span class="token operator">=</span> module
        self<span class="token punctuation">.</span>batch_first <span class="token operator">=</span> batch_first

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>

        <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">&lt;=</span> <span class="token number">2</span><span class="token punctuation">:</span>
            <span class="token keyword">return</span> self<span class="token punctuation">.</span>module<span class="token punctuation">(</span>x<span class="token punctuation">)</span>

        <span class="token comment"># Squash samples and timesteps into a single axis</span>
        x_reshape <span class="token operator">=</span> x<span class="token punctuation">.</span>contiguous<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># (samples * timesteps, input_size)，view变换原矩阵的大小，需要原矩阵的内存是整块的。</span>
        <span class="token comment"># print(x_reshape.device)</span>

        y <span class="token operator">=</span> self<span class="token punctuation">.</span>module<span class="token punctuation">(</span>x_reshape<span class="token punctuation">)</span>

        <span class="token comment"># We have to reshape Y</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>batch_first<span class="token punctuation">:</span>
            y <span class="token operator">=</span> y<span class="token punctuation">.</span>contiguous<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span>x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> y<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># (samples, timesteps, output_size)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            y <span class="token operator">=</span> y<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> y<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># (timesteps, samples, output_size)</span>

        <span class="token keyword">return</span> y

<span class="token keyword">class</span> <span class="token class-name">GRN</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># GatedResidualNetwork</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>input_size<span class="token punctuation">,</span>hidden_state_size<span class="token punctuation">,</span>output_size<span class="token punctuation">,</span>drop_out<span class="token punctuation">,</span>hidden_context_size<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span>batch_first<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>GRN<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>input_size<span class="token operator">=</span>input_size
        self<span class="token punctuation">.</span>output_size<span class="token operator">=</span>output_size
        self<span class="token punctuation">.</span>hidden_context_size<span class="token operator">=</span>hidden_context_size
        self<span class="token punctuation">.</span>hidden_state_size<span class="token operator">=</span>hidden_state_size
        self<span class="token punctuation">.</span>drop_out<span class="token operator">=</span>drop_out

        <span class="token keyword">if</span> self<span class="token punctuation">.</span>input_size<span class="token operator">!=</span>self<span class="token punctuation">.</span>output_size<span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>skip_layer<span class="token operator">=</span>TimeDistributed<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>self<span class="token punctuation">.</span>input_size<span class="token punctuation">,</span>self<span class="token punctuation">.</span>output_size<span class="token punctuation">)</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>fc1<span class="token operator">=</span>TimeDistributed<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>self<span class="token punctuation">.</span>input_size<span class="token punctuation">,</span>self<span class="token punctuation">.</span>hidden_state_size<span class="token punctuation">)</span><span class="token punctuation">,</span>batch_first<span class="token operator">=</span>batch_first<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>elu1<span class="token operator">=</span>nn<span class="token punctuation">.</span>ELU<span class="token punctuation">(</span><span class="token punctuation">)</span>

        <span class="token keyword">if</span> self<span class="token punctuation">.</span>hidden_context_size <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            <span class="token comment"># 如果c能够传递的话，将c的大小化为和a的大小一致</span>
            self<span class="token punctuation">.</span>context<span class="token operator">=</span>TimeDistributed<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>self<span class="token punctuation">.</span>hidden_context_size<span class="token punctuation">,</span>self<span class="token punctuation">.</span>hidden_state_size<span class="token punctuation">)</span><span class="token punctuation">,</span>batch_first<span class="token operator">=</span>batch_first<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>fc2<span class="token operator">=</span>TimeDistributed<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>self<span class="token punctuation">.</span>hidden_state_size<span class="token punctuation">,</span>self<span class="token punctuation">.</span>output_size<span class="token punctuation">)</span><span class="token punctuation">,</span>batch_first<span class="token operator">=</span>batch_first<span class="token punctuation">)</span>
        <span class="token comment"># self.elu2=nn.ELU()#做不做问题不大</span>
        self<span class="token punctuation">.</span>dropout<span class="token operator">=</span>nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>self<span class="token punctuation">.</span>drop_out<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>ln<span class="token operator">=</span>TimeDistributed<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>LayerNorm<span class="token punctuation">(</span>self<span class="token punctuation">.</span>output_size<span class="token punctuation">)</span><span class="token punctuation">,</span>batch_first<span class="token operator">=</span>batch_first<span class="token punctuation">)</span><span class="token comment">#层归一化归一化最后k个维度</span>
        self<span class="token punctuation">.</span>gate<span class="token operator">=</span>TimeDistributed<span class="token punctuation">(</span>GLU<span class="token punctuation">(</span>self<span class="token punctuation">.</span>output_size<span class="token punctuation">)</span><span class="token punctuation">,</span>batch_first<span class="token operator">=</span>batch_first<span class="token punctuation">)</span>



    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>x<span class="token punctuation">,</span>context<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>

        <span class="token keyword">if</span> self<span class="token punctuation">.</span>input_size<span class="token operator">!=</span>self<span class="token punctuation">.</span>output_size<span class="token punctuation">:</span>
            residual<span class="token operator">=</span>self<span class="token punctuation">.</span>skip_layer<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            residual<span class="token operator">=</span>x
        x<span class="token operator">=</span>self<span class="token punctuation">.</span>fc1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token keyword">if</span> context <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            context<span class="token operator">=</span>self<span class="token punctuation">.</span>context<span class="token punctuation">(</span>context<span class="token punctuation">)</span>
            x<span class="token operator">=</span>x<span class="token operator">+</span>context
        x<span class="token operator">=</span>self<span class="token punctuation">.</span>elu1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>

        x<span class="token operator">=</span>self<span class="token punctuation">.</span>fc2<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x<span class="token operator">=</span>self<span class="token punctuation">.</span>dropout<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x<span class="token operator">=</span>self<span class="token punctuation">.</span>gate<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x<span class="token operator">=</span>x<span class="token operator">+</span>residual
        x<span class="token operator">=</span>self<span class="token punctuation">.</span>ln<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token keyword">return</span> x

<span class="token keyword">class</span> <span class="token class-name">PositionalEncoder</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token comment">##仿照transformer层添加位置编码,有点多此一举</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>d_model<span class="token punctuation">,</span>max_seq_len<span class="token operator">=</span><span class="token number">160</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>PositionalEncoder<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>d_model<span class="token operator">=</span>d_model<span class="token comment">#Embedding大小，输入为(seq_len,batch_size,index)--&gt;(seq_len,batch_size,input_size)</span>
        pe<span class="token operator">=</span>torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>max_seq_len<span class="token punctuation">,</span>d_model<span class="token punctuation">)</span>
        <span class="token keyword">for</span> pos <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>max_seq_len<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span>d_model<span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                pe<span class="token punctuation">[</span>pos<span class="token punctuation">,</span> i<span class="token punctuation">]</span> <span class="token operator">=</span> 
                    math<span class="token punctuation">.</span>sin<span class="token punctuation">(</span>pos <span class="token operator">/</span> <span class="token punctuation">(</span><span class="token number">10000</span> <span class="token operator">**</span> <span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">2</span> <span class="token operator">*</span> i<span class="token punctuation">)</span> <span class="token operator">/</span> d_model<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
                pe<span class="token punctuation">[</span>pos<span class="token punctuation">,</span> i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">=</span> 
                    math<span class="token punctuation">.</span>cos<span class="token punctuation">(</span>pos <span class="token operator">/</span> <span class="token punctuation">(</span><span class="token number">10000</span> <span class="token operator">**</span> <span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">2</span> <span class="token operator">*</span> <span class="token punctuation">(</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">/</span> d_model<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        pe <span class="token operator">=</span> pe<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>register_buffer<span class="token punctuation">(</span><span class="token string">'pe'</span><span class="token punctuation">,</span> pe<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            x<span class="token operator">=</span>x<span class="token operator">*</span>math<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>self<span class="token punctuation">.</span>d_model<span class="token punctuation">)</span>
            seq_len<span class="token operator">=</span>x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
            pe<span class="token operator">=</span>self<span class="token punctuation">.</span>pe<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span>seq_len<span class="token punctuation">]</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span>seq_len<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span>self<span class="token punctuation">.</span>d_model<span class="token punctuation">)</span>
            x<span class="token operator">=</span>x<span class="token operator">+</span>pe
            <span class="token keyword">return</span> x

<span class="token keyword">class</span> <span class="token class-name">VSN</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># Variable Selection Network</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>input_size<span class="token punctuation">,</span>num_inputs<span class="token punctuation">,</span>hidden_size<span class="token punctuation">,</span>drop_out<span class="token punctuation">,</span>context<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>VSN<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>hidden_size<span class="token operator">=</span>hidden_size
        self<span class="token punctuation">.</span>input_size<span class="token operator">=</span>input_size
        self<span class="token punctuation">.</span>num_inputs<span class="token operator">=</span>num_inputs
        self<span class="token punctuation">.</span>drop_out<span class="token operator">=</span>drop_out
        self<span class="token punctuation">.</span>context<span class="token operator">=</span>context

        <span class="token comment">#num_inputs*input_size的原因是这里将所有的变量摊平了，原来先将num_inputs中的每个变量都做了embedding</span>
        self<span class="token punctuation">.</span>flattened_grn<span class="token operator">=</span>GRN<span class="token punctuation">(</span>input_size<span class="token operator">=</span>self<span class="token punctuation">.</span>num_inputs<span class="token operator">*</span>self<span class="token punctuation">.</span>input_size<span class="token punctuation">,</span>hidden_state_size<span class="token operator">=</span>self<span class="token punctuation">.</span>hidden_size<span class="token punctuation">,</span>output_size<span class="token operator">=</span>self<span class="token punctuation">.</span>num_inputs<span class="token punctuation">,</span>drop_out<span class="token operator">=</span>self<span class="token punctuation">.</span>drop_out<span class="token punctuation">,</span>hidden_context_size<span class="token operator">=</span>self<span class="token punctuation">.</span>context<span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>single_variable_grns<span class="token operator">=</span>nn<span class="token punctuation">.</span>ModuleList<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>num_inputs<span class="token punctuation">)</span><span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>single_variable_grns<span class="token punctuation">.</span>append<span class="token punctuation">(</span>GRN<span class="token punctuation">(</span>self<span class="token punctuation">.</span>input_size<span class="token punctuation">,</span>self<span class="token punctuation">.</span>hidden_size<span class="token punctuation">,</span>self<span class="token punctuation">.</span>hidden_size<span class="token punctuation">,</span>self<span class="token punctuation">.</span>drop_out<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment">#为每一个展开变量均添加一个GRN</span>

        self<span class="token punctuation">.</span>softmax<span class="token operator">=</span>nn<span class="token punctuation">.</span>Softmax<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>embedding<span class="token punctuation">,</span>context<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        sparse_weights<span class="token operator">=</span>self<span class="token punctuation">.</span>flattened_grn<span class="token punctuation">(</span>embedding<span class="token punctuation">,</span>context<span class="token punctuation">)</span><span class="token comment">#将embedding铺平+grn+softmax cat embedding</span>

        sparse_weights<span class="token operator">=</span>self<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>sparse_weights<span class="token punctuation">)</span><span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token comment">#强制加入第二个维度，【seq,bs,1,num_inputs]</span>

        var_outputs<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token comment">#对每一个emb计算GRN并化为列表</span>
        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>num_inputs<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token comment"># 每个对应的输入维度的embedding分别求GRN,这里embedding后的维度为(seq,bs,input_size*num_inputs)</span>
            var_outputs<span class="token punctuation">.</span>append<span class="token punctuation">(</span>self<span class="token punctuation">.</span>single_variable_grns<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">(</span>embedding<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">(</span>i<span class="token operator">*</span>self<span class="token punctuation">.</span>input_size<span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token punctuation">(</span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token operator">*</span>self<span class="token punctuation">.</span>input_size<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

        var_outputs<span class="token operator">=</span>torch<span class="token punctuation">.</span>stack<span class="token punctuation">(</span>var_outputs<span class="token punctuation">,</span>dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token comment">#在最后一个维度上进行堆叠,结果为[seq,bs,input_size,num_inputs]</span>
        <span class="token comment"># print(var_outputs.shape)</span>
        <span class="token comment"># print(sparse_weights.shape)</span>
        <span class="token triple-quoted-string string">'''
        ggg
        ggg
        '''</span>
        outputs<span class="token operator">=</span>var_outputs<span class="token operator">*</span>sparse_weights
        outputs<span class="token operator">=</span>outputs<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
        
        <span class="token keyword">return</span> outputs<span class="token punctuation">,</span>sparse_weights

<span class="token keyword">class</span> <span class="token class-name">TFT</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>config<span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token comment">#传入config字典</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>TFT<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>device<span class="token operator">=</span>config<span class="token punctuation">[</span><span class="token string">'device'</span><span class="token punctuation">]</span>
        self<span class="token punctuation">.</span>batch_size<span class="token operator">=</span>config<span class="token punctuation">[</span><span class="token string">'batch_size'</span><span class="token punctuation">]</span>
        self<span class="token punctuation">.</span>static_variables<span class="token operator">=</span>config<span class="token punctuation">[</span><span class="token string">'static_variables'</span><span class="token punctuation">]</span>
        self<span class="token punctuation">.</span>encode_length<span class="token operator">=</span>config<span class="token punctuation">[</span><span class="token string">'encode_length'</span><span class="token punctuation">]</span>
        self<span class="token punctuation">.</span>time_varying_categorical_variables<span class="token operator">=</span>config<span class="token punctuation">[</span><span class="token string">'time_varying_categorical_variables'</span><span class="token punctuation">]</span><span class="token comment">#随时间变化的离散型变量(分类型)</span>
        self<span class="token punctuation">.</span>time_varying_real_variables_encoder<span class="token operator">=</span>config<span class="token punctuation">[</span><span class="token string">'time_varying_real_variables_encoder'</span><span class="token punctuation">]</span><span class="token comment">#encoder中随时间变化的连续型变量</span>
        self<span class="token punctuation">.</span>time_varying_real_variables_decoder<span class="token operator">=</span>config<span class="token punctuation">[</span><span class="token string">'time_varying_real_variables_decoder'</span><span class="token punctuation">]</span><span class="token comment">#decoder中随时间变化的连续型变量</span>
        self<span class="token punctuation">.</span>num_input_series_to_mask<span class="token operator">=</span>config<span class="token punctuation">[</span><span class="token string">'num_masked_series'</span><span class="token punctuation">]</span>
        self<span class="token punctuation">.</span>hidden_size<span class="token operator">=</span>config<span class="token punctuation">[</span><span class="token string">'lstm_hidden_dimension'</span><span class="token punctuation">]</span>
        self<span class="token punctuation">.</span>lstm_layers<span class="token operator">=</span>config<span class="token punctuation">[</span><span class="token string">'lstm_layers'</span><span class="token punctuation">]</span>
        self<span class="token punctuation">.</span>drop_out<span class="token operator">=</span>config<span class="token punctuation">[</span><span class="token string">'drop_out'</span><span class="token punctuation">]</span>
        self<span class="token punctuation">.</span>embedding_dim<span class="token operator">=</span>config<span class="token punctuation">[</span><span class="token string">'embedding_dim'</span><span class="token punctuation">]</span>
        self<span class="token punctuation">.</span>attn_heads<span class="token operator">=</span>config<span class="token punctuation">[</span><span class="token string">'attn_heads'</span><span class="token punctuation">]</span>
        self<span class="token punctuation">.</span>num_quantiles<span class="token operator">=</span>config<span class="token punctuation">[</span><span class="token string">'num_quantiles'</span><span class="token punctuation">]</span><span class="token comment">#分位数的个数</span>
        self<span class="token punctuation">.</span>valid_quantiles<span class="token operator">=</span>config<span class="token punctuation">[</span><span class="token string">'valid_quantiles'</span><span class="token punctuation">]</span><span class="token comment">#有效分位数</span>
        self<span class="token punctuation">.</span>seq_length<span class="token operator">=</span>config<span class="token punctuation">[</span><span class="token string">'seq_length'</span><span class="token punctuation">]</span>

        self<span class="token punctuation">.</span>static_embedding_layers<span class="token operator">=</span>nn<span class="token punctuation">.</span>ModuleList<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment">#对每一个变量分别做embedding,[bs,1]对应着所有bs的第i个变量</span>
        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>static_variables<span class="token punctuation">)</span><span class="token punctuation">:</span>
            emb<span class="token operator">=</span>nn<span class="token punctuation">.</span>Embedding<span class="token punctuation">(</span>config<span class="token punctuation">[</span><span class="token string">'static_embedding_vocab_sizes'</span><span class="token punctuation">]</span><span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span>config<span class="token punctuation">[</span><span class="token string">'embedding_dim'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>self<span class="token punctuation">.</span>device<span class="token punctuation">)</span><span class="token comment">#有可能static_embedding_vocab_sizes不为1？</span>
            self<span class="token punctuation">.</span>static_embedding_layers<span class="token punctuation">.</span>append<span class="token punctuation">(</span>emb<span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>time_varying_embedding_layers<span class="token operator">=</span>nn<span class="token punctuation">.</span>ModuleList<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment">#随时间变化的变量的编码</span>
        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>time_varying_categorical_variables<span class="token punctuation">)</span><span class="token punctuation">:</span>
            emb<span class="token operator">=</span>TimeDistributed<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Embedding<span class="token punctuation">(</span>config<span class="token punctuation">[</span><span class="token string">'time_varying_embedding_vocab_sizes'</span><span class="token punctuation">]</span><span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span>config<span class="token punctuation">[</span><span class="token string">'embedding_dim'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            self<span class="token punctuation">.</span>time_varying_embedding_layers<span class="token punctuation">.</span>append<span class="token punctuation">(</span>emb<span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>time_varying_linear_layers<span class="token operator">=</span>nn<span class="token punctuation">.</span>ModuleList<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>time_varying_real_variables_encoder<span class="token punctuation">)</span><span class="token punctuation">:</span>
            emb<span class="token operator">=</span>TimeDistributed<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span>config<span class="token punctuation">[</span><span class="token string">'embedding_dim'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>batch_first<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>self<span class="token punctuation">.</span>device<span class="token punctuation">)</span>
            self<span class="token punctuation">.</span>time_varying_linear_layers<span class="token punctuation">.</span>append<span class="token punctuation">(</span>emb<span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>encoder_variable_selection<span class="token operator">=</span>VSN<span class="token punctuation">(</span>config<span class="token punctuation">[</span><span class="token string">'embedding_dim'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                                            <span class="token punctuation">(</span>config<span class="token punctuation">[</span><span class="token string">'time_varying_real_variables_encoder'</span><span class="token punctuation">]</span><span class="token operator">+</span>
                                            config<span class="token punctuation">[</span><span class="token string">'time_varying_categorical_variables'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                            self<span class="token punctuation">.</span>hidden_size<span class="token punctuation">,</span>
                                            self<span class="token punctuation">.</span>drop_out<span class="token punctuation">,</span>
                                            config<span class="token punctuation">[</span><span class="token string">'embedding_dim'</span><span class="token punctuation">]</span><span class="token operator">*</span>config<span class="token punctuation">[</span><span class="token string">'static_variables'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>decoder_variable_selection <span class="token operator">=</span> VSN<span class="token punctuation">(</span>config<span class="token punctuation">[</span><span class="token string">'embedding_dim'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                                <span class="token punctuation">(</span>config<span class="token punctuation">[</span><span class="token string">'time_varying_real_variables_decoder'</span><span class="token punctuation">]</span> <span class="token operator">+</span>  config<span class="token punctuation">[</span><span class="token string">'time_varying_categorical_variables'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                self<span class="token punctuation">.</span>hidden_size<span class="token punctuation">,</span>
                                self<span class="token punctuation">.</span>drop_out<span class="token punctuation">,</span>
                                config<span class="token punctuation">[</span><span class="token string">'embedding_dim'</span><span class="token punctuation">]</span><span class="token operator">*</span>config<span class="token punctuation">[</span><span class="token string">'static_variables'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>lstm_encoder_input_size <span class="token operator">=</span> config<span class="token punctuation">[</span><span class="token string">'embedding_dim'</span><span class="token punctuation">]</span><span class="token operator">*</span><span class="token punctuation">(</span>config<span class="token punctuation">[</span><span class="token string">'time_varying_real_variables_encoder'</span><span class="token punctuation">]</span> <span class="token operator">+</span>
                                                        config<span class="token punctuation">[</span><span class="token string">'time_varying_categorical_variables'</span><span class="token punctuation">]</span> <span class="token operator">+</span>
                                                        config<span class="token punctuation">[</span><span class="token string">'static_variables'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token comment">#输入lstm的变量应当是三个不同变量分类的和</span>

        self<span class="token punctuation">.</span>lstm_decoder_input_size <span class="token operator">=</span> config<span class="token punctuation">[</span><span class="token string">'embedding_dim'</span><span class="token punctuation">]</span><span class="token operator">*</span><span class="token punctuation">(</span>config<span class="token punctuation">[</span><span class="token string">'time_varying_real_variables_decoder'</span><span class="token punctuation">]</span> <span class="token operator">+</span>
                                                        config<span class="token punctuation">[</span><span class="token string">'time_varying_categorical_variables'</span><span class="token punctuation">]</span> <span class="token operator">+</span>
                                                        config<span class="token punctuation">[</span><span class="token string">'static_variables'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>lstm_encoder<span class="token operator">=</span>nn<span class="token punctuation">.</span>LSTM<span class="token punctuation">(</span>input_size<span class="token operator">=</span>self<span class="token punctuation">.</span>hidden_size<span class="token punctuation">,</span>hidden_size<span class="token operator">=</span>self<span class="token punctuation">.</span>hidden_size<span class="token punctuation">,</span>num_layers<span class="token operator">=</span>self<span class="token punctuation">.</span>lstm_layers
                                  <span class="token punctuation">,</span>dropout<span class="token operator">=</span>self<span class="token punctuation">.</span>drop_out<span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>lstm_decoder<span class="token operator">=</span>nn<span class="token punctuation">.</span>LSTM<span class="token punctuation">(</span>input_size<span class="token operator">=</span>self<span class="token punctuation">.</span>hidden_size<span class="token punctuation">,</span>hidden_size<span class="token operator">=</span>self<span class="token punctuation">.</span>hidden_size<span class="token punctuation">,</span>num_layers<span class="token operator">=</span>self<span class="token punctuation">.</span>lstm_layers
                                  <span class="token punctuation">,</span>dropout<span class="token operator">=</span>self<span class="token punctuation">.</span>drop_out<span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>post_lstm_gate<span class="token operator">=</span>TimeDistributed<span class="token punctuation">(</span>GLU<span class="token punctuation">(</span>self<span class="token punctuation">.</span>hidden_size<span class="token punctuation">)</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>post_lstm_norm<span class="token operator">=</span>TimeDistributed<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>LayerNorm<span class="token punctuation">(</span>self<span class="token punctuation">.</span>hidden_size<span class="token punctuation">)</span><span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>static_enrichment<span class="token operator">=</span>GRN<span class="token punctuation">(</span>self<span class="token punctuation">.</span>hidden_size<span class="token punctuation">,</span>self<span class="token punctuation">.</span>hidden_size<span class="token punctuation">,</span>self<span class="token punctuation">.</span>hidden_size<span class="token punctuation">,</span>self<span class="token punctuation">.</span>drop_out<span class="token punctuation">,</span>config<span class="token punctuation">[</span><span class="token string">'embedding_dim'</span><span class="token punctuation">]</span><span class="token operator">*</span>self<span class="token punctuation">.</span>static_variables<span class="token punctuation">)</span><span class="token comment">#最后一项是static_context_size</span>

        self<span class="token punctuation">.</span>position_encoding<span class="token operator">=</span>PositionalEncoder<span class="token punctuation">(</span>self<span class="token punctuation">.</span>hidden_size<span class="token punctuation">,</span>self<span class="token punctuation">.</span>seq_length<span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>multihead_attn<span class="token operator">=</span>nn<span class="token punctuation">.</span>MultiheadAttention<span class="token punctuation">(</span>self<span class="token punctuation">.</span>hidden_size<span class="token punctuation">,</span>self<span class="token punctuation">.</span>attn_heads<span class="token punctuation">)</span><span class="token comment">#第二项是头的数量</span>
        self<span class="token punctuation">.</span>post_attn_gate<span class="token operator">=</span>TimeDistributed<span class="token punctuation">(</span>GLU<span class="token punctuation">(</span>self<span class="token punctuation">.</span>hidden_size<span class="token punctuation">)</span><span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>post_attn_norm<span class="token operator">=</span>TimeDistributed<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>LayerNorm<span class="token punctuation">(</span>self<span class="token punctuation">.</span>hidden_size<span class="token punctuation">)</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>pos_wise_ff<span class="token operator">=</span>GRN<span class="token punctuation">(</span>self<span class="token punctuation">.</span>hidden_size<span class="token punctuation">,</span>self<span class="token punctuation">.</span>hidden_size<span class="token punctuation">,</span>self<span class="token punctuation">.</span>hidden_size<span class="token punctuation">,</span>self<span class="token punctuation">.</span>drop_out<span class="token punctuation">)</span><span class="token comment">#Position_wise_Feed_forward</span>

        self<span class="token punctuation">.</span>pre_output_norm<span class="token operator">=</span>TimeDistributed<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>LayerNorm<span class="token punctuation">(</span>self<span class="token punctuation">.</span>hidden_size<span class="token punctuation">)</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>pre_output_gate<span class="token operator">=</span>TimeDistributed<span class="token punctuation">(</span>GLU<span class="token punctuation">(</span>self<span class="token punctuation">.</span>hidden_size<span class="token punctuation">)</span><span class="token punctuation">)</span>

        self<span class="token punctuation">.</span> output_layer<span class="token operator">=</span>TimeDistributed<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>self<span class="token punctuation">.</span>hidden_size<span class="token punctuation">,</span>self<span class="token punctuation">.</span>num_quantiles<span class="token punctuation">)</span><span class="token punctuation">,</span>batch_first<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">init_hidden</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>self<span class="token punctuation">.</span>lstm_layers<span class="token punctuation">,</span>self<span class="token punctuation">.</span>batch_size<span class="token punctuation">,</span>self<span class="token punctuation">.</span>hidden_size<span class="token punctuation">,</span>device<span class="token operator">=</span>self<span class="token punctuation">.</span>device<span class="token punctuation">)</span><span class="token comment">#初始化隐藏层大小</span>

    <span class="token keyword">def</span> <span class="token function">apply_embedding</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>x<span class="token punctuation">,</span>static_embedding<span class="token punctuation">,</span>apply_masking<span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token comment">#连续型变量</span>
        <span class="token comment">###x should have dimensions (batch_size, timesteps, input_size)</span>
        <span class="token keyword">if</span> apply_masking<span class="token punctuation">:</span><span class="token comment">#判断是否进行masking</span>
            time_varying_real_vectors<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span>
            <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>time_varying_real_variables_decoder<span class="token punctuation">)</span><span class="token punctuation">:</span>
                emb<span class="token operator">=</span>self<span class="token punctuation">.</span>time_varying_linear_layers<span class="token punctuation">[</span>i<span class="token operator">+</span>self<span class="token punctuation">.</span>num_input_series_to_mask<span class="token punctuation">]</span><span class="token punctuation">(</span>x<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">,</span>i<span class="token operator">+</span>self<span class="token punctuation">.</span>num_input_series_to_mask<span class="token punctuation">]</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span>x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
                <span class="token comment"># print(emb.device)</span>
                time_varying_real_vectors<span class="token punctuation">.</span>append<span class="token punctuation">(</span>emb<span class="token punctuation">)</span>
            time_varying_real_embedding<span class="token operator">=</span>torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span>time_varying_real_vectors<span class="token punctuation">,</span>dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>

        <span class="token keyword">else</span><span class="token punctuation">:</span><span class="token comment">#正常的进行embedding[bs,time_steps,input_size]--&gt;[bs,time_step,input_size*num_inputs]</span>
            time_varying_real_vectors <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
            <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>time_varying_real_variables_encoder<span class="token punctuation">)</span><span class="token punctuation">:</span>
                emb <span class="token operator">=</span> self<span class="token punctuation">.</span>time_varying_linear_layers<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">(</span>x<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">,</span>i<span class="token punctuation">]</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span>x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
                time_varying_real_vectors<span class="token punctuation">.</span>append<span class="token punctuation">(</span>emb<span class="token punctuation">)</span>
            time_varying_real_embedding <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span>time_varying_real_vectors<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>

        <span class="token comment">##Time-varying categorical embeddings (eg:hour),时序离散型变量</span>
        time_varying_categorical_vectors<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span>
        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>time_varying_categorical_variables<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token comment"># print(x[:,:,self.time_varying_real_variables_encoder+i].view(x.size(0),-1,1).long().device)</span>
            emb<span class="token operator">=</span>self<span class="token punctuation">.</span>time_varying_embedding_layers<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">(</span>x<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">,</span>self<span class="token punctuation">.</span>time_varying_real_variables_encoder<span class="token operator">+</span>i<span class="token punctuation">]</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span>x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">long</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

            time_varying_categorical_vectors<span class="token punctuation">.</span>append<span class="token punctuation">(</span>emb<span class="token punctuation">)</span>
        time_varying_categorical_embedding<span class="token operator">=</span>torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span>time_varying_categorical_vectors<span class="token punctuation">,</span>dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>

        <span class="token comment"># 对static_embedding在时间步上进行扩维</span>
        static_embedding <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span>time_varying_categorical_embedding<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token operator">*</span><span class="token punctuation">[</span>static_embedding<span class="token punctuation">]</span><span class="token punctuation">)</span>
        static_embedding <span class="token operator">=</span> static_embedding<span class="token punctuation">.</span>view<span class="token punctuation">(</span>time_varying_categorical_embedding<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span>time_varying_categorical_embedding<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">1</span> <span class="token punctuation">)</span>

        <span class="token comment">#连接所有的embeddings</span>
        embeddings<span class="token operator">=</span>torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>static_embedding<span class="token punctuation">,</span>time_varying_categorical_embedding<span class="token punctuation">,</span>time_varying_real_embedding<span class="token punctuation">]</span><span class="token punctuation">,</span>dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>

        <span class="token keyword">return</span> embeddings<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span>x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span>embeddings<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment">#最后一项返回的是num_inputs*inputs_size的大小</span>
    <span class="token keyword">def</span> <span class="token function">encode</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> hidden<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>

        <span class="token keyword">if</span> hidden <span class="token keyword">is</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            hidden <span class="token operator">=</span> self<span class="token punctuation">.</span>init_hidden<span class="token punctuation">(</span><span class="token punctuation">)</span>

        output<span class="token punctuation">,</span> <span class="token punctuation">(</span>hidden<span class="token punctuation">,</span> cell<span class="token punctuation">)</span> <span class="token operator">=</span> self<span class="token punctuation">.</span>lstm_encoder<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token punctuation">(</span>hidden<span class="token punctuation">,</span> hidden<span class="token punctuation">)</span><span class="token punctuation">)</span>

        <span class="token keyword">return</span> output<span class="token punctuation">,</span> hidden

    <span class="token keyword">def</span> <span class="token function">decode</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> hidden<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>

        <span class="token keyword">if</span> hidden <span class="token keyword">is</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            hidden <span class="token operator">=</span> self<span class="token punctuation">.</span>init_hidden<span class="token punctuation">(</span><span class="token punctuation">)</span>

        output<span class="token punctuation">,</span> <span class="token punctuation">(</span>hidden<span class="token punctuation">,</span> cell<span class="token punctuation">)</span> <span class="token operator">=</span> self<span class="token punctuation">.</span>lstm_decoder<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token punctuation">(</span>hidden<span class="token punctuation">,</span>hidden<span class="token punctuation">)</span><span class="token punctuation">)</span>

        <span class="token keyword">return</span> output<span class="token punctuation">,</span> hidden

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment">#输入的顺序为：static,time_varying_categorical,time_varying_real</span>
        embedding_vectors<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span>
        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>static_variables<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token comment">#静态变量只需要从第一个时间步获取即可 x:--&gt;[bs,time_step,num_inputs]</span>
            emb<span class="token operator">=</span>self<span class="token punctuation">.</span>static_embedding_layers<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">(</span>x<span class="token punctuation">[</span><span class="token string">'identifier'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>self<span class="token punctuation">.</span>device<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span>i<span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">long</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            embedding_vectors<span class="token punctuation">.</span>append<span class="token punctuation">(</span>emb<span class="token punctuation">)</span><span class="token comment">#[bs,inputs]*number_inputs--&gt;[bs,inputs*num_inputs]</span>



        <span class="token comment"># Embedding和variables selection</span>
        static_embedding<span class="token operator">=</span>torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span>embedding_vectors<span class="token punctuation">,</span>dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>self<span class="token punctuation">.</span>device<span class="token punctuation">)</span><span class="token comment">#[bs,inputs*num_inputs]</span>
        <span class="token comment"># print(static_embedding.device)</span>
        <span class="token comment"># print(x['inputs'][:,:self.encode_length,:].float().to(self.device).device)</span>
        embeddings_encoder<span class="token operator">=</span>self<span class="token punctuation">.</span>apply_embedding<span class="token punctuation">(</span>x<span class="token punctuation">[</span><span class="token string">'inputs'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span>self<span class="token punctuation">.</span>encode_length<span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>self<span class="token punctuation">.</span>device<span class="token punctuation">)</span><span class="token punctuation">,</span>static_embedding<span class="token punctuation">,</span>apply_masking<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token comment">#</span>

        embeddings_decoder<span class="token operator">=</span>self<span class="token punctuation">.</span>apply_embedding<span class="token punctuation">(</span>x<span class="token punctuation">[</span><span class="token string">'inputs'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span>self<span class="token punctuation">.</span>encode_length<span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>self<span class="token punctuation">.</span>device<span class="token punctuation">)</span><span class="token punctuation">,</span>static_embedding<span class="token punctuation">,</span>apply_masking<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
        embeddings_encoder<span class="token punctuation">,</span>encoder_sparse_weights<span class="token operator">=</span>self<span class="token punctuation">.</span>encoder_variable_selection<span class="token punctuation">(</span>embeddings_encoder<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>embedding_dim<span class="token operator">*</span>self<span class="token punctuation">.</span>static_variables<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span>embeddings_encoder<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>embedding_dim<span class="token operator">*</span>self<span class="token punctuation">.</span>static_variables<span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        embeddings_decoder<span class="token punctuation">,</span>decoder_sparse_weights<span class="token operator">=</span>self<span class="token punctuation">.</span>decoder_variable_selection<span class="token punctuation">(</span>embeddings_decoder<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>embedding_dim<span class="token operator">*</span>self<span class="token punctuation">.</span>static_variables<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span>embeddings_decoder<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>embedding_dim<span class="token operator">*</span>self<span class="token punctuation">.</span>static_variables<span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span>


        <span class="token comment">#进行位置编码</span>
        pe<span class="token operator">=</span>self<span class="token punctuation">.</span>position_encoding<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>self<span class="token punctuation">.</span>seq_length<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span>embeddings_encoder<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>self<span class="token punctuation">.</span>device<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>self<span class="token punctuation">.</span>device<span class="token punctuation">)</span>

        embeddings_encoder<span class="token operator">=</span>embeddings_encoder<span class="token operator">+</span>pe<span class="token punctuation">[</span><span class="token punctuation">:</span>self<span class="token punctuation">.</span>encode_length<span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token comment">##[seq_len_encoder,bs,num_inputs*inputs_len]</span>
        embeddings_decoder<span class="token operator">=</span>embeddings_decoder<span class="token operator">+</span>pe<span class="token punctuation">[</span>self<span class="token punctuation">.</span>encode_length<span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token comment">##[seq_len_decoder,bs,num_inputs*inputs_len]</span>

        <span class="token comment">##LSTM</span>
        lstm_input<span class="token operator">=</span>torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>embeddings_encoder<span class="token punctuation">,</span>embeddings_decoder<span class="token punctuation">]</span><span class="token punctuation">,</span>dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token comment">#在时间序列上对编码和解码后的数据进行拼接</span>
        encoder_output<span class="token punctuation">,</span>hidden<span class="token operator">=</span>self<span class="token punctuation">.</span>encode<span class="token punctuation">(</span>embeddings_encoder<span class="token punctuation">)</span><span class="token comment">#对encoder部分的数据进行编码，并传回hidden层的数据给下一步解码</span>
        decoder_output<span class="token punctuation">,</span>_<span class="token operator">=</span>self<span class="token punctuation">.</span>decode<span class="token punctuation">(</span>embeddings_decoder<span class="token punctuation">,</span>hidden<span class="token punctuation">)</span>
        lstm_output<span class="token operator">=</span>torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>encoder_output<span class="token punctuation">,</span>decoder_output<span class="token punctuation">]</span><span class="token punctuation">,</span>dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token comment">#将lstm的输出在序列维度上进行拼接[sq,bs,hidden_len]</span>

        <span class="token comment">#进行残差连接并通过gate(GLU)+Norm</span>
        lstm_output<span class="token operator">=</span>self<span class="token punctuation">.</span>post_lstm_norm<span class="token punctuation">(</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>post_lstm_gate<span class="token punctuation">(</span>lstm_output<span class="token punctuation">)</span><span class="token operator">+</span>lstm_input<span class="token punctuation">)</span><span class="token punctuation">)</span>

        <span class="token comment">##static enrichment</span>
        static_embedding<span class="token operator">=</span>torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span>lstm_output<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token operator">*</span><span class="token punctuation">[</span>static_embedding<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span>lstm_output<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span>lstm_output<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token comment">#[bs,inputs*num_static_inputs]--&gt;GRN(inputs,se)--&gt;context</span>
        attn_input<span class="token operator">=</span>self<span class="token punctuation">.</span>static_enrichment<span class="token punctuation">(</span>lstm_output<span class="token punctuation">,</span>static_embedding<span class="token punctuation">)</span>

        <span class="token comment">#求一个LN</span>

        <span class="token comment">## Attention层(Multihead Attention)</span>
        attn_output<span class="token punctuation">,</span>atten_output_weight<span class="token operator">=</span>self<span class="token punctuation">.</span>multihead_attn<span class="token punctuation">(</span>attn_input<span class="token punctuation">[</span>self<span class="token punctuation">.</span>encode_length<span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">,</span>attn_input<span class="token punctuation">[</span><span class="token punctuation">:</span>self<span class="token punctuation">.</span>encode_length<span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">,</span>attn_input<span class="token punctuation">[</span><span class="token punctuation">:</span>self<span class="token punctuation">.</span>encode_length<span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token comment">#结果大小同查询，也就是Q的大小，weights的大小为：(N, num_heads, L, S),L为Q的大小，S为K,V的大小</span>

        <span class="token comment">## gate</span>
        attn_output<span class="token operator">=</span>self<span class="token punctuation">.</span>post_attn_gate<span class="token punctuation">(</span>attn_output<span class="token punctuation">)</span><span class="token operator">+</span>attn_input<span class="token punctuation">[</span>self<span class="token punctuation">.</span>encode_length<span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span>
        <span class="token comment"># print(attn_output.shape)</span>
        attn_output<span class="token operator">=</span>self<span class="token punctuation">.</span>post_attn_norm<span class="token punctuation">(</span>attn_output<span class="token punctuation">)</span>

        output<span class="token operator">=</span>self<span class="token punctuation">.</span>pos_wise_ff<span class="token punctuation">(</span>attn_output<span class="token punctuation">)</span> <span class="token comment">#[self.encode_length:,:,:]</span>

        <span class="token comment"># resurial</span>
        output<span class="token operator">=</span>self<span class="token punctuation">.</span>pre_output_gate<span class="token punctuation">(</span>output<span class="token punctuation">)</span><span class="token operator">+</span>lstm_output<span class="token punctuation">[</span>self<span class="token punctuation">.</span>encode_length<span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span>
        output<span class="token operator">=</span>self<span class="token punctuation">.</span>pre_output_norm<span class="token punctuation">(</span>output<span class="token punctuation">)</span>

        <span class="token comment">#Final output layers(Dense)</span>
        output<span class="token operator">=</span>self<span class="token punctuation">.</span>output_layer<span class="token punctuation">(</span>output<span class="token punctuation">.</span>view<span class="token punctuation">(</span>self<span class="token punctuation">.</span>batch_size<span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span>self<span class="token punctuation">.</span>hidden_size<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment">#这里batch_first=ture</span>

        <span class="token keyword">return</span> output<span class="token punctuation">,</span>encoder_output<span class="token punctuation">,</span>decoder_output<span class="token punctuation">,</span>attn_output<span class="token punctuation">,</span>atten_output_weight<span class="token punctuation">,</span>encoder_sparse_weights<span class="token punctuation">,</span>decoder_sparse_weights

<span class="token comment">#损失：</span>
<span class="token keyword">class</span> <span class="token class-name">QuantileLoss</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token comment">#--》input:&lt;bs,ts,q&gt;--&gt;&lt;ts,q&gt;-&gt;,计算损失如下：</span>
    <span class="token comment">## From: https://medium.com/the-artificial-impostor/quantile-regression-part-2-6fdbc26b2629</span>

    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> quantiles<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment">##takes a list of quantiles</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>quantiles <span class="token operator">=</span> quantiles

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> preds<span class="token punctuation">,</span> target<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">assert</span> <span class="token keyword">not</span> target<span class="token punctuation">.</span>requires_grad
        <span class="token keyword">assert</span> preds<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span> <span class="token operator">==</span> target<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token comment">#检验程序使用的，如果不满足条件，程序会自动退出</span>
        losses <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        <span class="token keyword">for</span> i<span class="token punctuation">,</span> q <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>quantiles<span class="token punctuation">)</span><span class="token punctuation">:</span>
            errors <span class="token operator">=</span> target <span class="token operator">-</span> preds<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> i<span class="token punctuation">]</span>
            losses<span class="token punctuation">.</span>append<span class="token punctuation">(</span>
                torch<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>
                   <span class="token punctuation">(</span>q<span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">*</span> errors<span class="token punctuation">,</span>
                   q <span class="token operator">*</span> errors
            <span class="token punctuation">)</span><span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        loss <span class="token operator">=</span> torch<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>
            torch<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span>losses<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> loss

</code></pre> 
<pre><code class="prism language-python"><span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> Dataset
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np


</code></pre> 
<h2>
<a id="_392"></a>构建数据集</h2> 
<pre><code class="prism language-python"><span class="token comment">#生成演示数据</span>
df<span class="token operator">=</span>pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">'LD2011_2014.txt'</span><span class="token punctuation">,</span>index_col<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span>sep<span class="token operator">=</span><span class="token string">';'</span><span class="token punctuation">,</span>decimal<span class="token operator">=</span><span class="token string">','</span><span class="token punctuation">)</span>
df<span class="token punctuation">.</span>index<span class="token operator">=</span>pd<span class="token punctuation">.</span>to_datetime<span class="token punctuation">(</span>df<span class="token punctuation">.</span>index<span class="token punctuation">)</span>
df<span class="token punctuation">.</span>sort_index<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token comment">#inplace是使用排序后的数据来代替现有数据</span>
</code></pre> 
<pre><code class="prism language-python"><span class="token comment">#定义时间步</span>
output<span class="token operator">=</span>df<span class="token punctuation">.</span>resample<span class="token punctuation">(</span><span class="token string">'1h'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span>np<span class="token punctuation">.</span>nan<span class="token punctuation">)</span>
earliest_time<span class="token operator">=</span>output<span class="token punctuation">.</span>index<span class="token punctuation">.</span><span class="token builtin">min</span><span class="token punctuation">(</span><span class="token punctuation">)</span>

df_list<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span>

<span class="token keyword">for</span> label <span class="token keyword">in</span> output<span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Processing {}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>label<span class="token punctuation">)</span><span class="token punctuation">)</span>
    srs <span class="token operator">=</span> output<span class="token punctuation">[</span>label<span class="token punctuation">]</span>

    start_date <span class="token operator">=</span> <span class="token builtin">min</span><span class="token punctuation">(</span>srs<span class="token punctuation">.</span>fillna<span class="token punctuation">(</span>method<span class="token operator">=</span><span class="token string">'ffill'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>dropna<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>index<span class="token punctuation">)</span>
    end_date <span class="token operator">=</span> <span class="token builtin">max</span><span class="token punctuation">(</span>srs<span class="token punctuation">.</span>fillna<span class="token punctuation">(</span>method<span class="token operator">=</span><span class="token string">'bfill'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>dropna<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>index<span class="token punctuation">)</span>

    active_range <span class="token operator">=</span> <span class="token punctuation">(</span>srs<span class="token punctuation">.</span>index <span class="token operator">&gt;=</span> start_date<span class="token punctuation">)</span> <span class="token operator">&amp;</span> <span class="token punctuation">(</span>srs<span class="token punctuation">.</span>index <span class="token operator">&lt;=</span> end_date<span class="token punctuation">)</span>
    srs <span class="token operator">=</span> srs<span class="token punctuation">[</span>active_range<span class="token punctuation">]</span><span class="token punctuation">.</span>fillna<span class="token punctuation">(</span><span class="token number">0.</span><span class="token punctuation">)</span>

    tmp <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span><span class="token punctuation">{<!-- --></span><span class="token string">'power_usage'</span><span class="token punctuation">:</span> srs<span class="token punctuation">}</span><span class="token punctuation">)</span>
    date <span class="token operator">=</span> tmp<span class="token punctuation">.</span>index
    tmp<span class="token punctuation">[</span><span class="token string">'t'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">(</span>date <span class="token operator">-</span> earliest_time<span class="token punctuation">)</span><span class="token punctuation">.</span>seconds <span class="token operator">/</span> <span class="token number">60</span> <span class="token operator">/</span> <span class="token number">60</span> <span class="token operator">+</span> <span class="token punctuation">(</span>
        date <span class="token operator">-</span> earliest_time<span class="token punctuation">)</span><span class="token punctuation">.</span>days <span class="token operator">*</span> <span class="token number">24</span>
    tmp<span class="token punctuation">[</span><span class="token string">'days_from_start'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">(</span>date <span class="token operator">-</span> earliest_time<span class="token punctuation">)</span><span class="token punctuation">.</span>days
    tmp<span class="token punctuation">[</span><span class="token string">'categorical_id'</span><span class="token punctuation">]</span> <span class="token operator">=</span> label
    tmp<span class="token punctuation">[</span><span class="token string">'date'</span><span class="token punctuation">]</span> <span class="token operator">=</span> date
    tmp<span class="token punctuation">[</span><span class="token string">'id'</span><span class="token punctuation">]</span> <span class="token operator">=</span> label
    tmp<span class="token punctuation">[</span><span class="token string">'hour'</span><span class="token punctuation">]</span> <span class="token operator">=</span> date<span class="token punctuation">.</span>hour
    tmp<span class="token punctuation">[</span><span class="token string">'day'</span><span class="token punctuation">]</span> <span class="token operator">=</span> date<span class="token punctuation">.</span>day
    tmp<span class="token punctuation">[</span><span class="token string">'day_of_week'</span><span class="token punctuation">]</span> <span class="token operator">=</span> date<span class="token punctuation">.</span>dayofweek
    tmp<span class="token punctuation">[</span><span class="token string">'month'</span><span class="token punctuation">]</span> <span class="token operator">=</span> date<span class="token punctuation">.</span>month

    df_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>tmp<span class="token punctuation">)</span>

</code></pre> 
<pre><code>Processing MT_001
Processing MT_002
Processing MT_003
Processing MT_004
Processing MT_005
Processing MT_006
Processing MT_007
Processing MT_008
Processing MT_009
Processing MT_010
Processing MT_011
Processing MT_012
Processing MT_013
Processing MT_014
Processing MT_015
Processing MT_016
Processing MT_017
Processing MT_018
Processing MT_019
Processing MT_020
Processing MT_021
Processing MT_022
Processing MT_023
Processing MT_024
Processing MT_025
Processing MT_026
Processing MT_027
Processing MT_028
Processing MT_029
Processing MT_030
Processing MT_031
Processing MT_032
Processing MT_033
Processing MT_034
Processing MT_035
Processing MT_036
Processing MT_037
Processing MT_038
Processing MT_039
Processing MT_040
Processing MT_041
Processing MT_042
Processing MT_043
Processing MT_044
Processing MT_045
Processing MT_046
Processing MT_047
Processing MT_048
Processing MT_049
Processing MT_050
Processing MT_051
Processing MT_052
Processing MT_053
Processing MT_054
Processing MT_055
Processing MT_056
Processing MT_057
Processing MT_058
Processing MT_059
Processing MT_060
Processing MT_061
Processing MT_062
Processing MT_063
Processing MT_064
Processing MT_065
Processing MT_066
Processing MT_067
Processing MT_068
Processing MT_069
Processing MT_070
Processing MT_071
Processing MT_072
Processing MT_073
Processing MT_074
Processing MT_075
Processing MT_076
Processing MT_077
Processing MT_078
Processing MT_079
Processing MT_080
Processing MT_081
Processing MT_082
Processing MT_083
Processing MT_084
Processing MT_085
Processing MT_086
Processing MT_087
Processing MT_088
Processing MT_089
Processing MT_090
Processing MT_091
Processing MT_092
Processing MT_093
Processing MT_094
Processing MT_095
Processing MT_096
Processing MT_097
Processing MT_098
Processing MT_099
Processing MT_100
Processing MT_101
Processing MT_102
Processing MT_103
Processing MT_104
Processing MT_105
Processing MT_106
Processing MT_107
Processing MT_108
Processing MT_109
Processing MT_110
Processing MT_111
Processing MT_112
Processing MT_113
Processing MT_114
Processing MT_115
Processing MT_116
Processing MT_117
Processing MT_118
Processing MT_119
Processing MT_120
Processing MT_121
Processing MT_122
Processing MT_123
Processing MT_124
Processing MT_125
Processing MT_126
Processing MT_127
Processing MT_128
Processing MT_129
Processing MT_130
Processing MT_131
Processing MT_132
Processing MT_133
Processing MT_134
Processing MT_135
Processing MT_136
Processing MT_137
Processing MT_138
Processing MT_139
Processing MT_140
Processing MT_141
Processing MT_142
Processing MT_143
Processing MT_144
Processing MT_145
Processing MT_146
Processing MT_147
Processing MT_148
Processing MT_149
Processing MT_150
Processing MT_151
Processing MT_152
Processing MT_153
Processing MT_154
Processing MT_155
Processing MT_156
Processing MT_157
Processing MT_158
Processing MT_159
Processing MT_160
Processing MT_161
Processing MT_162
Processing MT_163
Processing MT_164
Processing MT_165
Processing MT_166
Processing MT_167
Processing MT_168
Processing MT_169
Processing MT_170
Processing MT_171
Processing MT_172
Processing MT_173
Processing MT_174
Processing MT_175
Processing MT_176
Processing MT_177
Processing MT_178
Processing MT_179
Processing MT_180
Processing MT_181
Processing MT_182
Processing MT_183
Processing MT_184
Processing MT_185
Processing MT_186
Processing MT_187
Processing MT_188
Processing MT_189
Processing MT_190
Processing MT_191
Processing MT_192
Processing MT_193
Processing MT_194
Processing MT_195
Processing MT_196
Processing MT_197
Processing MT_198
Processing MT_199
Processing MT_200
Processing MT_201
Processing MT_202
Processing MT_203
Processing MT_204
Processing MT_205
Processing MT_206
Processing MT_207
Processing MT_208
Processing MT_209
Processing MT_210
Processing MT_211
Processing MT_212
Processing MT_213
Processing MT_214
Processing MT_215
Processing MT_216
Processing MT_217
Processing MT_218
Processing MT_219
Processing MT_220
Processing MT_221
Processing MT_222
Processing MT_223
Processing MT_224
Processing MT_225
Processing MT_226
Processing MT_227
Processing MT_228
Processing MT_229
Processing MT_230
Processing MT_231
Processing MT_232
Processing MT_233
Processing MT_234
Processing MT_235
Processing MT_236
Processing MT_237
Processing MT_238
Processing MT_239
Processing MT_240
Processing MT_241
Processing MT_242
Processing MT_243
Processing MT_244
Processing MT_245
Processing MT_246
Processing MT_247
Processing MT_248
Processing MT_249
Processing MT_250
Processing MT_251
Processing MT_252
Processing MT_253
Processing MT_254
Processing MT_255
Processing MT_256
Processing MT_257
Processing MT_258
Processing MT_259
Processing MT_260
Processing MT_261
Processing MT_262
Processing MT_263
Processing MT_264
Processing MT_265
Processing MT_266
Processing MT_267
Processing MT_268
Processing MT_269
Processing MT_270
Processing MT_271
Processing MT_272
Processing MT_273
Processing MT_274
Processing MT_275
Processing MT_276
Processing MT_277
Processing MT_278
Processing MT_279
Processing MT_280
Processing MT_281
Processing MT_282
Processing MT_283
Processing MT_284
Processing MT_285
Processing MT_286
Processing MT_287
Processing MT_288
Processing MT_289
Processing MT_290
Processing MT_291
Processing MT_292
Processing MT_293
Processing MT_294
Processing MT_295
Processing MT_296
Processing MT_297
Processing MT_298
Processing MT_299
Processing MT_300
Processing MT_301
Processing MT_302
Processing MT_303
Processing MT_304
Processing MT_305
Processing MT_306
Processing MT_307
Processing MT_308
Processing MT_309
Processing MT_310
Processing MT_311
Processing MT_312
Processing MT_313
Processing MT_314
Processing MT_315
Processing MT_316
Processing MT_317
Processing MT_318
Processing MT_319
Processing MT_320
Processing MT_321
Processing MT_322
Processing MT_323
Processing MT_324
Processing MT_325
Processing MT_326
Processing MT_327
Processing MT_328
Processing MT_329
Processing MT_330
Processing MT_331
Processing MT_332
Processing MT_333
Processing MT_334
Processing MT_335
Processing MT_336
Processing MT_337
Processing MT_338
Processing MT_339
Processing MT_340
Processing MT_341
Processing MT_342
Processing MT_343
Processing MT_344
Processing MT_345
Processing MT_346
Processing MT_347
Processing MT_348
Processing MT_349
Processing MT_350
Processing MT_351
Processing MT_352
Processing MT_353
Processing MT_354
Processing MT_355
Processing MT_356
Processing MT_357
Processing MT_358
Processing MT_359
Processing MT_360
Processing MT_361
Processing MT_362
Processing MT_363
Processing MT_364
Processing MT_365
Processing MT_366
Processing MT_367
Processing MT_368
Processing MT_369
Processing MT_370
</code></pre> 
<pre><code class="prism language-python">output<span class="token operator">=</span>pd<span class="token punctuation">.</span>concat<span class="token punctuation">(</span>df_list<span class="token punctuation">,</span>axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span>join<span class="token operator">=</span><span class="token string">'outer'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reset_index<span class="token punctuation">(</span>drop<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
output<span class="token punctuation">[</span><span class="token string">'categorical_id'</span><span class="token punctuation">]</span> <span class="token operator">=</span> output<span class="token punctuation">[</span><span class="token string">'id'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token punctuation">)</span>
output<span class="token punctuation">[</span><span class="token string">'hours_from_start'</span><span class="token punctuation">]</span> <span class="token operator">=</span> output<span class="token punctuation">[</span><span class="token string">'t'</span><span class="token punctuation">]</span>
output<span class="token punctuation">[</span><span class="token string">'categorical_day_of_week'</span><span class="token punctuation">]</span> <span class="token operator">=</span> output<span class="token punctuation">[</span><span class="token string">'day_of_week'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token punctuation">)</span>
output<span class="token punctuation">[</span><span class="token string">'categorical_hour'</span><span class="token punctuation">]</span> <span class="token operator">=</span> output<span class="token punctuation">[</span><span class="token string">'hour'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment"># Filter to match range used by other academic papers</span>
output <span class="token operator">=</span> output<span class="token punctuation">[</span><span class="token punctuation">(</span>output<span class="token punctuation">[</span><span class="token string">'days_from_start'</span><span class="token punctuation">]</span> <span class="token operator">&gt;=</span> <span class="token number">1096</span><span class="token punctuation">)</span>
              <span class="token operator">&amp;</span> <span class="token punctuation">(</span>output<span class="token punctuation">[</span><span class="token string">'days_from_start'</span><span class="token punctuation">]</span> <span class="token operator">&lt;</span> <span class="token number">1346</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<pre><code class="prism language-python">
</code></pre> 
<pre><code class="prism language-python"><span class="token comment">##查看数据格式:</span>
<span class="token keyword">import</span> expt_settings<span class="token punctuation">.</span>configs
ExperimentConfig <span class="token operator">=</span> expt_settings<span class="token punctuation">.</span>configs<span class="token punctuation">.</span>ExperimentConfig

config <span class="token operator">=</span> ExperimentConfig<span class="token punctuation">(</span><span class="token string">'electricity'</span><span class="token punctuation">,</span> <span class="token string">'outputs'</span><span class="token punctuation">)</span>
data_formatter <span class="token operator">=</span> config<span class="token punctuation">.</span>make_data_formatter<span class="token punctuation">(</span><span class="token punctuation">)</span>


<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"*** Training from defined parameters for {} ***"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span><span class="token string">'electricity'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
data_csv_path <span class="token operator">=</span> <span class="token string">'hourly_electricity.csv'</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Loading &amp; splitting data..."</span><span class="token punctuation">)</span>
raw_data <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span>data_csv_path<span class="token punctuation">,</span> index_col<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
train<span class="token punctuation">,</span> valid<span class="token punctuation">,</span> test <span class="token operator">=</span> data_formatter<span class="token punctuation">.</span>split_data<span class="token punctuation">(</span>raw_data<span class="token punctuation">)</span>
train_samples<span class="token punctuation">,</span> valid_samples <span class="token operator">=</span> data_formatter<span class="token punctuation">.</span>get_num_samples_for_calibration<span class="token punctuation">(</span>
<span class="token punctuation">)</span>
</code></pre> 
<pre><code>*** Training from defined parameters for electricity ***
Loading &amp; splitting data...
Formatting train-valid-test splits.
Setting scalers with training data...
</code></pre> 
<pre><code class="prism language-python"><span class="token comment"># Sets up default params</span>
fixed_params <span class="token operator">=</span> data_formatter<span class="token punctuation">.</span>get_experiment_params<span class="token punctuation">(</span><span class="token punctuation">)</span>
params <span class="token operator">=</span> data_formatter<span class="token punctuation">.</span>get_default_model_params<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<pre><code class="prism language-python"><span class="token comment"># train#对部分数据进行了标准化</span>
<span class="token builtin">len</span><span class="token punctuation">(</span>train<span class="token punctuation">.</span><span class="token builtin">id</span><span class="token punctuation">.</span>unique<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<pre><code>369
</code></pre> 
<pre><code class="prism language-python"><span class="token comment">##定义time_step dataset--&gt;[bs,ts,num_inputs]</span>
<span class="token keyword">class</span> <span class="token class-name">TSDataset</span><span class="token punctuation">(</span>Dataset<span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token comment">#继承Dataset,核心在于__getitem__和__len__</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>id_col<span class="token punctuation">,</span>static_cols<span class="token punctuation">,</span>time_col<span class="token punctuation">,</span>input_col<span class="token punctuation">,</span>target_col<span class="token punctuation">,</span>time_steps<span class="token punctuation">,</span>max_samples<span class="token punctuation">,</span>input_size<span class="token punctuation">,</span>num_encoder_steps<span class="token punctuation">,</span>num_static<span class="token punctuation">,</span>output_size<span class="token punctuation">,</span>data<span class="token punctuation">)</span><span class="token punctuation">:</span>

        self<span class="token punctuation">.</span>time_steps<span class="token operator">=</span>time_steps
        self<span class="token punctuation">.</span>input_size<span class="token operator">=</span>input_size
        self<span class="token punctuation">.</span>output_size<span class="token operator">=</span>output_size
        self<span class="token punctuation">.</span>num_encoder_steps<span class="token operator">=</span>num_encoder_steps

        data<span class="token punctuation">.</span>sort_values<span class="token punctuation">(</span>by<span class="token operator">=</span><span class="token punctuation">[</span>id_col<span class="token punctuation">,</span>time_col<span class="token punctuation">]</span><span class="token punctuation">,</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token comment">#将数据根据id和时间轴进行排序</span>

        valid_sampling_locations<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span>
        split_data_map<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token punctuation">}</span>
        <span class="token keyword">for</span> identifier<span class="token punctuation">,</span>df <span class="token keyword">in</span> data<span class="token punctuation">.</span>groupby<span class="token punctuation">(</span>id_col<span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token comment">#group本质上是一个聚合函数，按照需求进行分类，将数据切分成i个df,每个df的聚合指标的值都是相同的</span>
            num_entries<span class="token operator">=</span><span class="token builtin">len</span><span class="token punctuation">(</span>df<span class="token punctuation">)</span>
            <span class="token keyword">if</span> num_entries<span class="token operator">&gt;=</span>self<span class="token punctuation">.</span>time_steps<span class="token punctuation">:</span><span class="token comment">#将数据进行切片</span>
                valid_sampling_locations<span class="token operator">+=</span><span class="token punctuation">[</span><span class="token punctuation">(</span>identifier<span class="token punctuation">,</span>self<span class="token punctuation">.</span>time_steps<span class="token operator">+</span>i<span class="token punctuation">)</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_entries<span class="token operator">-</span>self<span class="token punctuation">.</span>time_steps<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token comment">#第identifier个元组列表，长度为时间轴-时间序列的长度(这里是做项的切割)</span>
                split_data_map<span class="token punctuation">[</span>identifier<span class="token punctuation">]</span><span class="token operator">=</span>df<span class="token comment">#第identifier的字典存放第identifier的项目数据</span>

        self<span class="token punctuation">.</span>inputs<span class="token operator">=</span>np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span>max_samples<span class="token punctuation">,</span>self<span class="token punctuation">.</span>time_steps<span class="token punctuation">,</span>self<span class="token punctuation">.</span>input_size<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment">#大小为samples*ts*input_num</span>
        self<span class="token punctuation">.</span>outputs<span class="token operator">=</span>np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span>max_samples<span class="token punctuation">,</span>self<span class="token punctuation">.</span>time_steps<span class="token punctuation">,</span>self<span class="token punctuation">.</span>output_size<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment">#samples*ts*output_num</span>
        self<span class="token punctuation">.</span>time<span class="token operator">=</span>np<span class="token punctuation">.</span>empty<span class="token punctuation">(</span><span class="token punctuation">(</span>max_samples<span class="token punctuation">,</span>self<span class="token punctuation">.</span>time_steps<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>identifiers<span class="token operator">=</span>np<span class="token punctuation">.</span>empty<span class="token punctuation">(</span><span class="token punctuation">(</span>max_samples<span class="token punctuation">,</span>self<span class="token punctuation">.</span>time_steps<span class="token punctuation">,</span>num_static<span class="token punctuation">)</span><span class="token punctuation">)</span>

        <span class="token keyword">if</span> max_samples<span class="token operator">&gt;</span><span class="token number">0</span> <span class="token keyword">and</span> <span class="token builtin">len</span><span class="token punctuation">(</span>valid_sampling_locations<span class="token punctuation">)</span><span class="token operator">&gt;</span>max_samples<span class="token punctuation">:</span><span class="token comment">#基本限制</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'Extracting </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>max_samples<span class="token punctuation">}</span></span><span class="token string"> samples'</span></span><span class="token punctuation">)</span>
            ranges<span class="token operator">=</span><span class="token punctuation">[</span>valid_sampling_locations<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>choice<span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>valid_sampling_locations<span class="token punctuation">)</span><span class="token punctuation">,</span>max_samples<span class="token punctuation">,</span>replace<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
            <span class="token comment"># 随机在数据集中抽取max_samples个数据</span>
            <span class="token comment"># replace是指允许出现相同的值(拿球后需要放回去),replace为flase是指禁止出现相同的值，此时所选取的数列长度必须要小于数据集合的元素数量</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'Max samples =</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>max_samples<span class="token punctuation">}</span></span><span class="token string">  available segments=</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span><span class="token builtin">len</span><span class="token punctuation">(</span>valid_sampling_locations<span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string">'</span></span><span class="token punctuation">)</span>
            ranges<span class="token operator">=</span>valid_sampling_locations
        <span class="token keyword">for</span> i<span class="token punctuation">,</span>tup <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>ranges<span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token comment">#ranges内为随机切割的(identifier,self.time_step+i)的元组</span>
            <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token punctuation">(</span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token operator">%</span><span class="token number">10000</span><span class="token punctuation">)</span><span class="token operator">==</span><span class="token number">0</span><span class="token punctuation">:</span>
                <span class="token keyword">print</span><span class="token punctuation">(</span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token string">'of'</span><span class="token punctuation">,</span>max_samples<span class="token punctuation">,</span><span class="token string">'samples done....'</span><span class="token punctuation">)</span>
            identifier<span class="token punctuation">,</span>start_idx<span class="token operator">=</span>tup
            sliced<span class="token operator">=</span>split_data_map<span class="token punctuation">[</span>identifier<span class="token punctuation">]</span><span class="token punctuation">.</span>iloc<span class="token punctuation">[</span>start_idx<span class="token operator">-</span>self<span class="token punctuation">.</span>time_steps<span class="token punctuation">:</span>start_idx<span class="token punctuation">]</span><span class="token comment">#默认先选第一维</span>

            self<span class="token punctuation">.</span>inputs<span class="token punctuation">[</span>i<span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token operator">=</span>sliced<span class="token punctuation">[</span>input_col<span class="token punctuation">]</span>
            self<span class="token punctuation">.</span>outputs<span class="token punctuation">[</span>i<span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token operator">=</span>sliced<span class="token punctuation">[</span><span class="token punctuation">[</span>target_col<span class="token punctuation">]</span><span class="token punctuation">]</span>
            self<span class="token punctuation">.</span>time<span class="token punctuation">[</span>i<span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token operator">=</span>sliced<span class="token punctuation">[</span>time_col<span class="token punctuation">]</span>
            <span class="token keyword">if</span> static_cols<span class="token punctuation">:</span>
                self<span class="token punctuation">.</span>identifiers<span class="token punctuation">[</span>i<span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token operator">=</span>sliced<span class="token punctuation">[</span>static_cols<span class="token punctuation">]</span>

        self<span class="token punctuation">.</span>sample_data<span class="token operator">=</span><span class="token punctuation">{<!-- --></span>
            <span class="token string">'inputs'</span><span class="token punctuation">:</span>self<span class="token punctuation">.</span>inputs<span class="token punctuation">,</span>
            <span class="token string">'outputs'</span><span class="token punctuation">:</span>self<span class="token punctuation">.</span>outputs<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span>self<span class="token punctuation">.</span>num_encoder_steps<span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
            <span class="token string">'active_entries'</span><span class="token punctuation">:</span>np<span class="token punctuation">.</span>ones_like<span class="token punctuation">(</span>self<span class="token punctuation">.</span>outputs<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span>self<span class="token punctuation">.</span>num_encoder_steps<span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token comment">#np.ones_like函数直接生成某大小的全为1的float数组</span>
            <span class="token string">'time'</span><span class="token punctuation">:</span>self<span class="token punctuation">.</span>time<span class="token punctuation">,</span>
            <span class="token string">'identifier'</span><span class="token punctuation">:</span>self<span class="token punctuation">.</span>identifiers
        <span class="token punctuation">}</span>
    <span class="token keyword">def</span> <span class="token function">__getitem__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>index<span class="token punctuation">)</span><span class="token punctuation">:</span>

        s<span class="token operator">=</span><span class="token punctuation">{<!-- --></span>
            <span class="token string">'inputs'</span><span class="token punctuation">:</span>self<span class="token punctuation">.</span>inputs<span class="token punctuation">[</span>index<span class="token punctuation">]</span><span class="token punctuation">,</span>
            <span class="token string">'outputs'</span><span class="token punctuation">:</span>self<span class="token punctuation">.</span>outputs<span class="token punctuation">[</span>index<span class="token punctuation">,</span>self<span class="token punctuation">.</span>num_encoder_steps<span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
            <span class="token string">'active_entries'</span><span class="token punctuation">:</span> np<span class="token punctuation">.</span>ones_like<span class="token punctuation">(</span>self<span class="token punctuation">.</span>outputs<span class="token punctuation">[</span>index<span class="token punctuation">,</span> self<span class="token punctuation">.</span>num_encoder_steps<span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token string">'time'</span><span class="token punctuation">:</span> self<span class="token punctuation">.</span>time<span class="token punctuation">[</span>index<span class="token punctuation">]</span><span class="token punctuation">,</span>
            <span class="token string">'identifier'</span><span class="token punctuation">:</span> self<span class="token punctuation">.</span>identifiers<span class="token punctuation">[</span>index<span class="token punctuation">]</span>
        <span class="token punctuation">}</span>




        <span class="token keyword">return</span> s
    <span class="token keyword">def</span> <span class="token function">__len__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>inputs<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token comment">#max_samples</span>

</code></pre> 
<pre><code class="prism language-python">
</code></pre> 
<pre><code class="prism language-python">id_col <span class="token operator">=</span> <span class="token string">'categorical_id'</span>
time_col<span class="token operator">=</span><span class="token string">'hours_from_start'</span>
input_cols <span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'power_usage'</span><span class="token punctuation">,</span> <span class="token string">'hour'</span><span class="token punctuation">,</span> <span class="token string">'day_of_week'</span><span class="token punctuation">,</span> <span class="token string">'hours_from_start'</span><span class="token punctuation">,</span> <span class="token string">'categorical_id'</span><span class="token punctuation">]</span>
target_col <span class="token operator">=</span> <span class="token string">'power_usage'</span>
time_steps<span class="token operator">=</span><span class="token number">192</span>
num_encoder_steps <span class="token operator">=</span> <span class="token number">168</span>
output_size <span class="token operator">=</span> <span class="token number">1</span>
max_samples <span class="token operator">=</span> <span class="token number">1000</span>
input_size <span class="token operator">=</span> <span class="token number">5</span>

elect<span class="token operator">=</span>TSDataset<span class="token punctuation">(</span>id_col<span class="token operator">=</span>id_col<span class="token punctuation">,</span>time_col<span class="token operator">=</span>time_col<span class="token punctuation">,</span>input_col<span class="token operator">=</span>input_cols<span class="token punctuation">,</span>target_col<span class="token operator">=</span>target_col<span class="token punctuation">,</span>time_steps<span class="token operator">=</span>time_steps<span class="token punctuation">,</span>max_samples<span class="token operator">=</span>max_samples<span class="token punctuation">,</span>input_size<span class="token operator">=</span>input_size<span class="token punctuation">,</span>num_encoder_steps<span class="token operator">=</span>num_encoder_steps<span class="token punctuation">,</span>output_size<span class="token operator">=</span>output_size<span class="token punctuation">,</span>data<span class="token operator">=</span>train<span class="token punctuation">,</span>static_cols<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span>num_static<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
</code></pre> 
<pre><code>Extracting 1000 samples
</code></pre> 
<pre><code class="prism language-python">batch_size<span class="token operator">=</span><span class="token number">128</span>
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader
loader<span class="token operator">=</span>DataLoader<span class="token punctuation">(</span>
    elect<span class="token punctuation">,</span>
    batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">,</span>
<span class="token punctuation">)</span>
</code></pre> 
<pre><code class="prism language-python">t<span class="token operator">=</span><span class="token builtin">next</span><span class="token punctuation">(</span><span class="token builtin">iter</span><span class="token punctuation">(</span>loader<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<pre><code class="prism language-python"><span class="token keyword">for</span> batch <span class="token keyword">in</span> loader<span class="token punctuation">:</span>
    <span class="token keyword">break</span>
</code></pre> 
<pre><code class="prism language-python">static_cols <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'meter'</span><span class="token punctuation">]</span>
categorical_cols <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'hour'</span><span class="token punctuation">]</span>
real_cols <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'power_usage'</span><span class="token punctuation">,</span> <span class="token string">'hour'</span><span class="token punctuation">,</span> <span class="token string">'day'</span><span class="token punctuation">]</span>
config <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span><span class="token punctuation">}</span>
config<span class="token punctuation">[</span><span class="token string">'static_variables'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">1</span><span class="token comment">#静态变量的数量</span>
config<span class="token punctuation">[</span><span class="token string">'time_varying_categorical_variables'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">1</span><span class="token comment">#离散变量的数量</span>
config<span class="token punctuation">[</span><span class="token string">'time_varying_real_variables_encoder'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">4</span><span class="token comment">#连续变量的数量</span>
config<span class="token punctuation">[</span><span class="token string">'time_varying_real_variables_decoder'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">3</span><span class="token comment">#解码层连续变量的数量</span>
config<span class="token punctuation">[</span><span class="token string">'num_masked_series'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">1</span><span class="token comment">#解码层需要mask的变量的数量(4-3)</span>
config<span class="token punctuation">[</span><span class="token string">'static_embedding_vocab_sizes'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">369</span><span class="token punctuation">]</span>
config<span class="token punctuation">[</span><span class="token string">'time_varying_embedding_vocab_sizes'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">369</span><span class="token punctuation">]</span>
config<span class="token punctuation">[</span><span class="token string">'embedding_dim'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">8</span>
config<span class="token punctuation">[</span><span class="token string">'lstm_hidden_dimension'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">160</span>
config<span class="token punctuation">[</span><span class="token string">'lstm_layers'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">1</span>
config<span class="token punctuation">[</span><span class="token string">'drop_out'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">0.05</span>
config<span class="token punctuation">[</span><span class="token string">'device'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">'cuda:0'</span>
config<span class="token punctuation">[</span><span class="token string">'batch_size'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">128</span>
config<span class="token punctuation">[</span><span class="token string">'encode_length'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">168</span>
config<span class="token punctuation">[</span><span class="token string">'attn_heads'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">4</span>
config<span class="token punctuation">[</span><span class="token string">'num_quantiles'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">3</span>
config<span class="token punctuation">[</span><span class="token string">'valid_quantiles'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.9</span><span class="token punctuation">]</span>
config<span class="token punctuation">[</span><span class="token string">'seq_length'</span><span class="token punctuation">]</span><span class="token operator">=</span><span class="token number">192</span><span class="token comment">#168+24</span>

</code></pre> 
<pre><code class="prism language-python">device<span class="token operator">=</span>torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">'cuda:0'</span><span class="token punctuation">)</span>
model<span class="token operator">=</span>TFT<span class="token punctuation">(</span>config<span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>

output<span class="token punctuation">,</span>encoder_output<span class="token punctuation">,</span>decoder_output<span class="token punctuation">,</span>attn_output<span class="token punctuation">,</span>atten_output_weight<span class="token punctuation">,</span>encoder_sparse_weights<span class="token punctuation">,</span>decoder_sparse_weights <span class="token operator">=</span> model<span class="token punctuation">(</span>batch<span class="token punctuation">)</span>
</code></pre> 
<pre><code>D:anaconda3envspytorchlibsite-packagestorchnnmodulesrnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.05 and num_layers=1
  "num_layers={}".format(dropout, num_layers))
D:anaconda3envspytorchlibsite-packagesipykernel_launcher.py:134: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
</code></pre> 
<pre><code class="prism language-python">output<span class="token punctuation">.</span>shape
</code></pre> 
<pre><code>torch.Size([128, 24, 3])
</code></pre> 
<pre><code class="prism language-python">q_loss_func<span class="token operator">=</span>QuantileLoss<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.1</span><span class="token punctuation">,</span><span class="token number">0.5</span><span class="token punctuation">,</span><span class="token number">0.9</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre> 
<pre><code class="prism language-python"><span class="token keyword">import</span> torch<span class="token punctuation">.</span>optim <span class="token keyword">as</span> optim
optimizer <span class="token operator">=</span> optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.0001</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>
epochs<span class="token operator">=</span><span class="token number">100</span>
losses <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
<span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>
    epoch_loss <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    j<span class="token operator">=</span><span class="token number">0</span>
    <span class="token keyword">for</span> batch <span class="token keyword">in</span> loader<span class="token punctuation">:</span>
        output<span class="token punctuation">,</span> encoder_ouput<span class="token punctuation">,</span> decoder_output<span class="token punctuation">,</span> attn<span class="token punctuation">,</span> attn_weights<span class="token punctuation">,</span>encoder_sparse_weights<span class="token punctuation">,</span>decoder_sparse_weights <span class="token operator">=</span> model<span class="token punctuation">(</span>batch<span class="token punctuation">)</span>
        <span class="token comment"># print(output.device,)</span>
        loss<span class="token operator">=</span> q_loss_func<span class="token punctuation">(</span>output<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> batch<span class="token punctuation">[</span><span class="token string">'outputs'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">)</span>
        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
        epoch_loss<span class="token punctuation">.</span>append<span class="token punctuation">(</span>loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        j<span class="token operator">+=</span><span class="token number">1</span>
        <span class="token keyword">if</span> j<span class="token operator">&gt;</span><span class="token number">5</span><span class="token punctuation">:</span>
            <span class="token keyword">break</span>
    losses<span class="token punctuation">.</span>append<span class="token punctuation">(</span>np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>epoch_loss<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>epoch_loss<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<pre><code>D:anaconda3envspytorchlibsite-packagesipykernel_launcher.py:134: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.


0.8006416956583658
0.7999884088834127
0.7668151756127676
0.7319403886795044
0.726747582356135
0.7607065538565317
0.8135423362255096
0.8432016670703888
0.8231969078381857
0.761721005042394
0.6956829130649567
0.6592607200145721
0.6720658640066782
0.7302353382110596
0.7924310863018036
0.8072405358155569
0.7689102192719778
0.7168515821297964
0.6805834372838339
0.6649592419465383
0.6662554542223612
0.678734670082728
0.6953920423984528
0.7107692460219065
0.7225532829761505
0.729248841603597
0.7277947465578715
0.7171043356259664
0.700122614701589
0.6821212271849314
0.6697695453961691
0.6694994668165842
0.6816134452819824
0.7033764322598776
0.725969264904658
0.7419355611006418
0.7459502319494883
0.7388339142004648
0.7245846688747406
0.7101153830687205
0.7013588547706604
0.703824390967687
0.7168124715487162
0.7370895445346832
0.7601349651813507
0.7801720400651296
0.7943577965100607
0.8007777631282806
0.7973537842432658
0.7844546735286713
0.7637931108474731
0.7376755177974701
0.7090499997138977
0.6818542381127676
0.6595257719357809
0.645796130100886
0.6428835491339365
0.6525691449642181
0.6745708882808685
0.7062879502773285
0.7445076505343119
0.7836808959643046
0.8192594250043234
0.8472486337025961
0.8637207349141439
0.8675130009651184
0.8589732150236765
0.8392985363801321
0.8106586337089539
0.7769776284694672
0.7424585918585459
0.7098000744978586
0.6822504798571268
0.661311407883962
0.6473604043324789
0.6410616636276245
0.6426865061124166
0.6523745556672415
0.6679417590300242
0.6892276406288147
0.7145460347334543
0.743001401424408
0.7725268006324768
0.801397830247879
0.8284187217553457
0.8512799839178721
0.868938128153483
0.8796140054861704
0.8833309511343638
0.8803511659304301
0.8718405067920685
0.8586658835411072
0.8424527943134308
0.8235893646876017
0.8035478393236796
0.7830379406611124
0.7635184427102407
0.7448866168657938
0.7281776269276937
0.7138447066148123
</code></pre> 
<pre><code class="prism language-python">output<span class="token punctuation">,</span> encoder_ouput<span class="token punctuation">,</span> decoder_output<span class="token punctuation">,</span> attn<span class="token punctuation">,</span> attn_weights<span class="token punctuation">,</span>encoder_sparse_weights<span class="token punctuation">,</span>decoder_sparse_weights <span class="token operator">=</span> model<span class="token punctuation">(</span>batch<span class="token punctuation">)</span>
</code></pre> 
<pre><code>D:anaconda3envspytorchlibsite-packagesipykernel_launcher.py:134: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
</code></pre> 
<pre><code class="prism language-python">output<span class="token punctuation">.</span>to<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">'cpu'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np

ind <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>choice<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>ind<span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>output<span class="token punctuation">[</span>ind<span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'pred_1'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>output<span class="token punctuation">[</span>ind<span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'pred_5'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>output<span class="token punctuation">[</span>ind<span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'pred_9'</span><span class="token punctuation">)</span>

plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>batch<span class="token punctuation">[</span><span class="token string">'outputs'</span><span class="token punctuation">]</span><span class="token punctuation">[</span>ind<span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'true'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<pre><code>53





&lt;matplotlib.legend.Legend at 0x239bea424c8&gt;
</code></pre> 
<p>​<br> <img src="https://images2.imgbox.com/c4/de/EyX1ONWp_o.png" alt="png"><br> ​</p> 
<pre><code class="prism language-python">
</code></pre> 
<pre><code class="prism language-python">
</code></pre>
                </div>
                
                

		</div>
	</article>
</main>




			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程小白.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://www.w3counter.com/tracker.js?id=150625"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>
	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>