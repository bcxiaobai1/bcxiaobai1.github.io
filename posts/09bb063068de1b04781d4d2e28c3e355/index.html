<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<title>kafka简述 - 编程小白</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程小白" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程小白</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">kafka简述</h1>
			
		</header>
		<div class="content post__content clearfix">
			


        
                <div id="content_views" class="markdown_views prism-atom-one-dark">
                    
                        
                    
                    <h3>
<a id="_0"></a>前言</h3> 
<p>​ 在大数据高并发场景下，当系统中出现“生产“和“消费“的速度或稳定性等因素不一致的时候，就需要消息队列，作为抽象层，弥合双方的差异。一般选型是Kafka、RocketMQ，这源于这些中间件的高吞吐、可扩展以及可靠性。</p> 
<p>​ <strong>另外企业中离线业务场景实时业务场景都需要使用到kafka，Kafka具备数据的计算能力和存储能力，但是两个能力相对（MR/SPARK，HDFS）较弱，Kafka角色的角色与hbase比较像，层级关系比较多。</strong></p> 
<h4>
<a id="_6"></a>消息队列</h4> 
<p>​ 是一种应用间的通信方式，消息发送后可以立即返回，由消息系统来确保信息的可靠专递，消息发布者只管把消息发布到MQ中而不管谁来取，消息使用者只管从MQ中取消息而不管谁发布的，这样发布者和使用者都不用知道对方的存在。</p> 
<h4>
<a id="_10"></a>消息队列的应用场景</h4> 
<p>消息队列在实际应用中包括如下四个场景：</p> 
<p><strong>应用耦合</strong>：多应用间通过消息队列对同一消息进行处理，避免调用接口失败导致整个过程失败；</p> 
<p><strong>异步处理</strong>：多应用对消息队列中同一消息进行处理，应用间并发处理消息，相比串行处理，减少处理时间；</p> 
<p><strong>限流削峰</strong>：广泛应用于秒杀或抢购活动中，避免流量过大导致应用系统挂掉的情况；</p> 
<p><strong>消息驱动的系统</strong>：系统分为消息队列、消息生产者、消息消费者，生产者负责产生消息，消费者(可能有多个)负责对消息进行处理；</p> 
<h4>
<a id="_22"></a>消息队列的两种模式</h4> 
<h5>
<a id="1_24"></a>1）点对点模式</h5> 
<p>​ 点对点模式下包括三个角色： 消息发送者 (生产者)、 接收者（消费者）</p> 
<p>​ 消息发送者生产消息发送到queue中，然后消息接收者从queue中取出并且消费消息。消息被消费以后，queue中不再有存储，所以消息接收者不可能消费到已经被消费的消息。</p> 
<blockquote> 
 <p><strong>特点：</strong></p> 
 <p>每个消息只有一个接收者（Consumer）(即一旦被消费，消息就不再在消息队列中)；</p> 
 <p>• 发送者和接收者间没有依赖性，发送者发送消息之后，不管有没有接收者在运行，都不会影响到发送者下次发送消息；</p> 
 <p>• 接收者在成功接收消息之后需向队列应答成功，以便消息队列删除当前接收的消息；</p> 
</blockquote> 
<h5>
<a id="2_38"></a>2）发布/订阅模式</h5> 
<p>​ 发布/订阅模式下包括三个角色： 角色主题（Topic）、 发布者(Publisher)、订阅者(Subscriber)</p> 
<p>​ <strong>发布者将消息发送到Topic，系统将这些消息传递给多个订阅者。</strong></p> 
<blockquote> 
 <p><strong>特点：</strong></p> 
 <p>• 每个消息可以有多个订阅者；</p> 
 <p>• 发布者和订阅者之间有时间上的依赖性。针对某个主题（Topic）的订阅者，它必须创建一个订阅者之后，才能消费发布者的消息。</p> 
 <p>• 为了消费消息，订阅者需要提前订阅该角色主题，并保持在线运行；</p> 
</blockquote> 
<h3>
<a id="_52"></a>介绍</h3> 
<p>​ **kafka是一个分布式，分区的，多副本的，多订阅者的消息发布订阅系统（分布式MQ系统）。基于zookeeper协调的分布式消息系统，它的最大的特性就是可以实时的处理大量数据以满足各种需求场景：比如基于hadoop的批处理系统、低延迟的实时系统、Storm/Spark流式处理引擎，web/nginx日志、搜索日志、监控日志、访问日志，消息服务等等。**用scala语言编写，Linkedin于2010年贡献给了Apache基金会并成为顶级开源项目。</p> 
<p>​ <strong>kafka</strong>适合离线和在线消息消费。<strong>kafka</strong>构建在<strong>zookeeper</strong>同步服务之上。它与<strong>apache</strong>和<strong>spark</strong>非常好的集成，应用于实时流式数据分析。</p> 
<h4>
<a id="_58"></a>好处</h4> 
<p>1、可靠性：分布式的，分区，复制和容错。</p> 
<p>2、可扩展性：kafka消息传递系统轻松缩放，无需停机。</p> 
<p>3、耐用性：kafka使用分布式提交日志，这意味着消息会尽可能快速的保存在磁盘上，因此它是持久的。</p> 
<p><strong>4、性能：kafka对于发布和定于消息都具有高吞吐量。即使存储了许多TB的消息，他也爆出稳定的性能。</strong> kafka非常快：保证零停机和零数据丢失。</p> 
<h4>
<a id="_68"></a>使用场景</h4> 
<p>**1）日志收集：**一个公司可以用Kafka收集各种服务的log，通过kafka以统一接口服务的方式开放给各种consumer，例如hadoop、Hbase、Solr等。</p> 
<p>**2）消息系统：**解耦和生产者和消费者、缓存消息等。</p> 
<p>**3）用户活动跟踪：**Kafka经常被用来记录web用户或者app用户的各种活动，如浏览网页、搜索、点击等活动，这些活动信息被各个服务器发布到kafka的topic中，<strong>订阅者通过订阅这些topic来做实时的监控分析，或者装载到hadoop、数据仓库中做离线分析和挖掘。</strong></p> 
<p>**4）运营指标：**Kafka也经常用来记录运营监控数据。包括收集各种分布式应用的数据，生产各种操作的集中反馈，比如报警和报告。</p> 
<p>**5）流式框架：**从主题中读取数据，对其进行处理，并将处理后的数据写入新的主题，供用户和应用程序使用，kafka的强耐久性在流处理的上下文中也非常的有用。</p> 
<h3>
<a id="_80"></a>基本概念</h3> 
<p>​ kafka是一个分布式的，分区的消息(官方称之为commit log)服务。它提供一个消息系统应该具备的功能，但是确有着独特的设计。</p> 
<p>​ 从宏观层面上看，Producer通过网络发送消息到Kafka集群，然后Consumer来进行消费。<strong>服务端(brokers)和客户端(producer、consumer)之间通信通过TCP协议来完成。</strong></p> 
<table>
<thead><tr>
<th align="left">名称</th>
<th align="left">解释</th>
</tr></thead>
<tbody>
<tr>
<td align="left">Broker</td>
<td align="left">消息中间件处理节点，一个Kafka节点就是一个broker，一个或者多个Broker可以组成一个Kafka集群</td>
</tr>
<tr>
<td align="left">Topic</td>
<td align="left">Kafka根据topic对消息进行归类，发布到Kafka集群的每条消息都需要指定一个topic</td>
</tr>
<tr>
<td align="left">Producer</td>
<td align="left">消息生产者，向Broker发送消息的客户端</td>
</tr>
<tr>
<td align="left">Consumer</td>
<td align="left">消息消费者，从Broker读取消息的客户端</td>
</tr>
<tr>
<td align="left">ConsumerGroup</td>
<td align="left">每个Consumer属于一个特定的Consumer Group，一条消息可以被多个不同的Consumer Group消费，但是一个Consumer Group中只能有一个Consumer能够消费该消息</td>
</tr>
<tr>
<td align="left">Partition</td>
<td align="left">物理上的概念，一个topic可以分为多个partition，每个partition内部消息是有序的</td>
</tr>
</tbody>
</table> 
<h3>
<a id="API_97"></a>基本使用（原生API）</h3> 
<h4>
<a id="1_99"></a>1、创建主题</h4> 
<p>【1】创建一个名字为“test”的Topic，这个topic只有一个partition，并且备份因子也设置为1：</p> 
<pre><code class="prism language-javascript">bin<span class="token operator">/</span>kafka<span class="token operator">-</span>topics<span class="token punctuation">.</span>sh <span class="token operator">--</span>create <span class="token operator">--</span>zookeeper <span class="token number">192.168</span><span class="token number">.65</span><span class="token number">.60</span><span class="token operator">:</span><span class="token number">2181</span> <span class="token operator">--</span>replication<span class="token operator">-</span>factor <span class="token number">1</span> <span class="token operator">--</span>partitions <span class="token number">1</span> <span class="token operator">--</span>topic test
</code></pre> 
<p>【2】通过以下命令来查看kafka中目前存在的topic</p> 
<pre><code class="prism language-javascript">bin<span class="token operator">/</span>kafka<span class="token operator">-</span>topics<span class="token punctuation">.</span>sh <span class="token operator">--</span>list <span class="token operator">--</span>zookeeper <span class="token number">192.168</span><span class="token number">.65</span><span class="token number">.60</span><span class="token operator">:</span><span class="token number">2181</span>
</code></pre> 
<p>【3】除了通过手工的方式创建Topic，当producer发布一个消息到某个指定的Topic，<strong>如果Topic不存在，就自动创建。所以如果发送错了Topic，那么就需要创建对应的消费者来消费掉发送错误的消息。</strong></p> 
<p>【4】删除主题</p> 
<pre><code class="prism language-javascript">bin<span class="token operator">/</span>kafka<span class="token operator">-</span>topics<span class="token punctuation">.</span>sh <span class="token operator">--</span><span class="token keyword">delete</span> <span class="token operator">--</span>topic test <span class="token operator">--</span>zookeeper <span class="token number">192.168</span><span class="token number">.65</span><span class="token number">.60</span><span class="token operator">:</span><span class="token number">2181</span>
</code></pre> 
<h4>
<a id="2_121"></a>2、发送消息</h4> 
<p>​ kafka自带了一个producer命令客户端，可以从本地文件中读取内容，也可以以命令行中直接输入内容，并将这些内容以消息的形式发送到kafka集群中。<strong>在默认情况下，每一个行会被当做成一个独立的消息。</strong></p> 
<p>​ 示例：运行发布消息的脚本，然后在命令中输入要发送的消息的内容：</p> 
<pre><code class="prism language-javascript"><span class="token comment">//指定往哪个broker（也就是服务器）上发消息</span>
bin<span class="token operator">/</span>kafka<span class="token operator">-</span>console<span class="token operator">-</span>producer<span class="token punctuation">.</span>sh <span class="token operator">--</span>broker<span class="token operator">-</span>list <span class="token number">192.168</span><span class="token number">.65</span><span class="token number">.60</span><span class="token operator">:</span><span class="token number">9092</span> <span class="token operator">--</span>topic test 
<span class="token operator">&gt;</span><span class="token keyword">this</span> is a msg
<span class="token operator">&gt;</span><span class="token keyword">this</span> is a another msg 
</code></pre> 
<h4>
<a id="3_134"></a>3、消费消息</h4> 
<p>​ 【1】对于consumer，kafka同样也携带了一个命令行客户端，会将获取到内容在命令中进行输出，默认是消费最新的消息：</p> 
<pre><code class="prism language-javascript">bin<span class="token operator">/</span>kafka<span class="token operator">-</span>console<span class="token operator">-</span>consumer<span class="token punctuation">.</span>sh <span class="token operator">--</span>bootstrap<span class="token operator">-</span>server <span class="token number">192.168</span><span class="token number">.65</span><span class="token number">.60</span><span class="token operator">:</span><span class="token number">9092</span> <span class="token operator">--</span>topic test   
</code></pre> 
<p>【2】想要消费之前的消息可以通过–from-beginning参数指定，如下命令：</p> 
<pre><code class="prism language-javascript"><span class="token comment">//这里便凸显了与传统消息中间件的不同，消费完，消息依旧保留（默认保留在磁盘一周）</span>
bin<span class="token operator">/</span>kafka<span class="token operator">-</span>console<span class="token operator">-</span>consumer<span class="token punctuation">.</span>sh <span class="token operator">--</span>bootstrap<span class="token operator">-</span>server <span class="token number">192.168</span><span class="token number">.65</span><span class="token number">.60</span><span class="token operator">:</span><span class="token number">9092</span> <span class="token operator">--</span>from<span class="token operator">-</span>beginning <span class="token operator">--</span>topic test
</code></pre> 
<p>【3】通过不同的终端窗口来运行以上的命令，你将会看到在producer终端输入的内容，很快就会在consumer的终端窗口上显示出来。</p> 
<p>【4】所有的命令都有一些附加的选项；当我们不携带任何参数运行命令的时候，将会显示出这个命令的详细用法</p> 
<pre><code class="prism language-javascript">执行bin<span class="token operator">/</span>kafka<span class="token operator">-</span>console<span class="token operator">-</span>consumer<span class="token punctuation">.</span>sh 命令显示所有的可选参数
</code></pre> 
<h4>
<a id="4_157"></a>4、消费消息类型分析</h4> 
<h5>
<a id="1_159"></a>1）单播消费</h5> 
<p><strong>单播消费是一条消息只能被一个消费组内的某一个消费者消费。</strong></p> 
<h5>
<a id="2_163"></a>2）多播消费</h5> 
<p><strong>多播消费是一条消息可以被不同组内的某一个消费者消费。</strong></p> 
<h3>
<a id="_167"></a>设计原理分析</h3> 
<h4>
<a id="KafkaController_169"></a>Kafka核心总控制器Controller</h4> 
<p>​ <strong>在Kafka集群中会有一个或者多个broker，其中有一个broker会被选举为控制器（Kafka Controller），它负责管理整个集群中所有分区和副本的状态。</strong></p> 
<p>​ 1）当某个分区的leader副本出现故障时，由控制器负责为该分区选举新的leader副本。</p> 
<p>​ 2）当检测到某个分区的ISR集合发生变化时，由控制器负责通知所有broker更新其元数据信息。</p> 
<p>​ 3）当使用kafka-topics.sh脚本为某个topic增加分区数量时，同样还是由控制器负责让新分区被其他节点感知到。</p> 
<h4>
<a id="Controller_179"></a>Controller选举机制</h4> 
<p>【1】<strong>在kafka集群启动的时候，会自动选举一台broker作为controller来管理整个集群，选举的过程是集群中每个broker都会尝试在zookeeper上创建一个 /controller 临时节点，zookeeper会保证有且仅有一个broker能创建成功，这个broker就会成为集群的总控器controller。</strong></p> 
<p>【2】当这个controller角色的broker宕机了，此时zookeeper临时节点会消失，集群里其他broker会一直监听这个临时节点，发现临时节点消失了，就竞争再次创建临时节点。</p> 
<p>【3】具备控制器身份的broker需要比其他普通的broker多一份职责，具体细节如下：</p> 
<blockquote> 
 <p>​ **1）监听broker相关的变化。**为Zookeeper中的/brokers/ids/节点添加BrokerChangeListener，用来处理broker增减的变化。</p> 
 <p>​ **2）监听topic相关的变化。**为Zookeeper中的/brokers/topics节点添加TopicChangeListener，用来处理topic增减的变化；为Zookeeper中的/admin/delete_topics节点添加TopicDeletionListener，用来处理删除topic的动作。<br> ​ **3）从Zookeeper中读取获取当前所有与topic、partition以及broker有关的信息并进行相应的管理。**对于所有topic所对应的Zookeeper中的/brokers/topics/[topic]节点添加PartitionModificationsListener，用来监听topic中的分区分配变化。<br> ​ <strong>4）更新集群的元数据信息，同步到其他普通的broker节点中。</strong></p> 
</blockquote> 
<h4>
<a id="PartitionLeader_193"></a>Partition副本选举Leader机制</h4> 
<p><strong>controller感知到分区leader所在的broker挂了(controller监听了很多zk节点可以感知到broker存活)，controller会从ISR列表(参数unclean.leader.election.enable=false的前提下)里挑第一个broker作为leader(第一个broker最先放进ISR列表，可能是同步数据最多的副本)【这种会阻塞直到ISR列表有数据】</strong>，</p> 
<p>​ 如果参数unclean.leader.election.enable为true，代表在ISR列表里所有副本都挂了的时候可以在ISR列表以外的副本中选leader，这种设置，可以提高可用性，但是选出的新leader有可能数据少很多。【其实就是知道/broker/ids/下面的数据没了】</p> 
<h5>
<a id="ISR_199"></a>副本进入ISR列表有两个条件：</h5> 
<p><strong>1）副本节点不能产生分区，必须能与zookeeper保持会话以及跟leader副本网络连通</strong></p> 
<p><strong>2）副本能复制leader上的所有写操作，并且不能落后太多。</strong>(与leader副本同步滞后的副本，是由 replica.lag.time.max.ms 配置决定的，超过这个时间都没有跟leader同步过的一次的副本会被移出ISR列表)</p> 
<h4>
<a id="offset_205"></a>消费者消费消息的offset记录机制</h4> 
<p><strong>每个consumer会定期将自己消费分区的offset提交给kafka内部topic：__consumer_offsets，提交过去的时候，key是consumerGroupId+topic+分区号，value就是当前offset的值，kafka会定期清理topic里的消息，最后就保留最新的那条数据。</strong>【相当于记录了这个消费组在这个topic的某分区上消费到了哪】</p> 
<p><strong>由于consumer_offsets可能会接收高并发的请求，kafka默认给其分配50个分区(可以通过offsets.topic.num.partitions设置)，这样可以通过加机器的方式抗大并发。</strong></p> 
<p>​ <strong>选出consumer消费的offset要提交到consumer_offsets的哪个分区公式：hash(consumerGroupId) % consumer_offsets主题的分区数</strong></p> 
<h4>
<a id="Rebalance_213"></a>消费者Rebalance机制（再平衡机制）</h4> 
<p>**rebalance就是指如果消费组里的消费者数量有变化或消费的分区数有变化，kafka会重新分配消费者消费分区的关系。**比如consumer group中某个消费者挂了，此时会自动把分配给他的分区交给其他的消费者，如果他又重启了，那么又会把一些分区重新交还给他。</p> 
<blockquote> 
 <p><strong>注意：</strong></p> 
 <p>​ 1）rebalance只针对subscribe这种不指定分区消费的情况，如果通过assign这种消费方式指定了分区，kafka不会进行rebanlance。</p> 
 <p>​ **2）rebalance过程中，消费者无法从kafka消费消息。**这对kafka的TPS会有影响，如果kafka集群内节点较多，比如数百个，那重平衡可能会耗时极多，所以应尽量避免在系统高峰期的重平衡发生。</p> 
 <p><strong>如下情况可能会触发消费者rebalance</strong></p> 
 <p>1.消费组里的consumer增加或减少了</p> 
 <p>2.动态给topic增加了分区</p> 
 <p>3.消费组订阅了更多的topic</p> 
</blockquote> 
<h4>
<a id="Rebalance_231"></a>消费者Rebalance分区分配策略：</h4> 
<p><strong>rebalance的策略：range、round-robin、sticky。</strong></p> 
<p><strong>Kafka 提供了消费者客户端参数partition.assignment.strategy 来设置消费者与订阅主题之间的分区分配策略。默认情况为range分配策略。</strong></p> 
<blockquote> 
 <p>假设一个主题有10个分区(0-9)，现在有三个consumer消费：</p> 
 <p><strong>1）range策略就是按照分区序号排序，比如分区0<sub>3给一个consumer，分区4</sub>6给一个consumer，分区7~9给一个consumer。</strong></p> 
 <p>​ 假设 n＝分区数／消费者数量 = 3， m＝分区数%消费者数量 = 1，那么前 m 个消费者每个分配 n+1 个分区，后面的（消费者数量－m ）个消费者每个分配 n 个分区。</p> 
 <p><strong>2）round-robin策略就是轮询分配</strong>，比如分区0、3、6、9给一个consumer，分区1、4、7给一个consumer，分区2、5、8给一个consumer。</p> 
 <p><strong>3）sticky策略初始时分配策略与round-robin类似，但是在rebalance的时候，需要保证如下两个原则。1）分区的分配要尽可能均匀 。2）分区的分配尽可能与上次分配的保持相同。</strong></p> 
</blockquote> 
<h4>
<a id="Rebalance_247"></a>Rebalance过程</h4> 
<p>​ 当有消费者加入消费组时，消费者、消费组及组协调器之间会经历以下几个阶段。</p> 
<p><strong>1）选择组协调器</strong></p> 
<p>​ consumer group中的每个consumer启动时会向kafka集群中的某个节点发送 FindCoordinatorRequest 请求来查找对应的组协调器GroupCoordinator，并跟其建立网络连接。</p> 
<p>​ <strong>组协调器GroupCoordinator</strong>：每个consumer group都会选择一个broker作为自己的组协调器coordinator，负责监控这个消费组里的所有消费者的心跳，以及判断是否宕机，然后开启消费者rebalance。</p> 
<p><strong>2）加入消费组JOIN GROUP</strong></p> 
<p>在成功找到消费组所对应的 GroupCoordinator 之后就进入加入消费组的阶段，在此阶段的消费者会向 GroupCoordinator 发送 JoinGroupRequest 请求，并处理响应。</p> 
<p>​ <strong>GroupCoordinator 从一个consumer group中选择第一个加入group的consumer作为leader(消费组协调器)，把consumer group情况发送给这个leader，接着这个leader会负责制定分区方案。</strong></p> 
<p>3）（ SYNC GROUP)</p> 
<p><strong>consumer leader通过给GroupCoordinator发送SyncGroupRequest，接着GroupCoordinator就把分区方案下发给各个consumer【心跳的时候】，他们会根据指定分区的leader broker进行网络连接以及消息消费。</strong></p> 
<h4>
<a id="producer_267"></a>producer发布消息机制剖析</h4> 
<p>producer 采用 push 模式将消息发布到 broker，每条消息都被 append 到 patition 中，属于顺序写磁盘（顺序写磁盘效率比随机写内存要高，保障 kafka 吞吐率）。存储分区会根据分区算法选择将其存储到哪一个 partition。</p> 
<h5>
<a id="_271"></a>路由机制为：</h5> 
<p>1）指定了 patition，则直接使用；</p> 
<p>2）未指定 patition 但指定 key，通过对 key 的 value 进行hash 选出一个 patition</p> 
<p>3）patition 和 key 都未指定，使用轮询选出一个 patition。</p> 
<h5>
<a id="_279"></a>写入流程</h5> 
<p>1）producer 先从 zookeeper 的 “/brokers/…/state” 节点找到该 partition 的 leader</p> 
<p>2）producer 将消息发送给该 leader</p> 
<p>3）leader 将消息写入本地 log</p> 
<p>4）followers 从 leader pull 消息，写入本地 log 后 向leader 发送 ACK</p> 
<p>5）leader 收到所有 ISR 中的 replica 的 ACK 后，增加 HW（high watermark，最后 commit 的 offset） 并向 producer 发送 ACK</p> 
<h3>
<a id="_295"></a>集群消费</h3> 
<p>​ partitions分布在kafka集群中不同的broker上，kafka集群支持配置partition备份的数量。针对每个partition，都有一个broker起到“leader”的作用，其他的broker作为“follwers”的作用。</p> 
<p>​ <strong>leader来负责处理所有关于这个partition的读写请求，而followers被动复制leader的结果，不提供读写(主要是为了保证多副本数据与消费的一致性)。如果这个leader失效了，其中的一个follower通过选举成为新的leader。</strong></p> 
<h4>
<a id="Producers_301"></a>Producers</h4> 
<p>生产者将消息发送到topic中去，同时负责选择将message发送到topic的哪一个partition中。通过round-robin做简单的负载均衡，也可以根据消息中的某一个关键字来进行区分。通常第二种方式使用的更多。</p> 
<h4>
<a id="Consumers_305"></a>Consumers</h4> 
<p>​ <strong>传统的消息传递模式有2种：队列( queue) 和（publish-subscribe）。Kafka基于这2种模式提供了一种consumer的抽象概念：consumer group。</strong></p> 
<p>​ 通常一个topic会有几个consumer group，每个consumer group都是一个逻辑上的订阅者（ logical subscriber ）。每个consumer group由多个consumer instance组成，从而达到可扩展和容灾的功能。</p> 
<h4>
<a id="_311"></a>其他</h4> 
<h5>
<a id="_313"></a>消息回溯消费的机制是怎么实现的？</h5> 
<p>因为kafka的消息存储在log文件里面，而且对应的还会有index与timeindex（可以加快对于消息的检索），根据设置给予的offset可以快速定位到是哪个log文件，因为文件名就是offset偏移值。快速拿出数据就可以进行消费了。此外根据时间回溯也是一样不过量会更大一点。</p> 
<h5>
<a id="topic_317"></a>如果新的消费组订阅已存在的topic，那么是重新开始消费么？</h5> 
<p>**默认是将当前topoc的最后offset传给消费组，作为其已消费的记录。**所以若是需要从头消费，则要设置为props.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, “earliest”)。这个消费组如果是已经存在的，那么这个参数其实不会变动已有的offset。默认处理大数据量的应该采用latest，业务场景则用earliest。</p> 
<h3>
<a id="_321"></a>日志分段存储</h3> 
<p>​ **Kafka 一个分区的消息数据对应存储在一个文件夹下，以topic名称+分区号命名，消息在分区内是分段(segment)存储，每个段的消息都存储在不一样的log文件里。**这种特性方便old segment file快速被删除，kafka规定了一个段位的 log 文件最大为 1G，做这个限制目的是为了方便把 log 文件加载到内存去操作。</p> 
<p>​ Kafka Broker 有一个参数，log.segment.bytes，限定了每个日志段文件的大小，最大就是 1GB。</p> 
<p>​ <strong>一个日志段文件满了，就自动开一个新的日志段文件来写入，避免单个文件过大，影响文件的读写性能，这个过程叫做 log rolling，正在被写入的那个日志段文件，叫做 active log segment。</strong></p> 
<h3>
<a id="_335"></a>总结</h3> 
<p>后续再次补充…</p>
                </div>
                
                

		</div>
	</article>
</main>




			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程小白.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://www.w3counter.com/tracker.js?id=150625"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>
	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>