<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<title>GCN-图卷积神经网络算法简单实现（含python代码） - 编程小白</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程小白" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程小白</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">GCN-图卷积神经网络算法简单实现（含python代码）</h1>
			
		</header>
		<div class="content post__content clearfix">
			


                <div id="content_views" class="htmledit_views">
                    <blockquote> 
 <p><strong>本文是就实现GCN算法模型进行的代码介绍，上一篇文章是GCN算法的原理和模型介绍。</strong></p> 
 <p>代码中用到的Cora数据集：</p> 
 <p>链接：<a class="link-info" href="https://pan.baidu.com/s/1SbqIOtysKqHKZ7C50DM_eA" title="https://pan.baidu.com/s/1SbqIOtysKqHKZ7C50DM_eA">https://pan.baidu.com/s/1SbqIOtysKqHKZ7C50DM_eA</a> <br> 提取码：pfny </p> 
</blockquote> 
<h3 id="main-toc"><strong>文章目录</strong></h3> 
<p id="%E7%9B%AE%E7%9A%84-toc" style="margin-left:0px"><a href="#%E7%9B%AE%E7%9A%84">目的</a></p> 
<p id="%E4%B8%80%E3%80%81%E6%95%B0%E6%8D%AE%E9%9B%86%E4%BB%8B%E7%BB%8D-toc" style="margin-left:0px"><a href="#%E4%B8%80%E3%80%81%E6%95%B0%E6%8D%AE%E9%9B%86%E4%BB%8B%E7%BB%8D">一、数据集介绍</a></p> 
<p id="%E4%BA%8C%E3%80%81%E5%AE%9E%E7%8E%B0%E8%BF%87%E7%A8%8B%E8%AE%B2%E8%A7%A3-toc" style="margin-left:0px"><a href="#%E4%BA%8C%E3%80%81%E5%AE%9E%E7%8E%B0%E8%BF%87%E7%A8%8B%E8%AE%B2%E8%A7%A3">二、实现过程讲解</a></p> 
<p id="%E4%B8%89%E3%80%81%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0%E5%92%8C%E7%BB%93%E6%9E%9C%E5%88%86%E6%9E%90-toc" style="margin-left:0px"><a href="#%E4%B8%89%E3%80%81%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0%E5%92%8C%E7%BB%93%E6%9E%9C%E5%88%86%E6%9E%90">三、代码实现和结果分析</a></p> 
<p id="1.%E5%AF%BC%E5%85%A5%E5%8C%85-toc" style="margin-left:40px"><a href="#1.%E5%AF%BC%E5%85%A5%E5%8C%85">1. 导入包</a></p> 
<p id="2.%E6%95%B0%E6%8D%AE%E5%87%86%E5%A4%87%C2%B6-toc" style="margin-left:40px"><a href="#2.%E6%95%B0%E6%8D%AE%E5%87%86%E5%A4%87%C2%B6">2. 数据准备¶</a></p> 
<p id="4.%C2%A0%E5%9B%BE%E5%8D%B7%E7%A7%AF%E5%B1%82%E5%AE%9A%E4%B9%89-toc" style="margin-left:40px"><a href="#4.%C2%A0%E5%9B%BE%E5%8D%B7%E7%A7%AF%E5%B1%82%E5%AE%9A%E4%B9%89">3. 图卷积层定义</a></p> 
<p id="5.%20GCN%E5%9B%BE%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E5%AE%9A%E4%B9%89-toc" style="margin-left:40px"><a href="#5.%20GCN%E5%9B%BE%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E5%AE%9A%E4%B9%89">4. GCN图卷积神经网络模型定义</a></p> 
<p id="6.%C2%A0%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83-toc" style="margin-left:40px"><a href="#6.%C2%A0%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83">5. 模型训练</a></p> 
<p id="6.1%20%E8%B6%85%E5%8F%82%E6%95%B0%E5%AE%9A%E4%B9%89%EF%BC%8C%E5%8C%85%E5%90%AB%E5%AD%A6%E4%B9%A0%E7%8E%87%E3%80%81%E6%AD%A3%E5%88%99%E5%8C%96%E7%B3%BB%E6%95%B0%E7%AD%89%E3%80%82-toc" style="margin-left:80px"><a href="#6.1%20%E8%B6%85%E5%8F%82%E6%95%B0%E5%AE%9A%E4%B9%89%EF%BC%8C%E5%8C%85%E5%90%AB%E5%AD%A6%E4%B9%A0%E7%8E%87%E3%80%81%E6%AD%A3%E5%88%99%E5%8C%96%E7%B3%BB%E6%95%B0%E7%AD%89%E3%80%82">5.1 超参数定义，包含学习率、正则化系数等。</a></p> 
<p id="6.2%20%E5%AE%9A%E4%B9%89%E6%A8%A1%E5%9E%8B%EF%BC%9A-toc" style="margin-left:80px"><a href="#6.2%20%E5%AE%9A%E4%B9%89%E6%A8%A1%E5%9E%8B%EF%BC%9A">5.2 定义模型：</a></p> 
<p id="6.3%20%E5%AE%9A%E4%B9%89%E8%AE%AD%E7%BB%83%E5%92%8C%E6%B5%8B%E8%AF%95%E5%87%BD%E6%95%B0%EF%BC%8C%E8%BF%9B%E8%A1%8C%E8%AE%AD%E7%BB%83-toc" style="margin-left:80px"><a href="#6.3%20%E5%AE%9A%E4%B9%89%E8%AE%AD%E7%BB%83%E5%92%8C%E6%B5%8B%E8%AF%95%E5%87%BD%E6%95%B0%EF%BC%8C%E8%BF%9B%E8%A1%8C%E8%AE%AD%E7%BB%83">5.3 定义训练和测试函数，进行训练</a></p> 
<p id="%C2%A07.%20%E5%8F%AF%E8%A7%86%E5%8C%96-toc" style="margin-left:40px"><a href="#%C2%A07.%20%E5%8F%AF%E8%A7%86%E5%8C%96">6. 可视化</a></p> 
<hr>
<h1 id="%E7%9B%AE%E7%9A%84">
<a id="_7"></a>目的</h1> 
<p>本次实验的目的是将论文分类，通过模型训练，利用已经分好类的训练集，将论文通过GCN算法分为7类。</p> 
<hr>
<h1 id="%E4%B8%80%E3%80%81%E6%95%B0%E6%8D%AE%E9%9B%86%E4%BB%8B%E7%BB%8D"><strong>一、数据集介绍</strong></h1> 
<p>数据集我选用的是GCN常用的Cora数据集，实验的目标就是通过对构造出来的两层GCN模型进行训练，实现对数据集样本节点的分类</p> 
<p>Cora数据集下载地址：<a href="https://linqs-data.soe.ucsc.edu/public/lbc/cora.tgz" title="https://linqs-data.soe.ucsc.edu/public/lbc/cora.tgz">https://linqs-data.soe.ucsc.edu/public/lbc/cora.tgz</a></p> 
<p>个人不建议用python的dgl包中的Cora数据，总是报错。</p> 
<p>Cora数据集由关于机器学习方面的论文组成。 这些论文分为以下七个类别之一：</p> 
<p>1.基于案例</p> 
<p>2.遗传算法</p> 
<p>3.神经网络</p> 
<p>4.概率方法</p> 
<p>5.强化学习</p> 
<p>6.规则学习</p> 
<p>7.理论</p> 
<p>这些论文都是经过筛选的，在最终的数据集中，每篇论文引用或被至少一篇其他论文引用。整个语料库中有2708篇论文。</p> 
<p>在词干堵塞和去除词尾后，只剩下1433个唯一的单词。文档频率小于10的所有单词都被删除。</p> 
<p><strong>即Cora数据集包含2708个顶点, 5429条边,每个顶点包含1433个特征，共有7个类别。</strong></p> 
<p>并且Cora已经把训练集和测试集的数据都划分好了，直接按照文件名读取数据即可，如</p> 
<p>文件ind.cora.x =&gt; 训练实例的特征向量；ind.cora.y =&gt; 训练实例的标签，独热编码</p> 
<p>ind.cora.tx =&gt; 测试实例的特征向量；ind.cora.ty =&gt; 测试实例的标签，独热编码</p> 
<p></p> 
<h1 id="%E4%BA%8C%E3%80%81%E5%AE%9E%E7%8E%B0%E8%BF%87%E7%A8%8B%E8%AE%B2%E8%A7%A3">
<a id="_19"></a>二、实现过程讲解</h1> 
<p>结合我最后做的代码实现，给大家先举一个引文网络的简单实例，方便大家了解处理过程。</p> 
<p>其中每个节点代表一篇研究论文，同时边代表的是引用关系。</p> 
<p>我们在这里有一个预处理步骤。在这里我们不使用原始论文作为特征，而是将论文转换成向量（通过使用NLP嵌入，例如tf-idf）。</p> 
<p>假设我们使用average()函数（实际上GCN内部的传递函数肯定不是平均值，这里只是方便理解）。我们将对所有的节点进行同样的获取特征向量的操作。最后，我们将这些计算得到的平均值输入到神经网络中。</p> 
<p style="text-align:center"><img alt="" src="https://images2.imgbox.com/ef/ab/MiDVlO7U_o.png"></p> 
<p>让我们考虑下绿色节点。首先，我们得到它的所有邻居的特征值，包括自身节点，接着取平均值。最后通过神经网络返回一个结果向量并将此作为最终结果。请注意，在GCN中，我们仅仅使用一个全连接层。在这个例子中，我们得到2维向量作为输出（全连接层的2个节点）。</p> 
<p>全连接网络的作用就是对上一层得到的向量做乘法，最终降低其维度，然后输入到softmax层中得到对应的每个类别的得分。</p> 
<p>在实际操作中，我们肯定是使用比average函数更复杂的聚合函数，也就是上面讲的那个传播函数。</p> 
<p>我们还可以将更多的层叠加在一起，以获得更深的GCN。其中每一层的输出会被视为下一层的输入。</p> 
<p></p> 
<p>2层GCN的例子：第一层的输出是第二层的输入。</p> 
<p style="text-align:center"><img alt="" height="403" src="https://images2.imgbox.com/86/ce/zttnOYDc_o.png" width="540"></p> 
<p>那么两层的GCN就可以在降维的同时，通过层间传播的公式获取到二阶邻居节点的特征：</p> 
<p style="text-align:center"><img alt="" height="383" src="https://images2.imgbox.com/2b/11/4OxNkrsM_o.jpg" width="594"></p> 
<p> 在节点分类问题中，实际上在输入的邻接矩阵和每个节点的特征中，既包含了节点间的联系情况，也包含了节点自身的特征。</p> 
<p>通过GCN的卷积层就可以实现降维，想要聚成几类就降成几维。</p> 
<p></p> 
<h1 id="%E4%B8%89%E3%80%81%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0%E5%92%8C%E7%BB%93%E6%9E%9C%E5%88%86%E6%9E%90">
<a id="2_34"></a>三、代码实现和结果分析</h1> 
<h2 id="1.%E5%AF%BC%E5%85%A5%E5%8C%85"><strong>1. 导入包</strong></h2> 
<pre><code class="language-python">import itertools
import os
import os.path as osp
import pickle
import urllib
from collections import namedtuple
import warnings
warnings.filterwarnings("ignore")
import numpy as np
import scipy.sparse as sp
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.nn.init as init
import torch.optim as optim
import matplotlib.pyplot as plt
%matplotlib inline</code></pre> 
<p></p> 
<h2 id="2.%E6%95%B0%E6%8D%AE%E5%87%86%E5%A4%87%C2%B6"><strong>2. 数据准备<a href="http://localhost:8888/notebooks/Desktop/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/32019070205%20%E5%88%98%E9%80%B8%E5%87%A1%20GCN%E7%AE%97%E6%B3%95%E8%AE%B2%E8%A7%A3/32019070205%20%E5%88%98%E9%80%B8%E5%87%A1%20GCN%E7%AE%97%E6%B3%95%E8%AE%B2%E8%A7%A3.ipynb#%E6%95%B0%E6%8D%AE%E5%87%86%E5%A4%87" title="¶">¶</a></strong></h2> 
<pre><code class="language-python">Data = namedtuple('Data', ['x', 'y', 'adjacency',
                           'train_mask', 'val_mask', 'test_mask'])


def tensor_from_numpy(x, device):
    return torch.from_numpy(x).to(device)


class CoraData(object):
    filenames = ["ind.cora.{}".format(name) for name in
                 ['x', 'tx', 'allx', 'y', 'ty', 'ally', 'graph', 'test.index']]

    def __init__(self, data_root="./data", rebuild=False):
        """Cora数据，包括数据下载，处理，加载等功能
        当数据的缓存文件存在时，将使用缓存文件，否则将下载、进行处理，并缓存到磁盘

        处理之后的数据可以通过属性 .data 获得，它将返回一个数据对象，包括如下几部分：
            * x: 节点的特征，维度为 2708 * 1433，类型为 np.ndarray
            * y: 节点的标签，总共包括7个类别，类型为 np.ndarray
            * adjacency: 邻接矩阵，维度为 2708 * 2708，类型为 scipy.sparse.coo.coo_matrix
            * train_mask: 训练集掩码向量，维度为 2708，当节点属于训练集时，相应位置为True，否则False
            * val_mask: 验证集掩码向量，维度为 2708，当节点属于验证集时，相应位置为True，否则False
            * test_mask: 测试集掩码向量，维度为 2708，当节点属于测试集时，相应位置为True，否则False

        Args:
        -------
            data_root: string, optional
                存放数据的目录，原始数据路径: ../data/cora
                缓存数据路径: {data_root}/ch5_cached.pkl
            rebuild: boolean, optional
                是否需要重新构建数据集，当设为True时，如果存在缓存数据也会重建数据

        """
        self.data_root = data_root #数据存放的路径
        save_file = osp.join(self.data_root, "ch5_cached.pkl")
        if osp.exists(save_file) and not rebuild:
            print("Using Cached file: {}".format(save_file))
            self._data = pickle.load(open(save_file, "rb"))
        else:
            self._data = self.process_data()
            with open(save_file, "wb") as f:
                pickle.dump(self.data, f)
            print("Cached file: {}".format(save_file))
    
    @property
    def data(self):
        """返回Data数据对象，包括x, y, adjacency, train_mask, val_mask, test_mask"""
        return self._data

    def process_data(self):
        """
        处理数据，得到节点特征和标签，邻接矩阵，训练集、验证集以及测试集
        引用自：https://github.com/rusty1s/pytorch_geometric
        """
        print("Process data ...")
        _, tx, allx, y, ty, ally, graph, test_index = [self.read_data(
            osp.join(self.data_root, name)) for name in self.filenames]
        train_index = np.arange(y.shape[0])
        val_index = np.arange(y.shape[0], y.shape[0] + 500)
        sorted_test_index = sorted(test_index)

        x = np.concatenate((allx, tx), axis=0)                #节点特征
        y = np.concatenate((ally, ty), axis=0).argmax(axis=1) #标签

        x[test_index] = x[sorted_test_index]
        y[test_index] = y[sorted_test_index]
        num_nodes = x.shape[0]

        train_mask = np.zeros(num_nodes, dtype=np.bool) #训练集
        val_mask = np.zeros(num_nodes, dtype=np.bool)   #验证集
        test_mask = np.zeros(num_nodes, dtype=np.bool)  #测试集
        train_mask[train_index] = True
        val_mask[val_index] = True
        test_mask[test_index] = True
        
        
        """"构建邻接矩阵"""
        adjacency = self.build_adjacency(graph)
        print("Node's feature shape: ", x.shape)
        print("Node's label shape: ", y.shape)
        print("Adjacency's shape: ", adjacency.shape)
        print("Number of training nodes: ", train_mask.sum())
        print("Number of validation nodes: ", val_mask.sum())
        print("Number of test nodes: ", test_mask.sum())

        return Data(x=x, y=y, adjacency=adjacency,
                    train_mask=train_mask, val_mask=val_mask, test_mask=test_mask)

    @staticmethod
    def build_adjacency(adj_dict):
        """根据邻接表创建邻接矩阵"""
        edge_index = []
        num_nodes = len(adj_dict)
        for src, dst in adj_dict.items():
            edge_index.extend([src, v] for v in dst)
            edge_index.extend([v, src] for v in dst)
        # 去除重复的边
        edge_index = list(k for k, _ in itertools.groupby(sorted(edge_index)))
        edge_index = np.asarray(edge_index)
        adjacency = sp.coo_matrix((np.ones(len(edge_index)), 
                                   (edge_index[:, 0], edge_index[:, 1])),
                    shape=(num_nodes, num_nodes), dtype="float32")
        return adjacency

    @staticmethod
    def read_data(path):
        """使用不同的方式读取原始数据以进一步处理"""
        name = osp.basename(path)
        if name == "ind.cora.test.index":
            out = np.genfromtxt(path, dtype="int64")
            return out
        else:
            out = pickle.load(open(path, "rb"), encoding="latin1")
            out = out.toarray() if hasattr(out, "toarray") else out
            return out

    @staticmethod
    def normalization(adjacency):
        """计算 H=D^-0.5 * (A+I) * D^-0.5"""
        adjacency += sp.eye(adjacency.shape[0])    # 增加自连接
        degree = np.array(adjacency.sum(1))
        d_hat = sp.diags(np.power(degree, -0.5).flatten())
        return d_hat.dot(adjacency).dot(d_hat).tocoo()</code></pre> 
<p></p> 
<h2 id="4.%C2%A0%E5%9B%BE%E5%8D%B7%E7%A7%AF%E5%B1%82%E5%AE%9A%E4%B9%89">3. 图卷积层定义</h2> 
<pre><code class="language-python">class GraphConvolution(nn.Module):
    def __init__(self, input_dim, output_dim, use_bias=True):
        """图卷积：H*X*theta

        Args:
        ----------
            input_dim: int
                节点输入特征的维度
            output_dim: int
                输出特征维度
            use_bias : bool, optional
                是否使用偏置
        """
        super(GraphConvolution, self).__init__()
        self.input_dim = input_dim
        self.output_dim = output_dim
        self.use_bias = use_bias
        self.weight = nn.Parameter(torch.Tensor(input_dim, output_dim))
        if self.use_bias:
            self.bias = nn.Parameter(torch.Tensor(output_dim))
        else:
            self.register_parameter('bias', None)
        self.reset_parameters() #初始化w

    def reset_parameters(self):
        init.kaiming_uniform_(self.weight) 
        #init.kaiming_uniform_神经网络权重初始化，神经网络要优化一个非常复杂的非线性模型，而且基本没有全局最优解，
        #初始化在其中扮演着非常重要的作用，尤其在没有BN等技术的早期，它直接影响模型能否收敛。
        
        if self.use_bias:
            init.zeros_(self.bias)

    def forward(self, adjacency, input_feature):
        """邻接矩阵是稀疏矩阵，因此在计算时使用稀疏矩阵乘法
    
        Args: 
        -------
            adjacency: torch.sparse.FloatTensor
                邻接矩阵
            input_feature: torch.Tensor
                输入特征
        """
        support = torch.mm(input_feature, self.weight)
        output = torch.sparse.mm(adjacency, support)
        if self.use_bias:
            output += self.bias
        return output

    def __repr__(self):
        return self.__class__.__name__ + ' (' 
            + str(self.input_dim) + ' -&gt; ' 
            + str(self.output_dim) + ')'</code></pre> 
<p></p> 
<h2 id="5.%20GCN%E5%9B%BE%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E5%AE%9A%E4%B9%89">4. GCN图卷积神经网络模型定义</h2> 
<p>有了数据和GCN层，就可以构建模型进行训练了。<br> 定义一个两层的GCN，其中输入的维度为1433，隐藏层维度设为16，最后一层GCN将输出维度变为类别数7，激活函数使用的是ReLU。</p> 
<pre><code class="language-python">class GcnNet(nn.Module):
    """
    定义一个包含两层GraphConvolution的模型
    """
    def __init__(self, input_dim=1433):
        super(GcnNet, self).__init__()
        self.gcn1 = GraphConvolution(input_dim, 16)
        self.gcn2 = GraphConvolution(16, 7)
    
    def forward(self, adjacency, feature):
        h = F.relu(self.gcn1(adjacency, feature))
        logits = self.gcn2(adjacency, h)
        return logits</code></pre> 
<p> </p> 
<h2 id="6.%C2%A0%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83">5. 模型训练</h2> 
<h3 id="6.1%20%E8%B6%85%E5%8F%82%E6%95%B0%E5%AE%9A%E4%B9%89%EF%BC%8C%E5%8C%85%E5%90%AB%E5%AD%A6%E4%B9%A0%E7%8E%87%E3%80%81%E6%AD%A3%E5%88%99%E5%8C%96%E7%B3%BB%E6%95%B0%E7%AD%89%E3%80%82">5.1 超参数定义，包含学习率、正则化系数等。</h3> 
<pre><code class="language-python">LEARNING_RATE = 0.1 #学习率 学习率过小→ →→收敛过慢，学习率过大→ →→错过局部最优；
WEIGHT_DACAY = 5e-4 #正则化系数 weight_dacay，解决过拟合问题
EPOCHS = 200        #完整遍历训练集的次数
DEVICE = "cuda" if torch.cuda.is_available() else "cpu" #指定设备，如果当前显卡忙于其他工作，可以设置为 DEVICE = "cpu"，使用cpu运行
</code></pre> 
<p>为什么要训练200轮呢，因为我们最开始是不知道边的权重的，需要通过模型训练出来合适的权重，也就是公式中的W。</p> 
<pre><code class="language-python"># 加载数据，并转换为torch.Tensor
dataset = CoraData().data
node_feature = dataset.x / dataset.x.sum(1, keepdims=True)  # 归一化数据，使得每一行和为1
tensor_x = tensor_from_numpy(node_feature, DEVICE)
tensor_y = tensor_from_numpy(dataset.y, DEVICE)
tensor_train_mask = tensor_from_numpy(dataset.train_mask, DEVICE)
tensor_val_mask = tensor_from_numpy(dataset.val_mask, DEVICE)
tensor_test_mask = tensor_from_numpy(dataset.test_mask, DEVICE)
normalize_adjacency = CoraData.normalization(dataset.adjacency)   # 规范化邻接矩阵

num_nodes, input_dim = node_feature.shape
indices = torch.from_numpy(np.asarray([normalize_adjacency.row, 
                                       normalize_adjacency.col]).astype('int64')).long()
values = torch.from_numpy(normalize_adjacency.data.astype(np.float32))
tensor_adjacency = torch.sparse.FloatTensor(indices, values, 
                                            (num_nodes, num_nodes)).to(DEVICE)
</code></pre> 
<p></p> 
<h3 id="6.2%20%E5%AE%9A%E4%B9%89%E6%A8%A1%E5%9E%8B%EF%BC%9A"><strong>5.2 定义模型：</strong></h3> 
<pre><code class="language-python"># 模型定义：Model, Loss, Optimizer
model = GcnNet(input_dim).to(DEVICE)
criterion = nn.CrossEntropyLoss().to(DEVICE) #nn.CrossEntropyLoss()函数计算交叉熵损失
optimizer = optim.Adam(model.parameters(), 
                       lr=LEARNING_RATE, 
                       weight_decay=WEIGHT_DACAY)</code></pre> 
<p>其中在定义模型时，还顺手定义了criterion，即在训练过程中可以用nn.CrossEntropyLoss()函数计算交叉熵损失：</p> 
<p><img alt="" height="73" src="https://images2.imgbox.com/03/66/WYONEmRn_o.png" width="673"></p> 
<p> </p> 
<h3 id="6.3%20%E5%AE%9A%E4%B9%89%E8%AE%AD%E7%BB%83%E5%92%8C%E6%B5%8B%E8%AF%95%E5%87%BD%E6%95%B0%EF%BC%8C%E8%BF%9B%E8%A1%8C%E8%AE%AD%E7%BB%83"><strong>5.3 定义训练和测试函数，进行训练</strong></h3> 
<pre><code class="language-python"># 训练主体函数
def train():
    loss_history = []
    val_acc_history = []
    model.train()
    train_y = tensor_y[tensor_train_mask]
    
    for epoch in range(EPOCHS):
        # 共进行200次训练
        logits = model(tensor_adjacency, tensor_x)  # 前向传播
        #其中logits是模型输出，tensor_adjacency, tensor_x分别是邻接矩阵和节点特征。
        
        train_mask_logits = logits[tensor_train_mask]   # 只选择训练节点进行监督
        loss = criterion(train_mask_logits, train_y)    # 计算损失值，目的是优化模型，获得更科学的权重W
        optimizer.zero_grad()
        loss.backward()     # 反向传播计算参数的梯度
        optimizer.step()    # 使用优化方法进行梯度更新
        train_acc, _, _ = test(tensor_train_mask)     # 计算当前模型训练集上的准确率
        val_acc, _, _ = test(tensor_val_mask)     # 计算当前模型在验证集上的准确率
        
        # 记录训练过程中损失值和准确率的变化，用于画图
        loss_history.append(loss.item())
        val_acc_history.append(val_acc.item())
        print("Epoch {:03d}: Loss {:.4f}, TrainAcc {:.4}, ValAcc {:.4f}".format(
            epoch, loss.item(), train_acc.item(), val_acc.item()))
    
    return loss_history, val_acc_history


# 测试函数
def test(mask):
    model.eval()  # 表示将模型转变为evaluation（测试）模式，这样就可以排除BN和Dropout对测试的干扰
    
    with torch.no_grad():  # 显著减少显存占用
        logits = model(tensor_adjacency, tensor_x) #(N,16)-&gt;(N,7) N节点数
        test_mask_logits = logits[mask]  # 矩阵形状和mask一样
        
        predict_y = test_mask_logits.max(1)[1]  # 返回每一行的最大值中索引（返回最大元素在各行的列索引）
        accuarcy = torch.eq(predict_y, tensor_y[mask]).float().mean()
    return accuarcy, test_mask_logits.cpu().numpy(), tensor_y[mask].cpu().numpy()</code></pre> 
<p> </p> 
<p><strong>使用上述代码进行模型训练，可以看到如下代码所示的日志输出:</strong></p> 
<pre><code class="language-python">loss, val_acc = train()
test_acc, test_logits, test_label = test(tensor_test_mask)
print("Test accuarcy: ", test_acc.item())#item()返回的是一个浮点型数据，测试集准确率
</code></pre> 
<p> <img alt="" height="308" src="https://images2.imgbox.com/fe/dd/39oSzDfx_o.png" width="290"><img alt="" height="312" src="https://images2.imgbox.com/de/79/UNLqE923_o.png" width="273"></p> 
<p><strong>其中Epoch为训练轮数；loss是损失值；TrainAcc训练集准确率；ValAcc测试集上的准确率；</strong></p> 
<p> </p> 
<h2 id="%C2%A07.%20%E5%8F%AF%E8%A7%86%E5%8C%96">6. 可视化</h2> 
<p><strong>将损失值和验证集准确率的变化趋势可视化：</strong></p> 
<p>损失函数用来测度模型的输出值和真实因变量值之间的差异</p> 
<pre><code class="language-python">def plot_loss_with_acc(loss_history, val_acc_history):
    fig = plt.figure()
    # 坐标系ax1画曲线1
    ax1 = fig.add_subplot(111)  # 指的是将plot界面分成1行1列，此子图占据从左到右从上到下的1位置
    ax1.plot(range(len(loss_history)), loss_history,
             c=np.array([255, 71, 90]) / 255.)  # c为颜色
    plt.ylabel('Loss')
    
    # 坐标系ax2画曲线2
    ax2 = fig.add_subplot(111, sharex=ax1, frameon=False)  # 其本质就是添加坐标系，设置共享ax1的x轴，ax2背景透明
    ax2.plot(range(len(val_acc_history)), val_acc_history,
             c=np.array([79, 179, 255]) / 255.)
    ax2.yaxis.tick_right()  # 开启右边的y坐标
    
    ax2.yaxis.set_label_position("right")
    plt.ylabel('ValAcc')
    
    plt.xlabel('Epoch')
    plt.title('Training Loss &amp; Validation Accuracy')
    plt.show()

plot_loss_with_acc(loss, val_acc)</code></pre> 
<p> <img alt="" height="316" src="https://images2.imgbox.com/1e/85/CmDJFyQ6_o.png" width="495"></p> 
<p><strong>可以看到红线代表的损失值随着训练次数的增加越来越小，蓝线代表的模型准确率越来越高。</strong></p> 
<p>将最后一层得到的输出进行TSNE降维，（TSNE）t分布随机邻域嵌入 是一种用于探索高维数据的非线性降维算法。</p> 
<p>它将多维数据映射到适合于人类观察的两个或多个维度。</p> 
<p>得到如下图所示的分类结果：</p> 
<p style="text-align:center"><img alt="" src="https://images2.imgbox.com/91/f0/sn4PH8p5_o.png"></p> 
<p><strong>绘制测试数据的TSNE降维图：</strong></p> 
<pre><code class="language-python">from sklearn.manifold import TSNE
tsne = TSNE()
out = tsne.fit_transform(test_logits)
fig = plt.figure()
for i in range(7):
    indices = test_label == i
    x, y = out[indices].T
    plt.scatter(x, y, label=str(i))
plt.legend()</code></pre> 
<p> <img alt="" height="292" src="https://images2.imgbox.com/ff/be/wtKRn7n8_o.png" width="437"></p> 
<p>根据上述结果：我们通过图卷积神经网络算法，可以成功将论文集划分为较为鲜明的7类，这与论文集原本的种类划分基本一致，效果还是较为可观的。</p>
                </div>

		</div>
	</article>
</main>




			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程小白.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://www.w3counter.com/tracker.js?id=150625"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>
	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>