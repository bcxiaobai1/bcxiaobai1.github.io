<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<title>Pytorch速成教程 - 编程小白</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程小白" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程小白</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Pytorch速成教程</h1>
			
		</header>
		<div class="content post__content clearfix">
			


                <div id="content_views" class="htmledit_views">
                    <p id="main-toc"><strong>目录</strong></p> 
<p id="-toc" style="margin-left:0px"></p> 
<p id="0%20%E7%AE%80%E4%BB%8B-toc" style="margin-left:0px"><a href="#0%20%E7%AE%80%E4%BB%8B">0 简介</a></p> 
<p id="1%20%E5%BC%A0%E9%87%8F%E7%9A%84%E6%A6%82%E5%BF%B5%E5%92%8C%E7%94%9F%E6%88%90-toc" style="margin-left:0px"><a href="#1%20%E5%BC%A0%E9%87%8F%E7%9A%84%E6%A6%82%E5%BF%B5%E5%92%8C%E7%94%9F%E6%88%90">1 张量的概念和生成</a></p> 
<p id="2%20%E8%87%AA%E5%8A%A8%E5%BE%AE%E5%88%86-toc" style="margin-left:0px"><a href="#2%20%E8%87%AA%E5%8A%A8%E5%BE%AE%E5%88%86">2 自动微分</a></p> 
<p id="2.1%20Tensor%E7%B1%BB-toc" style="margin-left:40px"><a href="#2.1%20Tensor%E7%B1%BB">2.1 Tensor类</a></p> 
<p id="2.2%20%E6%A2%AF%E5%BA%A6-toc" style="margin-left:40px"><a href="#2.2%20%E6%A2%AF%E5%BA%A6">2.2 梯度</a></p> 
<p id="3%20%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-toc" style="margin-left:0px"><a href="#3%20%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C">3 神经网络</a></p> 
<p id="%C2%A03.1%20%E5%AE%9A%E4%B9%89%E7%BD%91%E7%BB%9C-toc" style="margin-left:40px"><a href="#%C2%A03.1%20%E5%AE%9A%E4%B9%89%E7%BD%91%E7%BB%9C"> 3.1 定义网络</a></p> 
<p id="3.2%20%E6%9F%A5%E7%9C%8B%E6%A8%A1%E5%9E%8B%E5%8F%82%E6%95%B0-toc" style="margin-left:40px"><a href="#3.2%20%E6%9F%A5%E7%9C%8B%E6%A8%A1%E5%9E%8B%E5%8F%82%E6%95%B0">3.2 查看模型参数</a></p> 
<p id="3.3%20%E6%B5%8B%E8%AF%95%E7%BD%91%E7%BB%9C-toc" style="margin-left:40px"><a href="#3.3%20%E6%B5%8B%E8%AF%95%E7%BD%91%E7%BB%9C">3.3 测试网络</a></p> 
<p id="3.4%20%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E6%9B%B4%E6%96%B0%E6%9D%83%E9%87%8D-toc" style="margin-left:40px"><a href="#3.4%20%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E6%9B%B4%E6%96%B0%E6%9D%83%E9%87%8D">3.4 损失函数更新权重</a></p> 
<p id="4%20%E8%AE%AD%E7%BB%83%E5%88%86%E7%B1%BB%E5%99%A8-toc" style="margin-left:0px"><a href="#4%20%E8%AE%AD%E7%BB%83%E5%88%86%E7%B1%BB%E5%99%A8">4 训练分类器</a></p> 
<p id="4.1%20%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E7%94%9F%E6%88%90Dataload-toc" style="margin-left:40px"><a href="#4.1%20%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E7%94%9F%E6%88%90Dataload">4.1 数据处理生成Dataload</a></p> 
<p id="4.2%20%E5%AE%9A%E4%B9%89%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C-toc" style="margin-left:40px"><a href="#4.2%20%E5%AE%9A%E4%B9%89%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C">4.2 定义卷积网络</a></p> 
<p id="4.3%20%E5%AE%9A%E4%B9%89%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0-toc" style="margin-left:40px"><a href="#4.3%20%E5%AE%9A%E4%B9%89%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0">4.3 定义损失函数</a></p> 
<p id="4.4%20%E9%81%8D%E5%8E%86DataLoader%E8%BF%9B%E8%A1%8C%E8%AE%AD%E7%BB%83-toc" style="margin-left:40px"><a href="#4.4%20%E9%81%8D%E5%8E%86DataLoader%E8%BF%9B%E8%A1%8C%E8%AE%AD%E7%BB%83">4.4 遍历DataLoader进行训练</a></p> 
<p id="4.5%20%E6%B5%8B%E8%AF%95-toc" style="margin-left:40px"><a href="#4.5%20%E6%B5%8B%E8%AF%95">4.5 测试</a></p> 
<p id="5%20GPU%E8%AE%AD%E7%BB%83-toc" style="margin-left:0px"><a href="#5%20GPU%E8%AE%AD%E7%BB%83">5 GPU训练</a></p> 
<hr id="hr-toc">
<h1 id="0%20%E7%AE%80%E4%BB%8B">0 简介</h1> 
<p>跟numpy功能一样，但可以GPU加速，和numpy可以相互转化。</p> 
<h1 id="1%20%E5%BC%A0%E9%87%8F%E7%9A%84%E6%A6%82%E5%BF%B5%E5%92%8C%E7%94%9F%E6%88%90">1 张量的概念和生成</h1> 
<p>张量是torch里的多维数组，和numpy中的ndarrays相似</p> 
<p>生成张量的方法：</p> 
<ul><li>空张量</li></ul>
<pre><code class="hljs"># 这个是用来生成一个为未初始化的5*3的张量，切记不是全零
x = torch.empty(5, 3</code></pre> 
<ul><li>随机化0-1张量</li></ul>
<pre><code class="hljs"># 这个是生成一个均匀分布的初始化的，每个元素从0~1的张量，与第一个要区别开，另外，还有其它的随机张量生成函数，如torch.randn()、torch.normal()、torch.linespace()，分别是标准正态分布，离散正态分布，线性间距向量
x = torch.rand(5, 3)</code></pre> 
<ul><li>全0张量</li></ul>
<pre><code class="hljs"># 这个是初始化一个全零张量，可以指定每个元素的类型。
x = torch.zeros(5, 3, dtype=torch.long)</code></pre> 
<ul><li>已有矩阵转化为张量</li></ul>
<pre><code class="hljs">x = torch.tensor([5.5, 3])</code></pre> 
<ul><li>size函数来看它的shape</li></ul>
<pre><code class="hljs">print(x.size())</code></pre> 
<ul><li>张量加法</li></ul>
<pre><code class="hljs">print(torch.add(x, y))</code></pre> 
<ul><li>张量的大小</li></ul>
<pre><code class="hljs">print(x.item())</code></pre> 
<ul><li>torch转numpy</li></ul>
<p>在使用Cpu的情况下，张量和array将共享他们的物理位置，改变其中一个的值，另一个也会随之变化。</p> 
<pre><code class="hljs">a = torch.ones(5)
b = a.numpy()</code></pre> 
<ul><li>numpy转torch</li></ul>
<pre><code class="hljs">a = np.ones(5)
b = torch.from_numpy(a)</code></pre> 
<ul><li>GPU下转化</li></ul>
<pre><code class="hljs">if torch.cuda.is_available():
    device = torch.device("cuda")          # a CUDA device object
    y = torch.ones_like(x, device=device)  # directly create a tensor on GPU
    x = x.to(device)                       # or just use strings ``.to("cuda")``
    z = x + y
</code></pre> 
<h1 id="2%20%E8%87%AA%E5%8A%A8%E5%BE%AE%E5%88%86">2 自动微分</h1> 
<p>在pytorch中，<a href="https://so.csdn.net/so/search?q=%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C&amp;spm=1001.2101.3001.7020" title="神经网络">神经网络</a>的核心是自动微分</p> 
<h2 id="2.1%20Tensor%E7%B1%BB">2.1 Tensor类</h2> 
<p>orch.Tensor 是这个包的核心类。如果它的属性requires_grad是True，那么PyTorch就会追踪所有与之相关的operation。当完成(正向)计算之后， 我们可以调用backward()，PyTorch会自动的把所有的梯度都计算好。与这个tensor相关的梯度都会累加到它的grad属性里。</p> 
<p>如果不想计算这个tensor的梯度，我们可以调用detach()，这样它就不会参与梯度的计算了。为了阻止PyTorch记录用于梯度计算相关的信息(从而节约内存)，我们可以使用 with torch.no_grad()。这在模型的预测时非常有用，因为预测的时候我们不需要计算梯度，否则我们就得一个个的修改Tensor的requires_grad属性，这会非常麻烦。</p> 
<p>关于autograd的实现还有一个很重要的Function类。Tensor和Function相互连接从而形成一个有向无环图, 这个图记录了计算的完整历史。每个tensor有一个grad_fn属性来引用创建这个tensor的Function(用户直接创建的Tensor，这些Tensor的grad_fn是None)。</p> 
<p>如果你想计算梯度，可以对一个Tensor调用它的backward()方法。如果这个Tensor是一个scalar(只有一个数)，那么调用时不需要传任何参数。如果Tensor多于一个数，那么需要传入和它的shape一样的参数，表示反向传播过来的梯度。</p> 
<p>创建tensor时设置属性requires_grad=True，PyTorch就会记录用于反向梯度计算的信息：</p> 
<pre><code class="language-python">    x = torch.ones(2, 2, requires_grad=True)
    print(x)</code></pre> 
<p>然后我们通过operation产生新的tensor：</p> 
<pre><code class="language-python">y = x + 2
print(y)</code></pre> 
<p>是通过operation产生的tensor，因此它的grad_fn不是None。</p> 
<pre><code class="language-python">    print(y.grad_fn)
    # &lt;AddBackward0 object at 0x7f35409a68d0&gt;</code></pre> 
<p>再通过y得到z和out </p> 
<pre><code class="language-python">    z = y * y * 3
    out = z.mean()
     
    print(z, out)
    # z = tensor([[ 27.,  27.],[ 27.,  27.]]) 
    # out = tensor(27.)</code></pre> 
<p>requires_grad_()函数会修改一个Tensor的requires_grad。</p> 
<pre><code class="language-python">a = torch.randn(2, 2)
a = ((a * 3) / (a - 1))
print(a.requires_grad)
a.requires_grad_(True)
print(a.requires_grad)
b = (a * a).sum()
print(b.grad_fn)
输出：
    False
    True
    &lt;SumBackward0 object at 0x7f35766827f0&gt;</code></pre> 
<h2 id="2.2%20%E6%A2%AF%E5%BA%A6">2.2 梯度</h2> 
<p>现在我们里反向计算梯度。因为out是一个scalar，因此out.backward()等价于out.backward(torch.tensor(1))。</p> 
<pre><code class="language-python">v = torch.tensor([0.1, 1.0, 0.0001], dtype=torch.float)
y.backward(v)

print(x.grad) #数量的梯度，即各个方向的导数的集合
"""
tensor([1.0240e+02, 1.0240e+03, 1.0240e-01])
"""
#停止计算微分
print(x.requires_grad)
print((x ** 2).requires_grad)

with torch.no_grad():
   print((x ** 2).requires_grad)
"""
True
True
False
"""</code></pre> 
<h1 id="3%20%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C">3 神经网络</h1> 
<p><strong>神经网络定义过程</strong></p> 
<ul>
<li>定义神经网络及其参数；</li>
<li>在数据集上多次迭代循环；</li>
<li>通过神经网络处理数据集；</li>
<li>计算损失（输出和正确的结果之间相差的距离）；</li>
<li>用梯度对参数反向影响；</li>
<li>更新神经网络的权重，weight = weight - rate * gradient；</li>
</ul>
<p><img alt="" height="209" src="https://images2.imgbox.com/2a/bd/NecVzMH8_o.png" width="759"></p> 
<h2 id="%C2%A03.1%20%E5%AE%9A%E4%B9%89%E7%BD%91%E7%BB%9C"> 3.1 定义网络</h2> 
<pre><code class="language-python">import torch
import torch.nn as nn
import torch.nn.functional as F


# 汉字均为我个人理解，英文为原文标注。
class Net(nn.Module):

 #1、初始化定义  
  def __init__(self):
        # 继承原有模型
        super(Net, self).__init__()
        # 1 input image channel, 6 output channels, 5x5 square convolution
        # kernel
        # 定义了两个卷积层
        # 第一层是输入1维的（说明是单通道，灰色的图片）图片，输出6维的的卷积层（说明用到了6个卷积核，而每个卷积核是5*5的）。
        self.conv1 = nn.Conv2d(1, 6, 5)
        # 第一层是输入1维的（说明是单通道，灰色的图片）图片，输出6维的的卷积层（说明用到了6个卷积核，而每个卷积核是5*5的）。
        self.conv2 = nn.Conv2d(6, 16, 5)
        # an affine operation: y = Wx + b
        # 定义了三个全连接层，即fc1与conv2相连，将16张5*5的卷积网络一维化，并输出120个节点。
        self.fc1 = nn.Linear(16 * 5 * 5, 120)
        # 将120个节点转化为84个。
        self.fc2 = nn.Linear(120, 84)
        # 将84个节点输出为10个，即有10个分类结果。
        self.fc3 = nn.Linear(84, 10)

 #2、搭建网络   我们只需要定义forward函数，而backward函数会自动通过autograd创建。
    def forward(self, x):
        # Max pooling over a (2, 2) window
        # 用relu激活函数作为一个池化层，池化的窗口大小是2*2，这个也与上文的16*5*5的计算结果相符（一开始我没弄懂为什么fc1的输入点数是16*5*5,后来发现，这个例子是建立在lenet5上的）。
        # 这句整体的意思是，先用conv1卷积，然后激活，激活的窗口是2*2。
        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))
        # If the size is a square you can only specify a single number
        # 作用同上，然后有个需要注意的地方是在窗口是正方形的时候，2的写法等同于（2，2）。
        # 这句整体的意思是，先用conv2卷积，然后激活，激活的窗口是2*2。
        x = F.max_pool2d(F.relu(self.conv2(x)), 2)
        # 实际上view（）类似于reshape（）的用法，将张量重新规划格式 -1代表待定
        x = x.view(-1, self.num_flat_features(x)) #一维化
        # 用一下全连接层fc1，然后做一个激活。
        x = F.relu(self.fc1(x))
        # 用一下全连接层fc2，然后做一个激活。
        x = F.relu(self.fc2(x))
        # 用一下全连接层fc3。
        x = self.fc3(x)
        return x

    def num_flat_features(self, x):
        # 承接上文的引用，这里需要注意的是，由于pytorch只接受图片集的输入方式（原文的单词是batch）,所以第一个代表个数的维度被忽略。
        size = x.size()[1:]  # all dimensions except the batch dimension
        num_features = 1
        for s in size:
            num_features *= s
        return num_features


net = Net()
print(net)

"""
Net(
  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))
  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=400, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=84, bias=True)
  (fc3): Linear(in_features=84, out_features=10, bias=True)
)
"""</code></pre> 
<h2 id="3.2%20%E6%9F%A5%E7%9C%8B%E6%A8%A1%E5%9E%8B%E5%8F%82%E6%95%B0">3.2 查看模型参数</h2> 
<pre><code class="language-python"># 现在我们已经构建好模型了，但是还没有开始用bp呢，如果你对前面的内容有一些印象的话，你就会想起来不需要我们自己去搭建，我们只需要用某一个属性就可以了，autograd。

# 现在我们需要来看一看我们的模型，下列语句可以帮助你看一下这个模型的一些具体情况。

params = list(net.parameters())
print(len(params))
print(params[0].size())  # conv1's .weight

"""
10
torch.Size([6, 1, 5, 5])
"""</code></pre> 
<h2 id="3.3%20%E6%B5%8B%E8%AF%95%E7%BD%91%E7%BB%9C">3.3 测试网络</h2> 
<pre><code class="language-python">input = torch.randn(1, 1, 32, 32)
out = net(input)
print(out)
# tensor([[-0.0198,  0.0438,  0.0930, -0.0267, -0.0344,  0.0330,  0.0664,
0.1244, -0.0379,  0.0890]])

#默认的梯度会累加，因此我们通常在backward之前清除掉之前的梯度值：
net.zero_grad()
out.backward(torch.randn(1, 10))</code></pre> 
<h2 id="3.4%20%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E6%9B%B4%E6%96%B0%E6%9D%83%E9%87%8D">3.4 损失函数更新权重</h2> 
<pre><code class="language-python">1、计算损失
# 这一部分是来搞定损失函数
output = net(input)
target = torch.randn(10)  # a dummy target, for example
target = target.view(1, -1)  # make it the same shape as output
criterion = nn.MSELoss()
loss = criterion(output, target)
print(loss)

2、查看结果
print(loss.grad_fn)  # MSELoss
print(loss.grad_fn.next_functions[0][0])  # Linear
print(loss.grad_fn.next_functions[0][0].next_functions[0][0])  # ReLU

3、计算梯度
#在调用loss.backward()之前，我们需要清除掉tensor里之前的梯度，否则会累加进去。
net.zero_grad() 
loss.backward()

4、更新权重 （梯度下降）
learning_rate = 0.01
for f in net.parameters():
   f.data.sub_(f.grad.data * learning_rate)</code></pre> 
<ul><li>使用优化包即使用optimizer，我们也需要清零梯度。但是我们不需要一个个的清除，而是用optimizer.zero_grad()一次清除所有。</li></ul>
<pre><code class="language-python">import torch.optim as optim
 
# 创建optimizer，需要传入参数和learning rate
optimizer = optim.SGD(net.parameters(), lr=0.01)
 
# 清除梯度
optimizer.zero_grad()  
output = net(input)
loss = criterion(output, target)
loss.backward()
optimizer.step()    # optimizer会自动帮我们更新参数</code></pre> 
<h1 id="4%20%E8%AE%AD%E7%BB%83%E5%88%86%E7%B1%BB%E5%99%A8">4 训练分类器</h1> 
<h2 id="4.1%20%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E7%94%9F%E6%88%90Dataload">4.1 数据处理生成Dataload</h2> 
<p>特别是对于视觉领域，我们写了一个叫做torchvision的包，他可以将很多知名数据的数据即涵盖在内。并且，通过torchvision.datasets 和 torch.utils.data.DataLoader 进行数据的转化。在本里中我们将会使用 CIFAR10 数据集，它有以下各类： ‘airplane’, ‘automobile’, ‘bird’, ‘cat’, ‘deer’, ‘dog’, ‘frog’, ‘horse’, ‘ship’, ‘truck’。在这个数据集中的图像尺寸都是33232的。</p> 
<pre><code class="language-python">import torch
import torchvision
import torchvision.transforms as transforms

#数据归一化
transform = transforms.Compose(
	[transforms.ToTensor(),
transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])
#训练集
trainset = torchvision.datasets.CIFAR10(root='/path/to/data', train=True,
	download=True, transform=transform)
trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,
	shuffle=True, num_workers=2)
#测试集
testset = torchvision.datasets.CIFAR10(root='/path/to/data', train=False,
	download=True, transform=transform)
testloader = torch.utils.data.DataLoader(testset, batch_size=4,
	shuffle=False, num_workers=2)
# 标签
classes = ('plane', 'car', 'bird', 'cat',
	'deer', 'dog', 'frog', 'horse', 'ship', 'truck')</code></pre> 
<h2 id="4.2%20%E5%AE%9A%E4%B9%89%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C">4.2 定义卷积网络</h2> 
<pre><code class="language-python">import torch.nn as nn
import torch.nn.functional as F
class Net(nn.Module):
	def __init__(self):
		super(Net, self).__init__()
		self.conv1 = nn.Conv2d(3, 6, 5)
		self.pool = nn.MaxPool2d(2, 2)
		self.conv2 = nn.Conv2d(6, 16, 5)
		self.fc1 = nn.Linear(16 * 5 * 5, 120)
		self.fc2 = nn.Linear(120, 84)
		self.fc3 = nn.Linear(84, 10)
	
	def forward(self, x):
		x = self.pool(F.relu(self.conv1(x)))
		x = self.pool(F.relu(self.conv2(x)))
		x = x.view(-1, 16 * 5 * 5)
		x = F.relu(self.fc1(x))
		x = F.relu(self.fc2(x))
		x = self.fc3(x)
		return x
net = Net()</code></pre> 
<h2 id="4.3%20%E5%AE%9A%E4%B9%89%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0">4.3 定义损失函数</h2> 
<pre><code class="language-python">import torch.optim as optim
#这里使用交叉熵损失函数，Optimizer使用带冲量的SGD。     
criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)</code></pre> 
<h2 id="4.4%20%E9%81%8D%E5%8E%86DataLoader%E8%BF%9B%E8%A1%8C%E8%AE%AD%E7%BB%83">4.4 遍历DataLoader进行训练</h2> 
<pre><code class="language-python">for epoch in range(2):  # 这里只迭代2个epoch，实际应该进行更多次训练 
 
	running_loss = 0.0
    #enumerate将其组成一个索引序列，利用它可以同时获得索引和值
	for i, data in enumerate(trainloader, 0):
		# 得到输入
		inputs, labels = data
		
		# 梯度清零 
		optimizer.zero_grad()
		
		# forward + backward + optimize
		outputs = net(inputs)
		loss = criterion(outputs, labels)
		loss.backward()
		optimizer.step()
		
		# 定义统计信息
		running_loss += loss.item()
		if i % 2000 == 1999:
			print('[%d, %5d] loss: %.3f' %
				(epoch + 1, i + 1, running_loss / 2000))
		running_loss = 0.0
 
print('Finished Training')</code></pre> 
<h2 id="4.5%20%E6%B5%8B%E8%AF%95">4.5 测试</h2> 
<ul><li>取样测试</li></ul>
<pre><code class="language-python">#next() 返回迭代器的下一个项目。
#next() 函数要和生成迭代器的iter() 函数一起使用。

# 1 选取图片
dataiter = iter(testloader)
images, labels = dataiter.next()
imshow(torchvision.utils.make_grid(images))
print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))
# 2 预测结果
outputs = net(images)
_, predicted = torch.max(outputs, 1)
print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]
		for j in range(4)))</code></pre> 
<ul><li>测试集一类测试</li></ul>
<pre><code class="language-python">correct = 0
total = 0
with torch.no_grad():
for data in testloader:
	images, labels = data
	outputs = net(images)
	_, predicted = torch.max(outputs.data, 1)
	total += labels.size(0)
	correct += (predicted == labels).sum().item()
 
print('Accuracy of the network on the 10000 test images: %d %%' % (
	100 * correct / total))</code></pre> 
<ul><li>每类的测试</li></ul>
<pre><code class="language-python">class_correct = list(0. for i in range(10))
class_total = list(0. for i in range(10))
with torch.no_grad():
	for data in testloader:
		images, labels = data
		outputs = net(images)
		_, predicted = torch.max(outputs, 1)
		c = (predicted == labels).squeeze()
		for i in range(4):
			label = labels[i]
			class_correct[label] += c[i].item()
			class_total[label] += 1
 
 
for i in range(10):
	print('Accuracy of %5s : %2d %%' % (
		classes[i], 100 * class_correct[i] / class_total[i]))


Accuracy of plane : 52 %
Accuracy of   car : 66 %
Accuracy of  bird : 49 %
Accuracy of   cat : 34 %
Accuracy of  deer : 30 %
Accuracy of   dog : 45 %
Accuracy of  frog : 72 %
Accuracy of horse : 71 %
Accuracy of  ship : 76 %
Accuracy of truck : 55 %</code></pre> 
<h1 id="5%20GPU%E8%AE%AD%E7%BB%83">5 GPU训练</h1> 
<pre><code class="language-python">device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
print(device)
# cuda:0
class Net2(nn.Module):
def __init__(self):
super(Net2, self).__init__()
self.conv1 = nn.Conv2d(3, 6, 5).to(device)
self.pool = nn.MaxPool2d(2, 2).to(device)
self.conv2 = nn.Conv2d(6, 16, 5).to(device)
self.fc1 = nn.Linear(16 * 5 * 5, 120).to(device)
self.fc2 = nn.Linear(120, 84).to(device)
self.fc3 = nn.Linear(84, 10).to(device)
 
def forward(self, x):
x = self.pool(F.relu(self.conv1(x)))
x = self.pool(F.relu(self.conv2(x)))
x = x.view(-1, 16 * 5 * 5)
x = F.relu(self.fc1(x))
x = F.relu(self.fc2(x))
x = self.fc3(x)
return x
 
 
net = Net2()
criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)
 
for epoch in range(20):
 
	running_loss = 0.0
	for i, data in enumerate(trainloader, 0):
		# 得到输入
		inputs, labels = data 
		inputs, labels = inputs.to(device), labels.to(device) 
		# 梯度清零 
		optimizer.zero_grad()
		
		# forward + backward + optimize
		outputs = net(inputs)
		loss = criterion(outputs, labels)
		loss.backward()
		optimizer.step()
		
		# 定义统计信息
		running_loss += loss.item()
		if i % 2000 == 1999:
			print('[%d, %5d] loss: %.3f' %
				(epoch + 1, i + 1, running_loss / 2000))
			running_loss = 0.0
		
		print('Finished Training')</code></pre> 
<p></p>
                </div>

		</div>
	</article>
</main>




			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程小白.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://www.w3counter.com/tracker.js?id=150625"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>
	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>