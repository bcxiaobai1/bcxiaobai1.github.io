<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<title>【云原生】k8s之pod控制器 - 编程小白</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程小白" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程小白</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">【云原生】k8s之pod控制器</h1>
			
		</header>
		<div class="content post__content clearfix">
			


        
                <div id="content_views" class="htmledit_views">
                    <h1 id="%C2%A0%E5%89%8D%E8%A8%80"><span style="background-color:#ff9900"> 前言</span></h1> 
<p><strong>Pod 是 Kubernetes 集群中能够被创建和管理的最小部署单元。所以需要有工具去操作和管理它们的生命周期,这里就需要用到控制器了。</strong></p> 
<p><strong>Pod 控制器由 master 的 kube-controller-manager 组件提供，常见的此类控制器有 Replication Controller、ReplicaSet、Deployment、DaemonSet、StatefulSet、Job 和 CronJob 等，它们分别以不同的方式管理 Pod 资源对象。</strong><br>  </p> 
<h1 id="%C2%A01.pod%E6%8E%A7%E5%88%B6%E5%99%A8%E7%9A%84%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86"><span style="background-color:#ff9900">1.pod控制器的相关知识</span></h1> 
<h1 id="%C2%A01.1%20pod%E6%8E%A7%E5%88%B6%E5%99%A8%E7%9A%84%E4%BD%9C%E7%94%A8"><span style="background-color:#a2e043"> 1.1 pod控制器的作用</span></h1> 
<p></p> 
<p><strong> Pod控制器，又称之为工作负载（workload），是用于实现管理pod的中间层，确保pod资源符合预期的状态，pod的资源出现故障时，会尝试进行重启，当根据重启策略无效，则会重新新建pod的资源。</strong></p> 
<p></p> 
<p><strong>按照pod的创建安方式可以将其分为两类：</strong></p> 
<p><strong><span style="color:#fe2c24">自主式pod</span>：kubernetes直接创建出来的pod，这种pod删除后就没有了，也不会重建<br><span style="color:#fe2c24">控制器创建的pod</span>：通过控制器创建的pod，这种pod删除了之后还会自动重建</strong></p> 
<p></p> 
<p><strong><span style="background-color:#38d8f0"> 控制器和pod的关系：</span></strong></p> 
<p><strong>controllers：在集群上管理和运行容器的 pod 对象， pod 通过 label-selector 相关联。<br> Pod 通过控制器实现应用的运维，如伸缩，升级等。</strong></p> 
<p></p> 
<p><img alt="" height="541" src="https://images2.imgbox.com/f2/2f/BLCE7iR0_o.png" width="1131"><br>  </p> 
<p></p> 
<h2 id="1.2%C2%A0pod%E6%8E%A7%E5%88%B6%E5%99%A8%E7%9A%84%E5%A4%9A%E7%A7%8D%E7%B1%BB%E5%9E%8B%C2%A0"><span style="background-color:#a2e043">1.2 pod控制器的多种类型 </span></h2> 
<p></p> 
<p><strong>1）<span style="color:#fe2c24">ReplicaSet</span>: 代用户创建指定数量的pod副本，确保pod副本数量符合预期状态，并且支持滚动式自动扩容和缩容功能。<br> ReplicaSet主要三个组件组成：<br>    1）用户期望的pod副本数量<br>    2）标签选择器，判断哪个pod归自己管理<br>    3）当现存的pod数量不足，会根据pod资源模板进行新建</strong><br><strong>帮助用户<span style="color:#fe2c24">管理无状态的pod资源</span>，精确反应用户定义的目标数量，但是RelicaSet不是直接使用的控制器，而是使用Deployment。</strong></p> 
<p></p> 
<p><strong>（2）<span style="color:#fe2c24">Deployment</span>：工作在ReplicaSet之上，用于<span style="color:#fe2c24">管理无状态应用</span>，目前来说最好的控制器。支持滚动更新和回滚功能，还提供声明式配置。<br> ReplicaSet 与Deployment 这两个资源对象逐步替换之前RC的作用。</strong></p> 
<p></p> 
<p><strong>（3）<span style="color:#fe2c24">DaemonSet</span>：用于确保集群中的每一个节点只运行特定的pod副本，通常用于实现系统级后台任务。比如ELK服务<br> 特性：服务是无状态的<br> 服务必须是守护进程</strong></p> 
<p></p> 
<p><strong>（4）<span style="color:#fe2c24">StatefulSet</span>：管理有状态应用</strong></p> 
<p><strong>（5）<span style="color:#fe2c24">Job</span>：只要完成就立即退出，不需要重启或重建</strong></p> 
<p><strong>（6）<span style="color:#fe2c24">Cronjob</span>：周期性任务控制，不需要持续后台运行</strong></p> 
<p></p> 
<h1 id="1.3%20pod%E5%AE%B9%E5%99%A8%E4%B8%AD%E7%9A%84%E6%9C%89%E7%8A%B6%E6%80%81%E5%92%8C%E6%97%A0%E7%8A%B6%E6%80%81%E7%9A%84%E5%AF%B9%E6%AF%94%C2%A0"><span style="background-color:#a2e043">1.3 pod容器中的有状态和无状态的对比 </span></h1> 
<p><strong><span style="color:#956fe7">（1）有状态实例 </span><br> 实例之间有差别，每个实例都有自己的独特性，元数据不同，例如etcd，zookeeper<br> 实例之间不对等的关系，以及依靠外部存储的应用 </strong></p> 
<p><br><strong><span style="color:#956fe7">（2）无状态实例 </span><br> deployment认为所有的pod都是一样的<br> 不用考虑顺序的要求<br> 不用考虑在哪个node节点上运行<br> 可以随意扩容和缩容</strong><br>  </p> 
<h1 id="%C2%A02.Deployment%E6%8E%A7%E5%88%B6%E5%99%A8"><span style="background-color:#a2e043">2.1Deployment控制器</span></h1> 
<p><strong>部署无状态应用<br> 管理Pod和ReplicaSet<br> 具有上线部署、副本设定、滚动升级、回滚等功能<br> 提供声明式更新，例如只更新一个新的image<br> 应用场景：web服务</strong></p> 
<p></p> 
<blockquote> 
 <p><strong><span style="color:#fe2c24">vim nginx-deployment.yaml</span></strong><br> apiVersion: apps/v1<br> kind: Deployment<br> metadata:<br>   name: nginx-deployment<br>   labels:<br>     app: nginx    <br> spec:<br>   replicas: 3<br>   selector:<br>     matchLabels:<br>       app: nginx<br>   template:<br>     metadata:<br>       labels:<br>         app: nginx<br>     spec:<br>       containers:<br>       - name: nginx<br>         image: nginx:1.15.4<br>         ports:<br>         - containerPort: 80</p> 
 <p><span style="color:#fe2c24"><strong>kubectl create -f nginx-deployment.yaml</strong></span></p> 
 <p><span style="color:#fe2c24"><strong>kubectl get pods,deploy,rs</strong></span><br>  </p> 
</blockquote> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<h2 id="2.1%20SatefulSet%C2%A0%E6%8E%A7%E5%88%B6%E5%99%A8%E7%9A%84%E8%BF%90%E7%94%A8%C2%A0"><strong><span style="background-color:#a2e043">2.2 SatefulSet 控制器的运用 </span></strong></h2> 
<p><strong> StatefulSet 是用来管理有状态应用的工作负载 API 对象。</strong></p> 
<p><strong>StatefulSet 用来管理某 Pod 集合的部署和扩缩， 并为这些 Pod 提供持久存储和持久标识符。</strong></p> 
<p><strong>和 Deployment 类似， StatefulSet 管理基于相同容器规约的一组 Pod。但和 Deployment 不同的是，<span style="color:#fe2c24"> StatefulSet 为它们的每个 Pod 维护了一个有粘性的 ID</span>。这些 Pod 是基于相同的规约来创建的， 但是不能相互替换：无论怎么调度，每个 Pod 都有一个永久不变的 ID。</strong></p> 
<p><strong>如果希望使用存储卷为工作负载提供持久存储，可以使用 StatefulSet 作为解决方案的一部分。 尽管 StatefulSet 中的单个 Pod 仍可能出现故障， 但持久的 Pod 标识符使得将现有卷与替换已失败 Pod 的新 Pod 相匹配变得更加容易。</strong><br><img alt="" height="373" src="https://images2.imgbox.com/5a/8e/h5wXcKoK_o.png" width="1135"></p> 
<p> </p> 
<p></p> 
<p><strong>StatefulSet 对于需要满足以下一个或多个需求的应用程序很有价值：</strong></p> 
<p><strong>稳定的、唯一的网络标识符。<br> 稳定的、持久的存储。<br> 有序的、优雅的部署和扩缩。<br> 有序的、自动的滚动更新。</strong></p> 
<p><br><strong>在上面描述中，“稳定的”意味着 Pod 调度或重调度的整个过程是有持久性的。 如果应用程序不需要任何稳定的标识符或有序的部署、删除或扩缩， 则应该使用由一组无状态的副本控制器提供的工作负载来部署应用程序，比如 Deployment 或者  ReplicaSet可能更适用于你的无状态应用部署需要。</strong><br>  </p> 
<p></p> 
<h1 id="%C2%A02.1%20SatefulSet%C2%A0%E6%8E%A7%E5%88%B6%E5%99%A8%E7%9A%84%E6%A1%88%E4%BE%8B%E6%BC%94%E7%A4%BA"><span style="background-color:#ff9900">2.2 SatefulSet 控制器</span></h1> 
<p><span style="color:#fe2c24"><strong>1 名为 nginx-svc 的 Headless Service 用来控制网络域名。<br> 2 名为 nginx-sts 的 StatefulSet 有一个 Spec，它表明将在独立的 3 个 Pod 副本中启动 nginx 容器。<br> 3 volumeClaimTemplates 将通过 PersistentVolume 制备程序所准备的  PersistentVolumes来提供稳定的存储</strong></span><br>  </p> 
<h3 id="%E6%A1%88%E4%BE%8B%E7%9A%84%E5%88%9B%E5%BB%BA%E6%BC%94%E7%A4%BA%C2%A0">案例的创建演示 </h3> 
<p></p> 
<blockquote> 
 <p>apiVersion: v1<br> kind: Service<br> metadata:<br>   <span style="color:#fe2c24"><strong>name: nginx-svc  </strong></span>    <strong><span style="color:#fe2c24">服务名  </span></strong><br> spec:<br>   ports:<br>   - port: 80<br>     targetPort: 80<br><strong><span style="color:#fe2c24">  clusterIP: None        无头服务的clusterIp为None</span></strong><br>   selector:<br><strong><span style="color:#fe2c24">    app: nginx-sts        拥有此标签的pod 都有此service</span></strong></p> 
 <p></p> 
 <p><br> ---<br> apiVersion: apps/v1<br> kind: StatefulSet<br> metadata:<br>   name: nginx-sts<br> spec:<br>   replicas: 3<br>   <strong><span style="color:#fe2c24">serviceName: "nginx-svc"     #声明它属于哪个Headless Service.</span></strong><br>   selector:<br>     matchLabels:<br>       <span style="color:#fe2c24"><strong>app: nginx-sts   和下面的标签必须对应</strong></span><br>   template:    <span style="color:#fe2c24"><strong>定义pod模板</strong></span><br>     metadata:<br>       labels:<br>      <span style="color:#fe2c24">  <strong> app: nginx-sts  和上面的标签必须对应</strong></span><br>     spec:<br>       containers:<br>       - image: nginx:1.14<br>         imagePullPolicy: IfNotPresent<br>         name: nginx-test<br>         ports:<br>         - containerPort: 80<br>           protocol: TCP<br>         volumeMounts:<br>         - name: www<br>           mountPath: /usr/share/nginx/html<br>  <strong><span style="color:#fe2c24"> volumeClaimTemplates:           #可看作pvc的模板 ---创建pod时，自动创建pvc，请求pv </span></strong><br>   - metadata:<br>       name: www<br>     spec:<br>       accessModes: [ "ReadWriteOnce" ]<br>       storageClassName: "nfs-client-storageclass"  <strong>  <span style="color:#fe2c24">#存储类名，改为集群中已存在的</span></strong><br>       resources:<br>         requests:<br>           storage: 2Gi</p> 
</blockquote> 
<p></p> 
<p><img alt="" height="544" src="https://images2.imgbox.com/58/c8/IPRTzVnR_o.png" width="1200"></p> 
<p> </p> 
<p style="text-align:center"><img alt="" src="https://images2.imgbox.com/d0/cb/z2Fis9Ik_o.png"></p> 
<p> </p> 
<p style="text-align:center"><img alt="" src="https://images2.imgbox.com/5d/94/coOVYzyd_o.png"></p> 
<p> </p> 
<h3 id="%E6%A1%88%E4%BE%8B%E7%9A%84%E6%9B%B4%E8%A1%8C%E6%89%A9%E5%AE%B9%E4%B8%8E%E7%BC%A9%E5%AE%B9%E6%BC%94%E7%A4%BA%C2%A0">案例的更行扩容与缩容演示 </h3> 
<blockquote> 
 <p>kubectl edit sts    (sts代表<span style="background-color:#ff9900">SatefulSet </span>)   只要时statefulset控制器创建的pod都会显示出来</p> 
</blockquote> 
<p><img alt="" height="772" src="https://images2.imgbox.com/7d/74/ixhgYLzN_o.png" width="1099"></p> 
<p> </p> 
<p><img alt="" height="276" src="https://images2.imgbox.com/72/81/HXSdYDcM_o.png" width="1200"></p> 
<p> </p> 
<p></p> 
<p><strong><span style="color:#fe2c24">kubectl get svc  #查看创建的无头服务myapp-svc</span></strong><br> NAME         TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)             AGE<br> kubernetes   ClusterIP   10.96.0.1        &lt;none&gt;        443/TCP             50d<br> myapp-svc    ClusterIP   None             &lt;none&gt;        80/TCP              38s</p> 
<p><span style="color:#fe2c24"><strong>kubectl get sts    #查看statefulset</strong></span><br> NAME      DESIRED   CURRENT   AGE<br> myapp     3         3         55s</p> 
<p><strong><span style="color:#fe2c24">kubectl get pvc    #查看pvc绑定</span></strong><br> NAME                STATUS    VOLUME    CAPACITY   ACCESS MODES   STORAGECLASS   AGE<br> myappdata-myapp-0   Bound     pv002     2Gi        RWO                           1m<br> myappdata-myapp-1   Bound     pv003     2Gi        RWO,RWX                       1m<br> myappdata-myapp-2   Bound     pv004     2Gi        RWO,RWX                       1m</p> 
<p><strong><span style="color:#fe2c24">kubectl get pv    #查看pv绑定</span></strong><br> NAME      CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS      CLAIM                       STORAGECLASS   REASON    AGE<br> pv001     1Gi        RWO,RWX        Retain           Available                                                        6m<br> pv002     2Gi        RWO            Retain           Bound       default/myappdata-myapp-0                            6m<br> pv003     2Gi        RWO,RWX        Retain           Bound       default/myappdata-myapp-1                            6m<br> pv004     2Gi        RWO,RWX        Retain           Bound       default/myappdata-myapp-2                            6m<br> pv005     2Gi        RWO,RWX        Retain           Available                                                        6m</p> 
<p></p> 
<blockquote> 
 <p><strong><span style="color:#fe2c24">//当删除一个 StatefulSet 时，该 StatefulSet 不提供任何终止 Pod 的保证。为了实现 StatefulSet 中的 Pod 可以有序且体面地终止，可以在删除之前将 StatefulSet 缩容到 0。</span></strong><br> kubectl scale statefulset myappdata-myapp --replicas=0<br> kubectl delete -f stateful-demo.yaml</p> 
 <p></p> 
</blockquote> 
<p></p> 
<blockquote> 
 <p><strong><span style="color:#fe2c24">//此时PVC依旧存在的，再重新创建pod时，依旧会重新去绑定原来的pvc</span></strong><br> kubectl apply -f stateful-demo.yaml</p> 
</blockquote> 
<p></p> 
<p><strong><span style="background-color:#ffd7b9">//总结</span><br><span style="background-color:#ffd7b9">无状态：</span><br><span style="background-color:#ffd7b9">1）deployment 认为所有的pod都是一样的</span><br><span style="background-color:#ffd7b9">2）不用考虑顺序的要求</span><br><span style="background-color:#ffd7b9">3）不用考虑在哪个node节点上运行</span><br><span style="background-color:#ffd7b9">4）可以随意扩容和缩容 </span></strong></p> 
<p><strong><span style="background-color:#ffd7b9">有状态</span><br><span style="background-color:#ffd7b9">1）实例之间有差别，每个实例都有自己的独特性，元数据不同，例如etcd，zookeeper</span><br><span style="background-color:#ffd7b9">2）实例之间不对等的关系，以及依靠外部存储的应用。</span></strong><br>  </p> 
<p></p> 
<p></p> 
<p><strong><span style="background-color:#fbd4d0">常规service和无头服务区别</span><br><span style="background-color:#fbd4d0">service：一组Pod访问策略，提供cluster-IP群集之间通讯，还提供负载均衡和服务发现。</span><br><span style="background-color:#fbd4d0">Headless service：无头服务，不需要cluster-IP，而是直接以DNS记录的方式解析出被代理Pod的IP地址。</span></strong><br>  </p> 
<p></p> 
<p></p> 
<p></p> 
<h2><strong><span style="background-color:#a2e043">(1) 为什么要有headless？</span></strong></h2> 
<p><br><strong>在deployment中，每一个pod是没有名称，是随机字符串，是无序的。而statefulset中是要求有序的，每一个pod的名称必须是固定的。当节点挂了，重建之后的标识符是不变的，每一个节点的节点名称是不能改变的。pod名称是作为pod识别的唯一标识符，必须保证其标识符的稳定并且唯一。</strong></p> 
<p><strong>为了实现标识符的稳定，这时候就需要一个headless service 解析直达到pod，还需要给pod配置一个唯一的名称。</strong></p> 
<h2><strong><span style="background-color:#a2e043">(2)为什么要有volumeClaimTemplate？</span></strong></h2> 
<p><br><strong> 大部分有状态副本集都会用到持久存储，比如分布式系统来说，由于数据是不一样的，每个节点都需要自己专用的存储节点。而在 deployment中pod模板中创建的存储卷是一个共享的存储卷，多个pod使用同一个存储卷，而statefulset定义中的每一个pod都不能使用同一个存储卷，由此基于pod模板创建pod是不适应的，这就需要引入volumeClaimTemplate，当在使用statefulset创建pod时，会自动生成一个PVC，从而请求绑定一个PV，从而有自己专用的存储卷。</strong></p> 
<p><strong>服务发现：就是应用服务之间相互定位的过程。<br> 应用场景：<br> ●动态性强：Pod会飘到别的node节点<br> ●更新发布频繁：互联网思维小步快跑，先实现再优化，老板永远是先上线再慢慢优化，先把idea变成产品挣到钱然后再慢慢一点一点优化<br> ●支持自动伸缩：一来大促，肯定是要扩容多个副本</strong></p> 
<p><strong>K8S里服务发现的方式---DNS，使K8S集群能够自动关联Service资源的“名称”和“CLUSTER-IP”，从而达到服务被集群自动发现的目的。</strong><br>  </p> 
<p></p> 
<h2><strong><span style="background-color:#a2e043"> (3)对StatefulSet控制的总结</span></strong></h2> 
<p><br><strong>1、部署有状态应用的   <br> 2、每个Pod的名称是唯一且固定不变的，而且每个Pod应该拥有自己专属的持久化存储（基于PVC模板volumeClaimTemplates绑定PV）<br> 3、需要关联 Headless Service（ClusterIP为None），在K8S集群内部可通过 &lt;pod_name&gt;.&lt;svc.name&gt;.&lt;namespace_name&gt;.svc.cluster.local 的格式解析出 PodIP （基于无头服务和CoreDNS实现）<br> 4、创建、删除、升级、扩缩容Pod都是有序进行的（默认为串行执行的）：<br>     创建、升级，扩容是升序执行的（顺序为Pod标识序号0..n-1），删除是逆序执行的（顺序为 n-1..0）<br>   缩容和回滚都是逆序执行的（顺序为 n-1..0），会先删除旧Pod，再创建新Pod </strong><br>  </p> 
<p></p> 
<p></p> 
<h1 id="%C2%A03.DaemonSet%E6%8E%A7%E5%88%B6%E5%99%A8"><span style="background-color:#ff9900">3.DaemonSet控制器</span></h1> 
<p></p> 
<h2><strong> <span style="background-color:#a2e043">3.1  DaemonSet控制器的运用</span></strong></h2> 
<p><br><strong><span style="color:#fe2c24">DaemonSet 确保全部（或者一些）Node 上运行一个 Pod 的副本。当有 Node 加入集群时，也会为他们新增一个 Pod 。当有 Node 从集群移除时，这些 Pod 也会被回收。删除 DaemonSet 将会删除它创建的所有 Pod。</span></strong></p> 
<p><strong>使用 DaemonSet 的一些典型用法：<br> ●运行集群存储 daemon，例如在每个 Node 上运行 glusterd、ceph。<br> ●在每个 Node 上运行日志收集 daemon，例如fluentd、logstash。<br> ●在每个 Node 上运行监控 daemon，例如 Prometheus Node Exporter、collectd、Datadog 代理、New Relic 代理，或 Ganglia gmond。<br> 应用场景：Agent<br> 官方案例（监控）：</strong><br>  </p> 
<p></p> 
<h2 id="3.2%C2%A0DaemonSet%E6%8E%A7%E5%88%B6%E5%99%A8%E7%9A%84%E6%A1%88%E4%BE%8B%E6%BC%94%E7%A4%BA"><span style="background-color:#a2e043">3.2 DaemonSet控制器的案例演示</span></h2> 
<blockquote> 
 <p>vim ds.yaml <br> apiVersion: apps/v1<br> kind: DaemonSet <br> metadata:<br>   name: nginx-daemonSet<br>   labels:<br>     app: nginx<br> spec:<br>   selector:<br>     matchLabels:<br>       app: nginx<br>   template:<br>     metadata:<br>       labels:<br>         app: nginx<br>     spec:<br>       containers:<br>       - name: nginx<br>         image: nginx:1.14<br>         ports:<br>         - containerPort: 80<br>  <br>  <br> kubectl apply -f ds.yaml</p> 
 <p></p> 
</blockquote> 
<blockquote> 
 <p><strong> 守护进程控制器会在每一个node节点上创建一个相同的pod</strong></p> 
 <p><strong> DaemonSet<br> 1、理论上可以在K8S集群的所有Node节点上创建同类型的Pod资源（无论Node节点什么加入到K8S集群）<br> 2、会受到Node节点上的污点或者cordon不可调度设置的影响。可以在Pod配置中设置容忍忽略污点，设置uncordon解除不可调度<br> 3、不需要设置副本数replicas</strong><br>  </p> 
</blockquote> 
<p></p> 
<h1 id="%C2%A04.Job%E6%8E%A7%E5%88%B6%E5%99%A8"><span style="background-color:#ff9900"> 4.Job控制器</span></h1> 
<h2 id="%C2%A04.1%20job%E6%8E%A7%E5%88%B6%E5%99%A8%E7%9A%84%E8%BF%90%E7%94%A8"><span style="background-color:#a2e043">4.1 job控制器的运用</span></h2> 
<p> <strong>Job分为普通任务（Job）和定时任务（CronJob）<br> 常用于运行那些仅需要执行一次的任务<br> 应用场景：数据库迁移、批处理脚本、kube-bench扫描、离线数据处理，视频解码等业务</strong></p> 
<p></p> 
<h2 id="4.2%20job%E6%8E%A7%E5%88%B6%E5%99%A8%E7%9A%84%E6%A1%88%E4%BE%8B%E6%BC%94%E7%A4%BA%C2%A0"><strong><span style="background-color:#a2e043">4.2 job控制器的案例演示 </span></strong></h2> 
<blockquote> 
 <p>vim job.yaml<br> apiVersion: batch/v1<br> kind: Job<br> metadata:<br>   name: pi<br> spec:<br>   template:<br>     spec:<br>       containers:<br>       - name: pi<br>         image: perl<br>         command: ["perl",  "-Mbignum=bpi", "-wle", "print bpi(2000)"]<br>       restartPolicy: Never<br>   backoffLimit: 4</p> 
</blockquote> 
<blockquote> 
 <p><strong>参数解释：<br> .spec.template.spec.restartPolicy该属性拥有三个候选值：OnFailure，Never和Always。默认值为Always。它主要用于描述Pod内容器的重启策略。在Job中只能将此属性设置为OnFailure或Never，否则Job将不间断运行。</strong></p> 
 <p><strong>.spec.backoffLimit用于设置job失败后进行重试的次数，默认值为6。默认情况下，除非Pod失败或容器异常退出，Job任务将不间断的重试，此时Job遵循 .spec.backoffLimit上述说明。一旦.spec.backoffLimit达到，作业将被标记为失败。</strong><br>  </p> 
</blockquote> 
<p></p> 
<p></p> 
<h1 id="%C2%A05.CronJob%C2%A0"><span style="background-color:#ff9900"> 5.CronJob </span></h1> 
<p><strong>周期性任务，像Linux的Crontab一样。<br> 周期性任务<br> 应用场景：通知，备份</strong></p> 
<p></p> 
<blockquote> 
 <p>示例：<br> //每分钟打印hello<br> vim cronjob.yaml<br> apiVersion: batch/v1beta1<br> kind: CronJob<br> metadata:<br>   name: hello<br> spec:<br>   schedule: "*/1 * * * *"<br>   jobTemplate:<br>     spec:<br>       template:<br>         spec:<br>           containers:<br>           - name: hello<br>             image: busybox<br>             imagePullPolicy: IfNotPresent<br>             args:<br>             - /bin/sh<br>             - -c<br>             - date; echo Hello from the Kubernetes cluster<br>           restartPolicy: OnFailure<br>           <br> //cronjob其它可用参数的配置<br> spec:<br>   concurrencyPolicy: Allow            #声明了 CronJob 创建的任务执行时发生重叠如何处理（并发性规则仅适用于相同 CronJob 创建的任务）。spec仅能声明下列规则中的一种:<br>                                          ●Allow (默认)：CronJob 允许并发任务执行。<br>                                          ●Forbid：CronJob 不允许并发任务执行；如果新任务的执行时间到了而老任务没有执行完，CronJob 会忽略新任务的执行。<br>                                          ●Replace：如果新任务的执行时间到了而老任务没有执行完，CronJob 会用新任务替换当前正在运行的任务。<br>   startingDeadlineSeconds: 15        #它表示任务如果由于某种原因错过了调度时间，开始该任务的截止时间的秒数。过了截止时间，CronJob 就不会开始任务，且标记失败.如果此字段未设置，那任务就没有最后期限。<br>   successfulJobsHistoryLimit: 3        #要保留的成功完成的任务数（默认为3）<br>   failedJobsHistoryLimit：1         #要保留多少已完成和失败的任务数（默认为1）<br>   suspend：true                     #如果设置为 true ，后续发生的执行都会被挂起。 这个设置对已经开始的执行不起作用。默认是 false。<br>   schedule: '*/1 * * * *'            #必需字段，作业时间表。在此示例中，作业将每分钟运行一次<br>   jobTemplate:                        #必需字段，作业模板。这类似于工作示例<br>  <br>  <br> kubectl create -f cronjob.yaml <br>  <br> kubectl get cronjob<br> NAME    SCHEDULE      SUSPEND   ACTIVE   LAST SCHEDULE   AGE<br> hello   */1 * * * *   False     0        &lt;none&gt;          25s<br>  <br> kubectl get pods<br> NAME                     READY   STATUS      RESTARTS   AGE<br> hello-1621587180-mffj6   0/1     Completed   0          3m<br> hello-1621587240-g68w4   0/1     Completed   0          2m<br> hello-1621587300-vmkqg   0/1     Completed   0          60s<br>  <br> kubectl logs hello-1621587180-mffj6<br> Fri May 21 09:03:14 UTC 2021<br> Hello from the Kubernetes cluster<br> //如果报错：Error from server (Forbidden): Forbidden (user=system:anonymous, verb=get, resource=nodes, subresource=proxy) ( pods/log hello-1621587780-c7v54)<br> //解决办法：绑定一个cluster-admin的权限<br> kubectl create clusterrolebinding system:anonymous --clusterrole=cluster-admin --user=system:anonymous</p> 
</blockquote> 
<p></p> 
<h1 id="%E6%80%BB%E7%BB%93"><span style="background-color:#ff9900">总结</span></h1> 
<p><span style="background-color:#ff9900">Pod 控制器有几种？<br> 1、Deployment+ReplicaSet  部署无状态应用的Pod<br> 2、StatefulSet    部署有状态应用的Pod<br> 3、DaemonSet      在K8S集群的所有Node节点上部署相同的Pod<br> 4、Job            部署一次性的任务Pod，完成后就会退出并不会重启<br> 5、CronJob        部署周期性的任务Pod，完成后就会退出并不会重启<br>  <br>  <br> Deployment<br> 1、部署无状态应用的<br> 2、创建和管理 ReplicaSet(RS)和Pod资源，维护Pod副本数量与期望值相同<br> 3、创建和删除Pod时是并行执行的，升级时是先创建一部分新Pod，再删除一部分旧Pod<br>  <br>  <br> StatefulSet<br> 1、部署有状态应用的   <br> 2、每个Pod的名称是唯一且固定不变的，而且每个Pod应该拥有自己专属的持久化存储（基于PVC模板volumeClaimTemplates绑定PV）<br> 3、需要关联 Headless Service（ClusterIP为None），在K8S集群内部可通过 &lt;pod_name&gt;.&lt;svc.name&gt;.&lt;namespace_name&gt;.svc.cluster.local 的格式解析出 PodIP （基于无头服务和CoreDNS实现）<br> 4、创建、删除、升级、扩缩容Pod都是有序进行的（默认为串行执行的）：<br>     创建、升级是升序执行的（顺序为Pod标识序号0..n-1），删除是逆序执行的（顺序为 n-1..0）<br>     扩缩容都是逆序执行的（顺序为 n-1..0），会先删除旧Pod，再创建新Pod<br>  <br> spec.podManagementPolicy: Parallel  #可设置StatefulSet创建和删除Pod时为并行执行<br>  <br>  <br> service类型种类  4+1<br> ClusterIP<br> NodePort<br> LoadBalancer<br> ExtenalName<br>  <br> Headless Service<br>  <br> 常规service与Headless Service的区别<br> 常规service：一组Pod的访问策略，提供ClusterIP在K8S集群内部访问，还提供负载均衡和服务发现功能<br> Headless Service：无头服务，可以不需要ClusterIP，与StatefulSet资源关联配合CoreDNS实现通过 Pod名称 解析出 PodIP<br>  <br>  <br> DaemonSet<br> 1、理论上可以在K8S集群的所有Node节点上创建同类型的Pod资源（无论Node节点什么加入到K8S集群）<br> 2、会受到Node节点上的污点或者cordon不可调度设置的影响。可以在Pod配置中设置容忍忽略污点，设置uncordon解除不可调度<br> 3、不需要设置副本数replicas<br>  <br>  <br> Job<br> 1、部署一次性任务的资源<br> 2、任务正常完成后Pod容器会立即退出并不会再重启（Job类型Pod容器的retartPolicy通常设置为Never），也不会重建Pod<br> 3、如果任务异常完成Pod容器异常退出，会重建Pod重试任务，重试次数根据 backoffLimit 配置（默认6次）<br>  <br>  <br> CronJob<br> 1、部署周期性任务的资源，一次任务至少创建一个Pod<br> 2、任务正常完成后Pod容器会立即退出并不会再重启（Job类型Pod容器的retartPolicy不设置为Always），也不会重建Pod<br> 3、使用 spec.schedule 字段设置时间周期表，格式为 '分 时 日 月 周'</span></p>
                </div>

		</div>
	</article>
</main>




			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程小白.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://www.w3counter.com/tracker.js?id=150625"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>
	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>