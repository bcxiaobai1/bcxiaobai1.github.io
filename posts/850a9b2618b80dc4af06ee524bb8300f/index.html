<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<title>神经网络学习小记录66——Vision Transformer（VIT）模型的复现详解 - 编程小白</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程小白" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程小白</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">神经网络学习小记录66——Vision Transformer（VIT）模型的复现详解</h1>
			
		</header>
		<div class="content post__content clearfix">
			


                <div id="content_views" class="markdown_views prism-tomorrow-night-eighties">
                    
                        
                    
                    <p></p>
<div class="toc">
 <h3>神经网络学习小记录66——Vision Transformer（VIT）模型的复现详解</h3>
 <ul>
<li><a href="#_2">学习前言</a></li>
<li><a href="#Vision_TransformerVIT_5">什么是Vision Transformer（VIT）</a></li>
<li><a href="#_10">代码下载</a></li>
<li><a href="#Vision_Transforme_14">Vision Transforme的实现思路</a></li>
<li>
<ul>
<li><a href="#_15">一、整体结构解析</a></li>
<li><a href="#_23">二、网络结构解析</a></li>
<li>
<ul>
<li><a href="#1_24">1、特征提取部分介绍</a></li>
<li>
<ul>
<li><a href="#aPatchPosition_Embedding_25">a、Patch+Position Embedding</a></li>
<li><a href="#bTransformer_Encoder_157">b、Transformer Encoder</a></li>
<li>
<ul>
<li><a href="#ISelfattention_161">I、Self-attention结构解析</a></li>
<li><a href="#IISelfattention_178">II、Self-attention的矩阵运算</a></li>
<li><a href="#IIIMultiHead_224">III、MultiHead多头注意力机制</a></li>
<li><a href="#IVTransformerBlock_315">IV、TransformerBlock的构建。</a></li>
</ul>
     </li>
<li><a href="#cVIT_358">c、整个VIT模型的构建</a></li>
</ul>
    </li>
<li><a href="#2_403">2、分类部分</a></li>
</ul>
  </li>
</ul>
  </li>
<li><a href="#Vision_Transforme_454">Vision Transforme的构建代码</a></li>
</ul>
</div>
<p></p> 
<h1>
<a id="_2"></a>学习前言</h1> 
<p>视觉Transformer最近非常的火热，从VIT开始，我先学学看。<br> <img src="https://images2.imgbox.com/d5/d3/FvsSUwhH_o.png" alt="在这里插入图片描述"></p> 
<h1>
<a id="Vision_TransformerVIT_5"></a>什么是Vision Transformer（VIT）</h1> 
<p>Vision Transformer是Transformer的视觉版本，Transformer基本上已经成为了自然语言处理的标配，但是在视觉中的运用还受到限制。</p> 
<p>Vision Transformer打破了这种NLP与CV的隔离，将Transformer应用于图像图块（patch）序列上，进一步完成图像分类任务。简单来理解，Vision Transformer就是将输入进来的图片，每隔一定的区域大小划分图片块。然后将划分后的图片块组合成序列，将组合后的结果传入Transformer特有的Multi-head Self-attention进行特征提取。最后利用Cls Token进行分类。<br> <img src="https://images2.imgbox.com/70/86/uvZYINsl_o.png" alt="在这里插入图片描述"></p> 
<h1>
<a id="_10"></a>代码下载</h1> 
<p>Github源码下载地址为：<br> https://github.com/bubbliiiing/classification-keras<br> 复制该路径到地址栏跳转。</p> 
<h1>
<a id="Vision_Transforme_14"></a>Vision Transforme的实现思路</h1> 
<h2>
<a id="_15"></a>一、整体结构解析</h2> 
<p><img src="https://images2.imgbox.com/70/86/uvZYINsl_o.png" alt="在这里插入图片描述"><br> 与寻常的分类网络类似，整个Vision Transformer可以氛围两部分，一部分是特征提取部分，另一部分是分类部分。</p> 
<p>在特征提取部分，VIT所做的工作是特征提取。特征提取部分在图片中的对应区域是Patch+Position Embedding和Transformer Encoder。Patch+Position Embedding的作用<strong>主要是对输入进来的图片进行分块处理</strong>，每隔一定的区域大小划分图片块。然后<strong>将划分后的图片块组合成序列</strong>。在获得序列信息后，传入Transformer Encoder进行特征提取，这是Transformer特有的Multi-head Self-attention结构，<strong>通过自注意力机制，关注每个图片块的重要程度。</strong></p> 
<p>在分类部分，VIT所做的工作是利用提取到的特征进行分类。在进行特征提取的时候，我们会在图片序列中添加上Cls Token，<strong>该Token会作为一个单位的序列信息</strong>一起进行特征提取，提取的过程中，<strong>该Cls Token会与其它的特征进行特征交互，融合其它图片序列的特征</strong>。最终，我们利用Multi-head Self-attention结构提取特征后的Cls Token进行全连接分类。</p> 
<h2>
<a id="_23"></a>二、网络结构解析</h2> 
<h3>
<a id="1_24"></a>1、特征提取部分介绍</h3> 
<h4>
<a id="aPatchPosition_Embedding_25"></a>a、Patch+Position Embedding</h4> 
<p><img src="https://images2.imgbox.com/ba/25/Ma824orx_o.png" alt="在这里插入图片描述"><br> Patch+Position Embedding的作用<strong>主要是对输入进来的图片进行分块处理</strong>，每隔一定的区域大小划分图片块。然后<strong>将划分后的图片块组合成序列</strong>。</p> 
<p>该部分首先对输入进来的图片进行分块处理，处理方式其实很简单，<strong>使用的是现成的卷积</strong>。由于卷积使用的是<strong>滑动窗口的思想</strong>，我们只需要<strong>设定特定的步长</strong>，就可以输入进来的图片进行<strong>分块处理了</strong>。</p> 
<p>在VIT中，<strong>我们常设置这个卷积的卷积核大小为16x16，步长也为16x16</strong>，此时卷积就会每隔16个像素点进行一次特征提取，由于卷积核大小为16x16，<strong>两个图片区域的特征提取过程就不会有重叠</strong>。<strong>当我们输入的图片是224, 224, 3的时候，我们可以获得一个14, 14, 768的特征层。</strong><br> <img src="https://images2.imgbox.com/b4/d7/VVUcu2qB_o.gif" alt="请添加图片描述"><br> 下一步就是将这个特征层组合成序列，<strong>组合的方式非常简单，就是将高宽维度进行平铺</strong>，14, 14, 768在高宽维度平铺后，<strong>获得一个196, 768的特征层</strong>。平铺完成后，我们会在图片序列中添加上Cls Token，<strong>该Token会作为一个单位的序列信息</strong>一起进行特征提取，<strong>图中的这个0*就是Cls Token</strong>，我们此时<strong>获得一个197, 768的特征层</strong>。<img src="https://images2.imgbox.com/ec/dc/lctYftXM_o.png" alt="在这里插入图片描述"><br> 添加完成Cls Token后，再<strong>为所有特征添加上位置信息</strong>，<strong>这样网络才有区分不同区域的能力</strong>。添加方式其实也非常简单，我们生成一个<strong>197, 768的参数矩阵</strong>，这个参数矩阵是可训练的，把这个矩阵加上<strong>197, 768的特征层</strong>即可。</p> 
<p>到这里，Patch+Position Embedding就构建完成了，构建代码如下：</p> 
<pre><code class="prism language-python"><span class="token comment">#--------------------------------------------------------------------------------------------------------------------#</span>
<span class="token comment">#   classtoken部分是transformer的分类特征。用于堆叠到序列化后的图片特征中，作为一个单位的序列特征进行特征提取。</span>
<span class="token comment">#</span>
<span class="token comment">#   在利用步长为16x16的卷积将输入图片划分成14x14的部分后，将14x14部分的特征平铺，一幅图片会存在序列长度为196的特征。</span>
<span class="token comment">#   此时生成一个classtoken，将classtoken堆叠到序列长度为196的特征上，获得一个序列长度为197的特征。</span>
<span class="token comment">#   在特征提取的过程中，classtoken会与图片特征进行特征的交互。最终分类时，我们取出classtoken的特征，利用全连接分类。</span>
<span class="token comment">#--------------------------------------------------------------------------------------------------------------------#</span>
<span class="token keyword">class</span> <span class="token class-name">ClassToken</span><span class="token punctuation">(</span>Layer<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> cls_initializer<span class="token operator">=</span><span class="token string">'zeros'</span><span class="token punctuation">,</span> cls_regularizer<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> cls_constraint<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>ClassToken<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token operator">**</span>kwargs<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>cls_initializer    <span class="token operator">=</span> keras<span class="token punctuation">.</span>initializers<span class="token punctuation">.</span>get<span class="token punctuation">(</span>cls_initializer<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>cls_regularizer    <span class="token operator">=</span> keras<span class="token punctuation">.</span>regularizers<span class="token punctuation">.</span>get<span class="token punctuation">(</span>cls_regularizer<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>cls_constraint     <span class="token operator">=</span> keras<span class="token punctuation">.</span>constraints<span class="token punctuation">.</span>get<span class="token punctuation">(</span>cls_constraint<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">get_config</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        config <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
            <span class="token string">'cls_initializer'</span><span class="token punctuation">:</span> keras<span class="token punctuation">.</span>initializers<span class="token punctuation">.</span>serialize<span class="token punctuation">(</span>self<span class="token punctuation">.</span>cls_initializer<span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token string">'cls_regularizer'</span><span class="token punctuation">:</span> keras<span class="token punctuation">.</span>regularizers<span class="token punctuation">.</span>serialize<span class="token punctuation">(</span>self<span class="token punctuation">.</span>cls_regularizer<span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token string">'cls_constraint'</span><span class="token punctuation">:</span> keras<span class="token punctuation">.</span>constraints<span class="token punctuation">.</span>serialize<span class="token punctuation">(</span>self<span class="token punctuation">.</span>cls_constraint<span class="token punctuation">)</span><span class="token punctuation">,</span>
        <span class="token punctuation">}</span>
        base_config <span class="token operator">=</span> <span class="token builtin">super</span><span class="token punctuation">(</span>ClassToken<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>get_config<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token builtin">list</span><span class="token punctuation">(</span>base_config<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token builtin">list</span><span class="token punctuation">(</span>config<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">compute_output_shape</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> input_shape<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> <span class="token punctuation">(</span>input_shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> input_shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span> input_shape<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">build</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> input_shape<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>num_features <span class="token operator">=</span> input_shape<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>
        self<span class="token punctuation">.</span>cls <span class="token operator">=</span> self<span class="token punctuation">.</span>add_weight<span class="token punctuation">(</span>
            shape       <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>num_features<span class="token punctuation">)</span><span class="token punctuation">,</span>
            initializer <span class="token operator">=</span> self<span class="token punctuation">.</span>cls_initializer<span class="token punctuation">,</span>
            regularizer <span class="token operator">=</span> self<span class="token punctuation">.</span>cls_regularizer<span class="token punctuation">,</span>
            constraint  <span class="token operator">=</span> self<span class="token punctuation">.</span>cls_constraint<span class="token punctuation">,</span>
            name        <span class="token operator">=</span> <span class="token string">'cls'</span><span class="token punctuation">,</span>
        <span class="token punctuation">)</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>ClassToken<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>build<span class="token punctuation">(</span>input_shape<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">call</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> inputs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        batch_size      <span class="token operator">=</span> tf<span class="token punctuation">.</span>shape<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
        cls_broadcasted <span class="token operator">=</span> tf<span class="token punctuation">.</span>cast<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>broadcast_to<span class="token punctuation">(</span>self<span class="token punctuation">.</span>cls<span class="token punctuation">,</span> <span class="token punctuation">[</span>batch_size<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>num_features<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dtype <span class="token operator">=</span> inputs<span class="token punctuation">.</span>dtype<span class="token punctuation">)</span>
        <span class="token keyword">return</span> tf<span class="token punctuation">.</span>concat<span class="token punctuation">(</span><span class="token punctuation">[</span>cls_broadcasted<span class="token punctuation">,</span> inputs<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>

<span class="token comment">#--------------------------------------------------------------------------------------------------------------------#</span>
<span class="token comment">#   为网络提取到的特征添加上位置信息。</span>
<span class="token comment">#   以输入图片为224, 224, 3为例，我们获得的序列化后的图片特征为196, 768。加上classtoken后就是197, 768</span>
<span class="token comment">#   此时生成的pos_Embedding的shape也为197, 768，代表每一个特征的位置信息。</span>
<span class="token comment">#--------------------------------------------------------------------------------------------------------------------#</span>
<span class="token keyword">class</span> <span class="token class-name">AddPositionEmbs</span><span class="token punctuation">(</span>Layer<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> image_shape<span class="token punctuation">,</span> patch_size<span class="token punctuation">,</span> pe_initializer<span class="token operator">=</span><span class="token string">'zeros'</span><span class="token punctuation">,</span> pe_regularizer<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> pe_constraint<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>AddPositionEmbs<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token operator">**</span>kwargs<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>image_shape        <span class="token operator">=</span> image_shape
        self<span class="token punctuation">.</span>patch_size         <span class="token operator">=</span> patch_size
        self<span class="token punctuation">.</span>pe_initializer     <span class="token operator">=</span> keras<span class="token punctuation">.</span>initializers<span class="token punctuation">.</span>get<span class="token punctuation">(</span>pe_initializer<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>pe_regularizer     <span class="token operator">=</span> keras<span class="token punctuation">.</span>regularizers<span class="token punctuation">.</span>get<span class="token punctuation">(</span>pe_regularizer<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>pe_constraint      <span class="token operator">=</span> keras<span class="token punctuation">.</span>constraints<span class="token punctuation">.</span>get<span class="token punctuation">(</span>pe_constraint<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">get_config</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        config <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
            <span class="token string">'pe_initializer'</span><span class="token punctuation">:</span> keras<span class="token punctuation">.</span>initializers<span class="token punctuation">.</span>serialize<span class="token punctuation">(</span>self<span class="token punctuation">.</span>pe_initializer<span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token string">'pe_regularizer'</span><span class="token punctuation">:</span> keras<span class="token punctuation">.</span>regularizers<span class="token punctuation">.</span>serialize<span class="token punctuation">(</span>self<span class="token punctuation">.</span>pe_regularizer<span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token string">'pe_constraint'</span><span class="token punctuation">:</span> keras<span class="token punctuation">.</span>constraints<span class="token punctuation">.</span>serialize<span class="token punctuation">(</span>self<span class="token punctuation">.</span>pe_constraint<span class="token punctuation">)</span><span class="token punctuation">,</span>
        <span class="token punctuation">}</span>
        base_config <span class="token operator">=</span> <span class="token builtin">super</span><span class="token punctuation">(</span>AddPositionEmbs<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>get_config<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token builtin">list</span><span class="token punctuation">(</span>base_config<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token builtin">list</span><span class="token punctuation">(</span>config<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">compute_output_shape</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> input_shape<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> input_shape

    <span class="token keyword">def</span> <span class="token function">build</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> input_shape<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">assert</span> <span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>input_shape<span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string-interpolation"><span class="token string">f"Number of dimensions should be 3, got </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span><span class="token builtin">len</span><span class="token punctuation">(</span>input_shape<span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string">"</span></span>
        length  <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">224</span> <span class="token operator">//</span> self<span class="token punctuation">.</span>patch_size<span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token punctuation">(</span><span class="token number">224</span> <span class="token operator">//</span> self<span class="token punctuation">.</span>patch_size<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">1</span>
        self<span class="token punctuation">.</span>pe <span class="token operator">=</span> self<span class="token punctuation">.</span>add_weight<span class="token punctuation">(</span>
            <span class="token comment"># shape       = [1, input_shape[1], input_shape[2]],</span>
            shape       <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> length<span class="token punctuation">,</span> input_shape<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
            initializer <span class="token operator">=</span> self<span class="token punctuation">.</span>pe_initializer<span class="token punctuation">,</span>
            regularizer <span class="token operator">=</span> self<span class="token punctuation">.</span>pe_regularizer<span class="token punctuation">,</span>
            constraint  <span class="token operator">=</span> self<span class="token punctuation">.</span>pe_constraint<span class="token punctuation">,</span>
            name        <span class="token operator">=</span> <span class="token string">'pos_embedding'</span><span class="token punctuation">,</span>
        <span class="token punctuation">)</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>AddPositionEmbs<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>build<span class="token punctuation">(</span>input_shape<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">call</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> inputs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        num_features <span class="token operator">=</span> tf<span class="token punctuation">.</span>shape<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span>

        cls_token_pe <span class="token operator">=</span> self<span class="token punctuation">.</span>pe<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">:</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span>
        img_token_pe <span class="token operator">=</span> self<span class="token punctuation">.</span>pe<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">:</span> <span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span>

        img_token_pe <span class="token operator">=</span> tf<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>img_token_pe<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">224</span> <span class="token operator">//</span> self<span class="token punctuation">.</span>patch_size<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">224</span> <span class="token operator">//</span> self<span class="token punctuation">.</span>patch_size<span class="token punctuation">)</span><span class="token punctuation">,</span> num_features<span class="token punctuation">]</span><span class="token punctuation">)</span>
        img_token_pe <span class="token operator">=</span> tf<span class="token punctuation">.</span>image<span class="token punctuation">.</span>resize_bicubic<span class="token punctuation">(</span>img_token_pe<span class="token punctuation">,</span> <span class="token punctuation">(</span>self<span class="token punctuation">.</span>image_shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">//</span> self<span class="token punctuation">.</span>patch_size<span class="token punctuation">,</span> self<span class="token punctuation">.</span>image_shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">//</span> self<span class="token punctuation">.</span>patch_size<span class="token punctuation">)</span><span class="token punctuation">,</span> align_corners<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
        img_token_pe <span class="token operator">=</span> tf<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>img_token_pe<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> num_features<span class="token punctuation">]</span><span class="token punctuation">)</span>
        
        pe <span class="token operator">=</span> tf<span class="token punctuation">.</span>concat<span class="token punctuation">(</span><span class="token punctuation">[</span>cls_token_pe<span class="token punctuation">,</span> img_token_pe<span class="token punctuation">]</span><span class="token punctuation">,</span> axis <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">)</span>

        <span class="token keyword">return</span> inputs <span class="token operator">+</span> tf<span class="token punctuation">.</span>cast<span class="token punctuation">(</span>pe<span class="token punctuation">,</span> dtype<span class="token operator">=</span>inputs<span class="token punctuation">.</span>dtype<span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">VisionTransformer</span><span class="token punctuation">(</span>input_shape <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">224</span><span class="token punctuation">,</span> <span class="token number">224</span><span class="token punctuation">]</span><span class="token punctuation">,</span> patch_size <span class="token operator">=</span> <span class="token number">16</span><span class="token punctuation">,</span> num_layers <span class="token operator">=</span> <span class="token number">12</span><span class="token punctuation">,</span> num_features <span class="token operator">=</span> <span class="token number">768</span><span class="token punctuation">,</span> num_heads <span class="token operator">=</span> <span class="token number">12</span><span class="token punctuation">,</span> mlp_dim <span class="token operator">=</span> <span class="token number">3072</span><span class="token punctuation">,</span> 
            classes <span class="token operator">=</span> <span class="token number">1000</span><span class="token punctuation">,</span> dropout <span class="token operator">=</span> <span class="token number">0.1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment">#-----------------------------------------------#</span>
    <span class="token comment">#   224, 224, 3</span>
    <span class="token comment">#-----------------------------------------------#</span>
    inputs      <span class="token operator">=</span> Input<span class="token punctuation">(</span>shape <span class="token operator">=</span> <span class="token punctuation">(</span>input_shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> input_shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    
    <span class="token comment">#-----------------------------------------------#</span>
    <span class="token comment">#   224, 224, 3 -&gt; 14, 14, 768</span>
    <span class="token comment">#-----------------------------------------------#</span>
    x           <span class="token operator">=</span> Conv2D<span class="token punctuation">(</span>num_features<span class="token punctuation">,</span> patch_size<span class="token punctuation">,</span> strides <span class="token operator">=</span> patch_size<span class="token punctuation">,</span> padding <span class="token operator">=</span> <span class="token string">"valid"</span><span class="token punctuation">,</span> name <span class="token operator">=</span> <span class="token string">"patch_embed.proj"</span><span class="token punctuation">)</span><span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>
    <span class="token comment">#-----------------------------------------------#</span>
    <span class="token comment">#   14, 14, 768 -&gt; 196, 768</span>
    <span class="token comment">#-----------------------------------------------#</span>
    x           <span class="token operator">=</span> Reshape<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token punctuation">(</span>input_shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">//</span> patch_size<span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token punctuation">(</span>input_shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">//</span> patch_size<span class="token punctuation">)</span><span class="token punctuation">,</span> num_features<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    <span class="token comment">#-----------------------------------------------#</span>
    <span class="token comment">#   196, 768 -&gt; 197, 768</span>
    <span class="token comment">#-----------------------------------------------#</span>
    x           <span class="token operator">=</span> ClassToken<span class="token punctuation">(</span>name<span class="token operator">=</span><span class="token string">"cls_token"</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    <span class="token comment">#-----------------------------------------------#</span>
    <span class="token comment">#   197, 768 -&gt; 197, 768</span>
    <span class="token comment">#-----------------------------------------------#</span>
    x           <span class="token operator">=</span> AddPositionEmbs<span class="token punctuation">(</span>input_shape<span class="token punctuation">,</span> patch_size<span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">"pos_embed"</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
</code></pre> 
<h4>
<a id="bTransformer_Encoder_157"></a>b、Transformer Encoder</h4> 
<p><img src="https://images2.imgbox.com/70/86/uvZYINsl_o.png" alt="在这里插入图片描述"><br> 在上一步<strong>获得shape为197, 768的序列信息</strong>后，将<strong>序列信息传入Transformer Encoder进行特征提取</strong>，这是Transformer特有的Multi-head Self-attention结构，<strong>通过自注意力机制，关注每个图片块的重要程度。</strong></p> 
<h5>
<a id="ISelfattention_161"></a>I、Self-attention结构解析</h5> 
<p>看懂Self-attention结构，其实看懂下面这个动图就可以了，动图中存在<strong>一个序列的三个单位输入</strong>，<strong>每一个序列单位的输入</strong>都可以通过<strong>三个处理（比如全连接）获得Query、Key、Value</strong>，Query是查询向量、Key是键向量、Value值向量。<br> <img src="https://images2.imgbox.com/9c/a8/rAqs14a4_o.gif" alt="请添加图片描述"><br> 如果我们想要获得input-1的输出，那么我们进行如下几步：<br> 1、利用<strong>input-1的查询向量</strong>，分别乘上<strong>input-1、input-2、input-3的键向量</strong>，此时我们获得了<strong>三个score</strong>。<br> 2、然后对<strong>这三个score取softmax</strong>，获得了<strong>input-1、input-2、input-3</strong>各自的重要程度。<br> 3、然后将这个重要程度乘上<strong>input-1、input-2、input-3</strong>的值向量，求和。<br> 4、此时我们获得了input-1的输出。</p> 
<p>如图所示，我们进行如下几步：<br> 1、<strong>input-1的查询向量为[1, 0, 2]</strong>，分别乘上<strong>input-1、input-2、input-3的键向量</strong>，获得三个score为2，4，4。<br> 2、然后对<strong>这三个score取softmax</strong>，获得了<strong>input-1、input-2、input-3</strong>各自的重要程度，获得三个重要程度为0.0，0.5，0.5。<br> 3、然后将这个重要程度乘上<strong>input-1、input-2、input-3</strong>的值向量，求和，即<br> <span class="katex--inline"><span class="katex"><span class="katex-mathml">
    
     
      
       
        0.0
       
       
        ∗
       
       
        [
       
       
        1
       
       
        ,
       
       
        2
       
       
        ,
       
       
        3
       
       
        ]
       
       
        +
       
       
        0.5
       
       
        ∗
       
       
        [
       
       
        2
       
       
        ,
       
       
        8
       
       
        ,
       
       
        0
       
       
        ]
       
       
        +
       
       
        0.5
       
       
        ∗
       
       
        [
       
       
        2
       
       
        ,
       
       
        6
       
       
        ,
       
       
        3
       
       
        ]
       
       
        =
       
       
        [
       
       
        1.0
       
       
        ,
       
       
        3.0
       
       
        ,
       
       
        1.5
       
       
        ]
       
      
      
       0.0 * [1, 2, 3] + 0.5 * [2, 8, 0] + 0.5 * [2, 6, 3] = [1.0, 3.0, 1.5]
      
     
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.64444em;vertical-align: 0em"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">0</span><span class="mspace" style="margin-right: 0.222222em"></span><span class="mbin">∗</span><span class="mspace" style="margin-right: 0.222222em"></span></span><span class="base"><span class="strut" style="height: 1em;vertical-align: -0.25em"></span><span class="mopen">[</span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.166667em"></span><span class="mord">2</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.166667em"></span><span class="mord">3</span><span class="mclose">]</span><span class="mspace" style="margin-right: 0.222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.222222em"></span></span><span class="base"><span class="strut" style="height: 0.64444em;vertical-align: 0em"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">5</span><span class="mspace" style="margin-right: 0.222222em"></span><span class="mbin">∗</span><span class="mspace" style="margin-right: 0.222222em"></span></span><span class="base"><span class="strut" style="height: 1em;vertical-align: -0.25em"></span><span class="mopen">[</span><span class="mord">2</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.166667em"></span><span class="mord">8</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.166667em"></span><span class="mord">0</span><span class="mclose">]</span><span class="mspace" style="margin-right: 0.222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.222222em"></span></span><span class="base"><span class="strut" style="height: 0.64444em;vertical-align: 0em"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">5</span><span class="mspace" style="margin-right: 0.222222em"></span><span class="mbin">∗</span><span class="mspace" style="margin-right: 0.222222em"></span></span><span class="base"><span class="strut" style="height: 1em;vertical-align: -0.25em"></span><span class="mopen">[</span><span class="mord">2</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.166667em"></span><span class="mord">6</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.166667em"></span><span class="mord">3</span><span class="mclose">]</span><span class="mspace" style="margin-right: 0.277778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em"></span></span><span class="base"><span class="strut" style="height: 1em;vertical-align: -0.25em"></span><span class="mopen">[</span><span class="mord">1</span><span class="mord">.</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.166667em"></span><span class="mord">3</span><span class="mord">.</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.166667em"></span><span class="mord">1</span><span class="mord">.</span><span class="mord">5</span><span class="mclose">]</span></span></span></span></span>。<br> 4、此时我们获得了input-1的输出 [1.0, 3.0, 1.5]。</p> 
<p>上述的例子中，<strong>序列长度仅为3，每个单位序列的特征长度仅为3</strong>，在VIT的Transformer Encoder中，<strong>序列长度为197，每个单位序列的特征长度为768 // num_heads</strong>。但计算过程是一样的。在实际运算时，<strong>我们采用矩阵进行运算。</strong></p> 
<h5>
<a id="IISelfattention_178"></a>II、Self-attention的矩阵运算</h5> 
<p>实际的矩阵运算过程如下图所示。我以实际矩阵为例子给大家解析：<br> <img src="https://images2.imgbox.com/b8/49/vtwiRYf7_o.png" alt="在这里插入图片描述"><br> 输入的Query、Key、Value如下图所示：<br> <img src="https://images2.imgbox.com/46/c5/NZNg1yZO_o.png" alt="在这里插入图片描述"><br> 首先利用 <strong>查询向量query</strong> 点乘 <strong>转置后的键向量key</strong>，这一步可以通俗的理解为，<strong>利用查询向量去查询序列的特征，获得序列每个部分的重要程度score。</strong></p> 
<p><strong>输出的每一行，都代表input-1、input-2、input-3，对当前input的贡献</strong>，我们对这个贡献值取一个softmax。<br> <img src="https://images2.imgbox.com/83/47/W9R1ew0J_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/18/28/belqBQj5_o.png" alt="在这里插入图片描述"><br> 然后利用 score 点乘 value，<strong>这一步可以通俗的理解为，将序列每个部分的重要程度重新施加到序列的值上去。</strong><br> <img src="https://images2.imgbox.com/67/d7/8JXIUmlS_o.png" alt="在这里插入图片描述"><br> 这个矩阵运算的代码如下所示，各位同学可以自己试试。</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np

<span class="token keyword">def</span> <span class="token function">soft_max</span><span class="token punctuation">(</span>z<span class="token punctuation">)</span><span class="token punctuation">:</span>
    t <span class="token operator">=</span> np<span class="token punctuation">.</span>exp<span class="token punctuation">(</span>z<span class="token punctuation">)</span>
    a <span class="token operator">=</span> np<span class="token punctuation">.</span>exp<span class="token punctuation">(</span>z<span class="token punctuation">)</span> <span class="token operator">/</span> np<span class="token punctuation">.</span>expand_dims<span class="token punctuation">(</span>np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>t<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> a

Query <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span>
    <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span>
<span class="token punctuation">]</span><span class="token punctuation">)</span>

Key <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span>
    <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    <span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span>
<span class="token punctuation">]</span><span class="token punctuation">)</span>

Value <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span>
    <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span>
<span class="token punctuation">]</span><span class="token punctuation">)</span>

scores <span class="token operator">=</span> Query @ Key<span class="token punctuation">.</span>T
<span class="token keyword">print</span><span class="token punctuation">(</span>scores<span class="token punctuation">)</span>
scores <span class="token operator">=</span> soft_max<span class="token punctuation">(</span>scores<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>scores<span class="token punctuation">)</span>
out <span class="token operator">=</span> scores @ Value
<span class="token keyword">print</span><span class="token punctuation">(</span>out<span class="token punctuation">)</span>
</code></pre> 
<h5>
<a id="IIIMultiHead_224"></a>III、MultiHead多头注意力机制</h5> 
<p>多头注意力机制的示意图如图所示：<br> <img src="https://images2.imgbox.com/5d/b6/ENjB2Ppr_o.png" alt="在这里插入图片描述"><br> 这幅图给人的感觉略显迷茫，我们跳脱出这个图，<strong>直接从矩阵的shape入手会清晰很多。</strong></p> 
<p>在第一步进行图像的分割后，我们获得的特征层为197, 768。</p> 
<p>在施加多头的时候，<strong>我们直接对196, 768的最后一维度进行分割，比如我们想分割成12个头，那么矩阵的shepe就变成了196, 12, 64。</strong></p> 
<p>然后我们将196, 12, 64进行转置，将12放到前面去，获得的特征层为12, 196, 64。<strong>之后我们忽略这个12，把它和batch维度同等对待</strong>，<strong>只对196, 64进行处理</strong>，<strong>其实也就是上面的注意力机制的过程了</strong>。</p> 
<pre><code class="prism language-python"><span class="token comment">#--------------------------------------------------------------------------------------------------------------------#</span>
<span class="token comment">#   Attention机制</span>
<span class="token comment">#   将输入的特征qkv特征进行划分，首先生成query, key, value。query是查询向量、key是键向量、v是值向量。</span>
<span class="token comment">#   然后利用 查询向量query 点乘 转置后的键向量key，这一步可以通俗的理解为，利用查询向量去查询序列的特征，获得序列每个部分的重要程度score。</span>
<span class="token comment">#   然后利用 score 点乘 value，这一步可以通俗的理解为，将序列每个部分的重要程度重新施加到序列的值上去。</span>
<span class="token comment">#--------------------------------------------------------------------------------------------------------------------#</span>
<span class="token keyword">class</span> <span class="token class-name">Attention</span><span class="token punctuation">(</span>Layer<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> num_features<span class="token punctuation">,</span> num_heads<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>Attention<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token operator">**</span>kwargs<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>num_features   <span class="token operator">=</span> num_features
        self<span class="token punctuation">.</span>num_heads      <span class="token operator">=</span> num_heads
        self<span class="token punctuation">.</span>projection_dim <span class="token operator">=</span> num_features <span class="token operator">//</span> num_heads

    <span class="token keyword">def</span> <span class="token function">compute_output_shape</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> input_shape<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> <span class="token punctuation">(</span>input_shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> input_shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> input_shape<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span> <span class="token operator">//</span> <span class="token number">3</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">call</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> inputs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment">#-----------------------------------------------#</span>
        <span class="token comment">#   获得batch_size</span>
        <span class="token comment">#-----------------------------------------------#</span>
        bs      <span class="token operator">=</span> tf<span class="token punctuation">.</span>shape<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>

        <span class="token comment">#-----------------------------------------------#</span>
        <span class="token comment">#   b, 197, 3 * 768 -&gt; b, 197, 3, 12, 64</span>
        <span class="token comment">#-----------------------------------------------#</span>
        inputs  <span class="token operator">=</span> tf<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>inputs<span class="token punctuation">,</span> <span class="token punctuation">[</span>bs<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>num_heads<span class="token punctuation">,</span> self<span class="token punctuation">.</span>projection_dim<span class="token punctuation">]</span><span class="token punctuation">)</span>
        <span class="token comment">#-----------------------------------------------#</span>
        <span class="token comment">#   b, 197, 3, 12, 64 -&gt; 3, b, 12, 197, 64</span>
        <span class="token comment">#-----------------------------------------------#</span>
        inputs  <span class="token operator">=</span> tf<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span>inputs<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        <span class="token comment">#-----------------------------------------------#</span>
        <span class="token comment">#   将query, key, value划分开</span>
        <span class="token comment">#   query     b, 12, 197, 64</span>
        <span class="token comment">#   key       b, 12, 197, 64</span>
        <span class="token comment">#   value     b, 12, 197, 64</span>
        <span class="token comment">#-----------------------------------------------#</span>
        query<span class="token punctuation">,</span> key<span class="token punctuation">,</span> value <span class="token operator">=</span> inputs<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> inputs<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> inputs<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span>
        <span class="token comment">#-----------------------------------------------#</span>
        <span class="token comment">#   b, 12, 197, 64 @ b, 12, 197, 64 = b, 12, 197, 197</span>
        <span class="token comment">#-----------------------------------------------#</span>
        score           <span class="token operator">=</span> tf<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>query<span class="token punctuation">,</span> key<span class="token punctuation">,</span> transpose_b<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
        <span class="token comment">#-----------------------------------------------#</span>
        <span class="token comment">#   进行数量级的缩放</span>
        <span class="token comment">#-----------------------------------------------#</span>
        scaled_score    <span class="token operator">=</span> score <span class="token operator">/</span> tf<span class="token punctuation">.</span>math<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>cast<span class="token punctuation">(</span>self<span class="token punctuation">.</span>projection_dim<span class="token punctuation">,</span> score<span class="token punctuation">.</span>dtype<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token comment">#-----------------------------------------------#</span>
        <span class="token comment">#   b, 12, 197, 197 -&gt; b, 12, 197, 197</span>
        <span class="token comment">#-----------------------------------------------#</span>
        weights         <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>scaled_score<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
        <span class="token comment">#-----------------------------------------------#</span>
        <span class="token comment">#   b, 12, 197, 197 @ b, 12, 197, 64 = b, 12, 197, 64</span>
        <span class="token comment">#-----------------------------------------------#</span>
        value          <span class="token operator">=</span> tf<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>weights<span class="token punctuation">,</span> value<span class="token punctuation">)</span>

        <span class="token comment">#-----------------------------------------------#</span>
        <span class="token comment">#   b, 12, 197, 64 -&gt; b, 197, 12, 64</span>
        <span class="token comment">#-----------------------------------------------#</span>
        value <span class="token operator">=</span> tf<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span>value<span class="token punctuation">,</span> perm<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        <span class="token comment">#-----------------------------------------------#</span>
        <span class="token comment">#   b, 197, 12, 64 -&gt; b, 197, 768</span>
        <span class="token comment">#-----------------------------------------------#</span>
        output <span class="token operator">=</span> tf<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>value<span class="token punctuation">,</span> <span class="token punctuation">(</span>tf<span class="token punctuation">.</span>shape<span class="token punctuation">(</span>value<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> tf<span class="token punctuation">.</span>shape<span class="token punctuation">(</span>value<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> output

<span class="token keyword">def</span> <span class="token function">MultiHeadSelfAttention</span><span class="token punctuation">(</span>inputs<span class="token punctuation">,</span> num_features<span class="token punctuation">,</span> num_heads<span class="token punctuation">,</span> dropout<span class="token punctuation">,</span> name<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment">#-----------------------------------------------#</span>
    <span class="token comment">#   qkv   b, 197, 768 -&gt; b, 197, 3 * 768</span>
    <span class="token comment">#-----------------------------------------------#</span>
    qkv <span class="token operator">=</span> Dense<span class="token punctuation">(</span><span class="token builtin">int</span><span class="token punctuation">(</span>num_features <span class="token operator">*</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> name <span class="token operator">=</span> name <span class="token operator">+</span> <span class="token string">"qkv"</span><span class="token punctuation">)</span><span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>
    <span class="token comment">#-----------------------------------------------#</span>
    <span class="token comment">#   b, 197, 3 * 768 -&gt; b, 197, 768</span>
    <span class="token comment">#-----------------------------------------------#</span>
    x   <span class="token operator">=</span> Attention<span class="token punctuation">(</span>num_features<span class="token punctuation">,</span> num_heads<span class="token punctuation">)</span><span class="token punctuation">(</span>qkv<span class="token punctuation">)</span>
    <span class="token comment">#-----------------------------------------------#</span>
    <span class="token comment">#   197, 768 -&gt; 197, 768</span>
    <span class="token comment">#-----------------------------------------------#</span>
    x   <span class="token operator">=</span> Dense<span class="token punctuation">(</span>num_features<span class="token punctuation">,</span> name <span class="token operator">=</span> name <span class="token operator">+</span> <span class="token string">"proj"</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    x   <span class="token operator">=</span> Dropout<span class="token punctuation">(</span>dropout<span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    <span class="token keyword">return</span> x
</code></pre> 
<h5>
<a id="IVTransformerBlock_315"></a>IV、TransformerBlock的构建。</h5> 
<p><img src="https://images2.imgbox.com/47/c8/8arqcAw9_o.png" alt="在这里插入图片描述"></p> 
<p><strong>在完成MultiHeadSelfAttention的构建后，我们需要在其后加上两个全连接。就构建了整个TransformerBlock。</strong></p> 
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">MLP</span><span class="token punctuation">(</span>y<span class="token punctuation">,</span> num_features<span class="token punctuation">,</span> mlp_dim<span class="token punctuation">,</span> dropout<span class="token punctuation">,</span> name<span class="token punctuation">)</span><span class="token punctuation">:</span>
    y <span class="token operator">=</span> Dense<span class="token punctuation">(</span>mlp_dim<span class="token punctuation">,</span> name <span class="token operator">=</span> name <span class="token operator">+</span> <span class="token string">"fc1"</span><span class="token punctuation">)</span><span class="token punctuation">(</span>y<span class="token punctuation">)</span>
    y <span class="token operator">=</span> Gelu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">(</span>y<span class="token punctuation">)</span>
    y <span class="token operator">=</span> Dropout<span class="token punctuation">(</span>dropout<span class="token punctuation">)</span><span class="token punctuation">(</span>y<span class="token punctuation">)</span>
    y <span class="token operator">=</span> Dense<span class="token punctuation">(</span>num_features<span class="token punctuation">,</span> name <span class="token operator">=</span> name <span class="token operator">+</span> <span class="token string">"fc2"</span><span class="token punctuation">)</span><span class="token punctuation">(</span>y<span class="token punctuation">)</span>
    <span class="token keyword">return</span> y

<span class="token keyword">def</span> <span class="token function">TransformerBlock</span><span class="token punctuation">(</span>inputs<span class="token punctuation">,</span> num_features<span class="token punctuation">,</span> num_heads<span class="token punctuation">,</span> mlp_dim<span class="token punctuation">,</span> dropout<span class="token punctuation">,</span> name<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment">#-----------------------------------------------#</span>
    <span class="token comment">#   施加层标准化</span>
    <span class="token comment">#-----------------------------------------------#</span>
    x <span class="token operator">=</span> LayerNormalization<span class="token punctuation">(</span>epsilon<span class="token operator">=</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">6</span><span class="token punctuation">,</span> name <span class="token operator">=</span> name <span class="token operator">+</span> <span class="token string">"norm1"</span><span class="token punctuation">)</span><span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>
    <span class="token comment">#-----------------------------------------------#</span>
    <span class="token comment">#   施加多头注意力机制</span>
    <span class="token comment">#-----------------------------------------------#</span>
    x <span class="token operator">=</span> MultiHeadSelfAttention<span class="token punctuation">(</span>x<span class="token punctuation">,</span> num_features<span class="token punctuation">,</span> num_heads<span class="token punctuation">,</span> dropout<span class="token punctuation">,</span> name <span class="token operator">=</span> name <span class="token operator">+</span> <span class="token string">"attn."</span><span class="token punctuation">)</span>
    x <span class="token operator">=</span> Dropout<span class="token punctuation">(</span>dropout<span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    <span class="token comment">#-----------------------------------------------#</span>
    <span class="token comment">#   施加残差结构</span>
    <span class="token comment">#-----------------------------------------------#</span>
    x <span class="token operator">=</span> Add<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">(</span><span class="token punctuation">[</span>x<span class="token punctuation">,</span> inputs<span class="token punctuation">]</span><span class="token punctuation">)</span>

    <span class="token comment">#-----------------------------------------------#</span>
    <span class="token comment">#   施加层标准化</span>
    <span class="token comment">#-----------------------------------------------#</span>
    y <span class="token operator">=</span> LayerNormalization<span class="token punctuation">(</span>epsilon<span class="token operator">=</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">6</span><span class="token punctuation">,</span> name <span class="token operator">=</span> name <span class="token operator">+</span> <span class="token string">"norm2"</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    <span class="token comment">#-----------------------------------------------#</span>
    <span class="token comment">#   施加两次全连接</span>
    <span class="token comment">#-----------------------------------------------#</span>
    y <span class="token operator">=</span> MLP<span class="token punctuation">(</span>y<span class="token punctuation">,</span> num_features<span class="token punctuation">,</span> mlp_dim<span class="token punctuation">,</span> dropout<span class="token punctuation">,</span> name <span class="token operator">=</span> name <span class="token operator">+</span> <span class="token string">"mlp."</span><span class="token punctuation">)</span>
    y <span class="token operator">=</span> Dropout<span class="token punctuation">(</span>dropout<span class="token punctuation">)</span><span class="token punctuation">(</span>y<span class="token punctuation">)</span>
    <span class="token comment">#-----------------------------------------------#</span>
    <span class="token comment">#   施加残差结构</span>
    <span class="token comment">#-----------------------------------------------#</span>
    y <span class="token operator">=</span> Add<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">(</span><span class="token punctuation">[</span>x<span class="token punctuation">,</span> y<span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> y
</code></pre> 
<h4>
<a id="cVIT_358"></a>c、整个VIT模型的构建</h4> 
<p><img src="https://images2.imgbox.com/70/86/uvZYINsl_o.png" alt="在这里插入图片描述"><br> 整个VIT模型由一个Patch+Position Embedding加上多个TransformerBlock组成。典型的TransforerBlock的数量为12个。</p> 
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">VisionTransformer</span><span class="token punctuation">(</span>input_shape <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">224</span><span class="token punctuation">,</span> <span class="token number">224</span><span class="token punctuation">]</span><span class="token punctuation">,</span> patch_size <span class="token operator">=</span> <span class="token number">16</span><span class="token punctuation">,</span> num_layers <span class="token operator">=</span> <span class="token number">12</span><span class="token punctuation">,</span> num_features <span class="token operator">=</span> <span class="token number">768</span><span class="token punctuation">,</span> num_heads <span class="token operator">=</span> <span class="token number">12</span><span class="token punctuation">,</span> mlp_dim <span class="token operator">=</span> <span class="token number">3072</span><span class="token punctuation">,</span> 
            classes <span class="token operator">=</span> <span class="token number">1000</span><span class="token punctuation">,</span> dropout <span class="token operator">=</span> <span class="token number">0.1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment">#-----------------------------------------------#</span>
    <span class="token comment">#   224, 224, 3</span>
    <span class="token comment">#-----------------------------------------------#</span>
    inputs      <span class="token operator">=</span> Input<span class="token punctuation">(</span>shape <span class="token operator">=</span> <span class="token punctuation">(</span>input_shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> input_shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    
    <span class="token comment">#-----------------------------------------------#</span>
    <span class="token comment">#   224, 224, 3 -&gt; 14, 14, 768</span>
    <span class="token comment">#-----------------------------------------------#</span>
    x           <span class="token operator">=</span> Conv2D<span class="token punctuation">(</span>num_features<span class="token punctuation">,</span> patch_size<span class="token punctuation">,</span> strides <span class="token operator">=</span> patch_size<span class="token punctuation">,</span> padding <span class="token operator">=</span> <span class="token string">"valid"</span><span class="token punctuation">,</span> name <span class="token operator">=</span> <span class="token string">"patch_embed.proj"</span><span class="token punctuation">)</span><span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>
    <span class="token comment">#-----------------------------------------------#</span>
    <span class="token comment">#   14, 14, 768 -&gt; 196, 768</span>
    <span class="token comment">#-----------------------------------------------#</span>
    x           <span class="token operator">=</span> Reshape<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token punctuation">(</span>input_shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">//</span> patch_size<span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token punctuation">(</span>input_shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">//</span> patch_size<span class="token punctuation">)</span><span class="token punctuation">,</span> num_features<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    <span class="token comment">#-----------------------------------------------#</span>
    <span class="token comment">#   196, 768 -&gt; 197, 768</span>
    <span class="token comment">#-----------------------------------------------#</span>
    x           <span class="token operator">=</span> ClassToken<span class="token punctuation">(</span>name<span class="token operator">=</span><span class="token string">"cls_token"</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    <span class="token comment">#-----------------------------------------------#</span>
    <span class="token comment">#   197, 768 -&gt; 197, 768</span>
    <span class="token comment">#-----------------------------------------------#</span>
    x           <span class="token operator">=</span> AddPositionEmbs<span class="token punctuation">(</span>input_shape<span class="token punctuation">,</span> patch_size<span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">"pos_embed"</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    <span class="token comment">#-----------------------------------------------#</span>
    <span class="token comment">#   197, 768 -&gt; 197, 768  12次</span>
    <span class="token comment">#-----------------------------------------------#</span>
    <span class="token keyword">for</span> n <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_layers<span class="token punctuation">)</span><span class="token punctuation">:</span>
        x <span class="token operator">=</span> TransformerBlock<span class="token punctuation">(</span>
            x<span class="token punctuation">,</span>
            num_features<span class="token operator">=</span> num_features<span class="token punctuation">,</span>
            num_heads   <span class="token operator">=</span> num_heads<span class="token punctuation">,</span>
            mlp_dim     <span class="token operator">=</span> mlp_dim<span class="token punctuation">,</span>
            dropout     <span class="token operator">=</span> dropout<span class="token punctuation">,</span>
            name        <span class="token operator">=</span> <span class="token string">"blocks."</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>n<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">"."</span><span class="token punctuation">,</span>
        <span class="token punctuation">)</span>
    x <span class="token operator">=</span> LayerNormalization<span class="token punctuation">(</span>
        epsilon<span class="token operator">=</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">6</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">"norm"</span>
    <span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
</code></pre> 
<h3>
<a id="2_403"></a>2、分类部分</h3> 
<p><img src="https://images2.imgbox.com/70/86/uvZYINsl_o.png" alt="在这里插入图片描述"><br> 在分类部分，VIT所做的工作是利用提取到的特征进行分类。</p> 
<p>在进行特征提取的时候，我们会在图片序列中添加上Cls Token，<strong>该Token会作为一个单位的序列信息</strong>一起进行特征提取，提取的过程中，<strong>该Cls Token会与其它的特征进行特征交互，融合其它图片序列的特征</strong>。</p> 
<p>最终，我们利用Multi-head Self-attention结构提取特征后的Cls Token进行<strong>全连接分类</strong>。</p> 
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">VisionTransformer</span><span class="token punctuation">(</span>input_shape <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">224</span><span class="token punctuation">,</span> <span class="token number">224</span><span class="token punctuation">]</span><span class="token punctuation">,</span> patch_size <span class="token operator">=</span> <span class="token number">16</span><span class="token punctuation">,</span> num_layers <span class="token operator">=</span> <span class="token number">12</span><span class="token punctuation">,</span> num_features <span class="token operator">=</span> <span class="token number">768</span><span class="token punctuation">,</span> num_heads <span class="token operator">=</span> <span class="token number">12</span><span class="token punctuation">,</span> mlp_dim <span class="token operator">=</span> <span class="token number">3072</span><span class="token punctuation">,</span> 
            classes <span class="token operator">=</span> <span class="token number">1000</span><span class="token punctuation">,</span> dropout <span class="token operator">=</span> <span class="token number">0.1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment">#-----------------------------------------------#</span>
    <span class="token comment">#   224, 224, 3</span>
    <span class="token comment">#-----------------------------------------------#</span>
    inputs      <span class="token operator">=</span> Input<span class="token punctuation">(</span>shape <span class="token operator">=</span> <span class="token punctuation">(</span>input_shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> input_shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    
    <span class="token comment">#-----------------------------------------------#</span>
    <span class="token comment">#   224, 224, 3 -&gt; 14, 14, 768</span>
    <span class="token comment">#-----------------------------------------------#</span>
    x           <span class="token operator">=</span> Conv2D<span class="token punctuation">(</span>num_features<span class="token punctuation">,</span> patch_size<span class="token punctuation">,</span> strides <span class="token operator">=</span> patch_size<span class="token punctuation">,</span> padding <span class="token operator">=</span> <span class="token string">"valid"</span><span class="token punctuation">,</span> name <span class="token operator">=</span> <span class="token string">"patch_embed.proj"</span><span class="token punctuation">)</span><span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>
    <span class="token comment">#-----------------------------------------------#</span>
    <span class="token comment">#   14, 14, 768 -&gt; 196, 768</span>
    <span class="token comment">#-----------------------------------------------#</span>
    x           <span class="token operator">=</span> Reshape<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token punctuation">(</span>input_shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">//</span> patch_size<span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token punctuation">(</span>input_shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">//</span> patch_size<span class="token punctuation">)</span><span class="token punctuation">,</span> num_features<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    <span class="token comment">#-----------------------------------------------#</span>
    <span class="token comment">#   196, 768 -&gt; 197, 768</span>
    <span class="token comment">#-----------------------------------------------#</span>
    x           <span class="token operator">=</span> ClassToken<span class="token punctuation">(</span>name<span class="token operator">=</span><span class="token string">"cls_token"</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    <span class="token comment">#-----------------------------------------------#</span>
    <span class="token comment">#   197, 768 -&gt; 197, 768</span>
    <span class="token comment">#-----------------------------------------------#</span>
    x           <span class="token operator">=</span> AddPositionEmbs<span class="token punctuation">(</span>input_shape<span class="token punctuation">,</span> patch_size<span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">"pos_embed"</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    <span class="token comment">#-----------------------------------------------#</span>
    <span class="token comment">#   197, 768 -&gt; 197, 768  12次</span>
    <span class="token comment">#-----------------------------------------------#</span>
    <span class="token keyword">for</span> n <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_layers<span class="token punctuation">)</span><span class="token punctuation">:</span>
        x <span class="token operator">=</span> TransformerBlock<span class="token punctuation">(</span>
            x<span class="token punctuation">,</span>
            num_features<span class="token operator">=</span> num_features<span class="token punctuation">,</span>
            num_heads   <span class="token operator">=</span> num_heads<span class="token punctuation">,</span>
            mlp_dim     <span class="token operator">=</span> mlp_dim<span class="token punctuation">,</span>
            dropout     <span class="token operator">=</span> dropout<span class="token punctuation">,</span>
            name        <span class="token operator">=</span> <span class="token string">"blocks."</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>n<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">"."</span><span class="token punctuation">,</span>
        <span class="token punctuation">)</span>
    x <span class="token operator">=</span> LayerNormalization<span class="token punctuation">(</span>
        epsilon<span class="token operator">=</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">6</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">"norm"</span>
    <span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    x <span class="token operator">=</span> Lambda<span class="token punctuation">(</span><span class="token keyword">lambda</span> v<span class="token punctuation">:</span> v<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">"ExtractToken"</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    x <span class="token operator">=</span> Dense<span class="token punctuation">(</span>classes<span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">"head"</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    x <span class="token operator">=</span> Softmax<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    <span class="token keyword">return</span> keras<span class="token punctuation">.</span>models<span class="token punctuation">.</span>Model<span class="token punctuation">(</span>inputs<span class="token punctuation">,</span> x<span class="token punctuation">)</span>
</code></pre> 
<h1>
<a id="Vision_Transforme_454"></a>Vision Transforme的构建代码</h1> 
<pre><code class="prism language-python"><span class="token keyword">import</span> math

<span class="token keyword">import</span> keras
<span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tf
<span class="token keyword">from</span> keras <span class="token keyword">import</span> backend <span class="token keyword">as</span> K
<span class="token keyword">from</span> keras<span class="token punctuation">.</span>layers <span class="token keyword">import</span> <span class="token punctuation">(</span>Add<span class="token punctuation">,</span> Conv2D<span class="token punctuation">,</span> Dense<span class="token punctuation">,</span> Dropout<span class="token punctuation">,</span> Input<span class="token punctuation">,</span> Lambda<span class="token punctuation">,</span> Layer<span class="token punctuation">,</span>
                          Reshape<span class="token punctuation">,</span> Softmax<span class="token punctuation">)</span>


<span class="token comment">#--------------------------------------#</span>
<span class="token comment">#   LayerNormalization</span>
<span class="token comment">#   层标准化的实现</span>
<span class="token comment">#--------------------------------------#</span>
<span class="token keyword">class</span> <span class="token class-name">LayerNormalization</span><span class="token punctuation">(</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Layer<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>
                 center<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
                 scale<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
                 epsilon<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span>
                 gamma_initializer<span class="token operator">=</span><span class="token string">'ones'</span><span class="token punctuation">,</span>
                 beta_initializer<span class="token operator">=</span><span class="token string">'zeros'</span><span class="token punctuation">,</span>
                 gamma_regularizer<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span>
                 beta_regularizer<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span>
                 gamma_constraint<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span>
                 beta_constraint<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span>
                 <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""Layer normalization layer

        See: [Layer Normalization](https://arxiv.org/pdf/1607.06450.pdf)

        :param center: Add an offset parameter if it is True.
        :param scale: Add a scale parameter if it is True.
        :param epsilon: Epsilon for calculating variance.
        :param gamma_initializer: Initializer for the gamma weight.
        :param beta_initializer: Initializer for the beta weight.
        :param gamma_regularizer: Optional regularizer for the gamma weight.
        :param beta_regularizer: Optional regularizer for the beta weight.
        :param gamma_constraint: Optional constraint for the gamma weight.
        :param beta_constraint: Optional constraint for the beta weight.
        :param kwargs:
        """</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>LayerNormalization<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token operator">**</span>kwargs<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>supports_masking <span class="token operator">=</span> <span class="token boolean">True</span>
        self<span class="token punctuation">.</span>center <span class="token operator">=</span> center
        self<span class="token punctuation">.</span>scale <span class="token operator">=</span> scale
        <span class="token keyword">if</span> epsilon <span class="token keyword">is</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            epsilon <span class="token operator">=</span> K<span class="token punctuation">.</span>epsilon<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">*</span> K<span class="token punctuation">.</span>epsilon<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>epsilon <span class="token operator">=</span> epsilon
        self<span class="token punctuation">.</span>gamma_initializer <span class="token operator">=</span> keras<span class="token punctuation">.</span>initializers<span class="token punctuation">.</span>get<span class="token punctuation">(</span>gamma_initializer<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>beta_initializer <span class="token operator">=</span> keras<span class="token punctuation">.</span>initializers<span class="token punctuation">.</span>get<span class="token punctuation">(</span>beta_initializer<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>gamma_regularizer <span class="token operator">=</span> keras<span class="token punctuation">.</span>regularizers<span class="token punctuation">.</span>get<span class="token punctuation">(</span>gamma_regularizer<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>beta_regularizer <span class="token operator">=</span> keras<span class="token punctuation">.</span>regularizers<span class="token punctuation">.</span>get<span class="token punctuation">(</span>beta_regularizer<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>gamma_constraint <span class="token operator">=</span> keras<span class="token punctuation">.</span>constraints<span class="token punctuation">.</span>get<span class="token punctuation">(</span>gamma_constraint<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>beta_constraint <span class="token operator">=</span> keras<span class="token punctuation">.</span>constraints<span class="token punctuation">.</span>get<span class="token punctuation">(</span>beta_constraint<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>gamma<span class="token punctuation">,</span> self<span class="token punctuation">.</span>beta <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token boolean">None</span>

    <span class="token keyword">def</span> <span class="token function">get_config</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        config <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
            <span class="token string">'center'</span><span class="token punctuation">:</span> self<span class="token punctuation">.</span>center<span class="token punctuation">,</span>
            <span class="token string">'scale'</span><span class="token punctuation">:</span> self<span class="token punctuation">.</span>scale<span class="token punctuation">,</span>
            <span class="token string">'epsilon'</span><span class="token punctuation">:</span> self<span class="token punctuation">.</span>epsilon<span class="token punctuation">,</span>
            <span class="token string">'gamma_initializer'</span><span class="token punctuation">:</span> keras<span class="token punctuation">.</span>initializers<span class="token punctuation">.</span>serialize<span class="token punctuation">(</span>self<span class="token punctuation">.</span>gamma_initializer<span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token string">'beta_initializer'</span><span class="token punctuation">:</span> keras<span class="token punctuation">.</span>initializers<span class="token punctuation">.</span>serialize<span class="token punctuation">(</span>self<span class="token punctuation">.</span>beta_initializer<span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token string">'gamma_regularizer'</span><span class="token punctuation">:</span> keras<span class="token punctuation">.</span>regularizers<span class="token punctuation">.</span>serialize<span class="token punctuation">(</span>self<span class="token punctuation">.</span>gamma_regularizer<span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token string">'beta_regularizer'</span><span class="token punctuation">:</span> keras<span class="token punctuation">.</span>regularizers<span class="token punctuation">.</span>serialize<span class="token punctuation">(</span>self<span class="token punctuation">.</span>beta_regularizer<span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token string">'gamma_constraint'</span><span class="token punctuation">:</span> keras<span class="token punctuation">.</span>constraints<span class="token punctuation">.</span>serialize<span class="token punctuation">(</span>self<span class="token punctuation">.</span>gamma_constraint<span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token string">'beta_constraint'</span><span class="token punctuation">:</span> keras<span class="token punctuation">.</span>constraints<span class="token punctuation">.</span>serialize<span class="token punctuation">(</span>self<span class="token punctuation">.</span>beta_constraint<span class="token punctuation">)</span><span class="token punctuation">,</span>
        <span class="token punctuation">}</span>
        base_config <span class="token operator">=</span> <span class="token builtin">super</span><span class="token punctuation">(</span>LayerNormalization<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>get_config<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token builtin">list</span><span class="token punctuation">(</span>base_config<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token builtin">list</span><span class="token punctuation">(</span>config<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">compute_output_shape</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> input_shape<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> input_shape

    <span class="token keyword">def</span> <span class="token function">compute_mask</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> inputs<span class="token punctuation">,</span> input_mask<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> input_mask

    <span class="token keyword">def</span> <span class="token function">build</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> input_shape<span class="token punctuation">)</span><span class="token punctuation">:</span>
        shape <span class="token operator">=</span> input_shape<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>scale<span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>gamma <span class="token operator">=</span> self<span class="token punctuation">.</span>add_weight<span class="token punctuation">(</span>
                shape<span class="token operator">=</span>shape<span class="token punctuation">,</span>
                initializer<span class="token operator">=</span>self<span class="token punctuation">.</span>gamma_initializer<span class="token punctuation">,</span>
                regularizer<span class="token operator">=</span>self<span class="token punctuation">.</span>gamma_regularizer<span class="token punctuation">,</span>
                constraint<span class="token operator">=</span>self<span class="token punctuation">.</span>gamma_constraint<span class="token punctuation">,</span>
                name<span class="token operator">=</span><span class="token string">'gamma'</span><span class="token punctuation">,</span>
            <span class="token punctuation">)</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>center<span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>beta <span class="token operator">=</span> self<span class="token punctuation">.</span>add_weight<span class="token punctuation">(</span>
                shape<span class="token operator">=</span>shape<span class="token punctuation">,</span>
                initializer<span class="token operator">=</span>self<span class="token punctuation">.</span>beta_initializer<span class="token punctuation">,</span>
                regularizer<span class="token operator">=</span>self<span class="token punctuation">.</span>beta_regularizer<span class="token punctuation">,</span>
                constraint<span class="token operator">=</span>self<span class="token punctuation">.</span>beta_constraint<span class="token punctuation">,</span>
                name<span class="token operator">=</span><span class="token string">'beta'</span><span class="token punctuation">,</span>
            <span class="token punctuation">)</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>LayerNormalization<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>build<span class="token punctuation">(</span>input_shape<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">call</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> inputs<span class="token punctuation">,</span> training<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        mean <span class="token operator">=</span> K<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>inputs<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> keepdims<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
        variance <span class="token operator">=</span> K<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>K<span class="token punctuation">.</span>square<span class="token punctuation">(</span>inputs <span class="token operator">-</span> mean<span class="token punctuation">)</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> keepdims<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
        std <span class="token operator">=</span> K<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>variance <span class="token operator">+</span> self<span class="token punctuation">.</span>epsilon<span class="token punctuation">)</span>
        outputs <span class="token operator">=</span> <span class="token punctuation">(</span>inputs <span class="token operator">-</span> mean<span class="token punctuation">)</span> <span class="token operator">/</span> std
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>scale<span class="token punctuation">:</span>
            outputs <span class="token operator">*=</span> self<span class="token punctuation">.</span>gamma
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>center<span class="token punctuation">:</span>
            outputs <span class="token operator">+=</span> self<span class="token punctuation">.</span>beta
        <span class="token keyword">return</span> outputs

<span class="token comment">#--------------------------------------#</span>
<span class="token comment">#   Gelu激活函数的实现</span>
<span class="token comment">#   利用近似的数学公式</span>
<span class="token comment">#--------------------------------------#</span>
<span class="token keyword">class</span> <span class="token class-name">Gelu</span><span class="token punctuation">(</span>Layer<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>Gelu<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token operator">**</span>kwargs<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>supports_masking <span class="token operator">=</span> <span class="token boolean">True</span>

    <span class="token keyword">def</span> <span class="token function">call</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> inputs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> <span class="token number">0.5</span> <span class="token operator">*</span> inputs <span class="token operator">*</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">+</span> tf<span class="token punctuation">.</span>tanh<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span><span class="token number">2</span> <span class="token operator">/</span> math<span class="token punctuation">.</span>pi<span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token punctuation">(</span>inputs <span class="token operator">+</span> <span class="token number">0.044715</span> <span class="token operator">*</span> tf<span class="token punctuation">.</span><span class="token builtin">pow</span><span class="token punctuation">(</span>inputs<span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">get_config</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        config <span class="token operator">=</span> <span class="token builtin">super</span><span class="token punctuation">(</span>Gelu<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>get_config<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> config

    <span class="token keyword">def</span> <span class="token function">compute_output_shape</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> input_shape<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> input_shape

<span class="token comment">#--------------------------------------------------------------------------------------------------------------------#</span>
<span class="token comment">#   classtoken部分是transformer的分类特征。用于堆叠到序列化后的图片特征中，作为一个单位的序列特征进行特征提取。</span>
<span class="token comment">#</span>
<span class="token comment">#   在利用步长为16x16的卷积将输入图片划分成14x14的部分后，将14x14部分的特征平铺，一幅图片会存在序列长度为196的特征。</span>
<span class="token comment">#   此时生成一个classtoken，将classtoken堆叠到序列长度为196的特征上，获得一个序列长度为197的特征。</span>
<span class="token comment">#   在特征提取的过程中，classtoken会与图片特征进行特征的交互。最终分类时，我们取出classtoken的特征，利用全连接分类。</span>
<span class="token comment">#--------------------------------------------------------------------------------------------------------------------#</span>
<span class="token keyword">class</span> <span class="token class-name">ClassToken</span><span class="token punctuation">(</span>Layer<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> cls_initializer<span class="token operator">=</span><span class="token string">'zeros'</span><span class="token punctuation">,</span> cls_regularizer<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> cls_constraint<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>ClassToken<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token operator">**</span>kwargs<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>cls_initializer    <span class="token operator">=</span> keras<span class="token punctuation">.</span>initializers<span class="token punctuation">.</span>get<span class="token punctuation">(</span>cls_initializer<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>cls_regularizer    <span class="token operator">=</span> keras<span class="token punctuation">.</span>regularizers<span class="token punctuation">.</span>get<span class="token punctuation">(</span>cls_regularizer<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>cls_constraint     <span class="token operator">=</span> keras<span class="token punctuation">.</span>constraints<span class="token punctuation">.</span>get<span class="token punctuation">(</span>cls_constraint<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">get_config</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        config <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
            <span class="token string">'cls_initializer'</span><span class="token punctuation">:</span> keras<span class="token punctuation">.</span>initializers<span class="token punctuation">.</span>serialize<span class="token punctuation">(</span>self<span class="token punctuation">.</span>cls_initializer<span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token string">'cls_regularizer'</span><span class="token punctuation">:</span> keras<span class="token punctuation">.</span>regularizers<span class="token punctuation">.</span>serialize<span class="token punctuation">(</span>self<span class="token punctuation">.</span>cls_regularizer<span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token string">'cls_constraint'</span><span class="token punctuation">:</span> keras<span class="token punctuation">.</span>constraints<span class="token punctuation">.</span>serialize<span class="token punctuation">(</span>self<span class="token punctuation">.</span>cls_constraint<span class="token punctuation">)</span><span class="token punctuation">,</span>
        <span class="token punctuation">}</span>
        base_config <span class="token operator">=</span> <span class="token builtin">super</span><span class="token punctuation">(</span>ClassToken<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>get_config<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token builtin">list</span><span class="token punctuation">(</span>base_config<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token builtin">list</span><span class="token punctuation">(</span>config<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">compute_output_shape</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> input_shape<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> <span class="token punctuation">(</span>input_shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> input_shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span> input_shape<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">build</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> input_shape<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>num_features <span class="token operator">=</span> input_shape<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>
        self<span class="token punctuation">.</span>cls <span class="token operator">=</span> self<span class="token punctuation">.</span>add_weight<span class="token punctuation">(</span>
            shape       <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>num_features<span class="token punctuation">)</span><span class="token punctuation">,</span>
            initializer <span class="token operator">=</span> self<span class="token punctuation">.</span>cls_initializer<span class="token punctuation">,</span>
            regularizer <span class="token operator">=</span> self<span class="token punctuation">.</span>cls_regularizer<span class="token punctuation">,</span>
            constraint  <span class="token operator">=</span> self<span class="token punctuation">.</span>cls_constraint<span class="token punctuation">,</span>
            name        <span class="token operator">=</span> <span class="token string">'cls'</span><span class="token punctuation">,</span>
        <span class="token punctuation">)</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>ClassToken<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>build<span class="token punctuation">(</span>input_shape<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">call</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> inputs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        batch_size      <span class="token operator">=</span> tf<span class="token punctuation">.</span>shape<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
        cls_broadcasted <span class="token operator">=</span> tf<span class="token punctuation">.</span>cast<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>broadcast_to<span class="token punctuation">(</span>self<span class="token punctuation">.</span>cls<span class="token punctuation">,</span> <span class="token punctuation">[</span>batch_size<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>num_features<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dtype <span class="token operator">=</span> inputs<span class="token punctuation">.</span>dtype<span class="token punctuation">)</span>
        <span class="token keyword">return</span> tf<span class="token punctuation">.</span>concat<span class="token punctuation">(</span><span class="token punctuation">[</span>cls_broadcasted<span class="token punctuation">,</span> inputs<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>

<span class="token comment">#--------------------------------------------------------------------------------------------------------------------#</span>
<span class="token comment">#   为网络提取到的特征添加上位置信息。</span>
<span class="token comment">#   以输入图片为224, 224, 3为例，我们获得的序列化后的图片特征为196, 768。加上classtoken后就是197, 768</span>
<span class="token comment">#   此时生成的pos_Embedding的shape也为197, 768，代表每一个特征的位置信息。</span>
<span class="token comment">#--------------------------------------------------------------------------------------------------------------------#</span>
<span class="token keyword">class</span> <span class="token class-name">AddPositionEmbs</span><span class="token punctuation">(</span>Layer<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> image_shape<span class="token punctuation">,</span> patch_size<span class="token punctuation">,</span> pe_initializer<span class="token operator">=</span><span class="token string">'zeros'</span><span class="token punctuation">,</span> pe_regularizer<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> pe_constraint<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>AddPositionEmbs<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token operator">**</span>kwargs<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>image_shape        <span class="token operator">=</span> image_shape
        self<span class="token punctuation">.</span>patch_size         <span class="token operator">=</span> patch_size
        self<span class="token punctuation">.</span>pe_initializer     <span class="token operator">=</span> keras<span class="token punctuation">.</span>initializers<span class="token punctuation">.</span>get<span class="token punctuation">(</span>pe_initializer<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>pe_regularizer     <span class="token operator">=</span> keras<span class="token punctuation">.</span>regularizers<span class="token punctuation">.</span>get<span class="token punctuation">(</span>pe_regularizer<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>pe_constraint      <span class="token operator">=</span> keras<span class="token punctuation">.</span>constraints<span class="token punctuation">.</span>get<span class="token punctuation">(</span>pe_constraint<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">get_config</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        config <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
            <span class="token string">'pe_initializer'</span><span class="token punctuation">:</span> keras<span class="token punctuation">.</span>initializers<span class="token punctuation">.</span>serialize<span class="token punctuation">(</span>self<span class="token punctuation">.</span>pe_initializer<span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token string">'pe_regularizer'</span><span class="token punctuation">:</span> keras<span class="token punctuation">.</span>regularizers<span class="token punctuation">.</span>serialize<span class="token punctuation">(</span>self<span class="token punctuation">.</span>pe_regularizer<span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token string">'pe_constraint'</span><span class="token punctuation">:</span> keras<span class="token punctuation">.</span>constraints<span class="token punctuation">.</span>serialize<span class="token punctuation">(</span>self<span class="token punctuation">.</span>pe_constraint<span class="token punctuation">)</span><span class="token punctuation">,</span>
        <span class="token punctuation">}</span>
        base_config <span class="token operator">=</span> <span class="token builtin">super</span><span class="token punctuation">(</span>AddPositionEmbs<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>get_config<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token builtin">list</span><span class="token punctuation">(</span>base_config<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token builtin">list</span><span class="token punctuation">(</span>config<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">compute_output_shape</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> input_shape<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> input_shape

    <span class="token keyword">def</span> <span class="token function">build</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> input_shape<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">assert</span> <span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>input_shape<span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string-interpolation"><span class="token string">f"Number of dimensions should be 3, got </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span><span class="token builtin">len</span><span class="token punctuation">(</span>input_shape<span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string">"</span></span>
        length  <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">224</span> <span class="token operator">//</span> self<span class="token punctuation">.</span>patch_size<span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token punctuation">(</span><span class="token number">224</span> <span class="token operator">//</span> self<span class="token punctuation">.</span>patch_size<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">1</span>
        self<span class="token punctuation">.</span>pe <span class="token operator">=</span> self<span class="token punctuation">.</span>add_weight<span class="token punctuation">(</span>
            <span class="token comment"># shape       = [1, input_shape[1], input_shape[2]],</span>
            shape       <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> length<span class="token punctuation">,</span> input_shape<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
            initializer <span class="token operator">=</span> self<span class="token punctuation">.</span>pe_initializer<span class="token punctuation">,</span>
            regularizer <span class="token operator">=</span> self<span class="token punctuation">.</span>pe_regularizer<span class="token punctuation">,</span>
            constraint  <span class="token operator">=</span> self<span class="token punctuation">.</span>pe_constraint<span class="token punctuation">,</span>
            name        <span class="token operator">=</span> <span class="token string">'pos_embedding'</span><span class="token punctuation">,</span>
        <span class="token punctuation">)</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>AddPositionEmbs<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>build<span class="token punctuation">(</span>input_shape<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">call</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> inputs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        num_features <span class="token operator">=</span> tf<span class="token punctuation">.</span>shape<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span>

        cls_token_pe <span class="token operator">=</span> self<span class="token punctuation">.</span>pe<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">:</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span>
        img_token_pe <span class="token operator">=</span> self<span class="token punctuation">.</span>pe<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">:</span> <span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span>

        img_token_pe <span class="token operator">=</span> tf<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>img_token_pe<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">224</span> <span class="token operator">//</span> self<span class="token punctuation">.</span>patch_size<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">224</span> <span class="token operator">//</span> self<span class="token punctuation">.</span>patch_size<span class="token punctuation">)</span><span class="token punctuation">,</span> num_features<span class="token punctuation">]</span><span class="token punctuation">)</span>
        img_token_pe <span class="token operator">=</span> tf<span class="token punctuation">.</span>image<span class="token punctuation">.</span>resize_bicubic<span class="token punctuation">(</span>img_token_pe<span class="token punctuation">,</span> <span class="token punctuation">(</span>self<span class="token punctuation">.</span>image_shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">//</span> self<span class="token punctuation">.</span>patch_size<span class="token punctuation">,</span> self<span class="token punctuation">.</span>image_shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">//</span> self<span class="token punctuation">.</span>patch_size<span class="token punctuation">)</span><span class="token punctuation">,</span> align_corners<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
        img_token_pe <span class="token operator">=</span> tf<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>img_token_pe<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> num_features<span class="token punctuation">]</span><span class="token punctuation">)</span>
        
        pe <span class="token operator">=</span> tf<span class="token punctuation">.</span>concat<span class="token punctuation">(</span><span class="token punctuation">[</span>cls_token_pe<span class="token punctuation">,</span> img_token_pe<span class="token punctuation">]</span><span class="token punctuation">,</span> axis <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">)</span>

        <span class="token keyword">return</span> inputs <span class="token operator">+</span> tf<span class="token punctuation">.</span>cast<span class="token punctuation">(</span>pe<span class="token punctuation">,</span> dtype<span class="token operator">=</span>inputs<span class="token punctuation">.</span>dtype<span class="token punctuation">)</span>

<span class="token comment">#--------------------------------------------------------------------------------------------------------------------#</span>
<span class="token comment">#   Attention机制</span>
<span class="token comment">#   将输入的特征qkv特征进行划分，首先生成query, key, value。query是查询向量、key是键向量、v是值向量。</span>
<span class="token comment">#   然后利用 查询向量query 点乘 转置后的键向量key，这一步可以通俗的理解为，利用查询向量去查询序列的特征，获得序列每个部分的重要程度score。</span>
<span class="token comment">#   然后利用 score 点乘 value，这一步可以通俗的理解为，将序列每个部分的重要程度重新施加到序列的值上去。</span>
<span class="token comment">#--------------------------------------------------------------------------------------------------------------------#</span>
<span class="token keyword">class</span> <span class="token class-name">Attention</span><span class="token punctuation">(</span>Layer<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> num_features<span class="token punctuation">,</span> num_heads<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>Attention<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token operator">**</span>kwargs<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>num_features   <span class="token operator">=</span> num_features
        self<span class="token punctuation">.</span>num_heads      <span class="token operator">=</span> num_heads
        self<span class="token punctuation">.</span>projection_dim <span class="token operator">=</span> num_features <span class="token operator">//</span> num_heads

    <span class="token keyword">def</span> <span class="token function">compute_output_shape</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> input_shape<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> <span class="token punctuation">(</span>input_shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> input_shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> input_shape<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span> <span class="token operator">//</span> <span class="token number">3</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">call</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> inputs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment">#-----------------------------------------------#</span>
        <span class="token comment">#   获得batch_size</span>
        <span class="token comment">#-----------------------------------------------#</span>
        bs      <span class="token operator">=</span> tf<span class="token punctuation">.</span>shape<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>

        <span class="token comment">#-----------------------------------------------#</span>
        <span class="token comment">#   b, 197, 3 * 768 -&gt; b, 197, 3, 12, 64</span>
        <span class="token comment">#-----------------------------------------------#</span>
        inputs  <span class="token operator">=</span> tf<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>inputs<span class="token punctuation">,</span> <span class="token punctuation">[</span>bs<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>num_heads<span class="token punctuation">,</span> self<span class="token punctuation">.</span>projection_dim<span class="token punctuation">]</span><span class="token punctuation">)</span>
        <span class="token comment">#-----------------------------------------------#</span>
        <span class="token comment">#   b, 197, 3, 12, 64 -&gt; 3, b, 12, 197, 64</span>
        <span class="token comment">#-----------------------------------------------#</span>
        inputs  <span class="token operator">=</span> tf<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span>inputs<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        <span class="token comment">#-----------------------------------------------#</span>
        <span class="token comment">#   将query, key, value划分开</span>
        <span class="token comment">#   query     b, 12, 197, 64</span>
        <span class="token comment">#   key       b, 12, 197, 64</span>
        <span class="token comment">#   value     b, 12, 197, 64</span>
        <span class="token comment">#-----------------------------------------------#</span>
        query<span class="token punctuation">,</span> key<span class="token punctuation">,</span> value <span class="token operator">=</span> inputs<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> inputs<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> inputs<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span>
        <span class="token comment">#-----------------------------------------------#</span>
        <span class="token comment">#   b, 12, 197, 64 @ b, 12, 197, 64 = b, 12, 197, 197</span>
        <span class="token comment">#-----------------------------------------------#</span>
        score           <span class="token operator">=</span> tf<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>query<span class="token punctuation">,</span> key<span class="token punctuation">,</span> transpose_b<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
        <span class="token comment">#-----------------------------------------------#</span>
        <span class="token comment">#   进行数量级的缩放</span>
        <span class="token comment">#-----------------------------------------------#</span>
        scaled_score    <span class="token operator">=</span> score <span class="token operator">/</span> tf<span class="token punctuation">.</span>math<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>cast<span class="token punctuation">(</span>self<span class="token punctuation">.</span>projection_dim<span class="token punctuation">,</span> score<span class="token punctuation">.</span>dtype<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token comment">#-----------------------------------------------#</span>
        <span class="token comment">#   b, 12, 197, 197 -&gt; b, 12, 197, 197</span>
        <span class="token comment">#-----------------------------------------------#</span>
        weights         <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>scaled_score<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
        <span class="token comment">#-----------------------------------------------#</span>
        <span class="token comment">#   b, 12, 197, 197 @ b, 12, 197, 64 = b, 12, 197, 64</span>
        <span class="token comment">#-----------------------------------------------#</span>
        value          <span class="token operator">=</span> tf<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>weights<span class="token punctuation">,</span> value<span class="token punctuation">)</span>

        <span class="token comment">#-----------------------------------------------#</span>
        <span class="token comment">#   b, 12, 197, 64 -&gt; b, 197, 12, 64</span>
        <span class="token comment">#-----------------------------------------------#</span>
        value <span class="token operator">=</span> tf<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span>value<span class="token punctuation">,</span> perm<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        <span class="token comment">#-----------------------------------------------#</span>
        <span class="token comment">#   b, 197, 12, 64 -&gt; b, 197, 768</span>
        <span class="token comment">#-----------------------------------------------#</span>
        output <span class="token operator">=</span> tf<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>value<span class="token punctuation">,</span> <span class="token punctuation">(</span>tf<span class="token punctuation">.</span>shape<span class="token punctuation">(</span>value<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> tf<span class="token punctuation">.</span>shape<span class="token punctuation">(</span>value<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> output

<span class="token keyword">def</span> <span class="token function">MultiHeadSelfAttention</span><span class="token punctuation">(</span>inputs<span class="token punctuation">,</span> num_features<span class="token punctuation">,</span> num_heads<span class="token punctuation">,</span> dropout<span class="token punctuation">,</span> name<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment">#-----------------------------------------------#</span>
    <span class="token comment">#   qkv   b, 197, 768 -&gt; b, 197, 3 * 768</span>
    <span class="token comment">#-----------------------------------------------#</span>
    qkv <span class="token operator">=</span> Dense<span class="token punctuation">(</span><span class="token builtin">int</span><span class="token punctuation">(</span>num_features <span class="token operator">*</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> name <span class="token operator">=</span> name <span class="token operator">+</span> <span class="token string">"qkv"</span><span class="token punctuation">)</span><span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>
    <span class="token comment">#-----------------------------------------------#</span>
    <span class="token comment">#   b, 197, 3 * 768 -&gt; b, 197, 768</span>
    <span class="token comment">#-----------------------------------------------#</span>
    x   <span class="token operator">=</span> Attention<span class="token punctuation">(</span>num_features<span class="token punctuation">,</span> num_heads<span class="token punctuation">)</span><span class="token punctuation">(</span>qkv<span class="token punctuation">)</span>
    <span class="token comment">#-----------------------------------------------#</span>
    <span class="token comment">#   197, 768 -&gt; 197, 768</span>
    <span class="token comment">#-----------------------------------------------#</span>
    x   <span class="token operator">=</span> Dense<span class="token punctuation">(</span>num_features<span class="token punctuation">,</span> name <span class="token operator">=</span> name <span class="token operator">+</span> <span class="token string">"proj"</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    x   <span class="token operator">=</span> Dropout<span class="token punctuation">(</span>dropout<span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    <span class="token keyword">return</span> x

<span class="token keyword">def</span> <span class="token function">MLP</span><span class="token punctuation">(</span>y<span class="token punctuation">,</span> num_features<span class="token punctuation">,</span> mlp_dim<span class="token punctuation">,</span> dropout<span class="token punctuation">,</span> name<span class="token punctuation">)</span><span class="token punctuation">:</span>
    y <span class="token operator">=</span> Dense<span class="token punctuation">(</span>mlp_dim<span class="token punctuation">,</span> name <span class="token operator">=</span> name <span class="token operator">+</span> <span class="token string">"fc1"</span><span class="token punctuation">)</span><span class="token punctuation">(</span>y<span class="token punctuation">)</span>
    y <span class="token operator">=</span> Gelu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">(</span>y<span class="token punctuation">)</span>
    y <span class="token operator">=</span> Dropout<span class="token punctuation">(</span>dropout<span class="token punctuation">)</span><span class="token punctuation">(</span>y<span class="token punctuation">)</span>
    y <span class="token operator">=</span> Dense<span class="token punctuation">(</span>num_features<span class="token punctuation">,</span> name <span class="token operator">=</span> name <span class="token operator">+</span> <span class="token string">"fc2"</span><span class="token punctuation">)</span><span class="token punctuation">(</span>y<span class="token punctuation">)</span>
    <span class="token keyword">return</span> y

<span class="token keyword">def</span> <span class="token function">TransformerBlock</span><span class="token punctuation">(</span>inputs<span class="token punctuation">,</span> num_features<span class="token punctuation">,</span> num_heads<span class="token punctuation">,</span> mlp_dim<span class="token punctuation">,</span> dropout<span class="token punctuation">,</span> name<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment">#-----------------------------------------------#</span>
    <span class="token comment">#   施加层标准化</span>
    <span class="token comment">#-----------------------------------------------#</span>
    x <span class="token operator">=</span> LayerNormalization<span class="token punctuation">(</span>epsilon<span class="token operator">=</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">6</span><span class="token punctuation">,</span> name <span class="token operator">=</span> name <span class="token operator">+</span> <span class="token string">"norm1"</span><span class="token punctuation">)</span><span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>
    <span class="token comment">#-----------------------------------------------#</span>
    <span class="token comment">#   施加多头注意力机制</span>
    <span class="token comment">#-----------------------------------------------#</span>
    x <span class="token operator">=</span> MultiHeadSelfAttention<span class="token punctuation">(</span>x<span class="token punctuation">,</span> num_features<span class="token punctuation">,</span> num_heads<span class="token punctuation">,</span> dropout<span class="token punctuation">,</span> name <span class="token operator">=</span> name <span class="token operator">+</span> <span class="token string">"attn."</span><span class="token punctuation">)</span>
    x <span class="token operator">=</span> Dropout<span class="token punctuation">(</span>dropout<span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    <span class="token comment">#-----------------------------------------------#</span>
    <span class="token comment">#   施加残差结构</span>
    <span class="token comment">#-----------------------------------------------#</span>
    x <span class="token operator">=</span> Add<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">(</span><span class="token punctuation">[</span>x<span class="token punctuation">,</span> inputs<span class="token punctuation">]</span><span class="token punctuation">)</span>

    <span class="token comment">#-----------------------------------------------#</span>
    <span class="token comment">#   施加层标准化</span>
    <span class="token comment">#-----------------------------------------------#</span>
    y <span class="token operator">=</span> LayerNormalization<span class="token punctuation">(</span>epsilon<span class="token operator">=</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">6</span><span class="token punctuation">,</span> name <span class="token operator">=</span> name <span class="token operator">+</span> <span class="token string">"norm2"</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    <span class="token comment">#-----------------------------------------------#</span>
    <span class="token comment">#   施加两次全连接</span>
    <span class="token comment">#-----------------------------------------------#</span>
    y <span class="token operator">=</span> MLP<span class="token punctuation">(</span>y<span class="token punctuation">,</span> num_features<span class="token punctuation">,</span> mlp_dim<span class="token punctuation">,</span> dropout<span class="token punctuation">,</span> name <span class="token operator">=</span> name <span class="token operator">+</span> <span class="token string">"mlp."</span><span class="token punctuation">)</span>
    y <span class="token operator">=</span> Dropout<span class="token punctuation">(</span>dropout<span class="token punctuation">)</span><span class="token punctuation">(</span>y<span class="token punctuation">)</span>
    <span class="token comment">#-----------------------------------------------#</span>
    <span class="token comment">#   施加残差结构</span>
    <span class="token comment">#-----------------------------------------------#</span>
    y <span class="token operator">=</span> Add<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">(</span><span class="token punctuation">[</span>x<span class="token punctuation">,</span> y<span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> y

<span class="token keyword">def</span> <span class="token function">VisionTransformer</span><span class="token punctuation">(</span>input_shape <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">224</span><span class="token punctuation">,</span> <span class="token number">224</span><span class="token punctuation">]</span><span class="token punctuation">,</span> patch_size <span class="token operator">=</span> <span class="token number">16</span><span class="token punctuation">,</span> num_layers <span class="token operator">=</span> <span class="token number">12</span><span class="token punctuation">,</span> num_features <span class="token operator">=</span> <span class="token number">768</span><span class="token punctuation">,</span> num_heads <span class="token operator">=</span> <span class="token number">12</span><span class="token punctuation">,</span> mlp_dim <span class="token operator">=</span> <span class="token number">3072</span><span class="token punctuation">,</span> 
            classes <span class="token operator">=</span> <span class="token number">1000</span><span class="token punctuation">,</span> dropout <span class="token operator">=</span> <span class="token number">0.1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment">#-----------------------------------------------#</span>
    <span class="token comment">#   224, 224, 3</span>
    <span class="token comment">#-----------------------------------------------#</span>
    inputs      <span class="token operator">=</span> Input<span class="token punctuation">(</span>shape <span class="token operator">=</span> <span class="token punctuation">(</span>input_shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> input_shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    
    <span class="token comment">#-----------------------------------------------#</span>
    <span class="token comment">#   224, 224, 3 -&gt; 14, 14, 768</span>
    <span class="token comment">#-----------------------------------------------#</span>
    x           <span class="token operator">=</span> Conv2D<span class="token punctuation">(</span>num_features<span class="token punctuation">,</span> patch_size<span class="token punctuation">,</span> strides <span class="token operator">=</span> patch_size<span class="token punctuation">,</span> padding <span class="token operator">=</span> <span class="token string">"valid"</span><span class="token punctuation">,</span> name <span class="token operator">=</span> <span class="token string">"patch_embed.proj"</span><span class="token punctuation">)</span><span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>
    <span class="token comment">#-----------------------------------------------#</span>
    <span class="token comment">#   14, 14, 768 -&gt; 196, 768</span>
    <span class="token comment">#-----------------------------------------------#</span>
    x           <span class="token operator">=</span> Reshape<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token punctuation">(</span>input_shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">//</span> patch_size<span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token punctuation">(</span>input_shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">//</span> patch_size<span class="token punctuation">)</span><span class="token punctuation">,</span> num_features<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    <span class="token comment">#-----------------------------------------------#</span>
    <span class="token comment">#   196, 768 -&gt; 197, 768</span>
    <span class="token comment">#-----------------------------------------------#</span>
    x           <span class="token operator">=</span> ClassToken<span class="token punctuation">(</span>name<span class="token operator">=</span><span class="token string">"cls_token"</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    <span class="token comment">#-----------------------------------------------#</span>
    <span class="token comment">#   197, 768 -&gt; 197, 768</span>
    <span class="token comment">#-----------------------------------------------#</span>
    x           <span class="token operator">=</span> AddPositionEmbs<span class="token punctuation">(</span>input_shape<span class="token punctuation">,</span> patch_size<span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">"pos_embed"</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    <span class="token comment">#-----------------------------------------------#</span>
    <span class="token comment">#   197, 768 -&gt; 197, 768  12次</span>
    <span class="token comment">#-----------------------------------------------#</span>
    <span class="token keyword">for</span> n <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_layers<span class="token punctuation">)</span><span class="token punctuation">:</span>
        x <span class="token operator">=</span> TransformerBlock<span class="token punctuation">(</span>
            x<span class="token punctuation">,</span>
            num_features<span class="token operator">=</span> num_features<span class="token punctuation">,</span>
            num_heads   <span class="token operator">=</span> num_heads<span class="token punctuation">,</span>
            mlp_dim     <span class="token operator">=</span> mlp_dim<span class="token punctuation">,</span>
            dropout     <span class="token operator">=</span> dropout<span class="token punctuation">,</span>
            name        <span class="token operator">=</span> <span class="token string">"blocks."</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>n<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">"."</span><span class="token punctuation">,</span>
        <span class="token punctuation">)</span>
    x <span class="token operator">=</span> LayerNormalization<span class="token punctuation">(</span>
        epsilon<span class="token operator">=</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">6</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">"norm"</span>
    <span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    x <span class="token operator">=</span> Lambda<span class="token punctuation">(</span><span class="token keyword">lambda</span> v<span class="token punctuation">:</span> v<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">"ExtractToken"</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    x <span class="token operator">=</span> Dense<span class="token punctuation">(</span>classes<span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">"head"</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    x <span class="token operator">=</span> Softmax<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    <span class="token keyword">return</span> keras<span class="token punctuation">.</span>models<span class="token punctuation">.</span>Model<span class="token punctuation">(</span>inputs<span class="token punctuation">,</span> x<span class="token punctuation">)</span>
</code></pre>
                </div>
                
                

		</div>
	</article>
</main>




			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程小白.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://www.w3counter.com/tracker.js?id=150625"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>
	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>