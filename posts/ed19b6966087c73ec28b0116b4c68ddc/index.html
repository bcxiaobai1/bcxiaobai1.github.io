<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<title>iGibson：Python就能玩的3D环境仿真 - 编程小白</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程小白" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程小白</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">iGibson：Python就能玩的3D环境仿真</h1>
			
		</header>
		<div class="content post__content clearfix">
			


                <div id="content_views" class="htmledit_views">
                    <h2>导语</h2> 
<p>今天小编给大家带来一个来源于李飞飞大佬团队的3D仿真环境iGibson。iGibson通过Python就能调用，在ROS中可直接观察，阿chai推荐做机器人、3D以及模型构建的小伙伴可以尝试，iGibson中的物理引擎是真的很强。</p> 
<p style="text-align:center"><img alt="" height="116" src="https://images2.imgbox.com/b3/af/STMDCUdv_o.gif" width="116"></p> 
<p style="text-align:center"><img alt="" height="58" src="https://images2.imgbox.com/1d/d9/NhfrO2Qj_o.png" width="311"></p> 
<p><a href="https://jq.qq.com/?_wv=1027&amp;k=BFElx1S7" title="想领取完整源码跟Python学习资料可点击这行字体">想领取完整源码跟Python学习资料可点击这行字体</a></p> 
<p>我们先看一段有关iGibson的介绍。</p> 
<p>iGibson是一个仿真环境，可基于Bullet提供快速的视觉渲染和物理仿真。iGibson配备了15个完全交互式的高质量场景，从真实的房屋和办公室重建的数百个大型3D场景，并与CubiCasa5K和3D-Front等数据集兼容，提供了8000多个附加的交互式场景。iGibson的一些功能包括域随机化，与运动计划器集成以及易于使用的工具来收集人类演示。借助这些场景和功能，iGibson允许研究人员训练和评估使用视觉信号来解决导航和操纵任务(例如开门，捡起和放置物体或在橱柜中搜索)的机器人代理。</p> 
<p style="text-align:center"><img alt="" src="https://images2.imgbox.com/db/cb/SxXEwjpA_o.gif"></p> 
<p></p> 
<p><strong>环境搭建</strong></p> 
<p>系统要求如下：</p> 
<ul>
<li> <p>Ubuntu 16.04</p> </li>
<li> <p>具有VRAM&gt; 6.0GB的Nvidia GPU</p> </li>
<li> <p>Nvidia驱动程序&gt; = 384</p> </li>
<li> <p>CUDA&gt; = 9.0，CuDNN&gt; = v7</p> </li>
<li> <p>CMake&gt; = 2.8.12（可以安装<code>pip install cmake</code>）</p> </li>
</ul>
<h3>1. pip安装</h3> 
<p>可以使用pip将iGibson的模拟器安装为python软件包：</p> 
<pre><code class="language-python">pip install gibson2 -i xxxx(镜像网址)

＃测试
python -m gibson2.scripts.demo_static</code></pre> 
<p>iGibson支持自定义pybullet版本来加快物理速度，如果要加快速度，则在安装后需要执行以下步骤：</p> 
<pre><code class="language-python"># 卸载pybullet
pip uninstall pybullet

pip instal lhttps://github.com/StanfordVL/bullet3/archive/master.zip</code></pre> 
<h3>2. Docker安装</h3> 
<p>Docker版本至少为v19.0，并启用本机GPU。接下来，使用<code>iGibson</code>回购中的脚本下载我们的预构建图像：</p> 
<pre><code class="language-python">cd iGibson
./docker/pull-images.sh</code></pre> 
<p>将下载两个图像：</p> 
<ul>
<li> <p><code>igibson/igibson:latest</code>：不支持GUI。</p> </li>
<li> <p><code>igibson/igibson-gui:latest</code>：支持VNC进行GUI和远程桌面。</p> </li>
</ul>
<p>提供以从头开始构建图像的脚本：</p> 
<pre><code class="language-python"># 不带GUI
cd iGibson/docker/base
./build.sh

# GUI和VNC:
cd iGibson/docker/headless-gui
./build.sh</code></pre> 
<h3>3. 自己编译源码</h3> 
<p>源码编译需要Anaconda</p> 
<pre><code class="language-python"># clone源码
git clone https://github.com/StanfordVL/iGibson --recursive

cd iGibson

# Python 3.6、3.7、3.8均可
conda create -n py3-igibson python=3.6 anaconda 

source activate py3-igibson

# 在末尾添加-i xxxx(镜像网站)
pip install -e . </code></pre> 
<p>iGibson支持自定义pybullet版本来加快物理速度，如果要加快速度，则在安装后需要执行以下步骤：</p> 
<pre><code class="language-python"># 卸载pybullet
pip uninstall pybullet

pip instal lhttps://github.com/StanfordVL/bullet3/archive/master.zip</code></pre> 
<p>数据下载、测试</p> 
<p>首先，配置iGibson(机器人代理，对象，3D环境等)存储位置。它在<code>your_installation_path/gibson2/global_config.yaml</code></p> 
<p>存储数据的默认位置是：</p> 
<pre><code class="language-python">assets_path: your_installation_path/gibson2/data/assets 
g_dataset_path: your_installation_path/gibson2/data/g_dataset
ig_dataset_path: your_installation_path/gibson2/data/ig_dataset
threedfront_dataset_path: your_installation_path/gibson2/data/threedfront_dataset 
cubicasa_dataset_path: your_installation_path/gibson2/data/assetscubicasa_dataset </code></pre> 
<p> 如果使用默认路径，则无需执行任何操作，否则可以运行以下脚本：</p> 
<pre><code class="language-python">python -m gibson2.utils.assets_utils --change_data_path</code></pre> 
<p>直接运行以下下载脚本：</p> 
<pre><code class="language-python"># 或者直接从此处下载
python -m gibson2.utils.assets_utils --download_assets</code></pre> 
<p> 需要从数据集中下载一些大型的3D重构现实世界环境(例如房屋和办公室),并将路径设置为<code>your_installation_path/gibson2/global_config.yaml</code>(默认和推荐：<code>your_installation_path/gibson2/data/g_dataset</code>和<code>your_installation_path/gibson2/data/ig_dataset</code>)。通过填写以下许可协议来访问和下载Gibson和iGibson数据集。也可以下载一个小型环境进行演示。</p> 
<p>要下载演示数据，请运行：</p> 
<pre><code class="language-python">python -m gibson2.utils.assets_utils --download_demo_data</code></pre> 
<p>可以使用以下命令下载完整的Gibson和iGibson数据集，此脚本将自动下载，解压缩数据集并将其放置到正确的位置。<code>URL</code>填写协议表格后将获取。</p> 
<p>下载iGibson数据集：</p> 
<pre><code class="language-python">python -m gibson2.utils.assets_utils --download_ig_dataset</code></pre> 
<p> 下载Gibson数据集(需要获得协议签名<code>URL</code>)</p> 
<pre><code>python -m gibson2.utils.assets_utils --download_dataset URL
</code></pre> 
<p>测试是否正确安装了gibson2，可以运行:</p> 
<pre><code>python
&gt;&gt;&gt; import gibson2
&gt;&gt;&gt; 
</code></pre> 
<p>通过运行测试脚本测试：</p> 
<pre><code>cd test

pytest --ignore disabled --ignore benchmark
</code></pre> 
<p>terminal中将看到如下输出：</p> 
<pre><code class="language-python">=============================== test session starts ================================
platform linux -- Python 3.5.6, pytest-4.6.9, py-1.5.3, pluggy-0.13.1
rootdir: /cvgl2/u/chengshu/gibsonv2
plugins: openfiles-0.3.0, doctestplus-0.1.3, arraydiff-0.2
collected 27 items

test_binding.py ..                                              [  7% ]
test_navigate_env.py ..                                         [ 14% ]
test_object.py ....                                             [ 29% ]
test_render.py ...                                              [ 40% ]
test_robot.py ..........                                        [ 77% ]
test_scene_importing.py ....                                    [ 92% ]
test_simulator.py .                                             [ 96% ]
test_viewer.py</code></pre> 
<p>物理引擎与渲染</p> 
<h3>1. 渲染器</h3> 
<p>iGibson中使用自己开发的MeshRenderer，它支持可自定义的相机配置和各种图像模式，并以超快的速度进行渲染，可以在的构造函数中指定图像的宽度，高度和垂直视场以及调用以检索图像。iGibson支持六种不同的图像模态：RGB，表面法线，分割，3D点云(z通道可以提取为深度图)，光流和场景流。我们还支持两种类型的LiDAR传感器：1光束和16光束(例如Velodyne VLP-16)。大部分代码可以在gibson2 / render中找到。<code>class MeshRenderer``renderer.render(modes=('rgb', 'normal', 'seg', '3d', 'optical_flow', 'scene_flow'))</code></p> 
<p>接下来使用几行代码渲染了一个iGibson场景：</p> 
<pre><code class="language-python">import cv2
import sys
import os
import numpy as np
from gibson2.render.mesh_renderer.mesh_renderer_cpu import MeshRenderer
from gibson2.utils.assets_utils import get_scene_path


def main():
    if len(sys.argv) &gt; 1:
        model_path = sys.argv[1]
    else:
        model_path = os.path.join(get_scene_path('Rs'), 'mesh_z_up.obj')

    renderer = MeshRenderer(width=512, height=512)
    renderer.load_object(model_path)
    renderer.add_instance(0)
    camera_pose = np.array([0, 0, 1.2])
    view_direction = np.array([1, 0, 0])
    renderer.set_camera(camera_pose, camera_pose + view_direction, [0, 0, 1])
    renderer.set_fov(90)
    frames = renderer.render(
        modes=('rgb', 'normal', '3d'))
    frames = cv2.cvtColor(np.concatenate(frames, axis=1), cv2.COLOR_RGB2BGR)
    cv2.imshow('image', frames)
    cv2.waitKey(0)

if __name__ == '__main__':
    main()</code></pre> 
<p> 渲染结果将如下所示：</p> 
<p style="text-align:center"><img alt="" src="https://images2.imgbox.com/65/f1/WiI7225r_o.png"></p> 
<p>可以使用PBR演示测试基于物理的渲染器。渲染iG数据集中包含的任何对象，例如，此处显示一个接收器，因为它包含不同的材质。需要构建文件夹，因为它将加载该文件夹中的所有对象。</p> 
<pre><code class="language-python">cd examples/demo
python mesh_renderer_example_pbr.py &lt;path to ig_dataset&gt;/objects/sink/sink_1/shape/visual</code></pre> 
<p> 效果如下：</p> 
<p style="text-align:center"><img alt="" src="https://images2.imgbox.com/3d/6c/z38Bj2xj_o.png"></p> 
<p>同样可以结合Pytorch，测试例子如下(需要了解Pytorch)：</p> 
<pre><code class="language-python">import sys
import os
import numpy as np
from gibson2.render.mesh_renderer.mesh_renderer_tensor import MeshRendererG2G
from gibson2.render.profiler import Profiler
from gibson2.utils.assets_utils import get_scene_path
import matplotlib.pyplot as plt

def main():
    if len(sys.argv) &gt; 1:
        model_path = sys.argv[1]
    else:
        model_path = os.path.join(get_scene_path('Rs'), 'mesh_z_up.obj')

    renderer = MeshRendererG2G(width=512, height=512, device_idx=0)
    renderer.load_object(model_path)
    renderer.add_instance(0)

    print(renderer.visual_objects, renderer.instances)
    print(renderer.materials_mapping, renderer.mesh_materials)
    camera_pose = np.array([0, 0, 1.2])
    view_direction = np.array([1, 0, 0])
    renderer.set_camera(camera_pose, camera_pose + view_direction, [0, 0, 1])
    renderer.set_fov(90)
    for i in range(3000):
        with Profiler('Render'):
            frame = renderer.render(modes=('rgb', 'normal', '3d'))

    print(frame)
    img_np = frame[0].flip(0).data.cpu().numpy().reshape(
        renderer.height, renderer.width, 4)
    normal_np = frame[1].flip(0).data.cpu().numpy().reshape(
        renderer.height, renderer.width, 4)
    plt.imshow(np.concatenate([img_np, normal_np], axis=1))
    plt.show()

if __name__ == '__main__':
    main()</code></pre> 
<h3>2. 物理引擎测试</h3> 
<p>iGibson使用PyBullet作为基础物理引擎,可以准确有效地模拟机器人和关节物体的刚体碰撞和关节致动。由于使用iGibson构建的MeshRenderer进行渲染，使用PyBullet进行物理模拟，因此需要始终保持同步。</p> 
<p>通常在使用场景时，对象和机器人<code>p.createMultiBody</code>并将<code>p.loadURDF</code>其加载到PyBullet中，用于<code>p.resetBasePositionAndOrientation</code>设置机器人和对象的基本姿势，<code>p.resetJointState</code>设置机器人和关节对象的关节位置以及<code>p.setJointMotorControl2</code>控制机器人和关节对象。</p> 
<p>下面代码将场景，机器人和对象导入PyBullet并逐步仿真：</p> 
<pre><code class="language-python">from gibson2.utils.assets_utils import get_scene_path, get_texture_file
import gibson2

import os
import sys
import time

def main():
    if len(sys.argv) &gt; 1:
        model_path = sys.argv[1]
    else:
        model_path = os.path.join(get_scene_path('Rs'), 'mesh_z_up.obj')

    p.connect(p.GUI)
    p.setGravity(0,0,-9.8)
    p.setTimeStep(1./240.)

    # Load scenes
    collision_id = p.createCollisionShape(p.GEOM_MESH,
                                          fileName=model_path,
                                          meshScale=1.0,
                                          flags=p.GEOM_FORCE_CONCAVE_TRIMESH)
    visual_id = p.createVisualShape(p.GEOM_MESH,
                                    fileName=model_path,
                                    meshScale=1.0)
    texture_filename = get_texture_file(model_path)
    texture_id = p.loadTexture(texture_filename)

    mesh_id = p.createMultiBody(baseCollisionShapeIndex=collision_id,
                                baseVisualShapeIndex=visual_id)

    # Load robots
    turtlebot_urdf = os.path.join(gibson2.assets_path, 'models/turtlebot/turtlebot.urdf')
    robot_id = p.loadURDF(turtlebot_urdf, flags=p.URDF_USE_MATERIAL_COLORS_FROM_MTL)

    # Load objects
    obj_visual_filename = os.path.join(gibson2.assets_path, 'models/ycb/002_master_chef_can/textured_simple.obj')
    obj_collision_filename = os.path.join(gibson2.assets_path, 'models/ycb/002_master_chef_can/textured_simple_vhacd.obj')
    collision_id = p.createCollisionShape(p.GEOM_MESH,
                                          fileName=obj_collision_filename,
                                          meshScale=1.0)
    visual_id = p.createVisualShape(p.GEOM_MESH,
                                    fileName=obj_visual_filename,
                                    meshScale=1.0)
    object_id = p.createMultiBody(baseCollisionShapeIndex=collision_id,
                                  baseVisualShapeIndex=visual_id,
                                  basePosition=[1.0, 0.0, 1.0],
                                  baseMass=0.1)

    for _ in range(10000):
        p.stepSimulation()

    p.disconnect()

if __name__ == '__main__':
    main()</code></pre> 
<p> </p> 
<p>将看到PyBullet界面，界面中包含一个Turtlebot机器人和一个蓝色的罐子。</p> 
<p style="text-align:center"><img alt="" src="https://images2.imgbox.com/04/8e/wYgheRxP_o.png"></p> 
<p>ROS中使用iGibson</p> 
<p>ROS包含了很多驱动以及算法的实现，因此需要利用ROS软件包来完善机器人应用程序。iGibson与ROS集成有三个关键应用。</p> 
<ul>
<li> <p>在可控的逼真的仿真环境中对现有算法进行基准测试。从而可以将基于学习的方法与模拟环境中的传统方法进行比较。</p> </li>
<li> <p>将仿真中的机器人与现实世界中的机器人进行比较。在模拟中，iGibson可以模拟机器人的传感器并发布为消息。在现实世界中，真正的机器人会发布传感器消息。因此，可以仅更改订阅的消息并基准测试下游应用程序的性能。这有助于定位域间隙和调试算法。</p> </li>
<li> <p>在仿真中使用ROS功能，例如许多运动计划的实现。</p> </li>
</ul>
<p>我们测试一下斯坦福官方提供的iGibson与ROS集成进行导航的示例。这是一个ros软件包，它将iGibson Env与ros导航堆栈集成在一起。</p> 
<p style="text-align:center"><img alt="" src="https://images2.imgbox.com/3f/fe/CNXbDtqs_o.png"></p> 
<ol>
<li> <p>安装ROS：在此软件包中，使用ros dynamic的导航堆栈。</p> </li>
<li> <p>由于ROS目前仅支持<code>python2.7</code>，因此您需要创建python2.7虚拟环境而不是python3.x。因此需要源码编译，请参考上文。</p> </li>
<li> <p>如果您使用annaconda设置python环境，则需要对<code>PATH</code>和进行一些调整<code>PYTHONPATH</code>以避免冲突。特别是：</p> <pre><code>echo $PATH | grep -oP "[^:;]+" | grep conda ## Remove these paths from $PATH
</code></pre> 
  <ol>
<li> <p>对于<code>PYTHONPATH</code>：<code>/usr/lib/python2.7/dist-packages/</code>，<code>/opt/ros/kinetic/lib/python2.7/dist-packages</code>(ROS python库)，(gibson依赖项)并且需要位于中。<code>&lt;anaconda installation root&gt;/anaconda2/envs/py27/lib/python2.7/site-packages``&lt;gibson root&gt;``PYTHONPATH</code></p> </li>
<li> <p>对于<code>PATH</code>：conda相关的需要从中删除<code>PATH</code></p> </li>
</ol>
</li>
<li> <p>将gibson-ros文件夹复制(或软链接)到您的文件夹中，<code>catkin_ws/src</code>然后运行catkin_make来索引gibson-ros软件包。</p> </li>
</ol>
<pre><code>ln -s $PWD/examples/ros/gibson-ros/ ~/catkin_ws/src/
cd ~/catkin_ws &amp;&amp; catkin_make &amp;&amp; cd -
</code></pre> 
<p>安装<code>gibson2-ros</code>依赖项：</p> 
<pre><code>rosdep install gibson2-ros
</code></pre> 
<p>检查demo：</p> 
<pre><code>which python 

python -c 'import gibson2, rospy, rospkg' 
</code></pre> 
<p>运行gibson + ros的demo：</p> 
<pre><code>source /opt/ros/kinetic/setup.bash
source &lt;catkin-workspace-root&gt;/catkin_ws/devel/setup.bash</code></pre> 
<pre><code class="language-python">roslaunch gibson2-ros turtlebot_rgbd.launch 

# Gmapping
roslaunch gibson2-ros turtlebot_gmapping.launch

# hector mapping
roslaunch gibson2-ros turtlebot_hector_mapping.launch

# navigation stack
roslaunch gibson2-ros turtlebot_navigation.launch

# navigation stack with ground truth localization
roslaunch gibson2-ros turtlebot_gt_navigation.launch </code></pre> 
<p>将看到如下效果：</p> 
<p style="text-align:center"><img alt="" src="https://images2.imgbox.com/8d/10/Bc7fU49E_o.png"></p> 
<p>Gmapping的效果如下：</p> 
<p style="text-align:center"><img alt="" src="https://images2.imgbox.com/11/c7/KKgMmKsv_o.png"></p> 
<p>消息订阅与节点可以通过ROS中的指令查询，这里不再演示。</p> 
<p style="text-align:center"><img alt="" src="https://images2.imgbox.com/c5/f9/qDFOd8Lm_o.png"></p> 
<p> end</p> 
<p>这期就到这里结束啦~~希望对你们有些许帮助！！</p> 
<p>喜欢的话记得给小编个三连再走也不迟啦~~</p>
                </div>

		</div>
	</article>
</main>




			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程小白.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://www.w3counter.com/tracker.js?id=150625"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>
	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>