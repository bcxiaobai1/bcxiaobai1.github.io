<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<title>基于k-means聚类图像分割&#43;lbp&#43;pca&#43;svm实现烟雾识别（利用matlab仿真实现） - 编程小白</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程小白" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程小白</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">基于k-means聚类图像分割&#43;lbp&#43;pca&#43;svm实现烟雾识别（利用matlab仿真实现）</h1>
			
		</header>
		<div class="content post__content clearfix">
			


                <div id="content_views" class="htmledit_views">
                    <h1 style="margin-left:.0001pt;text-align:center">一、算法简介</h1> 
<h2 style="margin-left:.0001pt;text-align:left">1.1 c-means聚类算法</h2> 
<p style="margin-left:.0001pt;text-align:justify">        聚类分析是根据在数据中发现的描述对象及其关系的信息，将数据对象进行分组。目的是使组内的对象相互之间是相似的（相关的），而不同组中的对象是不同的（不相关的）。组内相似性越大，组间差距越大，说明聚类效果越好。</p> 
<p style="margin-left:.0001pt;text-align:justify">也就是说，聚类的目标是得到较高的类内相似度和较低的类间相似度，使得类间的距离尽可能大，类内样本与类中心的距离尽可能小。在此，我们选用k-means聚类算法。</p> 
<h2 style="margin-left:.0001pt;text-align:left"><strong>1 .2 LBP算法</strong></h2> 
<p style="margin-left:.0001pt;text-align:left">        LBP（Local Binary Pattern，局部二值模式）是一种用来描述图像局部纹理特征的算子；它具有旋转不变性和灰度不变性等显著的优点。它是首先由T. Ojala, M.Pietikäinen, 和D. Harwood 在1994年提出，用于纹理特征提取，提取的特征是图像的局部的纹理特征。</p> 
<p style="margin-left:.0001pt;text-align:left">原始的LBP算子定义为在3*3的窗口内，以窗口中心像素为阈值，将相邻的8个像素的灰度值与其进行比较，若周围像素值大于中心像素值，则该像素点的位置被标记为1，否则为0。这样，3*3邻域内的8个点经比较可产生8位二进制数（通常转换为十进制数即LBP码，共256种），即得到该窗口中心像素点的LBP值，并用这个值来反映该区域的纹理信息。</p> 
<h2 style="margin-left:.0001pt;text-align:left">1.3 PCA算法</h2> 
<p style="margin-left:.0001pt;text-align:left">        PCA(Principal Component Analysis)，即主成分分析方法，是一种使用最广泛的数据降维算法。其算法步骤如下：    </p> 
<p style="margin-left:.0001pt;text-align:left">        1）数据中心化——去均值，根据需要，有的需要归一化——Normalized；</p> 
<p style="margin-left:.0001pt;text-align:left">        2）求解协方差矩阵；</p> 
<p style="margin-left:.0001pt;text-align:left">        3）利用特征值分解/奇异值分解 求解特征值以及特征向量；</p> 
<p style="margin-left:.0001pt;text-align:left"><span style="background-color:#ffffff"><span style="color:#333333">        4）</span></span><span style="background-color:#ffffff"><span style="color:#333333">将特征值从大到小排序</span></span><span style="background-color:#ffffff"><span style="color:#333333">，</span></span><span style="background-color:#ffffff"><span style="color:#333333">保留</span></span><span style="background-color:#ffffff"><span style="color:#333333">前</span></span><span style="background-color:#ffffff"><span style="color:#333333">k</span></span><span style="background-color:#ffffff"><span style="color:#333333">个特征向量</span></span></p> 
<p style="margin-left:.0001pt;text-align:left">        5）利用特征向量构造投影矩阵；</p> 
<p style="margin-left:.0001pt;text-align:left">        6）利用投影矩阵，得出降维的数据。</p> 
<h2 style="margin-left:.0001pt;text-align:left">1.4 SVM算法      </h2> 
<p style="margin-left:.0001pt;text-align:left">        支持向量机（support vector machines, SVM）是一种二分类模型，它的基本模型是定义在特征空间上的间隔最大的线性分类器，间隔最大使它有别于感知机；SVM还包括核技巧，这使它成为实质上的非线性分类器。SVM的的学习策略就是间隔最大化，可形式化为一个求解凸二次规划的问题，也等价于正则化的合页损失函数的最小化问题。SVM的的学习算法就是求解凸二次规划的最优化算法。</p> 
<p style="margin-left:.0001pt;text-align:left">        SVM学习的基本想法是求解能够正确划分训练数据集并且几何间隔最大的分离超平面。如下图所示即为分类超平面，对于线性可分的数据集来说，这样的超平面有无穷多个（即感知机），但是几何间隔最大的分类超平面却是唯一的。如下图1-1SVM算法示意图</p> 
<p style="text-align:center"><img alt="" height="296" src="https://images2.imgbox.com/2c/c1/bmvB8lAC_o.png" width="336"></p> 
<p style="text-align:center"><strong>图1-1SVM算法示意图</strong></p> 
<h1 style="text-align:center">二、算法实现</h1> 
<h2>2.1 烟雾识别算法流程</h2> 
<p style="text-align:justify">        1）首先对所有图像进行预处理，假定将有烟当作正样本，将没烟看作负样本，train集的smoke文件夹改名为pos，train集的non文件夹改名为neg；同理将test集的smoke文件夹改名为pos，test集的non文件夹改名为neg。为了对所有图片进行处理，将train和test中的pos和neg中的图片全部规范命名格式为0001.jpg、0002.jpg、0003.jpg、0004.jpg、0005.jpg......。将这些图片名字提取出来分别存到“pos_list.txt、neg_list.txt、pos_test_list.txt、neg_test_list.txt文本中。如下图2-1图2-2所示</p> 
<p style="text-align:center"><img alt="" src="https://images2.imgbox.com/e9/19/gAC3l3xu_o.png"></p> 
<p style="text-align:center"><strong>图2-1</strong></p> 
<p style="text-align:center"><img alt="" src="https://images2.imgbox.com/49/d7/WeLFygP5_o.png"></p> 
<p style="text-align:center"><strong>图2-2</strong></p> 
<p style="text-align:justify">        </p> 
<p style="text-align:justify">        2）利用c-means聚类算法对训练集和测试集图像的像素进行聚类，实现图像分割。</p> 
<p style="text-align:justify">        3）利用LBP对分割后的训练集图像和测试集图像进行特征提取。</p> 
<p style="text-align:justify"><span style="background-color:#ffffff"><span style="color:#333333">        4）</span></span>分别对训练集和测试集使用主成分分析法（PCA）进行特征降维。</p> 
<p style="text-align:justify">        5）利用对训练集降维后得到的二维特征训练SVM二分类模型，</p> 
<p style="text-align:justify">        6）最后利用对测试集降维后得到的二维特征进行分类预测。</p> 
<p style="text-align:justify">        整体算法流程如下图2-3所示</p> 
<p style="text-align:center"><img alt="" height="435" src="https://images2.imgbox.com/10/e8/u1OAJ67N_o.png" width="1012"></p> 
<p style="text-align:center"><strong>图2-3 算法流程框图</strong></p> 
<h2 style="margin-left:.0001pt;text-align:justify">2.2 c-means算法实现</h2> 
<p style="margin-left:.0001pt;text-align:justify">        图像分割是利用图像的灰度、颜色、纹理、形状等特征，把图像分成若干个互不重叠的区域，并使这些特征在同一区域内呈现相似性，在不同的区域之间存在明显的差异性。然后就可以将分割的图像中具有独特性质的区域提取出来用于不同的研究。图像识别的基础是图像分割，其作用是把反映物体真实情况的、占据不同区域的、具有不同特性的目标区分开来，并形成数字特征。因此本文利用c-means聚类算法实现图像分割，实现对噪声的过滤，在构建烟雾识别模型的过程中，首先分别对无烟和有烟的图像进行c-means聚类图像分割。</p> 
<p style="margin-left:.0001pt;text-align:justify">        本文对预处理过后的训练集和测试集图像进行像素聚类，在此分别列举一张有烟图和无烟图的图像分割前后的效果对比。如图2-4和图2-5所示</p> 
<p style="text-align:center"><img alt="" height="318" src="https://images2.imgbox.com/fa/fb/AjHmJKXe_o.png" width="424"></p> 
<p style="text-align:center"><strong>图2-4 <strong>无烟图像分割前后对照图</strong></strong></p> 
<p style="text-align:center"><img alt="" height="261" src="https://images2.imgbox.com/e7/2f/xAK76nSb_o.png" width="347"></p> 
<p style="text-align:center"><strong><strong>图</strong></strong><strong><strong>2-5</strong></strong><strong><strong>有</strong></strong><strong><strong>烟图像分割前后对照图</strong></strong> </p> 
<h2 style="margin-left:.0001pt;text-align:justify">2.3 LBP算法实现</h2> 
<p style="margin-left:.0001pt;text-align:justify">        本文LBP算法将像素聚类（3类）以后的图像进行特征提取。在此分别列举一张有烟图和无烟图的图像特征提取前后的效果对比。</p> 
<p style="text-align:center"><img alt="" height="155" src="https://images2.imgbox.com/09/5b/WaGHrIoz_o.png" width="352"></p> 
<p style="text-align:center"><strong>图2-6无烟三像素聚类LBP特征提取前后对照图 </strong></p> 
<p style="text-align:center"><img alt="" height="155" src="https://images2.imgbox.com/00/6e/2immmlz7_o.png" width="353"></p> 
<p style="margin-left:.0001pt;text-align:center"><strong><strong>图</strong></strong><strong><strong>2-7</strong></strong><strong><strong>有烟三像素聚类</strong></strong><strong><strong>LBP</strong></strong><strong><strong>特征提取前后对照图</strong></strong></p> 
<p>         本文PCA算法将HOG或LBP提取的特征进行特征降维，使数据可视化。PCA算法可以获取原有特征的大部分信息，降维以后的前k个特征值保留下来的信息占原有信息的比例可有下式计算获得。</p> 
<p style="text-align:center"><img alt="" height="81" src="https://images2.imgbox.com/d0/9a/VJW5gSof_o.png" width="73"></p> 
<p>        对LBP算法提取的特征进行特征降维，在此取前两维特征进行模型训练，前两维度保留的信息含有98.75%，如下图2-8所示.</p> 
<p style="text-align:center"><img alt="" height="262" src="https://images2.imgbox.com/ae/0f/fm4vkQxl_o.png" width="354"></p> 
<h2 style="margin-left:.0001pt;text-align:justify">2.4 SVM算法实现</h2> 
<p style="margin-left:.0001pt;text-align:justify">        在经过上述图像预处理、图像像素聚类、LBP特征提取、PCA特征降维至两维过程之后，将二维特征向量作为输入训练SVM模型，最终得到模型在训练集上的分类准确度。</p> 
<p style="margin-left:.0001pt;text-align:justify">        利用k-means+LBP+PCA+SVM算法，多次训练模型，最终取平均值，得到在训练集上的分类准确度为79%，在测试集上的分类准确度为78%。下图为模型在训练集上的分类效果图。</p> 
<p style="text-align:center"><img alt="" height="361" src="https://images2.imgbox.com/37/c4/N1JfXlHA_o.png" width="482"></p> 
<h1 style="margin-left:.0001pt;text-align:center">三、结果分析</h1> 
<p style="margin-left:.0001pt;text-align:justify">        经过第二章的算法实现，最终得到了完整的SVM二分类模型，利用该模型对test中的pos样本的图片和neg样本的图片进行预测。预测前，首先需要对测试集图片经过预处理、其次利用k-means3聚类法对像素进行聚类得到最终图像分割聚类图、然后对聚类图进行LBP特征提取、最后再利用PCA对提取出来的特征进行特征降维。将最终得到的二维特征向量作为模型的输入，进行分类预测，最终得到结果。对于LBP特征提取方法，在训练集和测试集上的准确率分别为79%和78%。经过对比可以发现模型的泛化性能良好。</p> 
<p style="margin-left:.0001pt;text-align:justify">        最后笔者不得不提的是，之所以采取上诉方法实现烟雾识别是因为，大作业要求必须包含聚类、分类、降维。笔者也尝试过直接使用LBP+SVM实现烟雾识别的方法，并且对测试集的准确率可以达到93%。</p> 
<p style="margin-left:.0001pt;text-align:justify">        这是两种不一样的解决问题的思路。若采用本文的思路是Pipeline，若直接采用LBP+SVM的思路叫做end2end，各有优缺点。Pipeline是将一个问题拆解成若干个子问题一次解决，然后串在一起，这种方法易于实现，且灵活性和可解释性更高，但缺点是多个子任务会造成错误累积。end2end是将一个问题看成一个整体，一般可以获得比pipeline更高的性能，但是整体像一个黑盒，可解释性差。现在深度学习最新研究的趋势是end2end的方法。</p> 
<p></p> 
<pre><code>%基于LBP特征提取的主程序代码
clc; 
clear ;  
k = 2;
acc1 = 0;
acc2 = 0;
acc = 0;
%%  标签制作  
ReadList1  = textread('pos_list.txt','%s','delimiter','n');%载入正样本列表  
sz1=size(ReadList1);   
label1=ones(sz1(1),1); %正样本标签  
ReadList2  = textread('neg_list.txt','%s','delimiter','n');%载入负样本列表
sz2=size(ReadList2);  
label2=zeros(sz2(1),1);%负样本标签  
label_train = [label1',label2'];%训练集标签
ReadList_pos = textread('pos_test_list.txt','%s','delimiter','n');%载入测试正样本列表  
sz_pos=size(ReadList_pos);   
label_pos=ones(sz_pos(1),1); %正样本标签
ReadList_neg  = textread('neg_test_list.txt','%s','delimiter','n');%载入测试负样本列表
sz_neg=size(ReadList_neg);  
label_neg=zeros(sz_neg(1),1);%负样本标签  
label_test = [label_pos',label_neg'];%测试集误差
total_trainnum=length(label_train);  
total_testnum = length(label_test);
data1 = zeros(total_trainnum,256);  
data2 = zeros(total_testnum,256);
%% 提取特征
%读取训练集正样本并计算lbp特征 
for i=1:sz1(1)
   name=char(ReadList1(i,1));  
   image1=imread(strcat('F:模式识别matlab程序模式识别大作业yanwujiancepos',name));
    I=double(image1)/255;
   clu_kmeans=imkmeans(I,3);
   clu_pic=clu_kmeans/3;
   lbps = lbp(clu_pic);
   data1(i,:)=lbps;  
end
%读取训练集负样本并计算lbp特征  
for j=1:sz2(1)
   name= char(ReadList2(j,1));  
   image2=imread(strcat('F:模式识别matlab程序模式识别大作业yanwujianceneg',name));  
    I=double(image2)/255;
   clu_kmeans=imkmeans(I,3);
   clu_pic=clu_kmeans/3;
   lbps = lbp(clu_pic);
   data1(sz1(1)+j,:)=lbps;  
end
%读取测试集正样本并计算lbp特征
for m=1:sz_pos(1)
   test_name= char(ReadList_pos(m,1));  
   image3=imread(strcat('F:模式识别matlab程序模式识别大作业yanwujiancetestpos_test',test_name));  
    I=double(image3)/255;
   clu_kmeans=imkmeans(I,3);
   clu_pic=clu_kmeans/3;
   lbpst= lbp(clu_pic);
   data2(m,:)=lbpst;  
end
%读取测试集负样本并计算lbp特征
for n =1:sz_neg(1)
    test_name=char(ReadList_neg(n,1)); 
    image4=imread(strcat('F:模式识别matlab程序模式识别大作业yanwujiancetestneg_test',test_name));
     I=double(image4)/255;
   clu_kmeans=imkmeans(I,3);
   clu_pic=clu_kmeans/3;
   lbps = lbp(clu_pic);
    data2(sz_pos(1)+n,:)=lbpst; 
end
load data1
load data2
load svmStruct3
%数据降维
[COEFF SCORE latent]=princomp(data1(:,:));%训练集数据降维
pcaData1 = SCORE(:,1:k);
latent = 100*latent/sum(latent);
for i = 1:8
latent(i+1) = latent(i+1)+latent(i)
end
plot(latent(1:8));%画出前8个特征值所包含的图像信息比例
x0 = bsxfun(@minus,data2,mean(data2,1));
pcaData2_sw = x0*COEFF(:,:);
pcaData2 = pcaData2_sw(:,1:k);
%%  评估方法：交叉验证法
[train, test] = crossvalind('holdOut',label_train);   %随机选择训练集合测试集
cp = classperf(label_train);  %评估分类器性能
svmStruct3hog = svmtrain(pcaData1(train,1:k),label_train(train));%训练SVM分类器  
%使用svmtrain进行训练,得到训练后的结构svmStruct3hog,在预测时使用
save svmStruct3hog   %%保存 svmStruct3hog
cros = svmclassify(svmStruct3hog,pcaData1(test,1:k)); 
classperf(cp,cros ,test);  
cp.CorrectRate   
%% 测试
load svmStruct3hog
for i=1:sz_pos(1)
       classes = svmclassify(svmStruct3,pcaData2(i,:));%classes的值即为分类结果
       if classes==1
           acc1=acc1+1;%记录正确分类的样本数
       end
end
for j = sz_pos(1)+1:1383
       classes = svmclassify(svmStruct3,pcaData2(j,:));%classes的值即为分类结果
       if classes~=1
           acc2=acc2+1;%记录正确分类的样本数
       end
end 
acc = acc1+acc2;
fprintf('精确度为：%5.2f%%n',(acc/(sz_neg(1)+sz_pos(1)))*100);%计算预测的正确率</code></pre> 
<pre><code>%lbp特征提取代码
function result = lbp(varargin) % image,radius,neighbors,mapping,mode)
% Check number of input arguments.
error(nargchk(1,5,nargin));
image=varargin{1};
d_image=double(image);

if nargin==1
    spoints=[-1 -1; -1 0; -1 1; 0 -1; -0 1; 1 -1; 1 0; 1 1];
    neighbors=8;
    mapping=0;
    mode='h';
end

if (nargin == 2) &amp;&amp; (length(varargin{2}) == 1)
    error('Input arguments');
end

if (nargin &gt; 2) &amp;&amp; (length(varargin{2}) == 1)
    radius=varargin{2};
    neighbors=varargin{3};
    spoints=zeros(neighbors,2);

    % Angle step.
    a = 2*pi/neighbors;
    for i = 1:neighbors
        spoints(i,1) = -radius*sin((i-1)*a);
        spoints(i,2) = radius*cos((i-1)*a);
    end
   
    if(nargin &gt;= 4)
        mapping=varargin{4};
        if(isstruct(mapping) &amp;&amp; mapping.samples ~= neighbors)
            error('Incompatible mapping');
        end
    else
        mapping=0;
    end
   
    if(nargin &gt;= 5)
        mode=varargin{5};
    else
        mode='h';
    end
end


if (nargin &gt; 1) &amp;&amp; (length(varargin{2}) &gt; 1)
    spoints=varargin{2};
    neighbors=size(spoints,1);
   
    if(nargin &gt;= 3)
        mapping=varargin{3};
        if(isstruct(mapping) &amp;&amp; mapping.samples ~= neighbors)
            error('Incompatible mapping');
        end
    else
        mapping=0;
    end
   
    if(nargin &gt;= 4)
        mode=varargin{4};
    else
        mode='h';
    end  
end

% Determine the dimensions of the input image.
[ysize xsize] = size(image);
 
miny=min(spoints(:,1));
maxy=max(spoints(:,1));
minx=min(spoints(:,2));
maxx=max(spoints(:,2));

% Block size, each LBP code is computed within a block of size bsizey*bsizex
bsizey=ceil(max(maxy,0))-floor(min(miny,0))+1;
bsizex=ceil(max(maxx,0))-floor(min(minx,0))+1;


% Coordinates of origin (0,0) in the block
origy=1-floor(min(miny,0));
origx=1-floor(min(minx,0));


% Minimum allowed size for the input image depends
% on the radius of the used LBP operator.
if(xsize &lt; bsizex || ysize &lt; bsizey)
  error('Too small input image. Should be at least (2*radius+1) x (2*radius+1)');
end


% Calculate dx and dy;
dx = xsize - bsizex;
dy = ysize - bsizey;


% Fill the center pixel matrix C.
C = image(origy:origy+dy,origx:origx+dx);
d_C = double(C);


bins = 2^neighbors;


% Initialize the result matrix with zeros.
result=zeros(dy+1,dx+1);


%Compute the LBP code image


for i = 1:neighbors
  y = spoints(i,1)+origy;
  x = spoints(i,2)+origx;
  % Calculate floors, ceils and rounds for the x and y.
  fy = floor(y); cy = ceil(y); ry = round(y);
  fx = floor(x); cx = ceil(x); rx = round(x);
  % Check if interpolation is needed.
  if (abs(x - rx) &lt; 1e-6) &amp;&amp; (abs(y - ry) &lt; 1e-6)
    % Interpolation is not needed, use original datatypes
    N = image(ry:ry+dy,rx:rx+dx);
    D = N &gt;= C;
  else
    % Interpolation needed, use double type images
    ty = y - fy;
    tx = x - fx;


    % Calculate the interpolation weights.
    w1 = (1 - tx) * (1 - ty);
    w2 =      tx  * (1 - ty);
    w3 = (1 - tx) *      ty ;
    w4 =      tx  *      ty ;
    % Compute interpolated pixel values
    N = w1*d_image(fy:fy+dy,fx:fx+dx) + w2*d_image(fy:fy+dy,cx:cx+dx) + ...
        w3*d_image(cy:cy+dy,fx:fx+dx) + w4*d_image(cy:cy+dy,cx:cx+dx);
    D = N &gt;= d_C;
  end 
  % Update the result matrix.
  v = 2^(i-1);
  result = result + v*D;
end


%Apply mapping if it is defined
if isstruct(mapping)
    bins = mapping.num;
    for i = 1:size(result,1)
        for j = 1:size(result,2)
            result(i,j) = mapping.table(result(i,j)+1);
        end
    end
end


if (strcmp(mode,'h') || strcmp(mode,'hist') || strcmp(mode,'nh'))
    % Return with LBP histogram if mode equals 'hist'.
    result=hist(result(:),0:(bins-1));
    if (strcmp(mode,'nh'))
        result=result/sum(result);
    end
else
    %Otherwise return a matrix of unsigned integers
    if ((bins-1)&lt;=intmax('uint8'))
        result=uint8(result);
    elseif ((bins-1)&lt;=intmax('uint16'))
        result=uint16(result);
    else
        result=uint32(result);
    end
end
end</code></pre> 
<pre><code>%k-means图像聚类分割
function [F,C]=imkmeans(I,C)
% I:图像矩阵,支持彩色或者灰度图
% C:聚类中心，可以是整数或者数组，整数表示随机选择K个聚类中心
% F:样本聚类编号
if nargin~=2
    error('IMKMEANS:InputParamterNotRight','只能有两个输入参数！');
end
if isempty(C)
    K=2;
    C=[];
elseif isscalar(C)
    K=C;
    C=[];
else
    K=size(C,1);
end
%% I.提取像素点特征向量
X=exactvecotr(I);
%% II.搜索初始聚类中心
if isempty(C)
    C=searchintial(X,'sample',K);
end
%% III.循环搜索聚类中心
Cprev=rand(size(C));
while true
    %计算样本到中心的距离
    D=sampledist(X,C,'euclidean');
    %找出最近的聚类中心
    [~,locs]=min(D,[],2);
    %使用样本均值更新中心
    for i=1:K
        C(i,:)=mean(X(locs==i,:),1);
    end
    %判断聚类算法是否收敛
    if norm(C(:)-Cprev(:))&lt;eps
        break
    end
    %保存上一次聚类中心
    Cprev=C;
end
[m,n,~]=size(I);
F=reshape(locs,[m,n]);</code></pre> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p style="text-align:center"></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p style="margin-left:.0001pt;text-align:justify">        </p>
                </div>

		</div>
	</article>
</main>




			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程小白.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://www.w3counter.com/tracker.js?id=150625"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>
	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>