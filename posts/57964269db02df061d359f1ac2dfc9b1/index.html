<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<title>【视觉SLAM】ORB-SLAM: Tracking and Mapping Recognizable Features - 编程小白</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程小白" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程小白</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">【视觉SLAM】ORB-SLAM: Tracking and Mapping Recognizable Features</h1>
			
		</header>
		<div class="content post__content clearfix">
			


                <div id="content_views" class="markdown_views prism-atom-one-dark">
                    
                        
                    
                    <blockquote> 
 <p>Mur-Artal R , Juan D. Tardós. ORB-SLAM: Tracking and Mapping Recognizable Features[C]// Workshop on Multi View Geometry in<br> Robotics. 2014.</p> 
</blockquote> 
<pre><code class="prism language-cpp">带着问题：怎么利用ORB特征进行定位和建图？传感器、视觉里程计、后端优化、回环检测和建图这五大模块的组成。
</code></pre> 
<table><thead><tr><th><font color="black" size="5">摘要</font></th></tr></thead></table>
<blockquote> 
 <p>当前的视觉 SLAM系统构建的地图非常适合在会话期间跟踪相机。然而，这些地图并非设计用于在其他会话中使用不同的相机甚至相同的相机执行定位，而是从不同的视点观察地图。这种限制来自缺乏被识别的地图能力。在本文中，我们提出了一种新的基于关键帧的SLAM系统，它通过直接映射可用于识别的特征来提高地图的可重用性。我们的系统实时执行重定位和闭环，对视点具有高不变性。大规模解决了构建一个允许在本地执行大多数映射和跟踪操作的共可见性图。我们还结合了一种修剪机制来减少地图中关键帧的冗余。我们相信，我们系统构建可重复使用地图的能力使其成为社区调查长期和识别问题的好选择。</p> 
</blockquote> 
<h1>
<a id="_14"></a>?一、引言</h1> 
<p>估计相机的位姿，同时对其所观察的世界进行几何重建的问题，通常被称为单目 SLAM。术语单目表示使用立体或 RGB-D 相机对同一问题的区别。仅使用一个相机是一个更复杂的问题，因为图像中观察到的特征的深度是未知的，并且需要多视图几何来解决该问题。立体和 RGB-D 相机具有可以恢复深度的范围，但在某些情况下仍需要单目技术。</p> 
<p>单目 SLAM 已经发展了很长时间，从最初的过滤方法到最现代的基于关键帧的 SLAM 系统。在最近的一项工作中，Strasdat 等人 [10] 得出结论，基于关键帧的技术在每个计算单元上比过滤方法更准确。最具代表性的基于关键帧的系统之一是并行跟踪和映射，PTAM [2]，仍然被许多人认为是单目 SLAM 的黄金标准。尽管如此，尽管问题已经成熟，并且如果我们将其与早期的解决方案进行比较，PTAM 的出色性能，单目 SLAM 仍然不能被视为已解决。如今，地图仅用于在特定操作期间计算相机的位姿，但它们对于定位不同的相机或从不同的视点重新定位相同的相机是无用的。如果场景不是静态的，问题会变得更糟。为了解决这个限制，我们认为要识别的地图的能力是至关重要的，我们发现在类似 PTAM 的系统中在这些意义上存在很大的缺陷。</p> 
<p>在我们之前的工作 [5] 中，我们在 PTAM 中集成了一个非常有效的位置识别系统来执行重新定位和闭环。该位置识别基于具有 ORB 特征 [6] 的二进制词袋，从而产生具有高度不变性的实时重定位系统。我们通过实验证明了系统重用具有不同相机和轨迹的地图的能力。需要注意的是，我们需要提取特定特征（ORB）进行识别才能获得这种能力。在这项工作中，我们希望更进一步，从头开始构建一个全新的 SLAM 系统，该系统使用相同的功能进行跟踪、映射和识别。我们计划在不久的将来发布 ROS 的开源实现，以便其他研究人员可以使用这个 SLAM 系统作为基础。</p> 
<p>类似于 Stradat [9] 中，我们的系统利用共视性信息进行大规模操作。我们还利用关键帧之间的共可见性信息来提高位置识别器的性能，并且我们集成了剪枝算法来减少地图中关键帧的冗余，因此它是多通道高效的。该系统由三个主要任务组成：跟踪、本地映射和闭环，它们在多核机器中并行运行。图 1 显示了系统的不同构建块的方案，我们将在以下部分中进行描述。</p> 
<p><img src="https://images2.imgbox.com/c1/04/1g9RNuY6_o.png" alt="在这里插入图片描述"></p> 
<h1>
<a id="_24"></a>?二、地图</h1> 
<p>在本节中，我们将介绍我们的系统从世界存储的信息。</p> 
<p><strong>A、地图点 或者 3D ORB</strong></p> 
<p>地图点构成了世界的 3D 重建结构。每个地图点对应于世界中的一个带纹理的平面补丁，其位置已从不同的视图进行三角测量，并通过捆绑调整进行了细化。在这项工作中，点对应于图像中的 ORB 特征，因此地图点是 FAST 角的三角剖分。世界中的补丁大小和方向取决于检测到 FAST 的比例级别和关键点的方向。每个地图点都关联了一个补丁法线 n，它是观察方向的平均向量（将点与关键帧相机中心连接的光线）。单个地图点可能与多个关键帧中的 ORB 特征相关联，因此有多个描述符相关联。在没有不匹配的情况下，这种描述符的多样性解释了地图点的不同外观，具体取决于视点。为了加快数据关联，每个地图点都存储了一个代表描述符 D，它与所有关联描述符的距离最小。此外，每个地图点都存储了根据已观察到的比例和距离可以观察到的最大 dmax 和最小距离 dmin。</p> 
<p><strong>B、关键帧</strong></p> 
<p>关键帧是总结现实世界视觉信息的快照。每个关键帧存储帧中的所有 ORB 特征（关联或不关联到地图点）和相机位姿。在我们的框架中，关键帧不是不可变的，相反，如果一个区域被其他关键帧充分表示，它们可以被丢弃，如第 V-E 节所述。</p> 
<p><strong>C、可视化图</strong></p> 
<p>共视性信息在确定本地地图或提高地点识别器的性能等多项任务中非常有用。该共可见性信息以无向加权图的形式存储在系统中，其中每个节点都是一个关键帧，如果两个关键帧之间至少看到 θ 个公共地图点，则它们之间存在一条边。最互连的最低θ是图，因此遍历的成本更高。斯特拉斯达特[9] 提出了 15 到 30 之间的典型值。边缘的权重是公共地图点的数量。</p> 
<h1>
<a id="_40"></a>?三、地点识别</h1> 
<p>该系统集成了一个位置识别器来检测循环和重新定位。这个识别器基于我们之前的工作 [5]，它建立在非常有效的二进制词袋位置识别器 DBoW2 [1] 上。与之前的工作相比，这项工作有两个主要改进。首先，地点识别器能够在数据库中没有明确匹配的情况下返回多个假设。其次，我们用共可见性信息替换所有时间信息。接下来，我们描述与我们以前的工作有关的新颖性。</p> 
<p><strong>A. 识别数据库</strong></p> 
<p>数据库包含一个倒排索引，它存储词汇表中每个关键帧的单词，以及它在关键帧中的权重。因此，通过只检查常见的视觉词，可以非常有效地查询数据库。在本地映射完成处理之后，闭环检测任务（见图 1）将新的关键帧插入到数据库中。</p> 
<p>当重定位或闭环检测器查询数据库时，计算所有与查询图像共享视觉词的关键帧之间的相似度分数。因为关键帧之间存在视觉重叠，所以不会存在唯一的高分关键帧，而是会有多个高分关键帧。在这项工作中，作为一项新颖性，我们形成了covisibility groups，这些组将covisibility graph中直接连接的所有关键帧的分数相加，作为关键帧匹配，即具有最高个人分数的关键帧匹配。在 [5] 和 [1] 中，图像按时间接近度分组，这不会将查看同一地点的关键帧的得分相加，而是在不同时间插入。我们不是只获得最佳匹配，而是获得所有分数高于最佳分数的 90% 的匹配。</p> 
<p><strong>B. 高效精细的ORB匹配</strong></p> 
<p>在重定位和循环检测中，查询数据库后，我们将分别计算相机位姿和相似度变换，这也将用作几何验证。我们首先需要计算两个图像之间的一组 ORB 对应关系。如果我们在词汇树的第二层仅比较属于同一节点的 ORB [1]，则蛮力匹配可以加快一个数量级，而不会显着降低匹配性能。这种初始对应关系可以通过方向一致性测试 [5] 进行细化。</p> 
<p><strong>C.可视化一致性</strong></p> 
<p>闭环的鲁棒性至关重要，因为错误的闭环会破坏地图。 Gálvez-López 和 Tardós [1] 提出了一种时间一致性测试，使系统等待获得多个连续的时间一致性匹配，以最终接受闭环。在这里，我们提出了一个可视化一致性测试，以便两个连续的关键帧匹配被认为是一致的，如果在covisibility graph中存在并且连接它们的边。</p> 
<h1>
<a id="_59"></a>✨四、跟踪</h1> 
<p><strong>A. ORB 提取</strong></p> 
<p>第一步是提取帧中的 ORB 特征。首先计算比例图像金字塔并在每个级别检测 FAST 关键点，然后将仅描述这些关键点的子集。此任务涉及多个参数，如金字塔中的级别数、级别之间的比例因子、要提取的 ORB 的数量（以及要描述的关键点）、检测器阈值以及非常重要的确定子集的规则要保留和描述的关键点。这些参数对特征的尺度不变性、其他任务（词袋转换、数据关联等）的计算成本以及图像上的关键点分布有直接影响。我们以 8 个比例提取 1000 个 ORB，比例因子为 1.2。为了最大限度地分散图像中的关键点，我们将图像离散化为网格并在每个单元格中保留相同数量的关键点。如果某个单元格没有足够的关键点，则允许其余单元格保留更多关键点。<br> <img src="https://images2.imgbox.com/7a/d9/9N1TryuY_o.png" alt="在这里插入图片描述"></p> 
<p><strong>B. 从前一帧开始跟踪</strong></p> 
<p>如果在最后一帧中跟踪成功，则跟踪尝试从最后一帧获得相机姿态的第一个估计。上一帧中的每个 ORB（具有关联的地图点）在当前帧中在其先前位置周围的小区域内搜索匹配项。如果由于相机的快速移动而没有找到足够的对应关系，则重复匹配过程，但搜索区域更大。初始对应关系通过方向一致性测试 [5] 进行细化。在这一点上，我们有一组 3D 到 2D 的对应关系，我们可以计算相机位姿来解决 RANSAC 方案中的 PnP 问题 [4]。</p> 
<p><strong>C. 重新定位：从头开始跟踪</strong></p> 
<p>如果跟踪丢失，我们将帧转换为词袋，并在关键帧数据库中查询重新定位候选者。如果有几个地方与当前帧外观相​​似，则可能有多个候选者。对于每个候选关键帧，我们计算当前帧和与关键帧中的映射点关联的 ORB 之间的 ORB 对应关系，如第 III-B 节所述。此时，每个候选关键帧都有一组 2D 到 3D 的对应关系。现在我们对每个候选者交替执行 RANSAC 迭代，并尝试在每次迭代时计算相机位姿以解决 PnP 问题。如果我们找到相机姿势，我们可以继续跟踪过程。</p> 
<p><strong>D. 追踪局部地图</strong></p> 
<p>现在我们已经对世界上的相机位姿进行了估计，我们可以将地图投影到框架中并搜索更多的地图点对应关系。我们不像在 PTAM [2] 中那样投影地图中的所有地图点，而是采用与 Strasdat 等人类似的方法 [9] 并投影局部地图。该局部地图包含一组关键帧 K1，与当前帧共享地图点，以及一组 K2，其与共可见图中的关键帧 K1 相邻。在非常相互关联的地图中，集合 K2 可能过度大，所以我们限制了从 K1 获取的邻居数量。本地地图还有一个参考关键帧 Kref∈ K1，它与当前帧共享大多数地图点。现在在帧中搜索局部地图的关键帧 K = K1∪ K2 中看到的所有地图点，如下所示：</p> 
<p><img src="https://images2.imgbox.com/b0/d9/YTyZeTrT_o.png" alt="在这里插入图片描述"><br> <strong>E. 最终位姿优化</strong></p> 
<p>跟踪的最后一步是优化相机位姿，使用来自 IV-B 或 IV-C 的初始估计以及在帧中的 ORB 特征和局部地图点之间找到的所有对应关系。优化最小化重投影误差保持固定的地图点位置。我们将 g2o [3] 与使用 Huber 成本函数稳健化的 Levenberg-Marquadt 算法结合使用。</p> 
<p><strong>F. 新的关键帧决策</strong></p> 
<p>如果跟踪成功，是时候决定是否插入新的关键帧了。要插入新的关键帧，必须满足以下所有条件：</p> 
<ol>
<li>从上次重新定位开始，必须经过 20 多帧。</li>
<li>当前帧跟踪至少 50 个点。</li>
<li>当前帧跟踪的地图点少于 Kref 的 90%。</li>
<li>从最后一个关键帧插入到已经过去了至少 10 帧，并且本地映射已经完成了对最后一个关键帧的处理。或者 20 帧过去了，一个信号被发送到本地映射以完成本地BA优化。</li>
</ol> 
<p>可以看出，我们没有像PTAM那样对到其他关键帧的距离使用任何条件，这里的条件更多的是视觉变化的感觉（条件3），并试图尽快插入帧（条件4）。第一个条件确保良好的先前重新定位，条件2确保良好的跟踪。</p> 
<h1>
<a id="_92"></a>?五、局部建图</h1> 
<p>局部建图线程处理新的关键帧，并更新和优化它们的局部邻域。跟踪插入的新关键帧存储在一个队列中，理想情况下该队列仅包含最后插入的关键帧。当局部建图采用队列中最旧的关键帧时，它遵循以下步骤：</p> 
<p><strong>A. 词袋转换</strong></p> 
<p>第一步是将关键帧转换为其词袋表示。这将返回一个词向量包，稍后将由循环关闭器使用，而且还将每个 ORB 特征关联到词汇树中的第二个节点，该节点将用于下一步的数据关联。</p> 
<p><strong>B. 对新地图点进行三角剖分</strong></p> 
<p>新地图点是通过在不同关键帧中对 ORB 进行三角剖分来创建的。 PTAM 仅使用最近的关键帧（即视差最低的关键帧）对点进行三角剖分，相反，我们使用共可见图中共享最多点的 N 个相邻关键帧对点进行三角剖分。我们需要限制关键帧的数量，因为在高度互连的地图中，计算成本会令人望而却步。对于当前关键帧中的每个空闲 ORB，我们只需比较描述符即可搜索与其他关键帧中其他空闲特征的匹配项。我们只比较词汇表中第二级属于同一节点的 ORB，并丢弃那些不满足极线约束的匹配项。一旦匹配了一对 ORB，就对它们进行三角剖分。如果地图点视差小于 1 度，则将其丢弃。最初，地图点出现在两个关键帧中，但它可能存在于其他关键帧中，因此地图点被投影在其余关键帧中，以预测跟踪所做的比例，请参阅第 IV-D 节。</p> 
<p><strong>C. 更新局部区域</strong></p> 
<p>地图点在创建后的以下三个关键帧中检查无误，必须满足以下两个条件才不会被丢弃：</p> 
<ol>
<li>跟踪必须在超过 25% 的帧中找到点预计在其中被发现。</li>
<li>如果从地图点创建开始已经经过了多个关键帧，则必须在至少三个关键帧中看到它。</li>
</ol> 
<p>由于已经对关键帧中的点进行了新的测量，因此必须重新计算这些关键帧的共视性图中的边缘。此外，我们为每个具有新测量值的点重新计算代表描述符 D。</p> 
<p><strong>D. 局部BA</strong></p> 
<p>与 PTAM [2] 类似，我们的局部束调整优化当前处理的关键帧、共视图中与其连接的所有关键帧，以及这些关键帧看到的所有地图点。看到该点但未连接到当前处理的关键帧的所有其他关键帧都包含在优化中但保持固定。为了解决非线性优化问题，我们使用在 g2o [3] 中实现的 Levenberg-Marquadt 方法和 Huber 鲁棒成本函数。优化后，我们重新计算每个地图点的法线 n，并缩放不变距离 dmin 和 dmax。</p> 
<p><strong>E. 修剪冗余关键帧</strong></p> 
<p>为了减少地图中关键帧的冗余信息，并且不允许关键帧的数量无限增长，我们丢弃了所有那些其 90% 的地图点至少在其他三个关键帧中出现过的关键帧相同的 orfiner 规模。这种修剪过程的一个例子如图 2 所示。</p> 
<p><img src="https://images2.imgbox.com/48/5c/rpOxE6z8_o.png" alt="在这里插入图片描述"></p> 
<h1>
<a id="__123"></a>?六、 闭环检测</h1> 
<p>闭环检测线程负责检测地图中的循环，如果发现，它会执行全局优化以保持地图的全局一致性。闭环检测器通过本地地图获取最后处理的关键帧 Ki 并执行我们接下来描述的几个任务。</p> 
<p><strong>A. 循环检测</strong></p> 
<p>首先，我们计算 Ki 的词袋向量与其在共可见图中的所有邻居之间的相似度，并保留最低分数 smin。然后循环关闭器查询关键帧数据库并丢弃所有分数低于 smin 的关键帧。此外，所有直接连接到 Ki 的关键帧都从结果中丢弃。为了提高检测器的鲁棒性，我们必须检测三个连续的候选循环，这些候选循环是covisibility一致的，见第III-C节。如果一个或多个循环候选关键帧通过了共可见性一致性测试，下一步是计算相似度变换。</p> 
<p><strong>B. 计算相似变换</strong></p> 
<p>在单目 SLAM 中有七个自由度，其中地图可以漂移，三个平移、三个旋转和一个比例因子 [8]。因此，要闭环检测，我们需要计算从当前关键帧 Ki 到循环关键帧 Kl 的相似性变换，以告知我们循环中累积的误差。这种相似性的计算也将作为闭环的几何验证。与在重新定位过程中一样，如果有多个位置与当前关键帧具有相似的外观，则可以有多个闭环候选。我们首先按照第 III-B 节中解释的过程计算与当前关键帧中的映射点相关联的 ORB 和循环关键帧之间的 ORB 对应关系。此时我们有3D转3D的每个循环候选的对应关系。我们交替地对每个候选者执行 RANSAC 迭代，试图计算相似度变换。接受我们找到具有足够内点的相似性 Sil 的第一个候选者。</p> 
<p><strong>C. 与局部建图线程同步</strong></p> 
<p>在纠正闭环之前，闭环检测器向局部建图发送一个信号，以便它在完成当前操作时停止。一旦局部建图停止，闭环检测器将继续纠正闭环。这是必要的，因为两个线程都会修改关键帧姿势和地图点，可能会混合结果并破坏地图。</p> 
<p><strong>D. 闭环融合</strong></p> 
<p>闭环校正的第一步是融合重复的地图点，并在将附加循环闭合的共可见性地图中插入新边。首先，当前关键帧位姿 Tiw 用相似变换 Sil 进行校正，并将该校正传播到 Ki 的所有邻居，连接变换，从而使循环的两侧对齐。循环关键帧及其邻居看到的所有地图点都投影到 Ki 及其邻居中，并在投影的狭窄区域中搜索匹配项，如第 IV-D 节中所做的那样。所有匹配的地图点和 Sil 计算中的内点都被融合了。融合中涉及的所有关键帧都将更新其在共可见图中的边，从而有效地创建附加闭环的边。</p> 
<p><strong>E. Covisibility 位姿图优化</strong></p> 
<p>为了闭环并纠正累积的误差，我们必须执行全局优化。然而，由于在执行BA时需要使用稳健的代价函数，为了对不匹配具有稳健性，我们首先需要计算一个初始解决方案，以便我们促进优化的收敛。该初始解决方案将包括对共可见性图的位姿图优化的结果，如果闭环边缘中的误差将沿图分布。位姿图优化应用于相似变换以纠正尺度漂移[8]。这种方法比我们之前的工作 [5] 更通用，如果姿势图只是将每个关键帧链接到前一个关键帧形成的一个循环，但残差和优化过程的定义仍然相同，这里不再重复。</p> 
<p><strong>F. 全局Bundle Adjustment</strong></p> 
<p>整个地图最终使用位姿图优化的种子进行优化。优化与 V-D 部分的局部捆绑调整相同，但这里所有关键帧和地图点都进行了优化。优化后再次释放局部映射。</p> 
<h1>
<a id="_154"></a>?七、实验</h1> 
<p>我们进行了两个实验，试图展示我们系统的不同优势。第一个是实验室中的手持相机序列，其中存在闭环、强烈的遮挡和相机的突然移动。第二个是 NewCollege 序列 [7] 的一部分，它在大范围内测试我们的系统。我们的系统集成在 <strong>ROS</strong> 中，并以与记录相同的 fps 模拟相机处理序列。随附的视频 1 显示了我们的系统在两个序列中运行，以及在实验室序列中运行 PTAM 以进行比较。</p> 
<p><strong>A. Lab sequence</strong></p> 
<p>该序列由 <strong>30 fps</strong> 的 <strong>752x480 分辨率</strong>图像组成。我们的系统在序列中运行的视图如图 3 所示。在序列期间执行的一些具有挑战性的重定位如图 4 所示。每帧的总跟踪时间如图 5 所示。可以看出，跟踪花费了在 90% 的帧中<strong>少于 40 毫秒</strong>。在序列期间跟踪时间略有增加，因为共可见图变得更加互连，因此局部地图更大。闭环检测器花费 5 毫秒在包含 86 个关键帧的数据库中检索闭环候选，<strong>计算相似度和融合闭环花费了 173 毫秒</strong>，<strong>位姿图优化花费了 187 毫秒</strong>来优化具有 1692 条边的图。最后<strong>光束平差法用了 518ms</strong>。为了比较，我们还按此顺序运行了 PTAM。首先我们必须说，它需要 20 多次试验才能实现良好的初始化。 PTAM 在我们的系统没有的序列的几个部分中丢失了轨道，并且由于缺乏视点不变性，重定位反复失败。</p> 
<p><img src="https://images2.imgbox.com/0c/fd/J2GPDRzp_o.png" alt="在这里插入图片描述"></p> 
<p><img src="https://images2.imgbox.com/b6/17/z2mE2VKP_o.png" alt="在这里插入图片描述"><br> <strong>B. NewCollege</strong></p> 
<p>这是一个立体序列，我们只处理左侧图像，其<strong>分辨率为 512x384</strong>，以 <strong>20 fps</strong> 拍摄。不同时间的地图重建如图 6 所示，最终重建如图 7 所示，其中包含 <strong>690 个关键帧</strong>和 <strong>33,000 个点</strong>。图 5 显示了每帧花费的总跟踪时间，其中 90% 的帧在不到 50 毫秒的时间内处理完毕。在序列的中心部分，机器人正在重新访问图 6 中可以看到的大闭环，其中局部地图大于探索区域，因此跟踪花费更多时间。当关键帧数据库包含 <strong>280 个关键帧</strong>时，闭环检测器花费 <strong>7 毫秒</strong>来检测关键帧数据库中的循环。闭环融合耗时 333 毫秒，位姿图优化耗时 2.07 秒，以优化 10831 条边的图。这清楚地表明，在大型闭环中优化整个 covisibility 图变得过于昂贵，因此并非所有边都应该包括在优化中，这种策略将在未来的工作中得到解决。</p> 
<p><img src="https://images2.imgbox.com/0c/a9/jxTaGfRd_o.png" alt="在这里插入图片描述"></p> 
<p><img src="https://images2.imgbox.com/de/9c/LTEzMxlr_o.png" alt="在这里插入图片描述"></p> 
<h1>
<a id="_175"></a>?八、结论</h1> 
<p>我们提出了一种新的视觉 SLAM 系统，重点是构建可识别的地图。我们不是对仅对跟踪当前相机有用的特征执行 SLAM，而是可用于位置和对象识别的特征的建图。这有效地扩展了地图的可重用性。与小地图中的 PTAM 相比，我们的前端更昂贵，但仍以帧速率运行，相机重定位能力有了很大改进。后端能够执行大规模映射，包括高效可靠的闭环。我们正在研究地图初始化的鲁棒性，由于空间不足，此处省略，以及要优化的位姿图的稀疏化闭环检测。我们计划发布代码，以便社区可以从我们的视觉 SLAM 方法中受益。</p>
                </div>
                
                

		</div>
	</article>
</main>




			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程小白.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://www.w3counter.com/tracker.js?id=150625"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>
	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>