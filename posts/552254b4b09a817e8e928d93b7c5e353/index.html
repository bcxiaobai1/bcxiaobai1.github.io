<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<title>2021-12-22 迈向程序猿的第五十一步 - 编程小白</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程小白" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程小白</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">2021-12-22 迈向程序猿的第五十一步</h1>
			
		</header>
		<div class="content post__content clearfix">
			


                <div id="content_views" class="htmledit_views">
                    <p id="main-toc"><strong>目录</strong></p> 
<p id="%E4%B8%80.Hbase%E7%9A%84%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6-toc" style="margin-left:0px"><a href="#%E4%B8%80.Hbase%E7%9A%84%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6" title="一.Hbase的工作机制">一.Hbase的工作机制</a></p> 
<p id="1.1%20Hbase%E7%9A%84%E5%AF%BB%E5%9D%80%E6%9C%BA%E5%88%B6%EF%BC%88%E9%87%8D%E7%82%B9%EF%BC%89-toc" style="margin-left:40px"><a href="#1.1%20Hbase%E7%9A%84%E5%AF%BB%E5%9D%80%E6%9C%BA%E5%88%B6%EF%BC%88%E9%87%8D%E7%82%B9%EF%BC%89" title="1.1 Hbase的寻址机制（重点）">1.1 Hbase的寻址机制（重点）</a></p> 
<p id="1.2%20Hbase%E7%9A%84%E5%AD%98%E5%82%A8%E6%9C%BA%E5%88%B6%EF%BC%88%E9%87%8D%E4%B8%AD%E4%B9%8B%E9%87%8D%EF%BC%89-toc" style="margin-left:40px"><a href="#1.2%20Hbase%E7%9A%84%E5%AD%98%E5%82%A8%E6%9C%BA%E5%88%B6%EF%BC%88%E9%87%8D%E4%B8%AD%E4%B9%8B%E9%87%8D%EF%BC%89" title="1.2 Hbase的存储机制（重中之重）">1.2 Hbase的存储机制（重中之重）</a></p> 
<p id="1.2.1%20%E5%AD%98%E5%82%A8%E6%9C%BA%E5%88%B6%E4%BB%8B%E7%BB%8D-toc" style="margin-left:80px"><a href="#1.2.1%20%E5%AD%98%E5%82%A8%E6%9C%BA%E5%88%B6%E4%BB%8B%E7%BB%8D" title="1.2.1 存储机制介绍">1.2.1 存储机制介绍</a></p> 
<p id="1.2.2%20%E5%90%8D%E8%AF%8D%E8%A7%A3%E9%87%8A-toc" style="margin-left:80px"><a href="#1.2.2%20%E5%90%8D%E8%AF%8D%E8%A7%A3%E9%87%8A" title="1.2.2 名词解释">1.2.2 名词解释</a></p> 
<p id="1.3%20Hbase%E7%9A%84Region%E7%AE%A1%E7%90%86-toc" style="margin-left:40px"><a href="#1.3%20Hbase%E7%9A%84Region%E7%AE%A1%E7%90%86" title="1.3 Hbase的Region管理">1.3 Hbase的Region管理</a></p> 
<p id="1.4%20Hbase%E7%9A%84%E8%AF%BB%E5%86%99%E6%B5%81%E7%A8%8B%EF%BC%88%E9%87%8D%E7%82%B9%EF%BC%89-toc" style="margin-left:40px"><a href="#1.4%20Hbase%E7%9A%84%E8%AF%BB%E5%86%99%E6%B5%81%E7%A8%8B%EF%BC%88%E9%87%8D%E7%82%B9%EF%BC%89" title="1.4 Hbase的读写流程（重点）">1.4 Hbase的读写流程（重点）</a></p> 
<p id="1.4.1%20Hbase%E7%9A%84%E8%AF%BB%E6%B5%81%E7%A8%8B-toc" style="margin-left:80px"><a href="#1.4.1%20Hbase%E7%9A%84%E8%AF%BB%E6%B5%81%E7%A8%8B" title="1.4.1 Hbase的读流程">1.4.1 Hbase的读流程</a></p> 
<p id="1.4.2%20Hbase%E7%9A%84%E5%86%99%E6%B5%81%E7%A8%8B-toc" style="margin-left:80px"><a href="#1.4.2%20Hbase%E7%9A%84%E5%86%99%E6%B5%81%E7%A8%8B" title="1.4.2 Hbase的写流程">1.4.2 Hbase的写流程</a></p> 
<p id="1.5%20%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8-toc" style="margin-left:40px"><a href="#1.5%20%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8" title="1.5 布隆过滤器">1.5 布隆过滤器</a></p> 
<p id="1.5.1%20%E7%AE%80%E4%BB%8B-toc" style="margin-left:80px"><a href="#1.5.1%20%E7%AE%80%E4%BB%8B" title="1.5.1 简介">1.5.1 简介</a></p> 
<p id="1.5.2%20%E5%8E%9F%E7%90%86-toc" style="margin-left:80px"><a href="#1.5.2%20%E5%8E%9F%E7%90%86" title="1.5.2 原理">1.5.2 原理</a></p> 
<p id="1.5.3%20Hbase%E4%B8%AD%E7%9A%84%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8%E7%9A%84%E8%AE%BE%E7%BD%AE%C2%A0-toc" style="margin-left:80px"><a href="#1.5.3%20Hbase%E4%B8%AD%E7%9A%84%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8%E7%9A%84%E8%AE%BE%E7%BD%AE%C2%A0" title="1.5.3 Hbase中的布隆过滤器的设置 ">1.5.3 Hbase中的布隆过滤器的设置 </a></p> 
<p id="%E4%BA%8C.Hbase%E4%B8%8EHive%2CMapreduce%E7%9A%84%E6%95%B4%E5%90%88-toc" style="margin-left:0px"><a href="#%E4%BA%8C.Hbase%E4%B8%8EHive%2CMapreduce%E7%9A%84%E6%95%B4%E5%90%88" title="二.Hbase与Hive,Mapreduce的整合">二.Hbase与Hive,Mapreduce的整合</a></p> 
<p id="2.1%20Hbase%E4%B8%8EHive%E7%9A%84%E6%95%B4%E5%90%88-toc" style="margin-left:40px"><a href="#2.1%20Hbase%E4%B8%8EHive%E7%9A%84%E6%95%B4%E5%90%88" title="2.1 Hbase与Hive的整合">2.1 Hbase与Hive的整合</a></p> 
<p id="2.1.1%20%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E6%95%B4%E5%90%88-toc" style="margin-left:80px"><a href="#2.1.1%20%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E6%95%B4%E5%90%88" title="2.1.1 为什么要整合">2.1.1 为什么要整合</a></p> 
<p id="2.1.2%20Hive-to-hbase-toc" style="margin-left:80px"><a href="#2.1.2%20Hive-to-hbase" title="2.1.2 Hive-to-hbase">2.1.2 Hive-to-hbase</a></p> 
<p id="2.1.3%20Hbase-to-Hive-toc" style="margin-left:80px"><a href="#2.1.3%20Hbase-to-Hive" title="2.1.3 Hbase-to-Hive">2.1.3 Hbase-to-Hive</a></p> 
<p id="2.1.4%20%E6%80%BB%E7%BB%93-toc" style="margin-left:80px"><a href="#2.1.4%20%E6%80%BB%E7%BB%93" title="2.1.4 总结">2.1.4 总结</a></p> 
<p id="%E4%B8%89.Hbase%E7%9A%84%E4%BA%8C%E7%BA%A7%E7%B4%A2%E5%BC%95%E5%92%8C%E5%8D%8F%E5%A4%84%E7%90%86%E5%99%A8-toc" style="margin-left:0px"><a href="#%E4%B8%89.Hbase%E7%9A%84%E4%BA%8C%E7%BA%A7%E7%B4%A2%E5%BC%95%E5%92%8C%E5%8D%8F%E5%A4%84%E7%90%86%E5%99%A8" title="三.Hbase的二级索引和协处理器">三.Hbase的二级索引和协处理器</a></p> 
<p id="3.1%20%E4%BA%8C%E7%BA%A7%E7%B4%A2%E5%BC%95%E7%9A%84%E7%AE%80%E4%BB%8B-toc" style="margin-left:40px"><a href="#3.1%20%E4%BA%8C%E7%BA%A7%E7%B4%A2%E5%BC%95%E7%9A%84%E7%AE%80%E4%BB%8B" title="3.1 二级索引的简介">3.1 二级索引的简介</a></p> 
<p id="3.2%20%E5%8D%8F%E5%A4%84%E7%90%86%E5%99%A8%E7%BB%84%E4%BB%B6%E7%AE%80%E4%BB%8B-toc" style="margin-left:40px"><a href="#3.2%20%E5%8D%8F%E5%A4%84%E7%90%86%E5%99%A8%E7%BB%84%E4%BB%B6%E7%AE%80%E4%BB%8B" title="3.2 协处理器组件简介">3.2 协处理器组件简介</a></p> 
<p id="3.2.1%20%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E5%BC%95%E5%85%A5%E5%8D%8F%E5%A4%84%E7%90%86%E5%99%A8-toc" style="margin-left:80px"><a href="#3.2.1%20%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E5%BC%95%E5%85%A5%E5%8D%8F%E5%A4%84%E7%90%86%E5%99%A8" title="3.2.1 为什么要引入协处理器">3.2.1 为什么要引入协处理器</a></p> 
<p id="3.2.2%20%E5%8D%8F%E5%A4%84%E7%90%86%E5%99%A8%E7%9A%84%E5%88%86%E7%B1%BB(%E7%86%9F%E6%82%89)-toc" style="margin-left:80px"><a href="#3.2.2%20%E5%8D%8F%E5%A4%84%E7%90%86%E5%99%A8%E7%9A%84%E5%88%86%E7%B1%BB%28%E7%86%9F%E6%82%89%29" title="3.2.2 协处理器的分类(熟悉)">3.2.2 协处理器的分类(熟悉)</a></p> 
<p id="3.2.3%20%E5%8D%8F%E5%A4%84%E7%90%86%E5%99%A8%E7%9A%84%E5%8A%A0%E8%BD%BD%E5%92%8C%E5%8D%B8%E8%BD%BD-toc" style="margin-left:80px"><a href="#3.2.3%20%E5%8D%8F%E5%A4%84%E7%90%86%E5%99%A8%E7%9A%84%E5%8A%A0%E8%BD%BD%E5%92%8C%E5%8D%B8%E8%BD%BD" title="3.2.3 协处理器的加载和卸载">3.2.3 协处理器的加载和卸载</a></p> 
<p id="3.3%20%E6%A1%88%E4%BE%8B%E6%BC%94%E7%A4%BA%EF%BC%9A%E4%BD%BF%E7%94%A8%E5%8D%8F%E5%A4%84%E7%90%86%E5%99%A8%E5%AE%8C%E6%88%90%E4%BA%8C%E7%BA%A7%E7%B4%A2%E5%BC%95%E8%A1%A8%E7%9A%84%E5%88%9B%E5%BB%BA-toc" style="margin-left:40px"><a href="#3.3%20%E6%A1%88%E4%BE%8B%E6%BC%94%E7%A4%BA%EF%BC%9A%E4%BD%BF%E7%94%A8%E5%8D%8F%E5%A4%84%E7%90%86%E5%99%A8%E5%AE%8C%E6%88%90%E4%BA%8C%E7%BA%A7%E7%B4%A2%E5%BC%95%E8%A1%A8%E7%9A%84%E5%88%9B%E5%BB%BA" title="3.3 案例演示：使用协处理器完成二级索引表的创建">3.3 案例演示：使用协处理器完成二级索引表的创建</a></p> 
<p id="3.3.1%20%E6%A1%88%E4%BE%8B%E6%8F%8F%E8%BF%B0-toc" style="margin-left:80px"><a href="#3.3.1%20%E6%A1%88%E4%BE%8B%E6%8F%8F%E8%BF%B0" title="3.3.1 案例描述">3.3.1 案例描述</a></p> 
<p id="3.3.2%20%E4%BB%A3%E7%A0%81%E7%BC%96%E5%86%99-toc" style="margin-left:80px"><a href="#3.3.2%20%E4%BB%A3%E7%A0%81%E7%BC%96%E5%86%99" title="3.3.2 代码编写">3.3.2 代码编写</a></p> 
<p id="3.3.3%20%E5%8A%A8%E6%80%81%E5%8A%A0%E8%BD%BD%E5%8D%8F%E5%A4%84%E7%90%86%E5%99%A8-toc" style="margin-left:80px"><a href="#3.3.3%20%E5%8A%A8%E6%80%81%E5%8A%A0%E8%BD%BD%E5%8D%8F%E5%A4%84%E7%90%86%E5%99%A8" title="3.3.3 动态加载协处理器">3.3.3 动态加载协处理器</a></p> 
<p id="3.3.4%20%E6%A1%88%E4%BE%8B%E6%B5%8B%E8%AF%95-toc" style="margin-left:80px"><a href="#3.3.4%20%E6%A1%88%E4%BE%8B%E6%B5%8B%E8%AF%95" title="3.3.4 案例测试">3.3.4 案例测试</a></p> 
<hr id="hr-toc">
<h1>一.Hbase的工作机制</h1> 
<h2 id="1.1%20Hbase%E7%9A%84%E5%AF%BB%E5%9D%80%E6%9C%BA%E5%88%B6%EF%BC%88%E9%87%8D%E7%82%B9%EF%BC%89" style="margin-left:0pt;text-align:left"><strong><strong><span style="color:#333333"><strong>1.1 Hbase的寻址机制（重点）</strong></span></strong></strong></h2> 
<pre><code>1.   table.put()      put 'myns:student'
     table.get()/getScanner()      get/scan....
     
     put 'myns:student', 'rk01000', 'f1:name'
       
       
     region:  startkey,   endkey
     
-- zookeeper:  维护了meta表的信息，就是地址
               get /hbase/meta-region-server
-- hbase:meta表:    记录了所有表的所有的region信息
                每个region以四个单元格进行记录，单元格的rowkey,就是region的名称
                四个单元格中的两个单元格：
                info:regioninfo维护的是region的名称，以及行范围
                info:server维护的region的位置
                
                region名称： schema:tablename,startkey,timestamp.ENCODED</code></pre> 
<h2 id="1.2%20Hbase%E7%9A%84%E5%AD%98%E5%82%A8%E6%9C%BA%E5%88%B6%EF%BC%88%E9%87%8D%E4%B8%AD%E4%B9%8B%E9%87%8D%EF%BC%89" style="margin-left:0pt;text-align:left"><strong><strong><span style="color:#333333"><strong>1.2 Hbase的存储机制（重中之重）</strong></span></strong></strong></h2> 
<h3 id="1.2.1%20%E5%AD%98%E5%82%A8%E6%9C%BA%E5%88%B6%E4%BB%8B%E7%BB%8D" style="margin-left:0pt;text-align:left"><strong><strong><span style="color:#333333"><strong>1.2.1 存储机制介绍</strong></span></strong></strong></h3> 
<pre><code>1.  通过寻址流程定位到具体的region。
2. 将单元格存储到store对应的memstore中
3. 排序:按照rowkey进行升序，key进行升序，timestamp降序
        单元格数据格式如下：  
        rowkey:column family:column:value:timestamp
        
4. 达到flush的阈值时，开始flush,生成storefile.然后由store来维护n个storefile的索引信息，比如path，startkey,endkey
      
      flush阈值： 128M、 1小时、  当前region内存的40%  、当前regionserver内存40%
      
5. 当storefile的数量达到阈值，比如是3个。就进行合并。  合并期间会进行排序(rowkey升序,column升序,timetamp降序),  还会进行真正的删除(当发现有delete标记的单元格，就将所有版本过滤掉)和修改操作(超过版本数量的老版本过滤掉)。
​
6. 当合并的文件越来越大时，如果达到阈值(10G)，就会触发split操作，数据尽量做到均分(会影响其他文件的切分)，从而造成了region的切分。  旧region下线，两个的新的region维护数据，由hmaster来重新进行负载均衡。        </code></pre> 
<h3 id="1.2.2%20%E5%90%8D%E8%AF%8D%E8%A7%A3%E9%87%8A" style="margin-left:0pt;text-align:left"><strong><strong><span style="color:#333333"><strong>1.2.2 名词解释</strong></span></strong></strong></h3> 
<p><span style="color:#333333">flush</span></p> 
<pre><code>当memstore达到阈值是，将内存中的数据冲刷成文件
​
可以手动flush
查看用法：  help 'flush'</code></pre> 
<p style="margin-left:.0001pt;text-align:justify"><span style="color:#333333">compact</span></p> 
<pre><code>当storefile达到数量阈值时，进行合并操作。
​
手动合并：
major_compact  regionname</code></pre> 
<p style="margin-left:.0001pt;text-align:justify"><span style="color:#333333">split</span></p> 
<pre><code>当文件大小达到阈值时，会造成region的切分
手动切分：
split regionname,splitkey</code></pre> 
<h2 id="1.3%20Hbase%E7%9A%84Region%E7%AE%A1%E7%90%86" style="margin-left:0pt;text-align:left"><strong><strong><span style="color:#333333"><strong>1.3 Hbase的Region管理</strong></span></strong></strong></h2> 
<p style="margin-left:.0001pt;text-align:justify"><span style="color:#333333">1）预切分</span></p> 
<pre><code>建表期间，进行预切分，指的就是提前划分region。
create tablename,column family,SPLITS=&gt;[startkey1,startkey2....] 
region数量 = startkey的数量+1</code></pre> 
<p style="margin-left:.0001pt;text-align:justify"><span style="color:#333333">2）当文件达到阈值时，会主动切分</span></p> 
<pre><code>split regionname,splitkey</code></pre> 
<p style="margin-left:.0001pt;text-align:justify"><span style="color:#333333">3）region也可以合并</span></p> 
<pre><code>merge_region  'encoded_region','encoded_region'</code></pre> 
<h2 id="1.4%20Hbase%E7%9A%84%E8%AF%BB%E5%86%99%E6%B5%81%E7%A8%8B%EF%BC%88%E9%87%8D%E7%82%B9%EF%BC%89" style="margin-left:0pt;text-align:left"><strong><strong><span style="color:#333333"><strong>1.4 Hbase的读写流程（重点）</strong></span></strong></strong></h2> 
<h3 id="1.4.1%20Hbase%E7%9A%84%E8%AF%BB%E6%B5%81%E7%A8%8B"><strong><strong><span style="color:#333333"><strong>1.4.1 Hbase的读流程</strong></span></strong></strong></h3> 
<pre><code>1.  客户端请求zookeeper,获取meta表的位置信息
2.  客户端跳转到meta表，获取要访问的表的具体region位置
3.  客户端跳转到具体region所在的regionserver，找到该region。
4.  访问对应的store下的memstore(写缓存), 如果有数据就返回，如果没有数据，就访问regionserver对应的读缓存，如果没有数据，再访问磁盘，然后数据返回给客户端，并保存到读缓存中，方便下次快速读取。</code></pre> 
<h3 id="1.4.2%20Hbase%E7%9A%84%E5%86%99%E6%B5%81%E7%A8%8B" style="margin-left:0pt;text-align:left"><strong><strong><span style="color:#333333"><strong>1.4.2 Hbase的写流程</strong></span></strong></strong></h3> 
<pre><code>1.  客户端请求zookeeper,获取meta表的位置信息
2.  客户端跳转到meta表，获取要访问的表的具体region位置
3.  客户端跳转到具体region所在的regionserver，找到该region，将单元格写入到对应的store里的memstore
4.  在memstore里进行排序(按照rowkey进行升序，key进行升序，timestamp降序)
5.  如果达到memstore的阈值，就会flush成storefile文件，由store来维护该文件的索引信息。
6.  如果storefile数量达到阈值是，会进行合并操作(排序，实际的删除和修改)
7.  如果合并成的文件达到大小阈值时，会进行切分，造成region的切分(旧region下线，两个新region生成)</code></pre> 
<h2 id="1.5%20%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8" style="margin-left:0pt;text-align:left"><strong><strong><span style="color:#333333"><strong>1.5 布隆过滤器</strong></span></strong></strong></h2> 
<h3 id="1.5.1%20%E7%AE%80%E4%BB%8B" style="margin-left:0pt;text-align:left"><strong><strong><span style="color:#333333"><strong>1.5.1 简介</strong></span></strong></strong></h3> 
<pre><code>- 布隆过滤器是一个数据结构
- 内部维护着一个二进制向量的位数组，默认大小64K
- 还维护着N个hash算法， 默认值是3个。
- 牺牲了准确率，算法的时间复杂度是O(1)。从而提高了查询效率
- 特点：  判断一个元素是否在一个集合中，有两种结果：一种就是在集合中，但是不一定真实存在
         另外一种结果就是不在集合中，那么就一定不在集合中。</code></pre> 
<h3 id="1.5.2%20%E5%8E%9F%E7%90%86" style="margin-left:0pt;text-align:left"><strong><strong><span style="color:#333333"><strong>1.5.2 原理</strong></span></strong></strong></h3> 
<pre><code>当存储元素时，会调用hash算法，计算元素的三个hash值，三个值作为bit数组的下标，将对应的元素由0改为1. (注意，hbase在put数据，不判断是否存在过)。
​
当在查询一个元素是否在这个集合中时，也是算出三个hash值作为下标，访问对应上的数据是否为1，如果全都是1，表明该元素可能存在这个集合中。只要有一个位置上是0，则表示该元素一定不在集合中。 </code></pre> 
<p><img alt="" height="262" src="https://images2.imgbox.com/1b/a6/tODa3mbr_o.png" width="756"></p> 
<h3 id="1.5.3%20Hbase%E4%B8%AD%E7%9A%84%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8%E7%9A%84%E8%AE%BE%E7%BD%AE%C2%A0">
<strong><strong><span style="color:#333333"><strong>1.5.3 Hbase中的布隆过滤器的设置</strong></span></strong></strong> </h3> 
<pre><code>方法：columnfamily.setBloomFilterType()
布隆过滤器的级别：
  BloomType.NONE:    表示不启用布隆过滤器
  BloomType.ROW：     行级别的，  只对每一个rowkey做 布隆过滤器的数据存储
  BloomType.ROWCOL：  行列级别的， 对rowkey:columnfamily:column做布隆过滤器的数据存储
  
  
  参考文档上的布隆过滤器章节的作用：</code></pre> 
<h1 id="%E4%BA%8C.Hbase%E4%B8%8EHive%2CMapreduce%E7%9A%84%E6%95%B4%E5%90%88" style="margin-left:0pt;text-align:left"><strong><strong><span style="color:#333333"><strong>二.Hbase与Hive,Mapreduce的整合</strong></span></strong></strong></h1> 
<h2 id="2.1%20Hbase%E4%B8%8EHive%E7%9A%84%E6%95%B4%E5%90%88"><strong><strong><span style="color:#333333"><strong>2.1 Hbase与Hive的整合</strong></span></strong></strong></h2> 
<h3 id="2.1.1%20%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E6%95%B4%E5%90%88"><strong><strong><span style="color:#333333"><strong>2.1.1 为什么要整合</strong></span></strong></strong></h3> 
<pre><code>hbase: hadoop数据库，本质用来存储大数据集，虽然提供了近似实时的读写功能
hive:  数据仓库的管理工具，作用就是用来使用hql语言对数据进行分析。</code></pre> 
<h3 id="2.1.2%20Hive-to-hbase" style="margin-left:0pt;text-align:left"><strong><strong><span style="color:#333333"><strong>2.1.2 Hive-to-hbase</strong></span></strong></strong></h3> 
<pre><code>在hive创建表， 可以在hbase中看见
create table if not exists employee (
uid int,
uname string,
age int,
sex string,
province string
)
stored by 'org.apache.hadoop.hive.hbase.HBaseStorageHandler'
with serdeproperties(
"hbase.columns.mapping"=":key,base_info:name,base_info:age,base_info:sex,address:provice"
)
tblproperties(
"hbase.table.name"="myns:employee"
);</code></pre> 
<p style="margin-left:.0001pt;text-align:justify"><span style="color:#333333">动态加载数据</span></p> 
<pre><code>insert into employee values(1, 'michael', 32, '男','jilin');
insert into employee values(2,'wcm',23,'男','heilongjiang');
put 'myns:employee','3','base_info:name','lisi'</code></pre> 
<p style="margin-left:.0001pt;text-align:justify"><span style="color:#333333">结果查看</span></p> 
<pre><code>- 在hive中写一个select语句
- 在50070webui上查看hive下的表目录，  结论：没有数据， hive不负责存储
- 在hbase中写一个scan语句
- 在50070webui上查看hbase下的表目录，  结论：应该有数据，如果看不到，是因为还在内存中</code></pre> 
<h3 id="2.1.3%20Hbase-to-Hive" style="margin-left:0pt;text-align:left"><strong><strong><span style="color:#333333"><strong>2.1.3 Hbase-to-Hive</strong></span></strong></strong></h3> 
<pre><code>hbase中先有表，然后映射到hive中
create 'myns:student','f1','f2'
​
put 'myns:student','rk00001','f1:name','zhaoyun'
put 'myns:student','rk00001','f1:age',23
put 'myns:student','rk00001','f1:gender','m'
put 'myns:student','rk00002','f1:name','zhenji'
put 'myns:student','rk00002','f1:age',24
put 'myns:student','rk00002','f2:province','hebei'</code></pre> 
<p style="margin-left:.0001pt;text-align:justify"><span style="color:#333333">在hive中创建表与hbase中的表进行映射</span></p> 
<pre><code>drop table student;
create external table if not exists student (
sid string,
name string,
province string,
gender string,
age int
)
stored by 'org.apache.hadoop.hive.hbase.HBaseStorageHandler'
with serdeproperties(
"hbase.columns.mapping"=":key,f1:name,f2:province,f1:gender,f1:age"
)
tblproperties(
"hbase.table.name"="myns:student"
);</code></pre> 
<p style="margin-left:.0001pt;text-align:justify"><span style="color:#333333">结果查看</span></p> 
<pre><code>在hive中 写select语句进行查看。</code></pre> 
<h3 id="2.1.4%20%E6%80%BB%E7%BB%93" style="margin-left:0pt;text-align:left"><strong><strong><span style="color:#333333"><strong>2.1.4 总结</strong></span></strong></strong></h3> 
<pre><code>-1.hive表的字段与hbase表的单元格 是按照顺序映射，而不是根据名称映射。
-2.hbase的rowkey 可以映射成hive中的一个字段，通过:key进行映射。可以不写:key，则与hive的第一个字段映射
-3.在字段映射时，注意字段类型的合理性
-4.如果hbase表已经存在，进行hive新表映射，hive表必须是外部表。</code></pre> 
<h1 id="%E4%B8%89.Hbase%E7%9A%84%E4%BA%8C%E7%BA%A7%E7%B4%A2%E5%BC%95%E5%92%8C%E5%8D%8F%E5%A4%84%E7%90%86%E5%99%A8" style="margin-left:0pt;text-align:left"><strong><strong><span style="color:#333333"><strong>三.Hbase的二级索引和协处理器</strong></span></strong></strong></h1> 
<h2 id="3.1%20%E4%BA%8C%E7%BA%A7%E7%B4%A2%E5%BC%95%E7%9A%84%E7%AE%80%E4%BB%8B" style="margin-left:0pt;text-align:left"><strong><strong><span style="color:#333333"><strong>3.1 二级索引的简介</strong></span></strong></strong></h2> 
<pre><code>rk1001     f1:name-zhangsan      f1:age-23           f2:province-guangdong
........................
rk2001     f1:name-gaoyuanyuan      f1:age-38        f2:province-shanghai
...........
rk3001     f1:name-gaoyuanyuan
​
​
需求：  查询 name叫gaoyuanyuan的年龄
​
    SingleColumnValueFilter---    name:gaoyuanyuan
    
    hbase的底层逻辑： 遍历数据块中的所有行信息，要查看是否有name:gaoyuanyuan单元格，有，返回所有行。
           程序员需要再次编程对返回的所有行数据，查看是否age单元格。有，就返回。 性能很低。
           
           
如何提高上述需求类型的查询性能？？？  再维护一张表：单元格与rowkey的映射关系表。
​
index表：
rowkey:
.........
f1:name-gaoyuanyuan     info:rk1  'rk2001'
                        info:rk2  'rk3001'
......
f1:name-zhangsan        info:rk1  'rk1001'
........
​</code></pre> 
<p style="margin-left:.0001pt;text-align:justify"><span style="color:#333333">什么是二级索引表</span></p> 
<pre><code>概念：维护的数据是另外一张表的单元格与rowkey的映射关系的表，就是二级索引表
作用：提高查询效率，避免对原表的全表遍历， 牺牲磁盘空间，换取查询效率。</code></pre> 
<p style="margin-left:.0001pt;text-align:justify"><span style="color:#333333">小贴士：</span></p> 
<pre><code>二级索引表，应该是程序自动维护的。</code></pre> 
<h2 id="3.2%20%E5%8D%8F%E5%A4%84%E7%90%86%E5%99%A8%E7%BB%84%E4%BB%B6%E7%AE%80%E4%BB%8B" style="margin-left:0pt;text-align:left"><strong><strong><span style="color:#333333"><strong>3.2 协处理器组件简介</strong></span></strong></strong></h2> 
<h3 id="3.2.1%20%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E5%BC%95%E5%85%A5%E5%8D%8F%E5%A4%84%E7%90%86%E5%99%A8"><strong><strong><span style="color:#333333"><strong>3.2.1 为什么要引入协处理器</strong></span></strong></strong></h3> 
<pre><code>在Hbase的低版本(0.92以前)作为列族数据库最经常被人诟病的特性包括：无法轻易建立“二级索引”，难以执行求和、计数、排序等操作。
之后引入了协处理器(coprocessor)进行改进，可以轻松的实现上述需求。</code></pre> 
<h3 id="3.2.2%20%E5%8D%8F%E5%A4%84%E7%90%86%E5%99%A8%E7%9A%84%E5%88%86%E7%B1%BB(%E7%86%9F%E6%82%89)" style="margin-left:0pt;text-align:left"><strong><strong><span style="color:#333333"><strong>3.2.2 协处理器的分类(熟悉)</strong></span></strong></strong></h3> 
<pre><code>分两大类型：一个是Observer类型， 一个是endpoint类型
​
- Observer 允许集群在正常的客户端操作过程中可以有不同的行为表现  
- Observer 类似于 RDBMS 中的触发器，主要在服务端工作
- Observer 可以实现权限管理、优先级设置、监控、ddl 控制、二级索引等功能
​
- Endpoint 类似于 RDBMS 中的存储过程，主要在服务端工作
- Endpoint 允许扩展集群的能力，对客户端应用开放新的运算命令  
- Endpoint 可以实现 min、max、avg、sum、distinct、group by 等功能</code></pre> 
<h3 id="3.2.3%20%E5%8D%8F%E5%A4%84%E7%90%86%E5%99%A8%E7%9A%84%E5%8A%A0%E8%BD%BD%E5%92%8C%E5%8D%B8%E8%BD%BD" style="margin-left:0pt;text-align:left"><strong><strong><span style="color:#333333"><strong>3.2.3 协处理器的加载和卸载</strong></span></strong></strong></h3> 
<p></p> 
<p style="margin-left:.0001pt;text-align:justify"><span style="color:#333333">1）加载方式：两种</span></p> 
<p style="margin-left:.0001pt;text-align:justify"><span style="color:#333333">第一种：静态加载，也叫系统级别的协处理器，只需要在hhbase-site.xml里添加如下属性和具体类名</span></p> 
<pre><code>&lt;property&gt;
   &lt;name&gt;hbase.coprocessor.user.region.classes&lt;/name&gt;
   &lt;value&gt;类全名&lt;/value&gt;
&lt;/property&gt;
​
可以用”,”分割加载多个 class</code></pre> 
<p style="margin-left:.0001pt;text-align:justify"><span style="color:#333333">第二种：动态记载，称之为表级别的协处理器</span></p> 
<pre><code>只对特定的表生效。通过 HBase Shell 来实现。
​
1. 停用表　　disable 'mytable'
​
2. 添加协处理器　　
alter 't_guanzhu',METHOD =&gt; 'table_att',
'coprocessor'=&gt;
'hdfs://supercluster/jar/mycoprocessor.jar|com.xx.hbase.coprocessor.MyIndexCoprocessor|1001|'
3. 启用表　　enable 'mytable'</code></pre> 
<p style="margin-left:.0001pt;text-align:justify"><span style="color:#333333">2）卸载方式</span></p> 
<pre><code>1. disable 'mytable'
2. alter 'mytable',METHOD=&gt;'table_att_unset',NAME=&gt;'coprocessor$1'
3. enable 'mytable'</code></pre> 
<p style="margin-left:.0001pt;text-align:justify"><span style="color:#333333">3）注意事项：</span></p> 
<pre><code>如果写的协处理器逻辑有问题，那么可能会造成hbase的集群宕机
​
解决办法：
1. 关闭所有的hbase的守护进程
2. 进入zookeeper,删除相关的znode。  如果不知道是哪一个znode，就将hbase 整个删掉
3. 重新启动hbase，删除掉挂载了协处理器的那张表。重新维护表
4. 再加载协处理器，进行测试</code></pre> 
<h2 id="3.3%20%E6%A1%88%E4%BE%8B%E6%BC%94%E7%A4%BA%EF%BC%9A%E4%BD%BF%E7%94%A8%E5%8D%8F%E5%A4%84%E7%90%86%E5%99%A8%E5%AE%8C%E6%88%90%E4%BA%8C%E7%BA%A7%E7%B4%A2%E5%BC%95%E8%A1%A8%E7%9A%84%E5%88%9B%E5%BB%BA" style="margin-left:0pt;text-align:left"><strong><strong><span style="color:#333333"><strong>3.3 案例演示：使用协处理器完成二级索引表的创建</strong></span></strong></strong></h2> 
<h3 id="3.3.1%20%E6%A1%88%E4%BE%8B%E6%8F%8F%E8%BF%B0" style="margin-left:0pt;text-align:left"><strong><strong><span style="color:#333333"><strong>3.3.1 案例描述</strong></span></strong></strong></h3> 
<pre><code>模拟博客上的关注信息表，以及粉丝表。 
1. 关注信息表是原表： 维护的是每个用户关注的人
      rk0001     f1:user-wcm    f1:obj-gaoyuanyuan    ......
      ......
      rk0009     f1:user-wcm    f1:obj-canglaoshi     .....
      ....
      rk0019     f1:user-laoli  f1:liuyifei
    
2. 粉丝表是二级索引表。
   
        wcm-gaoyuanyuan      f1:rk-rk0001
        wcm-canglaoshi       f1:rk-rk0009
        ...........
        laoli-gaoyuanyuan    f1:rk-rk0019
        
create 'fans','f1'      </code></pre> 
<h3 id="3.3.2%20%E4%BB%A3%E7%A0%81%E7%BC%96%E5%86%99" style="margin-left:0pt;text-align:left"><strong><strong><span style="color:#333333"><strong>3.3.2 代码编写</strong></span></strong></strong></h3> 
<pre><code>package com.xx.hbase.coprocessor;
​
import com.xx.hbase.util.HbaseUtil;
import org.apache.hadoop.hbase.Cell;
import org.apache.hadoop.hbase.CellUtil;
import org.apache.hadoop.hbase.client.Durability;
import org.apache.hadoop.hbase.client.Put;
import org.apache.hadoop.hbase.client.Table;
import org.apache.hadoop.hbase.coprocessor.BaseRegionObserver;
import org.apache.hadoop.hbase.coprocessor.ObserverContext;
import org.apache.hadoop.hbase.coprocessor.RegionCoprocessorEnvironment;
import org.apache.hadoop.hbase.regionserver.wal.WALEdit;
​
import java.io.IOException;
import java.util.List;
​
public class FansObServer extends BaseRegionObserver {
    /**
     * 重写prePut方法。
     * @param e
     * @param put    put形参就会主动接受客户端提交的put对象
     * @param edit
     * @param durability
     * @throws IOException
     *
     *      rk0001     f1:user-wcm    f1:obj-gaoyuanyuan
     *
     *
     *      注意：该Observer是对原表进行监听
     */
    @Override
    public void prePut(ObserverContext&lt;RegionCoprocessorEnvironment&gt; e, Put put, WALEdit edit, Durability durability) throws IOException {
        //获取put对象上的rowkey
        byte[] row = put.getRow();
        String rowkey = new String(row);  //rk0001
        List&lt;Cell&gt; users = put.get("f1".getBytes(), "user".getBytes());
        Cell cell = users.get(0);
        String value = new String(CellUtil.cloneValue(cell));  //wcm
​
        List&lt;Cell&gt; objs = put.get("f1".getBytes(), "obj".getBytes());
        Cell cell2 = objs.get(0);
        String value1 = new String(CellUtil.cloneValue(cell2));  //gaoyuanyuan
​
        //先封装一个新的put对象,准备提交到Fans表中   wcm-gaoyuanyuan      f1:rk-rk0001
        Put newPut = new Put((value+"-"+value1).getBytes());
        newPut.addColumn("f1".getBytes(),"rk".getBytes(),rowkey.getBytes());
​
        Table table = HbaseUtil.getTable("Fans");  //千万别写错表名
        table.put(newPut);
        table.close();
​
    }
}</code></pre> 
<h3 id="3.3.3%20%E5%8A%A8%E6%80%81%E5%8A%A0%E8%BD%BD%E5%8D%8F%E5%A4%84%E7%90%86%E5%99%A8" style="margin-left:0pt;text-align:left"><strong><strong><span style="color:#333333"><strong>3.3.3 动态加载协处理器</strong></span></strong></strong></h3> 
<pre><code>--1. 创建关注表
create 'guanzhu','f1'
​
--2. 加载协处理器
     （1）先将jar包上传到hdfs上的/jar目录下
     （2）挂载
alter 'hello',METHOD =&gt; 'table_att','coprocessor'=&gt;'hdfs://xxx01/jar/hello3_hbase.jar|com.xx.hbase.coprocessor.Hello2ObServer|1001|'</code></pre> 
<h3 id="3.3.4%20%E6%A1%88%E4%BE%8B%E6%B5%8B%E8%AF%95" style="margin-left:0pt;text-align:left"><strong><strong><span style="color:#333333"><strong>3.3.4 案例测试</strong></span></strong></strong></h3> 
<p><span style="color:#333333">小贴士：基于案例的需求，user和obj单元格应该同时添加，所以，应该使用api添加数据</span></p> 
<pre><code>@Before
public void getTable(){
   table = HbaseUtil.getTable("guanzhu");
}
@Test
public void putOne() throws IOException {
   //1. 获取Put对象,指定rowkey
   Put put = new Put(Bytes.toBytes("rk0001"));
   //2. 指定列族名，列名，列值
   put.addColumn(Bytes.toBytes("f1"), Bytes.toBytes("user"), Bytes.toBytes("wcm"));
   put.addColumn(Bytes.toBytes("f1"), Bytes.toBytes("obj"), Bytes.toBytes("gaoyuanyuan"));
   //3. 提交
   table.put(put);
}</code></pre> 
<p style="margin-left:.0001pt;text-align:justify"><span style="color:#333333">最后查看两张表的信息</span></p> 
<pre><code>hbase(main):009:0&gt; scan 'Fans'
ROW                              COLUMN+CELL
wcm-gaoyuanyuan                  column=f1:rk, timestamp=1640165499598, value=rk0001
​
​
​
hbase(main):010:0&gt; scan 'guanzhu'
ROW                               COLUMN+CELL
 rk0001                           column=f1:obj, timestamp=1640165499610, value=gaoyuanyuan
 rk0001                           column=f1:user, timestamp=1640165499610, value=wcm
</code></pre> 
<p>(=-=,这里写协助器的时候一定要注意逻辑,万一错了,hbase集群就直接瘫痪,处理起来很是麻烦!!!)</p>
                </div>

		</div>
	</article>
</main>




			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程小白.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://www.w3counter.com/tracker.js?id=150625"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>
	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>