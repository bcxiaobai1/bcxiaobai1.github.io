<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<title>猿创征文丨深度学习基于双向LSTM模型完成文本分类任务 - 编程小白</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程小白" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程小白</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">猿创征文丨深度学习基于双向LSTM模型完成文本分类任务</h1>
			
		</header>
		<div class="content post__content clearfix">
			


                <div id="content_views" class="markdown_views prism-dracula">
                    
                        
                    
                    <blockquote> 
 <p>大家好，我是猿童学，本期猿创征文的第三期，也是最后一期，给大家带来神经网络中的循环神经网络案例，基于双向LSTM模型完成文本分类任务，数据集来自kaggle，对电影评论进行文本分类。</p> 
</blockquote> 
<p>电影评论可以蕴含丰富的情感：比如喜欢、讨厌、等等．情感分析（Sentiment Analysis）是为一个文本分类问题，即使用判定给定的一段文本信息表达的情感属于积极情绪，还是消极情绪．<br> 本实践使用 IMDB 电影评论数据集，使用双向 LSTM 对电影评论进行情感分析．</p> 
<h3>
<a id="__7"></a>一、 数据处理</h3> 
<p><a href="https://www.kaggle.com/c/word2vec-nlp-tutorial/data">IMDB电影评论数据集</a>是一份关于电影评论的经典二分类数据集．IMDB 按照评分的高低筛选出了积极评论和消极评论，如果评分 <span class="katex--inline"><span class="katex"><span class="katex-mathml">
    
     
      
       
        ≥
       
       
        7
       
      
      
       ge 7
      
     
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.7719em;vertical-align: -0.136em"></span><span class="mrel">≥</span><span class="mspace" style="margin-right: 0.2778em"></span></span><span class="base"><span class="strut" style="height: 0.6444em"></span><span class="mord">7</span></span></span></span></span>，则认为是积极评论；如果评分 <span class="katex--inline"><span class="katex"><span class="katex-mathml">
    
     
      
       
        ≤
       
       
        4
       
      
      
       le4
      
     
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.7719em;vertical-align: -0.136em"></span><span class="mrel">≤</span><span class="mspace" style="margin-right: 0.2778em"></span></span><span class="base"><span class="strut" style="height: 0.6444em"></span><span class="mord">4</span></span></span></span></span>，则认为是消极评论．数据集包含训练集和测试集数据，数量各为 25000 条，每条数据都是一段用户关于某个电影的真实评价，以及观众对这个电影的情感倾向，其目录结构如下所示</p> 
<pre><code>  ├── train/
      ├── neg                 # 消极数据  
      ├── pos                 # 积极数据
      ├── unsup               # 无标签数据
  ├── test/
      ├── neg                 # 消极数据
      ├── pos                 # 积极数据
</code></pre> 
<p>在test/neg目录中任选一条电影评论数据，内容如下：</p> 
<blockquote> 
 <p>“Cover Girl” is a lacklustre WWII musical with absolutely nothing memorable about it, save for its signature song, “Long Ago and Far Away.”</p> 
</blockquote> 
<p>LSTM 模型不能直接处理文本数据，需要先将文本中单词转为向量表示，称为词向量（Word Embedding）．为了提高转换效率，通常会事先把文本的每个单词转换为数字 ID，再使用第节中介绍的方法进行向量转换．因此，需要准备一个词典（Vocabulary），将文本中的每个单词转换为它在词典中的序号 ID．同时还要设置一个特殊的词 [UNK]，表示未知词．在处理文本时，如果碰到不在词表的词，一律按 [UNK] 处理．</p> 
<h4>
<a id="11__25"></a>1.1 数据加载</h4> 
<p>原始训练集和测试集数据分别25000条，本节将原始的测试集平均分为两份，分别作为验证集和测试集，存放于<code>./dataset</code>目录下。使用如下代码便可以将数据加载至内存：</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> os
<span class="token comment"># 加载数据集</span>
<span class="token keyword">def</span> <span class="token function">load_imdb_data</span><span class="token punctuation">(</span>path<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">assert</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>exists<span class="token punctuation">(</span>path<span class="token punctuation">)</span> 
    trainset<span class="token punctuation">,</span> devset<span class="token punctuation">,</span> testset <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>path<span class="token punctuation">,</span> <span class="token string">"train.txt"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">"r"</span><span class="token punctuation">)</span> <span class="token keyword">as</span> fr<span class="token punctuation">:</span>
        <span class="token keyword">for</span> line <span class="token keyword">in</span> fr<span class="token punctuation">:</span>
            sentence_label<span class="token punctuation">,</span> sentence <span class="token operator">=</span> line<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>lower<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">"t"</span><span class="token punctuation">,</span> maxsplit<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
            trainset<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">(</span>sentence<span class="token punctuation">,</span> sentence_label<span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>path<span class="token punctuation">,</span> <span class="token string">"dev.txt"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">"r"</span><span class="token punctuation">)</span> <span class="token keyword">as</span> fr<span class="token punctuation">:</span>
        <span class="token keyword">for</span> line <span class="token keyword">in</span> fr<span class="token punctuation">:</span>
            sentence_label<span class="token punctuation">,</span> sentence <span class="token operator">=</span> line<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>lower<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">"t"</span><span class="token punctuation">,</span> maxsplit<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
            devset<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">(</span>sentence<span class="token punctuation">,</span> sentence_label<span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>path<span class="token punctuation">,</span> <span class="token string">"test.txt"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">"r"</span><span class="token punctuation">)</span> <span class="token keyword">as</span> fr<span class="token punctuation">:</span>
        <span class="token keyword">for</span> line <span class="token keyword">in</span> fr<span class="token punctuation">:</span>
            sentence_label<span class="token punctuation">,</span> sentence <span class="token operator">=</span> line<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>lower<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">"t"</span><span class="token punctuation">,</span> maxsplit<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
            testset<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">(</span>sentence<span class="token punctuation">,</span> sentence_label<span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">return</span> trainset<span class="token punctuation">,</span> devset<span class="token punctuation">,</span> testset

<span class="token comment"># 加载IMDB数据集</span>
train_data<span class="token punctuation">,</span> dev_data<span class="token punctuation">,</span> test_data <span class="token operator">=</span> load_imdb_data<span class="token punctuation">(</span><span class="token string">"./dataset/"</span><span class="token punctuation">)</span> 
<span class="token comment"># 打印一下加载后的数据样式</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>train_data<span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre> 
<blockquote> 
 <p>(“the premise of an african-american female scrooge in the modern, struggling city was inspired, but nothing else in this film is. here, ms. scrooge is a miserly banker who takes advantage of the employees and customers in the largely poor and black neighborhood it inhabits. there is no doubt about the good intentions of the people involved. part of the problem is that story’s roots don’t translate well into the urban setting of this film, and the script fails to make the update work. also, the constant message about sharing and giving is repeated so endlessly, the audience becomes tired of it well before the movie reaches its familiar end. this is a message film that doesn’t know when to quit. in the title role, the talented cicely tyson gives an overly uptight performance, and at times lines are difficult to understand. the charles dickens novel has been adapted so many times, it’s a struggle to adapt it in a way that makes it fresh and relevant, in spite of its very relevant message.”, ‘0’)</p> 
</blockquote> 
<p>从输出结果看，加载后的每条样本包含两部分内容：文本串和标签。</p> 
<h4>
<a id="12_Dataset_62"></a>1.2 构造Dataset类</h4> 
<p>首先，我们构造IMDBDataset类用于数据管理，它继承自paddle.io.DataSet类。</p> 
<p>由于这里的输入是文本序列，需要先将其中的每个词转换为该词在词表中的序号 ID，然后根据词表ID查询这些词对应的词向量，该过程同第同6.1节中将数字向量化的操作，在获得词向量后会将其输入至模型进行后续计算。可以使用IMDBDataset类中的words_to_id方法实现这个功能。 具体而言，利用词表word2id_dict将序列中的每个词映射为对应的数字编号，便于进一步转为为词向量。当序列中的词没有包含在词表时，默认会将该词用[UNK]代替。words_to_id方法利用一个如图6.14所示的哈希表来进行转换。</p> 

 <img src="https://images2.imgbox.com/6b/08/DXbD5ByF_o.png">
 

 图6.14 word2id词表示例
 
<p>代码实现如下：</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> paddle
<span class="token keyword">import</span> paddle<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn
<span class="token keyword">from</span> paddle<span class="token punctuation">.</span>io <span class="token keyword">import</span> Dataset
<span class="token keyword">from</span> utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> load_vocab

<span class="token keyword">class</span> <span class="token class-name">IMDBDataset</span><span class="token punctuation">(</span>Dataset<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> examples<span class="token punctuation">,</span> word2id_dict<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>IMDBDataset<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token comment"># 词典，用于将单词转为字典索引的数字</span>
        self<span class="token punctuation">.</span>word2id_dict <span class="token operator">=</span>  word2id_dict
        <span class="token comment"># 加载后的数据集</span>
        self<span class="token punctuation">.</span>examples <span class="token operator">=</span> self<span class="token punctuation">.</span>words_to_id<span class="token punctuation">(</span>examples<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">words_to_id</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> examples<span class="token punctuation">)</span><span class="token punctuation">:</span>
        tmp_examples <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        <span class="token keyword">for</span> idx<span class="token punctuation">,</span> example <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>examples<span class="token punctuation">)</span><span class="token punctuation">:</span>
            seq<span class="token punctuation">,</span> label <span class="token operator">=</span> example
            <span class="token comment"># 将单词映射为字典索引的ID， 对于词典中没有的单词用[UNK]对应的ID进行替代</span>
            seq <span class="token operator">=</span> <span class="token punctuation">[</span>self<span class="token punctuation">.</span>word2id_dict<span class="token punctuation">.</span>get<span class="token punctuation">(</span>word<span class="token punctuation">,</span> self<span class="token punctuation">.</span>word2id_dict<span class="token punctuation">[</span><span class="token string">'[UNK]'</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token keyword">for</span> word <span class="token keyword">in</span> seq<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">" "</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
            label <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>label<span class="token punctuation">)</span>
            tmp_examples<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">[</span>seq<span class="token punctuation">,</span> label<span class="token punctuation">]</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> tmp_examples

    <span class="token keyword">def</span> <span class="token function">__getitem__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> idx<span class="token punctuation">)</span><span class="token punctuation">:</span>
        seq<span class="token punctuation">,</span> label <span class="token operator">=</span> self<span class="token punctuation">.</span>examples<span class="token punctuation">[</span>idx<span class="token punctuation">]</span>
        <span class="token keyword">return</span> seq<span class="token punctuation">,</span> label

    <span class="token keyword">def</span> <span class="token function">__len__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> <span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>examples<span class="token punctuation">)</span>
    
<span class="token comment"># 加载词表</span>
word2id_dict<span class="token operator">=</span> load_vocab<span class="token punctuation">(</span><span class="token string">"./dataset/vocab.txt"</span><span class="token punctuation">)</span> 

<span class="token comment"># 实例化Dataset</span>
train_set <span class="token operator">=</span> IMDBDataset<span class="token punctuation">(</span>train_data<span class="token punctuation">,</span> word2id_dict<span class="token punctuation">)</span>
dev_set <span class="token operator">=</span> IMDBDataset<span class="token punctuation">(</span>dev_data<span class="token punctuation">,</span> word2id_dict<span class="token punctuation">)</span>
test_set <span class="token operator">=</span> IMDBDataset<span class="token punctuation">(</span>test_data<span class="token punctuation">,</span> word2id_dict<span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'训练集样本数：'</span><span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>train_set<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'样本示例：'</span><span class="token punctuation">,</span> train_set<span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre> 
<blockquote> 
 <p>训练集样本数： 25000<br> 样本示例： ([2, 976, 5, 32, 6860, 618, 7673, 8, 2, 13073, 2525, 724, 14, 22837, 18, 164, 416, 8, 10, 24, 701, 611, 1743, 7673, 7, 3, 56391, 21652, 36, 271, 3495, 5, 2, 11373, 4, 13244, 8, 2, 2157, 350, 4, 328, 4118, 12, 48810, 52, 7, 60, 860, 43, 2, 56, 4393, 5, 2, 89, 4152, 182, 5, 2, 461, 7, 11, 7321, 7730, 86, 7931, 107, 72, 2, 2830, 1165, 5, 10, 151, 4, 2, 272, 1003, 6, 91, 2, 10491, 912, 826, 2, 1750, 889, 43, 6723, 4, 647, 7, 2535, 38, 39222, 2, 357, 398, 1505, 5, 12, 107, 179, 2, 20, 4279, 83, 1163, 692, 10, 7, 3, 889, 24, 11, 141, 118, 50, 6, 28642, 8, 2, 490, 1469, 2, 1039, 98975, 24541, 344, 32, 2074, 11852, 1683, 4, 29, 286, 478, 22, 823, 6, 5222, 2, 1490, 6893, 883, 41, 71, 3254, 38, 100, 1021, 44, 3, 1700, 6, 8768, 12, 8, 3, 108, 11, 146, 12, 1761, 4, 92295, 8, 2641, 5, 83, 49, 3866, 5352], 0)</p> 
</blockquote> 
<h4>
<a id="13_DataLoader_118"></a>1.3 封装DataLoader</h4> 
<p>在构建 Dataset 类之后，我们构造对应的 DataLoader，用于批次数据的迭代．和前几章的 DataLoader 不同，这里的 DataLoader 需要引入下面两个功能：</p> 
<ol>
<li>长度限制：需要将序列的长度控制在一定的范围内，避免部分数据过长影响整体训练效果</li>
<li>长度补齐：神经网络模型通常需要同一批处理的数据的序列长度是相同的，然而在分批时通常会将不同长度序列放在同一批，因此需要对序列进行补齐处理．</li>
</ol> 
<p>对于长度限制，我们使用max_seq_len参数对于过长的文本进行截断．<br> 对于长度补齐，我们先统计该批数据中序列的最大长度，并将短的序列填充一些没有特殊意义的占位符 [PAD]，将长度补齐到该批次的最大长度，这样便能使得同一批次的数据变得规整．比如给定两个句子：</p> 
<ul>
<li>句子1: This movie was craptacular.</li>
<li>句子2: I got stuck in traffic on the way to the theater.</li>
</ul> 
<p>将上面的两个句子补齐，变为：</p> 
<ul>
<li>句子1: This movie was craptacular [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]</li>
<li>句子2: I got stuck in traffic on the way to the theater</li>
</ul> 
<p>具体来讲，本节定义了一个collate_fn函数来做数据的截断和填充. 该函数可以作为回调函数传入 DataLoader，DataLoader 在返回一批数据之前，调用该函数去处理数据，并返回处理后的序列数据和对应标签。</p> 
<p>另外，使用[PAD]占位符对短序列填充后，再进行文本分类任务时，默认无须使用[PAD]位置，因此需要使用变量seq_lens来表示序列中非[PAD]位置的真实长度。seq_lens可以在collate_fn函数处理批次数据时进行获取并返回。需要注意的是，由于RunnerV3类默认按照输入数据和标签两类信息获取数据，因此需要将序列数据和序列长度组成元组作为输入数据进行返回，以方便RunnerV3解析数据。</p> 
<p>代码实现如下：</p> 
<pre><code class="prism language-python"><span class="token keyword">from</span> functools <span class="token keyword">import</span> partial

<span class="token keyword">def</span> <span class="token function">collate_fn</span><span class="token punctuation">(</span>batch_data<span class="token punctuation">,</span> pad_val<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> max_seq_len<span class="token operator">=</span><span class="token number">256</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    seqs<span class="token punctuation">,</span> seq_lens<span class="token punctuation">,</span> labels <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    max_len <span class="token operator">=</span> <span class="token number">0</span>
    <span class="token keyword">for</span> example <span class="token keyword">in</span> batch_data<span class="token punctuation">:</span>
        seq<span class="token punctuation">,</span> label <span class="token operator">=</span> example
        <span class="token comment"># 对数据序列进行截断</span>
        seq <span class="token operator">=</span> seq<span class="token punctuation">[</span><span class="token punctuation">:</span>max_seq_len<span class="token punctuation">]</span>
        <span class="token comment"># 对数据截断并保存于seqs中</span>
        seqs<span class="token punctuation">.</span>append<span class="token punctuation">(</span>seq<span class="token punctuation">)</span>
        seq_lens<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>seq<span class="token punctuation">)</span><span class="token punctuation">)</span>
        labels<span class="token punctuation">.</span>append<span class="token punctuation">(</span>label<span class="token punctuation">)</span>
        <span class="token comment"># 保存序列最大长度</span>
        max_len <span class="token operator">=</span> <span class="token builtin">max</span><span class="token punctuation">(</span>max_len<span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>seq<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token comment"># 对数据序列进行填充至最大长度</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>seqs<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        seqs<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> seqs<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token punctuation">[</span>pad_val<span class="token punctuation">]</span> <span class="token operator">*</span> <span class="token punctuation">(</span>max_len <span class="token operator">-</span> <span class="token builtin">len</span><span class="token punctuation">(</span>seqs<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">return</span> <span class="token punctuation">(</span>paddle<span class="token punctuation">.</span>to_tensor<span class="token punctuation">(</span>seqs<span class="token punctuation">)</span><span class="token punctuation">,</span> paddle<span class="token punctuation">.</span>to_tensor<span class="token punctuation">(</span>seq_lens<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> paddle<span class="token punctuation">.</span>to_tensor<span class="token punctuation">(</span>labels<span class="token punctuation">)</span>

    
</code></pre> 
<blockquote> 
 <p>下面我们自定义一批数据来测试一下collate_fn函数的功能，这里假定一下max_seq_len为5，然后定义序列长度分别为6和3的两条数据，传入collate_fn函数中。</p> 
</blockquote> 
<pre><code class="prism language-python">max_seq_len <span class="token operator">=</span> <span class="token number">5</span>
batch_data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
<span class="token punctuation">(</span>seqs<span class="token punctuation">,</span> seq_lens<span class="token punctuation">)</span><span class="token punctuation">,</span> labels <span class="token operator">=</span> collate_fn<span class="token punctuation">(</span>batch_data<span class="token punctuation">,</span> pad_val<span class="token operator">=</span>word2id_dict<span class="token punctuation">[</span><span class="token string">"[PAD]"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> max_seq_len<span class="token operator">=</span>max_seq_len<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"seqs: "</span><span class="token punctuation">,</span> seqs<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"seq_lens: "</span><span class="token punctuation">,</span> seq_lens<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"labels: "</span><span class="token punctuation">,</span> labels<span class="token punctuation">)</span>

</code></pre> 
<blockquote> 
 <p>seqs: Tensor(shape=[2, 5], dtype=int64, place=CPUPlace, stop_gradient=True,<br> [[1, 2, 3, 4, 5],<br> [2, 4, 6, 0, 0]])<br> seq_lens: Tensor(shape=[2], dtype=int64, place=CPUPlace, stop_gradient=True,<br> [5, 3])<br> labels: Tensor(shape=[2], dtype=int64, place=CPUPlace, stop_gradient=True,<br> [1, 0])</p> 
</blockquote> 
<p>可以看到，原始序列中长度为6的序列被截断为5，同时原始序列中长度为3的序列被填充到5，同时返回了非<code>[PAD]</code>的序列长度。<br> 接下来，我们将collate_fn作为回调函数传入DataLoader中， 其在返回一批数据时，可以通过collate_fn函数处理该批次的数据。 这里需要注意的是，这里通过partial函数对collate_fn函数中的关键词参数进行设置，并返回一个新的函数对象作为collate_fn。</p> 
<p>在使用DataLoader按批次迭代数据时，最后一批的数据样本数量可能不够设定的batch_size，可以通过参数drop_last来判断是否丢弃最后一个batch的数据。</p> 
<pre><code class="prism language-python">max_seq_len <span class="token operator">=</span> <span class="token number">256</span>
batch_size <span class="token operator">=</span> <span class="token number">128</span>
collate_fn <span class="token operator">=</span> partial<span class="token punctuation">(</span>collate_fn<span class="token punctuation">,</span> pad_val<span class="token operator">=</span>word2id_dict<span class="token punctuation">[</span><span class="token string">"[PAD]"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> max_seq_len<span class="token operator">=</span>max_seq_len<span class="token punctuation">)</span>
train_loader <span class="token operator">=</span> paddle<span class="token punctuation">.</span>io<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>train_set<span class="token punctuation">,</span> batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> drop_last<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> collate_fn<span class="token operator">=</span>collate_fn<span class="token punctuation">)</span>
dev_loader <span class="token operator">=</span> paddle<span class="token punctuation">.</span>io<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>dev_set<span class="token punctuation">,</span> batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> drop_last<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> collate_fn<span class="token operator">=</span>collate_fn<span class="token punctuation">)</span>
test_loader <span class="token operator">=</span> paddle<span class="token punctuation">.</span>io<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>test_set<span class="token punctuation">,</span> batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> drop_last<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> collate_fn<span class="token operator">=</span>collate_fn<span class="token punctuation">)</span>
</code></pre> 
<h3>
<a id="_196"></a>二、模型构建</h3> 
<p>本实践的整个模型结构如图6.15所示．</p> 

 <img src="https://images2.imgbox.com/b6/d2/gvF9cVTO_o.png" width="50%/">
 

 图6.15 基于双向LSTM的文本分类模型结构
 
<p>由如下几部分组成：<br> （1）嵌入层：将输入的数字序列进行向量化，即将每个数字映射为向量。这里直接使用飞桨API：paddle.nn.Embedding来完成。</p> 
<blockquote> 
 <p>class paddle.nn.Embedding(num_embeddings, embedding_dim, padding_idx=None, sparse=False, weight_attr=None, name=None)</p> 
</blockquote> 
<p>该API有两个重要的参数：num_embeddings表示需要用到的Embedding的数量。embedding_dim表示嵌入向量的维度。<br> paddle.nn.Embedding会根据[num_embeddings, embedding_dim]自动构造一个二维嵌入矩阵。参数padding_idx是指用来补齐序列的占位符[PAD]对应的词表ID，那么在训练过程中遇到此ID时，其参数及对应的梯度将会以0进行填充。在实现中为了简单起见，我们通常会将[PAD]放在词表中的第一位，即对应的ID为0。</p> 
<p>（2）双向LSTM层：接收向量序列，分别用前向和反向更新循环单元。这里我们直接使用飞桨API：paddle.nn.LSTM来完成。只需要在定义LSTM时设置参数direction为bidirectional，便可以直接使用双向LSTM。</p> 
<blockquote> 
 <p>思考: 在实现双向LSTM时，因为需要进行序列补齐，在计算反向LSTM时，占位符[PAD]是否会对LSTM参数梯度的更新有影响。如果有的话，如何消除影响？<br> 注：在调用paddle.nn.LSTM实现双向LSTM时，可以传入该批次数据的真实长度，paddle.nn.LSTM会根据真实序列长度处理数据，对占位符[PAD]进行掩蔽，[PAD]位置将返回零向量。</p> 
</blockquote> 
<p>（3）聚合层：将双向LSTM层所有位置上的隐状态进行平均，作为整个句子的表示。</p> 
<p>（4）输出层：输出层，输出分类的几率。这里可以直接调用paddle.nn.Linear来完成。</p> 
<blockquote> 
 <p><strong>动手练习6.5</strong>：改进第6.3.1.1节中的LSTM算子，使其可以支持一个批次中包含不同长度的序列样本。</p> 
</blockquote> 
<p>上面模型中的嵌入层、双向LSTM层和线性层都可以直接调用飞桨API来实现，这里我们只需要实现汇聚层算子。需要注意的是，虽然飞桨内置LSTM在传入批次数据的真实长度后，会对[PAD]位置返回零向量，但考虑到汇聚层与处理序列数据的模型进行解耦，因此在本节汇聚层的实现中，会对[PAD]位置进行掩码。</p> 
<p><strong>汇聚层算子</strong></p> 
<p>汇聚层算子将双向LSTM层所有位置上的隐状态进行平均，作为整个句子的表示。这里我们实现了AveragePooling算子进行隐状态的汇聚，首先利用序列长度向量生成掩码（Mask）矩阵，用于对文本序列中[PAD]位置的向量进行掩蔽，然后将该序列的向量进行相加后取均值。代码实现如下：</p> 
<p>将上面各个模块汇总到一起，代码实现如下：</p> 
<pre><code class="prism language-python"><span class="token keyword">class</span> <span class="token class-name">AveragePooling</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Layer<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>AveragePooling<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
    
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> sequence_output<span class="token punctuation">,</span> sequence_length<span class="token punctuation">)</span><span class="token punctuation">:</span>
        sequence_length <span class="token operator">=</span> paddle<span class="token punctuation">.</span>cast<span class="token punctuation">(</span>sequence_length<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span><span class="token string">"float32"</span><span class="token punctuation">)</span>
        <span class="token comment"># 根据sequence_length生成mask矩阵，用于对Padding位置的信息进行mask</span>
        max_len <span class="token operator">=</span> sequence_output<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>
        mask <span class="token operator">=</span> paddle<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>max_len<span class="token punctuation">)</span> <span class="token operator">&lt;</span> sequence_length
        mask <span class="token operator">=</span> paddle<span class="token punctuation">.</span>cast<span class="token punctuation">(</span>mask<span class="token punctuation">,</span> dtype<span class="token operator">=</span><span class="token string">"float32"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
        <span class="token comment"># 对序列中paddling部分进行mask</span>
        sequence_output <span class="token operator">=</span> paddle<span class="token punctuation">.</span>multiply<span class="token punctuation">(</span>sequence_output<span class="token punctuation">,</span> mask<span class="token punctuation">)</span>
        <span class="token comment"># 对序列中的向量取均值</span>
        batch_mean_hidden <span class="token operator">=</span> paddle<span class="token punctuation">.</span>divide<span class="token punctuation">(</span>paddle<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>sequence_output<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> sequence_length<span class="token punctuation">)</span>
        <span class="token keyword">return</span> batch_mean_hidden
</code></pre> 
<p><strong>模型汇总</strong></p> 
<p>将上面的算子汇总，组合为最终的分类模型。代码实现如下：</p> 
<pre><code class="prism language-python"><span class="token keyword">class</span> <span class="token class-name">Model_BiLSTM_FC</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Layer<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> num_embeddings<span class="token punctuation">,</span> input_size<span class="token punctuation">,</span> hidden_size<span class="token punctuation">,</span> num_classes<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>Model_BiLSTM_FC<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token comment"># 词典大小</span>
        self<span class="token punctuation">.</span>num_embeddings <span class="token operator">=</span> num_embeddings
        <span class="token comment"># 单词向量的维度</span>
        self<span class="token punctuation">.</span>input_size <span class="token operator">=</span> input_size
        <span class="token comment"># LSTM隐藏单元数量</span>
        self<span class="token punctuation">.</span>hidden_size <span class="token operator">=</span> hidden_size
        <span class="token comment"># 情感分类类别数量</span>
        self<span class="token punctuation">.</span>num_classes <span class="token operator">=</span> num_classes
        <span class="token comment"># 实例化嵌入层</span>
        self<span class="token punctuation">.</span>embedding_layer <span class="token operator">=</span> nn<span class="token punctuation">.</span>Embedding<span class="token punctuation">(</span>num_embeddings<span class="token punctuation">,</span> input_size<span class="token punctuation">,</span> padding_idx<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
        <span class="token comment"># 实例化LSTM层</span>
        self<span class="token punctuation">.</span>lstm_layer <span class="token operator">=</span> nn<span class="token punctuation">.</span>LSTM<span class="token punctuation">(</span>input_size<span class="token punctuation">,</span> hidden_size<span class="token punctuation">,</span> direction<span class="token operator">=</span><span class="token string">"bidirectional"</span><span class="token punctuation">)</span>
        <span class="token comment"># 实例化聚合层</span>
        self<span class="token punctuation">.</span>average_layer <span class="token operator">=</span> AveragePooling<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token comment"># 实例化输出层</span>
        self<span class="token punctuation">.</span>output_layer <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>hidden_size <span class="token operator">*</span> <span class="token number">2</span><span class="token punctuation">,</span> num_classes<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> inputs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 对模型输入拆分为序列数据和mask</span>
        input_ids<span class="token punctuation">,</span> sequence_length <span class="token operator">=</span> inputs
        <span class="token comment"># 获取词向量</span>
        inputs_emb <span class="token operator">=</span> self<span class="token punctuation">.</span>embedding_layer<span class="token punctuation">(</span>input_ids<span class="token punctuation">)</span>
        <span class="token comment"># 使用lstm处理数据</span>
        sequence_output<span class="token punctuation">,</span> _ <span class="token operator">=</span> self<span class="token punctuation">.</span>lstm_layer<span class="token punctuation">(</span>inputs_emb<span class="token punctuation">,</span> sequence_length<span class="token operator">=</span>sequence_length<span class="token punctuation">)</span>
        <span class="token comment"># 使用聚合层聚合sequence_output</span>
        batch_mean_hidden <span class="token operator">=</span> self<span class="token punctuation">.</span>average_layer<span class="token punctuation">(</span>sequence_output<span class="token punctuation">,</span> sequence_length<span class="token punctuation">)</span>
        <span class="token comment"># 输出文本分类logits</span>
        logits <span class="token operator">=</span> self<span class="token punctuation">.</span>output_layer<span class="token punctuation">(</span>batch_mean_hidden<span class="token punctuation">)</span>
        <span class="token keyword">return</span> logits
</code></pre> 
<h3>
<a id="_285"></a>三、模型训练</h3> 
<p>本节将基于RunnerV3进行训练，首先指定模型训练的超参，然后设定模型、优化器、损失函数和评估指标，其中损失函数使用<code>paddle.nn.CrossEntropyLoss</code>，该损失函数内部会对预测结果使用<code>softmax</code>进行计算，数字预测模型输出层的输出<code>logits</code>不需要使用softmax进行归一化，定义完Runner的相关组件后，便可以进行模型训练。代码实现如下。</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> time
<span class="token keyword">import</span> random
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">from</span> nndl <span class="token keyword">import</span> Accuracy<span class="token punctuation">,</span> RunnerV3

np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
paddle<span class="token punctuation">.</span>seed<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>

<span class="token comment"># 指定训练轮次</span>
num_epochs <span class="token operator">=</span> <span class="token number">3</span>
<span class="token comment"># 指定学习率</span>
learning_rate <span class="token operator">=</span> <span class="token number">0.001</span>
<span class="token comment"># 指定embedding的数量为词表长度</span>
num_embeddings <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>word2id_dict<span class="token punctuation">)</span>
<span class="token comment"># embedding向量的维度</span>
input_size <span class="token operator">=</span> <span class="token number">256</span>
<span class="token comment"># LSTM网络隐状态向量的维度</span>
hidden_size <span class="token operator">=</span> <span class="token number">256</span>

<span class="token comment"># 实例化模型</span>
model <span class="token operator">=</span> Model_BiLSTM_FC<span class="token punctuation">(</span>num_embeddings<span class="token punctuation">,</span> input_size<span class="token punctuation">,</span> hidden_size<span class="token punctuation">)</span>
<span class="token comment"># 指定优化器</span>
optimizer <span class="token operator">=</span> paddle<span class="token punctuation">.</span>optimizer<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>learning_rate<span class="token operator">=</span>learning_rate<span class="token punctuation">,</span> beta1<span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">,</span> beta2<span class="token operator">=</span><span class="token number">0.999</span><span class="token punctuation">,</span> parameters<span class="token operator">=</span> model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> 
<span class="token comment"># 指定损失函数</span>
loss_fn <span class="token operator">=</span> paddle<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span> 
<span class="token comment"># 指定评估指标</span>
metric <span class="token operator">=</span> Accuracy<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment"># 实例化Runner</span>
runner <span class="token operator">=</span> RunnerV3<span class="token punctuation">(</span>model<span class="token punctuation">,</span> optimizer<span class="token punctuation">,</span> loss_fn<span class="token punctuation">,</span> metric<span class="token punctuation">)</span>
<span class="token comment"># 模型训练</span>
start_time <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>
runner<span class="token punctuation">.</span>train<span class="token punctuation">(</span>train_loader<span class="token punctuation">,</span> dev_loader<span class="token punctuation">,</span> num_epochs<span class="token operator">=</span>num_epochs<span class="token punctuation">,</span> eval_steps<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> log_steps<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> save_path<span class="token operator">=</span><span class="token string">"./checkpoints/best.pdparams"</span><span class="token punctuation">)</span>
end_time <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"time: "</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>end_time<span class="token operator">-</span>start_time<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<blockquote> 
 <p>[Train] epoch: 0/3, step: 0/588, loss: 0.69294</p> 
</blockquote> 
<p>绘制训练过程中在训练集和验证集上的损失图像和在验证集上的准确率图像：</p> 
<pre><code class="prism language-python"><span class="token keyword">from</span> nndl <span class="token keyword">import</span> plot_training_loss_acc

<span class="token comment"># 图像名字</span>
fig_name <span class="token operator">=</span> <span class="token string">"./images/6.16.pdf"</span>
<span class="token comment"># sample_step: 训练损失的采样step，即每隔多少个点选择1个点绘制</span>
<span class="token comment"># loss_legend_loc: loss 图像的图例放置位置</span>
<span class="token comment"># acc_legend_loc： acc 图像的图例放置位置</span>
plot_training_loss_acc<span class="token punctuation">(</span>runner<span class="token punctuation">,</span> fig_name<span class="token punctuation">,</span> fig_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">,</span> sample_step<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> loss_legend_loc<span class="token operator">=</span><span class="token string">"lower left"</span><span class="token punctuation">,</span> acc_legend_loc<span class="token operator">=</span><span class="token string">"lower right"</span><span class="token punctuation">)</span>
</code></pre> 
<p>图6.16 展示了文本分类模型在训练过程中的损失曲线和在验证集上的准确率曲线，其中在损失图像中，实线表示训练集上的损失变化，虚线表示验证集上的损失变化. 可以看到，随着训练过程的进行，训练集的损失不断下降， 验证集上的损失在大概200步后开始上升，这是因为在训练过程中发生了过拟合，可以选择保存在训练过程中在验证集上效果最好的模型来解决这个问题. 从准确率曲线上可以看到，首先在验证集上的准确率大幅度上升，然后大概200步后准确率不再上升，并且由于过拟合的因素，在验证集上的准确率稍微降低。</p> 

 <img src="https://images2.imgbox.com/6d/6e/et2cyDyy_o.png" width="70%/">
 

 图6.16 文本分类模型训练损失变化图
 
<h3>
<a id="_346"></a>四、模型评价</h3> 
<p>加载训练过程中效果最好的模型，然后使用测试集进行测试。</p> 
<pre><code class="prism language-python">model_path <span class="token operator">=</span> <span class="token string">"./checkpoints/best.pdparams"</span>
runner<span class="token punctuation">.</span>load_model<span class="token punctuation">(</span>model_path<span class="token punctuation">)</span>
accuracy<span class="token punctuation">,</span> _ <span class="token operator">=</span>  runner<span class="token punctuation">.</span>evaluate<span class="token punctuation">(</span>test_loader<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Evaluate on test set, Accuracy: </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>accuracy<span class="token punctuation">:</span><span class="token format-spec">.5f</span><span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>
</code></pre> 
<h3>
<a id="_355"></a>五、模型预测</h3> 
<p>给定任意的一句话，使用训练好的模型进行预测，判断这句话中所蕴含的情感极性。</p> 
<pre><code class="prism language-python">id2label<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token number">0</span><span class="token punctuation">:</span><span class="token string">"消极情绪"</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">:</span><span class="token string">"积极情绪"</span><span class="token punctuation">}</span>
text <span class="token operator">=</span> <span class="token string">"this movie is so great. I watched it three times already"</span>
<span class="token comment"># 处理单条文本</span>
sentence <span class="token operator">=</span> text<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">" "</span><span class="token punctuation">)</span>
words <span class="token operator">=</span> <span class="token punctuation">[</span>word2id_dict<span class="token punctuation">[</span>word<span class="token punctuation">]</span> <span class="token keyword">if</span> word <span class="token keyword">in</span> word2id_dict <span class="token keyword">else</span> word2id_dict<span class="token punctuation">[</span><span class="token string">'[UNK]'</span><span class="token punctuation">]</span> <span class="token keyword">for</span> word <span class="token keyword">in</span> sentence<span class="token punctuation">]</span> 
words <span class="token operator">=</span> words<span class="token punctuation">[</span><span class="token punctuation">:</span>max_seq_len<span class="token punctuation">]</span>
sequence_length <span class="token operator">=</span> paddle<span class="token punctuation">.</span>to_tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token builtin">len</span><span class="token punctuation">(</span>words<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span><span class="token string">"int64"</span><span class="token punctuation">)</span>
words <span class="token operator">=</span> paddle<span class="token punctuation">.</span>to_tensor<span class="token punctuation">(</span>words<span class="token punctuation">,</span> dtype<span class="token operator">=</span><span class="token string">"int64"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
<span class="token comment"># 使用模型进行预测</span>
logits <span class="token operator">=</span> runner<span class="token punctuation">.</span>predict<span class="token punctuation">(</span><span class="token punctuation">(</span>words<span class="token punctuation">,</span> sequence_length<span class="token punctuation">)</span><span class="token punctuation">)</span>
max_label_id <span class="token operator">=</span> paddle<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>logits<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
pred_label <span class="token operator">=</span> id2label<span class="token punctuation">[</span>max_label_id<span class="token punctuation">]</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Label: "</span><span class="token punctuation">,</span> pred_label<span class="token punctuation">)</span>
</code></pre> 
<h3>
<a id="_375"></a>六、小结</h3> 
<p>本章通过实践来加深对循环神经网络的基本概念、网络结构和长程依赖问题问题的理解．我们构建一个数字求和任务，并动手实现了 SRN 和 LSTM 模型，对比它们在数字求和任务上的记忆能力．在实践部分，我们利用双向 LSTM 模型来进行文本分类任务：IMDB 电影评论情感分析，并了解如何通过嵌入层将文本数据转换为向量表示.</p>
                </div>
                
                

		</div>
	</article>
</main>




			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程小白.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://www.w3counter.com/tracker.js?id=150625"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>
	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>