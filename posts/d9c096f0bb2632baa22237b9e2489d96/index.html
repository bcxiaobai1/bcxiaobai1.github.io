<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<title>【推荐系统论文精读系列】(四)--Practical Lessons from Predicting Clicks on Ads at Facebook - 编程小白</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程小白" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程小白</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">【推荐系统论文精读系列】(四)--Practical Lessons from Predicting Clicks on Ads at Facebook</h1>
			
		</header>
		<div class="content post__content clearfix">
			


                <div id="content_views" class="markdown_views prism-github-gist">
                    
                        
                    
                    <p></p>
<div class="toc">
 <h3>文章目录</h3>
 <ul>
<li><a href="#Practical_Lessons_from_Predicting_Clicks_on_Ads_at_Facebook_2">Practical Lessons from Predicting Clicks on Ads at Facebook</a></li>
<li><a href="#_4">一、摘要</a></li>
<li><a href="#_10">二、简介</a></li>
<li><a href="#_22">三、实验设置</a></li>
<li>
<ul><li><a href="#31__26">3.1 评估指标</a></li></ul>
  </li>
<li><a href="#_38">四、预测模型结构</a></li>
<li>
<ul>
<li><a href="#41__40">4.1 决策树特征变换</a></li>
<li><a href="#42__57">4.2 数据新鲜度</a></li>
<li><a href="#43__69">4.3 在线线性分类器</a></li>
</ul>
  </li>
<li><a href="#_105">五、在线数据连接器</a></li>
<li><a href="#_118">六、包含内存和延迟</a></li>
<li>
<ul>
<li><a href="#61__120">6.1 提升树的数目</a></li>
<li><a href="#62__128">6.2 增加特征的重要性</a></li>
<li><a href="#63__136">6.3 历史特征</a></li>
</ul>
  </li>
<li><a href="#_153">七、处理海量数据</a></li>
<li>
<ul>
<li><a href="#71_Uniform_subsampling_157">7.1 Uniform subsampling</a></li>
<li><a href="#72_Negative_down_sampling_163">7.2 Negative down sampling</a></li>
</ul>
  </li>
<li><a href="#_169">八、总结</a></li>
</ul>
</div>
<p></p> 
<h1>
<a id="Practical_Lessons_from_Predicting_Clicks_on_Ads_at_Facebook_2"></a>Practical Lessons from Predicting Clicks on Ads at Facebook</h1> 
<h1>
<a id="_4"></a>一、摘要</h1> 
<p>点击预测系统大多是以在线广告系统维中心，每天7亿的日常活跃用户和超过1百万的活跃广告，因此预测FaceBook上的广告点击率是一项具有挑战的机器学习任务。本片论文中我们介绍了一个模型采用决策树和逻辑回归结合的模式，融合模型的表现胜过它们自己单独建模的效果3%，这个一个重大的影响对于整个系统的表现。</p> 
<p>我们然后探索了一些基本参数对我们真个系统的预测表现进行了探索，不足为奇，我们获得来了一个重要的结论就是：使系统整体表现提高最重要的就是拥有正确的特征（那么捕捉了用户或者广告的历史信息），这些特征在所有的特征中占据着主导地位，一旦我们拥有了正确的特征和正确的模型（决策树+逻辑回归），其它的特征几乎发挥很小的作用（尽管小的提升在整个业务范围内也是很重要的）。挑选一些最优的数据处理方式，例如数据新鲜度、学习率模式、数据采样，这些都会轻微的提升模型的性能，但是提升的幅度仍会小于拥有高效的特征组合或者是使用正确的模型。</p> 
<h1>
<a id="_10"></a>二、简介</h1> 
<p>数字广告使一个几十亿美元的工业并且每年都在急剧地增加。在众多互联网广告平台，支配广告是动态的，居于观察到的用户返回合理为它们调整用户的兴趣。机器学习发挥了重要的作用在计算预测效用和一个用户对于一个广告的点击率，并且这种方式会增加整个市场的效率。</p> 
<p>在2007年Varian和Edelman发表了一篇开创性的论文，描述了出家和每次的点击拍卖。同年，微软基于相同的拍卖模型构建了一个赞助搜索市场，这个广告拍卖的有效性依赖于点击率预测的精度和校准。点击率预测系统需要健壮性和适应性，并且有能力从海量数据中进行学习。这篇论文的目标就是分享来自实验的观点，这些实验考虑了这些需求并且在真实世界中的数据进行的执行。</p> 
<p>在赞助的搜索广告，用户搜索被用于去检索候选的广告，这些广告可以隐式或者显示的进行匹配用户的搜索，说白了就是可以从用户每次的搜索匹配对应的广告，但是FaceBook与微软不同，它的用户搜索较少，广告和搜索几乎没什么关联，它们只和特定的人口特征和兴趣目标相关。因此，当一个用户访问Facebook时符合条件被展示的广告要远大于基于搜索的模型。</p> 
<p>为了解决每次请求的候选广告非常多的问题，当一个用户访问Facebook时，这时请求广告就会被触发，我们首先建立了一个不断增加成本的级联分类器。本篇论文中，主要研究级联分类器的最后阶段的点击预测模型，即对最终候选广告集进行预测的模型。</p> 
<p>我们发现了一种混合模型（决策树+逻辑回归），这种模型比这两种方法各自的性能都要好3%以上。这种提升在整个系统的表现能力上是有重大意义的。大量的基本参数会影响最终的预测系统的表现。正如预期的那样，最重要的就是拥有好的特征组合，这些特征会捕捉用户或者广告的历史信息并且还会占据主导地位在所有的特征中。一旦我们有了这些特征并且使用了我们的混合模型，其它的特征因子将起到很小的作用。挑选一些最优的数据处理方式，例如数据新鲜度、学习率模式、数据采样，这些都会轻微的提升模型的性能，但是提升的幅度仍会小于拥有高效的特征组合或者是使用正确的模型。</p> 
<h1>
<a id="_22"></a>三、实验设置</h1> 
<p>为了实现严格的控制实验，我们准备了线下数据通过挑选出任意一周的数据。为了保持相同的训练和测试集数据分布在不同的条件下，我们准备的线下数据是与线上观测到的数据是相似的。我们将线下数据分成了训练集和测试集，并且使用它们去模型数据流，对于线上训练和预测。</p> 
<h2>
<a id="31__26"></a>3.1 评估指标</h2> 
<p>因为我们最关心的是特征对整个模型的影响，所以我们使用了预测准确率作为衡量指标而不是以和利益或者收入相关的指标。我们使用Normalized Entropy(NE)和Calibration作为我们主要的评估指标。</p> 
<p>NE的评估公式为：<br> <span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml">
     
      
       
        
         N
        
        
         E
        
        
         =
        
        
         
          
           −
          
          
           
            1
           
           
            N
           
          
          
           
            ∑
           
           
            
             i
            
            
             =
            
            
             1
            
           
           
            n
           
          
          
           (
          
          
           
            
             1
            
            
             +
            
            
             
              y
             
             
              i
             
            
           
           
            2
           
          
          
           l
          
          
           o
          
          
           g
          
          
           (
          
          
           
            p
           
           
            i
           
          
          
           )
          
          
           +
          
          
           
            
             1
            
            
             −
            
            
             
              y
             
             
              i
             
            
           
           
            2
           
          
          
           l
          
          
           o
          
          
           g
          
          
           (
          
          
           1
          
          
           −
          
          
           
            y
           
           
            i
           
          
          
           )
          
          
           )
          
         
         
          
           −
          
          
           (
          
          
           p
          
          
           ∗
          
          
           (
          
          
           l
          
          
           o
          
          
           g
          
          
           (
          
          
           p
          
          
           )
          
          
           )
          
          
           +
          
          
           (
          
          
           1
          
          
           −
          
          
           p
          
          
           )
          
          
           ∗
          
          
           l
          
          
           o
          
          
           g
          
          
           (
          
          
           1
          
          
           −
          
          
           p
          
          
           )
          
          
           )
          
         
        
       
       
         NE=frac{-frac{1}{N}sum_{i=1}^n(frac{1+y_i}{2}log(p_i)+frac{1-y_i}{2}log(1-y_i))}{-(p*(log(p))+(1-p)*log(1-p))} 
       
      
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.68333em;vertical-align: 0em"></span><span class="mord mathdefault" style="margin-right: 0.10903em">N</span><span class="mord mathdefault" style="margin-right: 0.05764em">E</span><span class="mspace" style="margin-right: 0.277778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em"></span></span><span class="base"><span class="strut" style="height: 2.56822em;vertical-align: -0.936em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.63222em"><span class=""><span class="pstrut" style="height: 3em"></span><span class="mord"><span class="mord">−</span><span class="mopen">(</span><span class="mord mathdefault">p</span><span class="mspace" style="margin-right: 0.222222em"></span><span class="mbin">∗</span><span class="mspace" style="margin-right: 0.222222em"></span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right: 0.01968em">l</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right: 0.03588em">g</span><span class="mopen">(</span><span class="mord mathdefault">p</span><span class="mclose">)</span><span class="mclose">)</span><span class="mspace" style="margin-right: 0.222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.222222em"></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right: 0.222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right: 0.222222em"></span><span class="mord mathdefault">p</span><span class="mclose">)</span><span class="mspace" style="margin-right: 0.222222em"></span><span class="mbin">∗</span><span class="mspace" style="margin-right: 0.222222em"></span><span class="mord mathdefault" style="margin-right: 0.01968em">l</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right: 0.03588em">g</span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right: 0.222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right: 0.222222em"></span><span class="mord mathdefault">p</span><span class="mclose">)</span><span class="mclose">)</span></span></span><span class=""><span class="pstrut" style="height: 3em"></span><span class="frac-line" style="border-bottom-width: 0.04em"></span></span><span class=""><span class="pstrut" style="height: 3em"></span><span class="mord"><span class="mord">−</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.845108em"><span class=""><span class="pstrut" style="height: 3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right: 0.10903em">N</span></span></span></span><span class=""><span class="pstrut" style="height: 3em"></span><span class="frac-line" style="border-bottom-width: 0.04em"></span></span><span class=""><span class="pstrut" style="height: 3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.345em"><span class=""></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right: 0.166667em"></span><span class="mop"><span class="mop op-symbol small-op">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.804292em"><span class="" style="margin-left: 0em;margin-right: 0.05em"><span class="pstrut" style="height: 2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span class="" style="margin-right: 0.05em"><span class="pstrut" style="height: 2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.29971em"><span class=""></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.897216em"><span class=""><span class="pstrut" style="height: 3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span><span class=""><span class="pstrut" style="height: 3em"></span><span class="frac-line" style="border-bottom-width: 0.04em"></span></span><span class=""><span class="pstrut" style="height: 3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mbin mtight">+</span><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right: 0.03588em">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.328086em"><span class="" style="margin-left: -0.03588em;margin-right: 0.0714286em"><span class="pstrut" style="height: 2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.143em"><span class=""></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.345em"><span class=""></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord mathdefault" style="margin-right: 0.01968em">l</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right: 0.03588em">g</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.311664em"><span class="" style="margin-left: 0em;margin-right: 0.05em"><span class="pstrut" style="height: 2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em"><span class=""></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right: 0.222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.222222em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.897216em"><span class=""><span class="pstrut" style="height: 3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span><span class=""><span class="pstrut" style="height: 3em"></span><span class="frac-line" style="border-bottom-width: 0.04em"></span></span><span class=""><span class="pstrut" style="height: 3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mbin mtight">−</span><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right: 0.03588em">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.328086em"><span class="" style="margin-left: -0.03588em;margin-right: 0.0714286em"><span class="pstrut" style="height: 2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.143em"><span class=""></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.345em"><span class=""></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord mathdefault" style="margin-right: 0.01968em">l</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right: 0.03588em">g</span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right: 0.222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right: 0.222222em"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.03588em">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.311664em"><span class="" style="margin-left: -0.03588em;margin-right: 0.05em"><span class="pstrut" style="height: 2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em"><span class=""></span></span></span></span></span></span><span class="mclose">)</span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.936em"><span class=""></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></span><br> Calibration评估指标：Calibration是平均估计CTR和经验CTR之比，换句话说，它是预测点击次数与实际观察到的点击次数之比，它是个非常重要的指标，准确预测CTR是在线招标和拍卖成功的关键。</p> 
<p>注意到，AUC也是一个非常好的评估指标对于衡量排序质量如果不考虑Calibration。在真实的环境中，我们期望的是准确的预测而不是仅仅得到最优的排序。</p> 
<h1>
<a id="_38"></a>四、预测模型结构</h1> 
<h2>
<a id="41__40"></a>4.1 决策树特征变换</h2> 
<p>由于线性模型过于简单，它只能够捕捉线性特征，对于非线性是无能为力的，这就会导致如果使用逻辑回归进行建模会导致丢失很多数据信息，虽然现在很多模型都可以捕捉非线性关系，但是它们的计算复杂度大，线性回归算法简单，容易实现并行，对于海量数据能大幅提高计算效率，那么我们就希望有没有一种方法可以转化特征，变成线性回归可以拟合的数据。</p> 
<p>两种转化特征的方法分别是：</p> 
<ul>
<li>连续型：将特征进行分箱，然后将每个箱的索引作为类别特征</li>
<li>类别型：对所有类别特征做笛卡尔积，产生组合特征</li>
</ul> 
<p>对于类别特征做笛卡尔积产生的新特征，不是所有的特征都是有用的，那么怎样才能组合出高效的特征呢。</p> 
<p>我们发现梯度提升树是一个强有力而且很方面去实现非线性和成对特征组合。我们将每个独立的树作为一个分类特征。然后使用OneHot编码将其转化成特征。例如，如果一个梯度提升树有两个子树，第一颗子树有3个叶子节点，第二颗子树有两个节点，假如样本x分别落在了第一个子树的第二个叶子节点，落在了第二颗子树的第1个叶子节点，那么我们就可以为其进行编码为【0，1，0，1，0】。在每次学习迭代的过程中，一个新的树会拟合前一棵树的残差。我们能够理解梯度提升树基于转化作为一个有监督的特征编码，会将一个真值向量转化成一个稠密的二值化向量。从根节点进行遍历到叶子节点，这时就会呈现一个规则对于某种特征，可以理解为这个样本可以按照这个路径的特征来进行区分。梯度提升树是以一个批次的方式进行训练。</p> 
<p>我们执行了这个实验去展示将提升树产生的特征输入到线性模型的效果。在这个实验中，我们对比了逻辑回归模型，一个是带有融合特征，另外一个是原始特征，我们也使用了一个梯度提升树模型仅仅用于对比。</p> 
<p>提升树产生的特征帮助我们的模型减少3.4%的损失使用NE熵，这是一个重大的提升。</p> 
<h2>
<a id="42__57"></a>4.2 数据新鲜度</h2> 
<p>点击预测系统通常被部署在一个动态的环境下，这个数据的分布会随着时间而改变。我们研究了训练数据新鲜度对于预测表现的影响。为了验证这个，我们训练了一个模型根据某一特定天的数据，然后进行验证测试使用之后连续几天的数据，我们进行这个实验使用的是梯度提升树和逻辑回归的模型带有融合获得的特征。</p> 
<p>在这个实验中，我们训练了一天的数据，然后对改天接下来的六天的数据进行了评估并且计算了NE。</p> 
<p>结果表明，预测精度随着每天的推移，训练集和测试集的精度都有所下降，很容易看出，如果我们从每周训练一次到每天训练一次，我们的模型的表现几乎可以提高1%。</p> 
<p>这些发现表明，我们是很值得每天进行重新训练模型的。一个选择就是我们每天将会有一个重复的工作就是重新训练模型，可能是以批次进行训练。重新训练梯度提升树模型的时间可能依赖不同的因素，例如：训练集的规模大小、树的数目、每棵树叶子节点的个数、CPU、内存大小等。如果我们采用单核CPU进行训练百万级别的数据，使用几百棵树的模型进行训练，那么我们的训练时间可能超过24个小时。但实际情况是，如果我们采用多核并行训练，训练时间可能缩小到几个小时内，原因是多核并行可以将整个训练集加载到内存中进行计算。</p> 
<p>梯度提升树需要每天重新训练或者每两天训练一次，但是我们的线性分类器需要通过在线学习进行实时学习。</p> 
<h2>
<a id="43__69"></a>4.3 在线线性分类器</h2> 
<p>为了最大化数据的新鲜程度，一个选择就是在线训练线性分类器，也就是说，当推荐广告到达的时候，我们就会为其打标签，然后进行建模。在接下来的章节，我们会描述一个基础架构，能够产生实时的训练数据。在这个部分我们会评估几种设置学习率的方式对于逻辑回归使用SGD进行求解。我们然后对比最好的变体对于在线学习与BOPR模型。</p> 
<p>1.Per-coordinate learning rate：<br> <span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml">
     
      
       
        
         
          η
         
         
          
           t
          
          
           ,
          
          
           i
          
         
        
        
         =
        
        
         
          α
         
         
          
           β
          
          
           +
          
          
           
            
             
              ∑
             
             
              
               j
              
              
               =
              
              
               1
              
             
             
              t
             
            
            
             g
            
            
             r
            
            
             a
            
            
             
              d
             
             
              
               j
              
              
               ,
              
              
               i
              
             
             
              2
             
            
           
          
         
        
       
       
         eta_{t,i}=frac{alpha}{beta+sqrt{sum_{j=1}^tgrad_{j,i}^2}} 
       
      
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.716668em;vertical-align: -0.286108em"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.03588em">η</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.311664em"><span class="" style="margin-left: -0.03588em;margin-right: 0.05em"><span class="pstrut" style="height: 2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span><span class="mpunct mtight">,</span><span class="mord mathdefault mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.286108em"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.277778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em"></span></span><span class="base"><span class="strut" style="height: 2.83756em;vertical-align: -1.73em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.10756em"><span class=""><span class="pstrut" style="height: 3.23382em"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.05278em">β</span><span class="mspace" style="margin-right: 0.222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.222222em"></span><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.23382em"><span class="svg-align"><span class="pstrut" style="height: 3.8em"></span><span class="mord" style="padding-left: 1em"><span class="mop"><span class="mop op-symbol small-op">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.933456em"><span class="" style="margin-left: 0em;margin-right: 0.05em"><span class="pstrut" style="height: 2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right: 0.05724em">j</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span class="" style="margin-right: 0.05em"><span class="pstrut" style="height: 2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.435818em"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.166667em"></span><span class="mord mathdefault" style="margin-right: 0.03588em">g</span><span class="mord mathdefault" style="margin-right: 0.02778em">r</span><span class="mord mathdefault">a</span><span class="mord"><span class="mord mathdefault">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.795908em"><span class="" style="margin-left: 0em;margin-right: 0.05em"><span class="pstrut" style="height: 2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right: 0.05724em">j</span><span class="mpunct mtight">,</span><span class="mord mathdefault mtight">i</span></span></span></span><span class="" style="margin-right: 0.05em"><span class="pstrut" style="height: 2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.412972em"><span class=""></span></span></span></span></span></span></span></span><span class=""><span class="pstrut" style="height: 3.8em"></span><span class="hide-tail" style="min-width: 1.02em;height: 1.88em">
                   
                    
                   </span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.606181em"><span class=""></span></span></span></span></span></span></span><span class=""><span class="pstrut" style="height: 3.23382em"></span><span class="frac-line" style="border-bottom-width: 0.04em"></span></span><span class=""><span class="pstrut" style="height: 3.23382em"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.0037em">α</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 1.73em"><span class=""></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></span><br> 2.Per-weight square root learning rate：<br> <span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml">
     
      
       
        
         
          η
         
         
          
           t
          
          
           ,
          
          
           i
          
         
        
        
         =
        
        
         
          α
         
         
          
           
            n
           
           
            
             t
            
            
             ,
            
            
             i
            
           
          
         
        
       
       
         eta_{t,i}=frac{alpha}{sqrt{n_{t,i}}} 
       
      
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.716668em;vertical-align: -0.286108em"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.03588em">η</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.311664em"><span class="" style="margin-left: -0.03588em;margin-right: 0.05em"><span class="pstrut" style="height: 2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span><span class="mpunct mtight">,</span><span class="mord mathdefault mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.286108em"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.277778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em"></span></span><span class="base"><span class="strut" style="height: 2.17633em;vertical-align: -1.06877em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.10756em"><span class=""><span class="pstrut" style="height: 3em"></span><span class="mord"><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.657226em"><span class="svg-align"><span class="pstrut" style="height: 3em"></span><span class="mord" style="padding-left: 0.833em"><span class="mord"><span class="mord mathdefault">n</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.311664em"><span class="" style="margin-left: 0em;margin-right: 0.05em"><span class="pstrut" style="height: 2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span><span class="mpunct mtight">,</span><span class="mord mathdefault mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.286108em"><span class=""></span></span></span></span></span></span></span></span><span class=""><span class="pstrut" style="height: 3em"></span><span class="hide-tail" style="min-width: 0.853em;height: 1.08em">
                   
                    
                   </span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.382774em"><span class=""></span></span></span></span></span></span></span><span class=""><span class="pstrut" style="height: 3em"></span><span class="frac-line" style="border-bottom-width: 0.04em"></span></span><span class=""><span class="pstrut" style="height: 3em"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.0037em">α</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 1.06877em"><span class=""></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></span><br> 3.Per-weight learning rate：<br> <span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml">
     
      
       
        
         
          η
         
         
          
           t
          
          
           ,
          
          
           i
          
         
        
        
         =
        
        
         
          α
         
         
          
           n
          
          
           
            t
           
           
            ,
           
           
            i
           
          
         
        
       
       
         eta_{t,i}=frac{alpha}{n_{t,i}} 
       
      
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.716668em;vertical-align: -0.286108em"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.03588em">η</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.311664em"><span class="" style="margin-left: -0.03588em;margin-right: 0.05em"><span class="pstrut" style="height: 2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span><span class="mpunct mtight">,</span><span class="mord mathdefault mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.286108em"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.277778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em"></span></span><span class="base"><span class="strut" style="height: 2.07967em;vertical-align: -0.972108em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.10756em"><span class=""><span class="pstrut" style="height: 3em"></span><span class="mord"><span class="mord"><span class="mord mathdefault">n</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.311664em"><span class="" style="margin-left: 0em;margin-right: 0.05em"><span class="pstrut" style="height: 2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span><span class="mpunct mtight">,</span><span class="mord mathdefault mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.286108em"><span class=""></span></span></span></span></span></span></span></span><span class=""><span class="pstrut" style="height: 3em"></span><span class="frac-line" style="border-bottom-width: 0.04em"></span></span><span class=""><span class="pstrut" style="height: 3em"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.0037em">α</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.972108em"><span class=""></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></span><br> 4.Global learning rate：<br> <span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml">
     
      
       
        
         
          η
         
         
          
           t
          
          
           ,
          
          
           i
          
         
        
        
         =
        
        
         
          α
         
         
          
           t
          
         
        
       
       
         eta_{t,i}=frac{alpha}{sqrt t} 
       
      
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.716668em;vertical-align: -0.286108em"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.03588em">η</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.311664em"><span class="" style="margin-left: -0.03588em;margin-right: 0.05em"><span class="pstrut" style="height: 2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span><span class="mpunct mtight">,</span><span class="mord mathdefault mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.286108em"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.277778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em"></span></span><span class="base"><span class="strut" style="height: 2.03756em;vertical-align: -0.93em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.10756em"><span class=""><span class="pstrut" style="height: 3em"></span><span class="mord"><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.89254em"><span class="svg-align"><span class="pstrut" style="height: 3em"></span><span class="mord mathdefault" style="padding-left: 0.833em">t</span></span><span class=""><span class="pstrut" style="height: 3em"></span><span class="hide-tail" style="min-width: 0.853em;height: 1.08em">
                   
                    
                   </span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.14746em"><span class=""></span></span></span></span></span></span></span><span class=""><span class="pstrut" style="height: 3em"></span><span class="frac-line" style="border-bottom-width: 0.04em"></span></span><span class=""><span class="pstrut" style="height: 3em"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.0037em">α</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.93em"><span class=""></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></span><br> 5.Constant learning rate：<br> <span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml">
     
      
       
        
         
          η
         
         
          
           t
          
          
           ,
          
          
           i
          
         
        
        
         =
        
        
         α
        
       
       
         eta_{t,i}=alpha 
       
      
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.716668em;vertical-align: -0.286108em"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.03588em">η</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.311664em"><span class="" style="margin-left: -0.03588em;margin-right: 0.05em"><span class="pstrut" style="height: 2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span><span class="mpunct mtight">,</span><span class="mord mathdefault mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.286108em"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.277778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em"></span></span><span class="base"><span class="strut" style="height: 0.43056em;vertical-align: 0em"></span><span class="mord mathdefault" style="margin-right: 0.0037em">α</span></span></span></span></span></span><br> 前三个设置学习率的模式每个特征之间是独立的，而后两个对于所有的特征学习率是相同的。所有可以调节的参数都会使用网格搜索进行优化。</p> 
<p>对于持续学习，我们将学习率下界设置为0.00001，我们训练和测试是使用相同的数据，然后使用上述的几种设置学习率的模式然后进行对比。</p> 
<p>从上述的结果，我们发现，SGD使用每个可调节的学习率实现了最好的预测精度，大约比使用每个权重的学习模式的NE低了大概5%。使用square root 和constant的学习模式是差不多的。另外两个学习模式比这几个的精度都要差。全局学习率模式失败主要是由于训练集的样本数据对于每个特征的分布不均衡。因为每个训练样例可能包含不同的特征，一些受欢迎的特征将会得到更多的训练相对于其它的特征。在全局学习率的模式下，对于较少的示例将会减小的非常快，并且阻止了算法的收敛。尽管per-weight学习率模式解决了这个问题，但是它仍然失败了，因为它将会减少所有特征的学习率。训练停止太早，会导致模型只收敛到局部最优位置。这也就是为什么，这个学习率模式会是所有选择中表现最差的。</p> 
<p>我们执行了一个实验去对比使用per-coordinate SGD和BOPR在同一数据集上的表现。我们给出了相似的定性模型更新方程。结果BOPR和SGD有着非常接近的预测表现使用NE或者是calibration指标。</p> 
<p>LR相对于BOPR的一个优点是模型大小为一半，因为每个稀疏特征值只惯量一个权重，而不是均值和方差，在执行过程中，较小的型号可能导致更好的缓存局部性，从而加快缓存查找速度。在预测是的计算费用方面，LR模型只需要在特征向量和权重上求一个内积，而BOPR模型则需要两个内积作为方差向量和带特征向量的均值向量。</p> 
<p>与LR相比，BOPR的一个重要优点是它是一个贝叶斯模型，它提供了一个完全的点击概率分布，这可用于计算点击分布的百分位数，可用于探索或者开发新的学习方案。</p> 
<h1>
<a id="_105"></a>五、在线数据连接器</h1> 
<p>之前的部分表明新的数据会导致增加预测精度，它也呈现了一个简单的模型架构，就是线性分类器是在线学习。</p> 
<p>这个部分介绍了一个实验系统能够产生实时的训练数据用于训练线性分类器通过在线学习。我们将使用这个系统作为在线连接器，去将标签（用户点击或不点击）与训练数据（推荐广告）连接起来作为新的训练输入数据。</p> 
<p>这和Google Advertising System被用于流计算的例子十分相像。在线数据连接器会输出一个实时的训练数据流给一个结构叫做Scribe。我们定义广告被点击为正样本，不点击为负样本，但是对于推荐广告对于用户来说是没有不点击的按钮的，那么我们就无法判断用户是否会点击该广告。对于这个原因我们将考虑使用一个时间停留窗口，如果当一个广告出现后，如果在指定的时间内用户没有点击，我们将视为用户没有点击。关于这个时间窗口的等待时间需要仔细设定。</p> 
<ul>
<li>点击时间长：会导致实时数据的延误，增加分配给缓冲的内存用于等待用户点击的信号</li>
<li>点击时间短：会导致数据的丢失，如果时间太短，可能一个用户会点击这个广告，由于时间短，在该时间内还没有点击就结束了</li>
</ul> 
<p>所以针对这个现象，就必须时间和点击覆盖取得权衡。</p> 
<h1>
<a id="_118"></a>六、包含内存和延迟</h1> 
<h2>
<a id="61__120"></a>6.1 提升树的数目</h2> 
<p>如果树的棵数越多，模型对一个预测所需要的时间就越长，在这个部分，我们将会研究提升树的数目对于评估精度的影响。</p> 
<p>我们改变树的个数从1-2000，并且训练这个模型使用一整天的数据然后进行预测评估使用接下来一天的数据，我们强制约束每棵树的叶子节点个数不超过12个。和之前的实验一样，我们使用NE作为评估准则。</p> 
<p>通过结果我们发现随着树的个数越多，模型的NE越来越小，但是当树的个数达到500棵左右，NE的下降趋势越来越小，而且最后增加1000棵树减少的NE少于0.1%。而且我们还看到使用NE submodel2的模型当树的棵数达到1000时，模型的效果反而有点倒退，原因就是随着树的数目增加，模型产生了过拟合效应。这是因为submodel2的数据集的规模相对于模型0和模型1的数据集规模小了近4倍左右。</p> 
<h2>
<a id="62__128"></a>6.2 增加特征的重要性</h2> 
<p>特征数目是模型的另外一个特征能够影响均衡评估精度和预测时间。为了更好的了解特征数目的影响，我们首先应用一个特征到每个特征中。</p> 
<p>为了衡量一个特征的重要性，我们使用了statistic Boosting Feature Importance，这样的目的是为了捕获计算每个特征减少的损失。在进行构建每个节点的过程中，挑选最好的特征作为分割节点，然后去最大化平方损失，因为一个特征可能用于多棵树的构建，所以每个特征的损失需要计算所有树对于这个特征的损失之和。</p> 
<p>结果表明，top10的特征的重要性占据了所有的一半，然而最后300个特征贡献却不足1%。基于这个发现，我们进一步研究了top10、20、50、100和200个特征的影响，并且它们是怎样影响模型的表现的。</p> 
<h2>
<a id="63__136"></a>6.3 历史特征</h2> 
<p>在提升树模型中使用的特征主要可以分成两类：上下文特征、历史特征。</p> 
<ul>
<li>上下文特征：依赖于当前的上下文信息，比如用户设备的型号、用户当前所在的页面</li>
<li>历史特征：依赖于用户和广告先前的交互信息，比如这条广告上周的点击率或者用户的平均点击率</li>
</ul> 
<p>在这个部分，我们将会研究系统依赖这两类特征的表现。首先我们会先查两类特征的的相关的重要性。我们通过重要性将特征进行排序，然后计算每个历史特征的重要性。</p> 
<p>通过结果表明，我们可以发现历史特征可以提供更多的解释性比上下文特征。最重要的10个特征都是基于历史特征。在前20个特征中，只有两个特征是上下文特征。为了更好的了解每种类型特征的对比，我们训练了两个提升树模型分别仅仅使用上下文特征和历史特征，然后对比两个模型和全部特征的比较。</p> 
<p>从结果我们可以发现历史特征是发挥了更大的作用比上下文特征。</p> 
<p>但是上下文特征也有个重要的作用就是能够解决冷启动问题，对于新的用户和新的广告，上下文特征是不依赖于点击率进行预测的。</p> 
<p>接下来，我们评估了训练模型只使用上下文特征和历史特征在连续周的训练数据针对于数据新鲜度的问题，我们发现有着上下文的特征是更加依赖于数据新鲜度的相对于历史特征。这符合我们的直觉，因为历史功能描述了长期积累的用户行为，这比上下文功能更稳定。</p> 
<h1>
<a id="_153"></a>七、处理海量数据</h1> 
<p>Facebook每天的广告数据多大几亿的数据量，为了减少训练的消耗，我们通用的做法就是减少训练数据的列数。在这个部分我们会评估两种下采样的方式，分别是：uniform subsampling和negative down sampling。我们会训练两个包含600棵树的模型，然后使用calibration和NE作为评估指标进行评估。</p> 
<h2>
<a id="71_Uniform_subsampling_157"></a>7.1 Uniform subsampling</h2> 
<p>对训练行进行均匀子抽样是一种很有吸引力的减少数据量的方法，因为它既易于实现，而且生成的模型可以在不修改下采样训练数据和非下采样测试数据的情况下使用。在这一部分，我们评估一组粗略指数增长的子抽样率。对于每个速率，我们训练一个增强的树模型，以该速率从基础数据集采样。我们分别设定了采样率为【0.001，0.01，0.1，0.5，1】</p> 
<p>通过结果可以表明，我们仅仅使用总共数据10%的数据，我们的模型表现仅仅下降了1%，可以看到均匀采样是有一定帮助的，在牺牲小的精度换的更高的时间效率。</p> 
<h2>
<a id="72_Negative_down_sampling_163"></a>7.2 Negative down sampling</h2> 
<p>类别不平衡已经被许多研究者进行研究，并且表明类别不平衡对模型的表现有着重大的影响。在这个部分，我们使用Negative down sampling去解决这个问题。我们使用不同的比率尽心采样，然后去测试模型的精度，我们设定采样率分别为【0.1，0.01，0.001，0.0001】。</p> 
<p>从结果发现，我们能够看到negative down sampling采样率有着重大的影响对于模型的表现，最好的表现是我们将这个比率设立在0.025。</p> 
<h1>
<a id="_169"></a>八、总结</h1> 
<p>我们已经呈现了一些来自实验的经验关于Facebook广告数据。这启发了一个很有前途的混合模型体系结构，用于点击预测领域。</p> 
<ul>
<li>Data freshness matters：我们至少每天都要将模型进行重新训练，本篇论文中我们进一步研究了不同种的在线学习模式。我们也给出了基础架构允许生成实时的训练数据。</li>
<li>使用梯度提升树进行转化特征极大的增加了线性分类器的预测精度。这启发了一种混合模型体系结构，该体系结构将增强决策树和稀疏线性分类器连接起来。</li>
<li>最优在线学习模式：LR与预协调学习率，最终与BOPR的性能相当，并优于所有正在研究的LR结合SGD的方案</li>
</ul> 
<p>我们已经描述了在大规模机器学习应用程序中保持内存和延迟的技巧</p> 
<ul>
<li>我们已经提出了改进决策树的数量和准确性之间的权衡。保持树的数量小有利于保持计算和内存</li>
<li>提升树给予了一个方便的方式去做特征选择通过特征的重要性，我们可以大幅减少主动特征的数量，同时适度降低预测精度</li>
<li>我们分析了历史特征和上下文特征的影响对于模型效果。对于广告和用户的历史特征，这些特征会提供更有的预测精度比上下文特征。</li>
</ul> 
<p>最后，我们讨论了对训练数据进行子采样的方法，既可以是一致的，更有趣的是，也可以是有偏差的，即只对负样本进行子采样。</p>
                </div>
                
                

		</div>
	</article>
</main>




			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程小白.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://www.w3counter.com/tracker.js?id=150625"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>
	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>