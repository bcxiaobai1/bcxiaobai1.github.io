<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<title>2.2 搭建Spark开发环境 - 编程小白</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程小白" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程小白</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">2.2 搭建Spark开发环境</h1>
			
		</header>
		<div class="content post__content clearfix">
			


        
                <div id="content_views" class="markdown_views prism-atom-one-light">
                    
                        
                    
                    <p>一、Spark开发环境准备工作<br> 由于Spark仅仅是一种计算框架，不负责数据的存储和管理，因此，通常都会将Spark和Hadoop进行统一部署，由Hadoop中的HDFS、HBase等组件负责数据的存储管理，Spark负责数据计算。</p> 
<p>安装Spark集群前，需要安装Hadoop环境</p> 
<p>软件 版本<br> Linux系统 CentOS7.9版本<br> Hadoop 3.3.4版本<br> JDK 1.8版本 (jdk8u231)<br> Spark 3.3.2版本<br> 二、了解Spark的部署模式<br> （一）Standalone模式<br> Standalone模式被称为集群单机模式。该模式下，Spark集群架构为主从模式，即一台Master节点与多台Slave节点，Slave节点启动的进程名称为Worker，存在单点故障的问题。<br> （二）Mesos模式<br> Mesos模式被称为Spark on Mesos模式。Mesos是一款资源调度管理系统，为Spark提供服务，由于Spark与Mesos存在密切的关系，因此在设计Spark框架时充分考虑到对Mesos的集成。<br> （三）Yarn模式<br> Yarn模式被称为Spark on Yarn模式，即把Spark作为一个客户端，将作业提交给Yarn服务。由于在生产环境中，很多时候都要与Hadoop使用同一个集群，因此采用Yarn来管理资源调度，可以提高资源利用率。<br> 三、搭建Spark单机版环境<br> （一）前提是安装配置好了JDK<br> 查看JDK版本</p> 
<p>（二）下载、安装与配置Spark<br> 1、下载Spark安装包<br> 官网下载页面：https://spark.apache.org/downloads.html</p> 
<p>下载链接：https://www.apache.org/dyn/closer.lua/spark/spark-3.3.2/spark-3.3.2-bin-hadoop3.tgz</p> 
<p>下载到本地</p> 
<p>2、将Spark安装包上传到虚拟机<br> 将Spark安装包上传到ied虚拟机/opt目录</p> 
<p>3、将Spark安装包解压到指定目录<br> 执行命令：tar -zxvf spark-3.3.2-bin-hadoop3.tgz -C /usr/local</p> 
<p>查看解压之后的spark目录</p> 
<p>4、配置Spark环境变量<br> 执行vim /etc/profile</p> 
<p>export SPARK_HOME=/usr/local/spark-3.3.2-bin-hadoop3<br> export PATH=<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         S 
        
       
         P 
        
       
         A 
        
       
         R 
        
        
        
          K 
         
        
          H 
         
        
       
         O 
        
       
         M 
        
       
         E 
        
       
         / 
        
       
         b 
        
       
         i 
        
       
         n 
        
       
         : 
        
       
      
        SPARK_HOME/bin: 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em;vertical-align: -0.25em"></span><span class="mord mathnormal" style="margin-right: 0.1389em">SP</span><span class="mord mathnormal">A</span><span class="mord mathnormal" style="margin-right: 0.0077em">R</span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0715em">K</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3283em"><span class="" style="margin-left: -0.0715em;margin-right: 0.05em"><span class="pstrut" style="height: 2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0813em">H</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em"><span class=""></span></span></span></span></span></span><span class="mord mathnormal" style="margin-right: 0.0576em">OME</span><span class="mord">/</span><span class="mord mathnormal">bin</span><span class="mspace" style="margin-right: 0.2778em"></span><span class="mrel">:</span></span></span></span></span>SPARK_HOME/sbin:$PATH<br> 1<br> 2<br> 存盘退出，执行命令：source /etc/profile，让环境配置生效</p> 
<p>（三）使用Spark单机版环境<br> 1、使用SparkPi来计算Pi的值<br> 执行命令：run-example SparkPi 2 （其中参数2是指两个并行度）</p> 
<p>查看计算结果：Pi is roughly 3.1412357061785308</p> 
<p>2、使用Scala版本Spark-Shell<br> Spark-Shell是一个强大的交互式数据分析工具，初学者可以很好的使用它来学习相关API，用户可以在命令行下使用Scala编写Spark程序，并且每当输入一条语句，Spark-Shell就会立即执行语句并返回结果，这就是我们所说的REPL（Read-Eval-Print Loop，交互式解释器），Spark-Shell支持Scala和Python。<br> 命令格式：spark-shell --master <br> –master表示指定当前连接的Master节点<br> 用于指定Spark的运行模式<br> 参数名称 相关说明<br> local 使用一个Worker线程本地化运行Spark<br> local[<em>] 本地运行Spark，工作线程数量与本机CPU逻辑核心数量相同<br> local[N] 使用N个Worker线程本地化运行Spark<br> spark://host:port Standalone模式下，连接到指定的Spark集群，默认端口7077<br> yarn-client 以客户端模式连接Yarn集群，集群位置可在HADOOP_CONF_DIR环境变量中配置<br> yarn-cluster 以集群模式连接Yarn集群，集群位置可在HADOOP_CONF_DIR 环境变量中配置<br> mesos://host:port 连接到指定的Mesos集群。默认接口是5050<br> 执行spark-shell命令，相当于执行spark-shell --master local[</em>]命令，启动Scala版的Spark-Shell</p> 
<p>访问Spark的Web UI界面 - http://ied:4040</p> 
<p>注意：Spark 3.3.2使用的Scala版本其实是2.12.15</p> 
<p>利用print函数输出了一条信息</p> 
<p>计算1 + 2 + 3 + …… + 100</p> 
<p>输出字符直角三角形</p> 
<p>打印九九表</p> 
<p>执行:quit命令，退出Spark Shell交互式环境</p> 
<p>3、使用Python版本Spark-Shell<br> 执行pyspark命令启动Python版的Spark-Shell</p> 
<p>执行命令：yum -y install python3</p> 
<p>执行命令：pyspark</p> 
<p>输出一条信息，进行加法运算，然后退出交互式环境</p> 
<p>4、初识弹性分布式数据集RDD<br> Spark 中的RDD (Resilient Distributed Dataset) 就是一个不可变的分布式对象集合。每个RDD 都被分为多个分区，这些分区运行在集群中的不同节点上。RDD 可以包含Python、Java、Scala 中任意类型的对象，甚至可以包含用户自定义的对象。用户可以使用两种方法创建RDD：读取一个外部数据集，或在驱动器程序里分发驱动器程序中的对象集合（比如list 和set）。</p> 
<p>演示利用集合创建RDD</p> 
<p>在/home目录下创建test.txt文件</p> 
<p>例1、创建一个RDD<br> 在pyspark命令行，执行命令：lines = sc.textFile(‘/home/test.txt’)</p> 
<p>创建出来后，RDD 支持两种类型的操作： 转化操作（transformation） 和行动操作（action）。转化操作会由一个RDD 生成一个新的RDD。另一方面，行动操作会对RDD 计算出一个结果，并把结果返回到驱动器程序中，或把结果存储到外部存储系统（如HDFS）中。</p> 
<p>例2、调用转化操作filter()<br> 执行命令：sparkLines = lines.filter(lambda line: ‘spark’ in line)</p> 
<p>例3、调用行动操作first()<br> 执行命令：sparkLines.first()</p> 
<p>转化操作和行动操作的区别在于Spark 计算RDD 的方式不同。虽然你可以在任何时候定义新的RDD，但Spark 只会惰性计算这些RDD。它们只有第一次在一个行动操作中用到时，才会真正计算。这种策略刚开始看起来可能会显得有些奇怪，不过在大数据领域是很有道理的。比如，看看例2 和例3，我们以一个文本文件定义了数据，然后把其中包含spark的行筛选出来。如果Spark 在我们运行lines = sc.textFile(…) 时就把文件中所有的行都读取并存储起来，就会消耗很多存储空间，而我们马上就要筛选掉其中的很多数据。相反， 一旦Spark 了解了完整的转化操作链之后，它就可以只计算求结果时真正需要的数据。事实上，在行动操作first() 中，Spark 只需要扫描文件直到找到第一个匹配的行为止，而不需要读取整个文件。<br> 如果要显示全部包含spark的行，执行命令：sparkLines.collect()</p> 
<p>同样的任务，在Scala的Spark Shell里完成</p> 
<p>补充练习：利用Spark RDD实现词频统计<br> 在spark-shell里完成</p> 
<p>在pyspark里完成</p> 
<p>但是执行wc1.collect()就会报错，目前没有解决问题。</p> 
<p>四、搭建Spark Standalone集群<br> （一）Spark Standalone架构<br> Spark Standalone模式为经典的Master/Slave（主/从）架构，资源调度是Spark自己实现的。在Standalone模式中，根据应用程序提交的方式不同，Driver（主控进程）在集群中的位置也有所不同。应用程序的提交方式主要有两种：client和cluster，默认是client。可以在向Spark集群提交应用程序时使用–deploy-mode参数指定提交方式。<br> 1、client提交方式<br> 当提交方式为client时，运行架构如下图所示</p> 
<p>集群的主节点称为Master节点，在集群启动时会在主节点启动一个名为Master的守护进程，类似YARN集群的ResourceManager；从节点称为Worker节点，在集群启动时会在各个从节点上启动一个名为Worker的守护进程，类似YARN集群的NodeManager。</p> 
<p>Spark在执行应用程序的过程中会启动Driver和Executor两种JVM进程。</p> 
<p>Driver为主控进程，负责执行应用程序的main()方法，创建SparkContext对象（负责与Spark集群进行交互），提交Spark作业，并将作业转化为Task（一个作业由多个Task任务组成），然后在各个Executor进程间对Task进行调度和监控。通常用SparkContext代表Driver。在上图的架构中，Spark会在客户端启动一个名为SparkSubmit的进程，Driver程序则运行于该进程。</p> 
<p>Executor为应用程序运行在Worker节点上的一个进程，由Worker进程启动，负责执行具体的Task，并存储数据在内存或磁盘上。每个应用程序都有各自独立的一个或多个Executor进程。在Spark Standalone模式和Spark on YARN模式中，Executor进程的名称为CoarseGrainedExecutorBackend，类似运行MapReduce程序所产生的YarnChild进程，并且同时与Worker、Driver都有通信。</p> 
<p>2、cluster提交方式<br> 当提交方式为cluster时，运行架构如下图所示</p> 
<p>Standalone cluster提交方式提交应用程序后，客户端仍然会产生一个名为SparkSubmit的进程，但是该进程会在应用程序提交给集群之后就立即退出。当应用程序运行时，Master会在集群中选择一个Worker进程启动一个名为DriverWrapper的子进程，该子进程即为Driver进程，所起的作用相当于YARN集群的ApplicationMaster角色，类似MapReduce程序运行时所产生的MRAppMaster进程。<br> （二）Spark集群拓扑<br> 1、集群拓扑<br> 一个主节点，两个从节点</p> 
<p>2、集群角色分配<br> Spark Standalone模式的集群搭建需要在集群的每个节点都安装Spark，集群角色分配如下表所示。<br> 节点 角色<br> master Master<br> slave1 Worker<br> slave2 Worker<br> （三）前提条件：安装配置了分布式Hadoop环境<br> 启动hadoop集群</p> 
<p>访问Hadoop WebUI界面</p> 
<p>（四）在master虚拟机上安装配置Spark<br> 1、将spark安装包上传到master虚拟机<br> 进入/opt目录，查看上传的spark安装包</p> 
<p>2、将spark安装包解压到指定目录<br> 执行命令：tar -zxvf spark-3.3.2-bin-hadoop3.tgz -C /usr/local</p> 
<p>3、配置spark环境变量<br> 执行命令：vim /etc/profile</p> 
<p>export SPARK_HOME=/usr/local/spark-3.3.2-bin-hadoop3<br> export PATH=<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         S 
        
       
         P 
        
       
         A 
        
       
         R 
        
        
        
          K 
         
        
          H 
         
        
       
         O 
        
       
         M 
        
       
         E 
        
       
         / 
        
       
         b 
        
       
         i 
        
       
         n 
        
       
         : 
        
       
      
        SPARK_HOME/bin: 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em;vertical-align: -0.25em"></span><span class="mord mathnormal" style="margin-right: 0.1389em">SP</span><span class="mord mathnormal">A</span><span class="mord mathnormal" style="margin-right: 0.0077em">R</span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0715em">K</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3283em"><span class="" style="margin-left: -0.0715em;margin-right: 0.05em"><span class="pstrut" style="height: 2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0813em">H</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em"><span class=""></span></span></span></span></span></span><span class="mord mathnormal" style="margin-right: 0.0576em">OME</span><span class="mord">/</span><span class="mord mathnormal">bin</span><span class="mspace" style="margin-right: 0.2778em"></span><span class="mrel">:</span></span></span></span></span>SPARK_HOME/sbin:$PATH</p> 
<p>存盘退出后，执行命令：source /etc/profile，让配置生效</p> 
<p>查看spark安装目录（bin、sbin和conf三个目录很重要）</p> 
<p>4、编辑spark环境配置文件<br> 进入spark配置目录后，执行命令：cp spark-env.sh.template spark-env.sh与vim spark-env.sh</p> 
<p>添加三行语句</p> 
<p>export JAVA_HOME=/usr/local/jdk1.8.0_231<br> export SPARK_MASTER_HOST=master<br> export SPARK_MASTER_PORT=7077</p> 
<p>JAVA_HOME：指定JAVA_HOME的路径。若集群中每个节点在/etc/profile文件中都配置了JAVA_HOME，则该选项可以省略，Spark集群启动时会自动读取。为了防止出错，建议此处将该选项配置上。<br> SPARK_MASTER_HOST：指定集群主节点（master）的主机名，此处为master。<br> SPARK_MASTER_PORT：指定Master节点的访问端口，默认为7077。<br> 存盘退出，执行命令：source spark-env.sh，让配置生效</p> 
<p>5、创建slaves文件，添加从节点<br> 执行命令：vim slaves，添加两个从节点主机名</p> 
<p>（五）在slave1虚拟机上安装配置Spark<br> 1、把master虚拟机上安装的spark分发给slave1虚拟机<br> 执行命令：scp -r <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         S 
        
       
         P 
        
       
         A 
        
       
         R 
        
        
        
          K 
         
        
          H 
         
        
       
         O 
        
       
         M 
        
       
         E 
        
       
         r 
        
       
         o 
        
       
         o 
        
       
         t 
        
       
         @ 
        
       
         s 
        
       
         l 
        
       
         a 
        
       
         v 
        
       
         e 
        
       
         1 
        
       
         : 
        
       
      
        SPARK_HOME root@slave1: 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8444em;vertical-align: -0.15em"></span><span class="mord mathnormal" style="margin-right: 0.1389em">SP</span><span class="mord mathnormal">A</span><span class="mord mathnormal" style="margin-right: 0.0077em">R</span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0715em">K</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3283em"><span class="" style="margin-left: -0.0715em;margin-right: 0.05em"><span class="pstrut" style="height: 2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0813em">H</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em"><span class=""></span></span></span></span></span></span><span class="mord mathnormal" style="margin-right: 0.0576em">OME</span><span class="mord mathnormal">roo</span><span class="mord mathnormal">t</span><span class="mord">@</span><span class="mord mathnormal">s</span><span class="mord mathnormal" style="margin-right: 0.0197em">l</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right: 0.0359em">v</span><span class="mord mathnormal">e</span><span class="mord">1</span><span class="mspace" style="margin-right: 0.2778em"></span><span class="mrel">:</span></span></span></span></span>SPARK_HOME</p> 
<p>2、将master虚拟机上环境变量配置文件分发到slave1虚拟机<br> 在master虚拟机上，执行命令：scp /etc/profile root@slave1:/etc/profile</p> 
<p>在slave1虚拟机上，执行命令：source /etc/profile，让环境配置生效</p> 
<p>3、在slave1虚拟机上让spark环境配置文件生效<br> 在slave1虚拟机上，进入spark配置目录，执行命令：source spark-env.sh</p> 
<p>（六）在slave2虚拟机上安装配置Spark<br> 1、把master虚拟机上安装的spark分发给slave2虚拟机<br> 执行命令：scp -r <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         S 
        
       
         P 
        
       
         A 
        
       
         R 
        
        
        
          K 
         
        
          H 
         
        
       
         O 
        
       
         M 
        
       
         E 
        
       
         r 
        
       
         o 
        
       
         o 
        
       
         t 
        
       
         @ 
        
       
         s 
        
       
         l 
        
       
         a 
        
       
         v 
        
       
         e 
        
       
         2 
        
       
         : 
        
       
      
        SPARK_HOME root@slave2: 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8444em;vertical-align: -0.15em"></span><span class="mord mathnormal" style="margin-right: 0.1389em">SP</span><span class="mord mathnormal">A</span><span class="mord mathnormal" style="margin-right: 0.0077em">R</span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0715em">K</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3283em"><span class="" style="margin-left: -0.0715em;margin-right: 0.05em"><span class="pstrut" style="height: 2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0813em">H</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em"><span class=""></span></span></span></span></span></span><span class="mord mathnormal" style="margin-right: 0.0576em">OME</span><span class="mord mathnormal">roo</span><span class="mord mathnormal">t</span><span class="mord">@</span><span class="mord mathnormal">s</span><span class="mord mathnormal" style="margin-right: 0.0197em">l</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right: 0.0359em">v</span><span class="mord mathnormal">e</span><span class="mord">2</span><span class="mspace" style="margin-right: 0.2778em"></span><span class="mrel">:</span></span></span></span></span>SPARK_HOME</p> 
<p>2、将master虚拟机上环境变量配置文件分发到slave2虚拟机<br> 在master虚拟机上，执行命令：scp /etc/profile root@slave2:/etc/profile</p> 
<p>在slave2虚拟机上，执行命令：source /etc/profile，让环境配置生效</p> 
<p>3、在slave2虚拟机上让spark环境配置文件生效<br> 在slave2虚拟机上，进入spark配置目录，执行命令：source spark-env.sh</p> 
<p>（七）启动Spark Standalone集群<br> Spark Standalone集群使用Spark自带的资源调度框架，但一般我们把数据保存在HDFS上，用HDFS做数据持久化，所以Hadoop还是需要配置，但是可以只配置HDFS相关的，而Hadoop YARN不需要配置。启动Spark Standalone集群，不需要启动YARN服务，因为Spark会使用自带的资源调度框架。<br> 1、启动hadoop的dfs服务<br> 在master虚拟机上执行命令：start-dfs.sh</p> 
<p>2、启动Spark集群<br> 执行命令：start-all.sh</p> 
<p>查看start-all.sh的源码启动Master与Worker的命令</p> 
<h1>
<a id="Start_Master_241"></a>Start Master</h1> 
<p>“${SPARK_HOME}/sbin”/start-master.sh</p> 
<h1>
<a id="Start_Worker_243"></a>Start Worker</h1> 
<p>s"${SPARK_HOME}/sbin"/start-slaves.sh</p> 
<p>可以看到，当执行start-all.sh命令时，会分别执行start-master.sh命令启动Master，执行start-slaves.sh命令启动Worker。</p> 
<p>注意，若spark-evn.sh中配置了SPARK_MASTER_HOST属性，则必须在该属性指定的主机上启动Spark集群，否则会启动不成功；若没有配置SPARK_MASTER_HOST属性，则可以在任意节点上启动Spark集群，当前执行启动命令的节点即为Master节点。</p> 
<p>启动完毕后，分别在各节点执行jps命令，查看启动的进程。若在master节点存在Master进程，slave1节点存在Worker进程，slave2节点存在Worker进程，则说明集群启动成功。</p> 
<p>查看master节点进程</p> 
<p>查看slave1节点进程</p> 
<p>查看slave2节点进程</p> 
<p>（八）访问Spark的WebUI<br> 在浏览器里访问http://master:8080</p> 
<p>在浏览器访问http://slave1:8081</p> 
<p>在浏览器访问http://slave2:8081</p> 
<p>如果要用IP地址来访问，得用浮动IP地址，不能用私有IP地址</p> 
<p>用私有IP地址访问是不行的 - http://192.168.1.101:8080/</p> 
<p>用浮动IP地址来访问才可以 - 192.168.218.181</p> 
<p>查看私有云上虚拟机的配置</p> 
<p>（九）启动Scala版Spark Shell<br> 执行命令：spark-shell --master spark://master:7077 （注意–master，两个-不能少）</p> 
<p>在/opt目录里执行命令：vim test.txt</p> 
<p>在HDFS上创建park目录，将test.txt上传到HDFS的/park目录</p> 
<p>读取HDFS上的文件，创建RDD，执行命令：val rdd = sc.textFile(“hdfs://master:9000/park/test.txt”)（说明：val rdd = sc.textFile(“/park/test.txt”)读取的依然是HDFS上的文件，绝对不是本地文件）</p> 
<p>收集rdd的数据，执行命令：rdd.collect</p> 
<p>进行词频统计，按单词个数降序排列，执行命令：val wordcount = rdd.flatMap(<em>.split(" ")).map((</em>, 1)).reduceByKey(_ + <em>).sortBy(</em>._2, false)与`wordcount.collect.foreach(println)</p> 
<p>（十）提交Spark应用程序<br> 1、提交语法格式<br> Spark提供了一个客户端应用程序提交工具spark-submit，使用该工具可以将编写好的Spark应用程序提交到Spark集群。<br> spark-submit的使用格式如下：$ bin/spark-submit [options] [app options]<br> options表示传递给spark-submit的控制参数；<br> app jar表示提交的程序JAR包（或Python脚本文件）所在位置；<br> app options表示jar程序需要传递的参数，例如main()方法中需要传递的参数。<br> 2、spark-submit常用参数<br> 除了–master参数外，spark-submit还提供了一些控制资源使用和运行时环境的参数。<br> 参数 描述<br> –master Master节点的连接地址，取值为spark://host:port、mesos://host:port、yarn、k8s://https://host:port 或 local（默认为local[*]）<br> –deploy-mode 提交方式，取值为client或cluster。client表示在本地客户端启动Driver程序，cluster表示在集群内部的工作节点上启动Driver程序，默认为client<br> –class 应用程序的主类（Java或Scala程序）<br> –name 应用程序名称，会在Spark Web UI中显示<br> –jars 应用依赖的第三方JAR包列表，以逗号分隔<br> –files 需要放到应用工作目录中的文件列表，以逗号分隔。此参数一般用来放需要分发到各节点的数据文件<br> –conf 设置任意的SparkConf配置属性，格式为“属性名=属性值”<br> –properties-file 加载外部包含键值对的属性文件。如果不指定，就默认读取Spark安装目录下的conf/spark-defaults.conf 文件中的配置<br> –driver-memory Driver进程使用的内存量，例如512MB或1GB，单位不区分大小写，默认为1GB<br> –executor-memory 每个Executor进程所使用的内存量。例如512MB或1GB，单位不区分大小写，默认为1GB<br> –driver-cores Driver进程使用的CPU核心数，仅在集群模式中使用，默认为1<br> -executor-cores 每个Executor进程所使用的CPU核心数，默认为1<br> num-executors Executor进程数量，默认为2。如果开启动态分配，那么初始Executor的数量至少是此参数配置的数量。需要注意的是，此参数仅在Spark On YARN模式中使用<br> 3、案例演示 - 提交Spark自带的圆周率计算程序<br> 进入Spark安装目录</p> 
<p>（1）Standalone模式，采用client提交方式<br> 执行下述命令，将Spark自带的求圆周率的程序提交到集群</p> 
<p>bin/spark-submit <br> –class org.apache.spark.examples.SparkPi <br> –master spark://master:7077 <br> ./examples/jars/spark-examples_2.12-3.3.2.jar</p> 
<p>提交Spark作业后，观察Spark集群管理界面，其中“Running Applications”列表表示当前Spark集群正在计算的作业，执行几秒后，刷新界面，在Completed Applications表单下，可以看到当前应用执行完毕，返回控制台查看输出信息，出现了“Pi is roughly 3.1424157120785603”，说明Pi值已经被计算完毕。</p> 
<p>上述命令中的–master参数指定了Master节点的连接地址。该参数根据不同的Spark集群模式，其取值也有所不同，常用取值如下表所示。</p> 
<p>取值 描述<br> spark://host:port Standalone模式下的Master节点的连接地址，默认端口为7077<br> yarn 连接到YARN集群。若YARN中没有指定ResourceManager的启动地址，则需要在ResourceManager所在的节点上进行应用程序的提交，否则将因找不到ResourceManager而提交失败<br> local 运行本地模式，使用1个CPU核心<br> local [N] 运行本地模式，使用N个CPU核心。例如，local[2]表示使用两个CPU核心运行程序<br> local[<em>] 运行本地模式，尽可能使用最多的CPU核心<br> 若不添加–master参数，则默认使用本地模式local[</em>]运行。<br> （2）Standalone模式，采用cluster提交方式<br> 在Standalone模式下，将Spark自带的圆周率计算程序提交到集群，并且设置Driver进程使用内存为512MB，每个Executor进程使用内存为1GB，每个Executor进程所使用的CPU核心数为2，提交方式为cluster（Driver进程运行在集群的工作节点中），执行命令如下：<br> bin/spark-submit <br> –master spark://master:7077 <br> –deploy-mode cluster <br> –class org.apache.spark.examples.SparkPi <br> –driver-memory 512m <br> –executor-memory 1g <br> –executor-cores 2 <br> ./examples/jars/spark-examples_2.12-3.3.2.jar</p> 
<p>当然可以写成一行<br> bin/spark-submit --master spark://master:7077 --deploy-mode cluster --class org.apache.spark.SparkPi --driver-memory 512m --executor-memory 1g --executor-cores 2 ./examples/jars/spark-examples_2.12-3.3.2.jar<br> 1<br> 执行命令后，看到State of driver-20230406114733-0000 is RUNNING，就表明运行成功~，否则会显示State of driver-20230406114733-0000 is FAILED</p> 
<p>在Spark WebUI界面上查看运行结果，访问http://master:8080</p> 
<p>单击圈红的Worker超链接 - worker-20230406114652-192.168.1.102-36708<br> 注意：必须把私有IP地址改成主机名slave1或者对应的浮动IP地址</p> 
<p>单击stdout超链接，可以查看到Pi的计算结果</p> 
<p>（十一）停止Spark集群服务<br> 在master节点执行命令：stop-all.sh</p>
                </div>
                
                

		</div>
	</article>
</main>




			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程小白.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://www.w3counter.com/tracker.js?id=150625"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>
	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>