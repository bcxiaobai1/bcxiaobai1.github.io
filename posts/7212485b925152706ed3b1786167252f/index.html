<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<title>N-CMAPSS代码解析 - 编程小白</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程小白" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程小白</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">N-CMAPSS代码解析</h1>
			
		</header>
		<div class="content post__content clearfix">
			


                <div id="content_views" class="markdown_views prism-atom-one-dark">
                    
                        
                    
                    <h2>
<a id="_2"></a>代码目录介绍</h2> 
<p><img src="https://images2.imgbox.com/ef/19/PpFh7k6t_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/82/00/YC71Qu03_o.png" alt="在这里插入图片描述"></p> 
<h1>
<a id="_7"></a>重点部分代码解读</h1> 
<h6>
<a id="sample_creator_unit_autopy_8"></a>sample_creator_unit_auto.py</h6> 
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># current_dir = os.path.dirname(os.path.abspath(__file__))</span>
    parser <span class="token operator">=</span> argparse<span class="token punctuation">.</span>ArgumentParser<span class="token punctuation">(</span>description<span class="token operator">=</span><span class="token string">'sample creator'</span><span class="token punctuation">)</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'-w'</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'window length'</span><span class="token punctuation">,</span> required<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'-s'</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'stride of window'</span><span class="token punctuation">)</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--sampling'</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'sub sampling of the given data. If it is 10, then this indicates that we assumes 0.1Hz of data collection'</span><span class="token punctuation">)</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--test'</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token string">'0'</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'select train or test, if it is zero, then extract samples from the engines used for training'</span><span class="token punctuation">)</span>

    args <span class="token operator">=</span> parser<span class="token punctuation">.</span>parse_args<span class="token punctuation">(</span><span class="token punctuation">)</span>   <span class="token comment">#解析参数——使用 parse_args() 解析添加的参数</span>


    sequence_length <span class="token operator">=</span> args<span class="token punctuation">.</span>w   <span class="token comment">#窗口长度</span>
    stride <span class="token operator">=</span> args<span class="token punctuation">.</span>s <span class="token comment">#步长</span>
    sampling <span class="token operator">=</span> args<span class="token punctuation">.</span>sampling
    selector <span class="token operator">=</span> args<span class="token punctuation">.</span>test



    <span class="token comment"># Load data</span>
    <span class="token triple-quoted-string string">'''
    W: operative conditions (Scenario descriptors)
    X_s: measured signals
    X_v: virtual sensors
    T(theta): engine health parameters
    Y: RUL [in cycles]
    A: auxiliary data
    '''</span>

    df_all <span class="token operator">=</span> df_all_creator<span class="token punctuation">(</span>data_filepath<span class="token punctuation">,</span> sampling<span class="token punctuation">)</span>

    <span class="token triple-quoted-string string">'''
    划分训练集和测试集
    Split dataframe into Train and Test
    Training units: 2, 5, 10, 16, 18, 20
    Test units: 11, 14, 15

    '''</span>
    <span class="token comment"># units = list(np.unique(df_A['unit']))</span>
    units_index_train <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">2.0</span><span class="token punctuation">,</span> <span class="token number">5.0</span><span class="token punctuation">,</span> <span class="token number">10.0</span><span class="token punctuation">,</span> <span class="token number">16.0</span><span class="token punctuation">,</span> <span class="token number">18.0</span><span class="token punctuation">,</span> <span class="token number">20.0</span><span class="token punctuation">]</span>
    units_index_test <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">11.0</span><span class="token punctuation">,</span> <span class="token number">14.0</span><span class="token punctuation">,</span> <span class="token number">15.0</span><span class="token punctuation">]</span>

    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"units_index_train"</span><span class="token punctuation">,</span> units_index_train<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"units_index_test"</span><span class="token punctuation">,</span> units_index_test<span class="token punctuation">)</span>

    <span class="token comment"># if any(int(idx) == unit_index for idx in units_index_train):</span>
    <span class="token comment">#     df_train = df_train_creator(df_all, units_index_train)</span>
    <span class="token comment">#     print(df_train)</span>
    <span class="token comment">#     print(df_train.columns)</span>
    <span class="token comment">#     print("num of inputs: ", len(df_train.columns) )</span>
    <span class="token comment">#     df_test = pd.DataFrame()</span>
    <span class="token comment">#</span>
    <span class="token comment"># else :</span>
    <span class="token comment">#     df_test = df_test_creator(df_all, units_index_test)</span>
    <span class="token comment">#     print(df_test)</span>
    <span class="token comment">#     print(df_test.columns)</span>
    <span class="token comment">#     print("num of inputs: ", len(df_test.columns))</span>
    <span class="token comment">#     df_train = pd.DataFrame()</span>


    df_train <span class="token operator">=</span> df_train_creator<span class="token punctuation">(</span>df_all<span class="token punctuation">,</span> units_index_train<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>df_train<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>df_train<span class="token punctuation">.</span>columns<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"num of inputs: "</span><span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>df_train<span class="token punctuation">.</span>columns<span class="token punctuation">)</span> <span class="token punctuation">)</span>
    df_test <span class="token operator">=</span> df_test_creator<span class="token punctuation">(</span>df_all<span class="token punctuation">,</span> units_index_test<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>df_test<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>df_test<span class="token punctuation">.</span>columns<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"num of inputs: "</span><span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>df_test<span class="token punctuation">.</span>columns<span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">del</span> df_all
    gc<span class="token punctuation">.</span>collect<span class="token punctuation">(</span><span class="token punctuation">)</span>
    df_all <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span><span class="token punctuation">)</span>
    sample_dir_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>data_filedir<span class="token punctuation">,</span> <span class="token string">'Samples_whole'</span><span class="token punctuation">)</span>
    sample_folder <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>isdir<span class="token punctuation">(</span>sample_dir_path<span class="token punctuation">)</span>
    <span class="token keyword">if</span> <span class="token keyword">not</span> sample_folder<span class="token punctuation">:</span>
        os<span class="token punctuation">.</span>makedirs<span class="token punctuation">(</span>sample_dir_path<span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"created folder : "</span><span class="token punctuation">,</span> sample_dir_path<span class="token punctuation">)</span>

    cols_normalize <span class="token operator">=</span> df_train<span class="token punctuation">.</span>columns<span class="token punctuation">.</span>difference<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'RUL'</span><span class="token punctuation">,</span> <span class="token string">'unit'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment">#去掉df_train中的['RUL', 'unit']这两列</span>
    sequence_cols <span class="token operator">=</span> df_train<span class="token punctuation">.</span>columns<span class="token punctuation">.</span>difference<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'RUL'</span><span class="token punctuation">,</span> <span class="token string">'unit'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token comment">#selector == 0则从train中选择数据进行训练，否则，从测试集单元中选择数据</span>
    <span class="token keyword">if</span> selector <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
        <span class="token keyword">for</span> unit_index <span class="token keyword">in</span> units_index_train<span class="token punctuation">:</span>
            data_class <span class="token operator">=</span> Input_Gen <span class="token punctuation">(</span>df_train<span class="token punctuation">,</span> df_test<span class="token punctuation">,</span> cols_normalize<span class="token punctuation">,</span> sequence_length<span class="token punctuation">,</span> sequence_cols<span class="token punctuation">,</span> sample_dir_path<span class="token punctuation">,</span>
                                    unit_index<span class="token punctuation">,</span> sampling<span class="token punctuation">,</span> stride <span class="token operator">=</span>stride<span class="token punctuation">)</span>
            data_class<span class="token punctuation">.</span>seq_gen<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token keyword">else</span><span class="token punctuation">:</span>
        <span class="token keyword">for</span> unit_index <span class="token keyword">in</span> units_index_test<span class="token punctuation">:</span>
            data_class <span class="token operator">=</span> Input_Gen <span class="token punctuation">(</span>df_train<span class="token punctuation">,</span> df_test<span class="token punctuation">,</span> cols_normalize<span class="token punctuation">,</span> sequence_length<span class="token punctuation">,</span> sequence_cols<span class="token punctuation">,</span> sample_dir_path<span class="token punctuation">,</span>
                                    unit_index<span class="token punctuation">,</span> sampling<span class="token punctuation">,</span> stride <span class="token operator">=</span>stride<span class="token punctuation">)</span>
            data_class<span class="token punctuation">.</span>seq_gen<span class="token punctuation">(</span><span class="token punctuation">)</span>



</code></pre> 
<h6>
<a id="data_preparation_unitpy_107"></a>data_preparation_unit.py</h6> 
<pre><code class="prism language-python"><span class="token comment">#加载所有特征</span>
<span class="token keyword">def</span> <span class="token function">df_all_creator</span><span class="token punctuation">(</span>data_filepath<span class="token punctuation">,</span> sampling<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""

     """</span>
    <span class="token comment"># Time tracking, Operation time (min):  0.003</span>
    t <span class="token operator">=</span> time<span class="token punctuation">.</span>process_time<span class="token punctuation">(</span><span class="token punctuation">)</span>


    <span class="token keyword">with</span> h5py<span class="token punctuation">.</span>File<span class="token punctuation">(</span>data_filepath<span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> hdf<span class="token punctuation">:</span>
        <span class="token comment"># Development(training) set  训练数据和测试数据是已经分好了的</span>
        W_dev <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>hdf<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">'W_dev'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># W</span>
        X_s_dev <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>hdf<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">'X_s_dev'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># X_s</span>
        X_v_dev <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>hdf<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">'X_v_dev'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># X_v</span>
        T_dev <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>hdf<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">'T_dev'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># T</span>
        Y_dev <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>hdf<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">'Y_dev'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># RUL</span>
        A_dev <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>hdf<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">'A_dev'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># Auxiliary</span>

        <span class="token comment"># Test set</span>
        W_test <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>hdf<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">'W_test'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># W</span>
        X_s_test <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>hdf<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">'X_s_test'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># X_s</span>
        X_v_test <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>hdf<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">'X_v_test'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># X_v</span>
        T_test <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>hdf<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">'T_test'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># T</span>
        Y_test <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>hdf<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">'Y_test'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># RUL</span>
        A_test <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>hdf<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">'A_test'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># Auxiliary</span>

        <span class="token comment"># Varnams</span>
        W_var <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>hdf<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">'W_var'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        X_s_var <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>hdf<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">'X_s_var'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        X_v_var <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>hdf<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">'X_v_var'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        T_var <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>hdf<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">'T_var'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        A_var <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>hdf<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">'A_var'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

        <span class="token comment"># from np.array to list dtype U4/U5</span>
        W_var <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>W_var<span class="token punctuation">,</span> dtype<span class="token operator">=</span><span class="token string">'U20'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        X_s_var <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>X_s_var<span class="token punctuation">,</span> dtype<span class="token operator">=</span><span class="token string">'U20'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        X_v_var <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>X_v_var<span class="token punctuation">,</span> dtype<span class="token operator">=</span><span class="token string">'U20'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        T_var <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>T_var<span class="token punctuation">,</span> dtype<span class="token operator">=</span><span class="token string">'U20'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        A_var <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>A_var<span class="token punctuation">,</span> dtype<span class="token operator">=</span><span class="token string">'U20'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>


    W <span class="token operator">=</span> np<span class="token punctuation">.</span>concatenate<span class="token punctuation">(</span><span class="token punctuation">(</span>W_dev<span class="token punctuation">,</span> W_test<span class="token punctuation">)</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
    X_s <span class="token operator">=</span> np<span class="token punctuation">.</span>concatenate<span class="token punctuation">(</span><span class="token punctuation">(</span>X_s_dev<span class="token punctuation">,</span> X_s_test<span class="token punctuation">)</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
    X_v <span class="token operator">=</span> np<span class="token punctuation">.</span>concatenate<span class="token punctuation">(</span><span class="token punctuation">(</span>X_v_dev<span class="token punctuation">,</span> X_v_test<span class="token punctuation">)</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
    T <span class="token operator">=</span> np<span class="token punctuation">.</span>concatenate<span class="token punctuation">(</span><span class="token punctuation">(</span>T_dev<span class="token punctuation">,</span> T_test<span class="token punctuation">)</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
    Y <span class="token operator">=</span> np<span class="token punctuation">.</span>concatenate<span class="token punctuation">(</span><span class="token punctuation">(</span>Y_dev<span class="token punctuation">,</span> Y_test<span class="token punctuation">)</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
    A <span class="token operator">=</span> np<span class="token punctuation">.</span>concatenate<span class="token punctuation">(</span><span class="token punctuation">(</span>A_dev<span class="token punctuation">,</span> A_test<span class="token punctuation">)</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>

    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">''</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Operation time (min): "</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>time<span class="token punctuation">.</span>process_time<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-</span> t<span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">60</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"number of training samples(timestamps): "</span><span class="token punctuation">,</span> Y_dev<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"number of test samples(timestamps): "</span><span class="token punctuation">,</span> Y_test<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">''</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"W shape: "</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>W<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"X_s shape: "</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>X_s<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"X_v shape: "</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>X_v<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"T shape: "</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>T<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Y shape: "</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>Y<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"A shape: "</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>A<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token triple-quoted-string string">'''
    Illusration of Multivariate time-series of condition monitoring sensors readings for Unit5 (fifth engine)
    5号机组(第五发动机)状态监测传感器读数的多元时间序列说明
    
    W: operative conditions (Scenario descriptors) - ['alt', 'Mach', 'TRA', 'T2']
    X_s: measured signals - ['T24', 'T30', 'T48', 'T50', 'P15', 'P2', 'P21', 'P24', 'Ps30', 'P40', 'P50', 'Nf', 'Nc', 'Wf']
    X_v: virtual sensors - ['T40', 'P30', 'P45', 'W21', 'W22', 'W25', 'W31', 'W32', 'W48', 'W50', 'SmFan', 'SmLPC', 'SmHPC', 'phi']
    T(theta): engine health parameters - ['fan_eff_mod', 'fan_flow_mod', 'LPC_eff_mod', 'LPC_flow_mod', 'HPC_eff_mod', 'HPC_flow_mod', 'HPT_eff_mod', 'HPT_flow_mod', 'LPT_eff_mod', 'LPT_flow_mod']
    Y: RUL [in cycles]
    A: auxiliary data - ['unit', 'cycle', 'Fc', 'hs']
    '''</span>

    df_W <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>data<span class="token operator">=</span>W<span class="token punctuation">,</span> columns<span class="token operator">=</span>W_var<span class="token punctuation">)</span>
    df_Xs <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>data<span class="token operator">=</span>X_s<span class="token punctuation">,</span> columns<span class="token operator">=</span>X_s_var<span class="token punctuation">)</span>
    df_Xv <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>data<span class="token operator">=</span>X_v<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> columns<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'T40'</span><span class="token punctuation">,</span> <span class="token string">'P30'</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment">#这里的virtual sensors只取了‘T40', 'P30'两个参数</span>
    <span class="token comment"># df_T = pd.DataFrame(data=T, columns=T_var)</span>
    df_Y <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>data<span class="token operator">=</span>Y<span class="token punctuation">,</span> columns<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'RUL'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    df_A <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>data<span class="token operator">=</span>A<span class="token punctuation">,</span> columns<span class="token operator">=</span>A_var<span class="token punctuation">)</span><span class="token punctuation">.</span>drop<span class="token punctuation">(</span>columns<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'cycle'</span><span class="token punctuation">,</span> <span class="token string">'Fc'</span><span class="token punctuation">,</span> <span class="token string">'hs'</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment">#只取unit</span>



    <span class="token comment"># Merge all the dataframes</span>
    df_all <span class="token operator">=</span> pd<span class="token punctuation">.</span>concat<span class="token punctuation">(</span><span class="token punctuation">[</span>df_W<span class="token punctuation">,</span> df_Xs<span class="token punctuation">,</span> df_Xv<span class="token punctuation">,</span> df_Y<span class="token punctuation">,</span> df_A<span class="token punctuation">]</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
    <span class="token comment"># 这里的df_all实际只有22个参数</span>
    <span class="token keyword">print</span> <span class="token punctuation">(</span><span class="token string">"df_all"</span><span class="token punctuation">,</span> df_all<span class="token punctuation">)</span>    <span class="token comment"># df_all = pd.concat([df_W, df_Xs, df_Xv, df_Y, df_A], axis=1).drop(columns=[ 'P45', 'W21', 'W22', 'W25', 'W31', 'W32', 'W48', 'W50', 'SmFan', 'SmLPC', 'SmHPC', 'phi', 'Fc', 'hs'])</span>

    <span class="token keyword">print</span> <span class="token punctuation">(</span><span class="token string">"df_all.shape"</span><span class="token punctuation">,</span> df_all<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
    <span class="token comment"># del [[df_W, df_Xs, df_Xv, df_Y, df_A]]</span>
    <span class="token comment"># gc.collect()</span>
    <span class="token comment"># df_W = pd.DataFrame()</span>
    <span class="token comment"># df_Xs = pd.DataFrame()</span>
    <span class="token comment"># df_Xv = pd.DataFrame()</span>
    <span class="token comment"># df_Y = pd.DataFrame()</span>
    <span class="token comment"># df_A = pd.DataFrame()</span>

    df_all_smp <span class="token operator">=</span> df_all<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">:</span>sampling<span class="token punctuation">]</span>
    <span class="token keyword">print</span> <span class="token punctuation">(</span><span class="token string">"df_all_sub"</span><span class="token punctuation">,</span> df_all_smp<span class="token punctuation">)</span>    <span class="token comment"># df_all = pd.concat([df_W, df_Xs, df_Xv, df_Y, df_A], axis=1).drop(columns=[ 'P45', 'W21', 'W22', 'W25', 'W31', 'W32', 'W48', 'W50', 'SmFan', 'SmLPC', 'SmHPC', 'phi', 'Fc', 'hs'])</span>

    <span class="token keyword">print</span> <span class="token punctuation">(</span><span class="token string">"df_all_sub.shape"</span><span class="token punctuation">,</span> df_all_smp<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>


    <span class="token keyword">return</span> df_all_smp


<span class="token comment">#加载训练集的所有数据</span>
<span class="token keyword">def</span> <span class="token function">df_train_creator</span><span class="token punctuation">(</span>df_all<span class="token punctuation">,</span> units_index_train<span class="token punctuation">)</span><span class="token punctuation">:</span>
    train_df_lst<span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token keyword">for</span> idx <span class="token keyword">in</span> units_index_train<span class="token punctuation">:</span>
        df_train_temp <span class="token operator">=</span> df_all<span class="token punctuation">[</span>df_all<span class="token punctuation">[</span><span class="token string">'unit'</span><span class="token punctuation">]</span> <span class="token operator">==</span> np<span class="token punctuation">.</span>float64<span class="token punctuation">(</span>idx<span class="token punctuation">)</span><span class="token punctuation">]</span>
        train_df_lst<span class="token punctuation">.</span>append<span class="token punctuation">(</span>df_train_temp<span class="token punctuation">)</span>
    df_train <span class="token operator">=</span> pd<span class="token punctuation">.</span>concat<span class="token punctuation">(</span>train_df_lst<span class="token punctuation">)</span>
    df_train <span class="token operator">=</span> df_train<span class="token punctuation">.</span>reset_index<span class="token punctuation">(</span>drop<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

    <span class="token keyword">return</span> df_train

<span class="token comment">#加载所有测试集数据</span>
<span class="token keyword">def</span> <span class="token function">df_test_creator</span><span class="token punctuation">(</span>df_all<span class="token punctuation">,</span> units_index_test<span class="token punctuation">)</span><span class="token punctuation">:</span>
    test_df_lst <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token keyword">for</span> idx <span class="token keyword">in</span> units_index_test<span class="token punctuation">:</span>
        df_test_temp <span class="token operator">=</span> df_all<span class="token punctuation">[</span>df_all<span class="token punctuation">[</span><span class="token string">'unit'</span><span class="token punctuation">]</span> <span class="token operator">==</span> np<span class="token punctuation">.</span>float64<span class="token punctuation">(</span>idx<span class="token punctuation">)</span><span class="token punctuation">]</span>
        test_df_lst<span class="token punctuation">.</span>append<span class="token punctuation">(</span>df_test_temp<span class="token punctuation">)</span>

    df_test <span class="token operator">=</span> pd<span class="token punctuation">.</span>concat<span class="token punctuation">(</span>test_df_lst<span class="token punctuation">)</span>
    df_test <span class="token operator">=</span> df_test<span class="token punctuation">.</span>reset_index<span class="token punctuation">(</span>drop<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

    <span class="token keyword">return</span> df_test
<span class="token comment">#特征滑窗如何选取数据</span>
<span class="token keyword">def</span> <span class="token function">gen_sequence</span><span class="token punctuation">(</span>id_df<span class="token punctuation">,</span> seq_length<span class="token punctuation">,</span> seq_cols<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">""" Only sequences that meet the window-length are considered, no padding is used. This means for testing
    we need to drop those which are below the window-length. An alternative would be to pad sequences so that
    we can use shorter ones """</span>
    <span class="token triple-quoted-string string">'''
    只考虑满足窗口长度的序列，不使用填充。这意味着在测试中，我们需要去掉那些低于窗口长度的部分。另一种选择是填充序列，这样我们就可以使用更短的序列
    '''</span>
    <span class="token comment"># for one id I put all the rows in a single matrix  例如id=2的发动机，所有数据放在一个矩阵中</span>
    data_matrix <span class="token operator">=</span> id_df<span class="token punctuation">[</span>seq_cols<span class="token punctuation">]</span><span class="token punctuation">.</span>values <span class="token comment">#此处只是特征部分，没有取RUL</span>
    num_elements <span class="token operator">=</span> data_matrix<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token comment">#行数</span>
    <span class="token comment"># Iterate over two lists in parallel.</span>
    <span class="token comment"># For example id1 have 192 rows and sequence_length is equal to 50  用长度为50的滑窗解释滑窗过程</span>
    <span class="token comment"># so zip iterate over two following list of numbers (0,142),(50,192)</span>
    <span class="token comment"># 0 50 -&gt; from row 0 to row 50</span>
    <span class="token comment"># 1 51 -&gt; from row 1 to row 51</span>
    <span class="token comment"># 2 52 -&gt; from row 2 to row 52</span>
    <span class="token comment"># ...</span>
    <span class="token comment"># 142 192 -&gt; from row 142 to 192</span>
    <span class="token keyword">for</span> start<span class="token punctuation">,</span> stop <span class="token keyword">in</span> <span class="token builtin">zip</span><span class="token punctuation">(</span><span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> num_elements <span class="token operator">-</span> seq_length<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token builtin">range</span><span class="token punctuation">(</span>seq_length<span class="token punctuation">,</span> num_elements<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">yield</span> data_matrix<span class="token punctuation">[</span>start<span class="token punctuation">:</span>stop<span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span>

<span class="token comment">#标签滑窗如何选取标签</span>
<span class="token keyword">def</span> <span class="token function">gen_labels</span><span class="token punctuation">(</span>id_df<span class="token punctuation">,</span> seq_length<span class="token punctuation">,</span> label<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">""" Only sequences that meet the window-length are considered, no padding is used. This means for testing
    we need to drop those which are below the window-length. An alternative would be to pad sequences so that
    we can use shorter ones """</span>
    <span class="token comment"># For one id I put all the labels in a single matrix.</span>
    <span class="token comment"># For example:</span>
    <span class="token comment"># [[1]</span>
    <span class="token comment"># [4]</span>
    <span class="token comment"># [1]</span>
    <span class="token comment"># [5]</span>
    <span class="token comment"># [9]</span>
    <span class="token comment"># ...</span>
    <span class="token comment"># [200]]</span>
    data_matrix <span class="token operator">=</span> id_df<span class="token punctuation">[</span>label<span class="token punctuation">]</span><span class="token punctuation">.</span>values  <span class="token comment">#只有lable值</span>
    num_elements <span class="token operator">=</span> data_matrix<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
    <span class="token comment"># I have to remove the first seq_length labels</span>
    <span class="token comment"># because for one id the first sequence of seq_length size have as target</span>
    <span class="token comment"># the last label (the previus ones are discarded).</span>
    <span class="token comment"># All the next id's sequences will have associated step by step one label as target.</span>
    <span class="token comment">#窗口的下一条RUL作为标签</span>
    <span class="token keyword">return</span> data_matrix<span class="token punctuation">[</span>seq_length<span class="token punctuation">:</span>num_elements<span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span>

<span class="token comment">#特征窗口滑动过程代码 ，利用滑窗生成特征sample_array，以及标签label_array</span>
<span class="token keyword">def</span> <span class="token function">time_window_slicing</span> <span class="token punctuation">(</span>input_array<span class="token punctuation">,</span> sequence_length<span class="token punctuation">,</span> sequence_cols<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># generate labels</span>
    label_gen <span class="token operator">=</span> <span class="token punctuation">[</span>gen_labels<span class="token punctuation">(</span>input_array<span class="token punctuation">[</span>input_array<span class="token punctuation">[</span><span class="token string">'unit'</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token builtin">id</span><span class="token punctuation">]</span><span class="token punctuation">,</span> sequence_length<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token string">'RUL'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
                 <span class="token keyword">for</span> <span class="token builtin">id</span> <span class="token keyword">in</span> input_array<span class="token punctuation">[</span><span class="token string">'unit'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>unique<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
    label_array <span class="token operator">=</span> np<span class="token punctuation">.</span>concatenate<span class="token punctuation">(</span>label_gen<span class="token punctuation">)</span><span class="token punctuation">.</span>astype<span class="token punctuation">(</span>np<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
    <span class="token comment"># label_array = np.concatenate(label_gen)</span>

    <span class="token comment"># transform each id of the train dataset in a sequence</span>
    seq_gen <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token builtin">list</span><span class="token punctuation">(</span>gen_sequence<span class="token punctuation">(</span>input_array<span class="token punctuation">[</span>input_array<span class="token punctuation">[</span><span class="token string">'unit'</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token builtin">id</span><span class="token punctuation">]</span><span class="token punctuation">,</span> sequence_length<span class="token punctuation">,</span> sequence_cols<span class="token punctuation">)</span><span class="token punctuation">)</span>
               <span class="token keyword">for</span> <span class="token builtin">id</span> <span class="token keyword">in</span> input_array<span class="token punctuation">[</span><span class="token string">'unit'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>unique<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    sample_array <span class="token operator">=</span> np<span class="token punctuation">.</span>concatenate<span class="token punctuation">(</span><span class="token builtin">list</span><span class="token punctuation">(</span>seq_gen<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>astype<span class="token punctuation">(</span>np<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
    <span class="token comment"># sample_array = np.concatenate(list(seq_gen))</span>

    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"sample_array"</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> sample_array<span class="token punctuation">,</span> label_array

<span class="token comment">#生成多个独立的窗口，只有RUL一列</span>
<span class="token keyword">def</span> <span class="token function">time_window_slicing_label_save</span> <span class="token punctuation">(</span>input_array<span class="token punctuation">,</span> sequence_length<span class="token punctuation">,</span> stride<span class="token punctuation">,</span> index<span class="token punctuation">,</span> sample_dir_path<span class="token punctuation">,</span> sequence_cols <span class="token operator">=</span> <span class="token string">'RUL'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">'''
    ref
        for i in range(0, input_temp.shape[0] - sequence_length):
        window = input_temp[i*stride:i*stride + sequence_length, :]  # each individual window
        window_lst.append(window)
        # print (window.shape)


    '''</span>
    <span class="token comment"># generate labels</span>
    window_lst <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>  <span class="token comment"># a python list to hold the windows</span>

    input_temp <span class="token operator">=</span> input_array<span class="token punctuation">[</span>input_array<span class="token punctuation">[</span><span class="token string">'unit'</span><span class="token punctuation">]</span> <span class="token operator">==</span> index<span class="token punctuation">]</span><span class="token punctuation">[</span>sequence_cols<span class="token punctuation">]</span><span class="token punctuation">.</span>values
    num_samples <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span><span class="token punctuation">(</span>input_temp<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">-</span> sequence_length<span class="token punctuation">)</span><span class="token operator">/</span>stride<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">1</span>  <span class="token comment">#samples数量 也就是有多少个窗口</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_samples<span class="token punctuation">)</span><span class="token punctuation">:</span>
        window <span class="token operator">=</span> input_temp<span class="token punctuation">[</span>i<span class="token operator">*</span>stride<span class="token punctuation">:</span>i<span class="token operator">*</span>stride <span class="token operator">+</span> sequence_length<span class="token punctuation">]</span>  <span class="token comment"># each individual window 每个窗口内的数据</span>
        window_lst<span class="token punctuation">.</span>append<span class="token punctuation">(</span>window<span class="token punctuation">)</span>
        <span class="token comment"># print (window.shape)</span>

    label_array <span class="token operator">=</span> np<span class="token punctuation">.</span>asarray<span class="token punctuation">(</span>window_lst<span class="token punctuation">)</span><span class="token punctuation">.</span>astype<span class="token punctuation">(</span>np<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
    <span class="token comment"># label_array = np.asarray(window_lst)</span>

    <span class="token comment"># np.save(os.path.join(sample_dir_path, 'Unit%s_rul_win%s_str%s' %(str(int(index)), sequence_length, stride)),</span>
    <span class="token comment">#         label_array)  # save the file as "outfile_name.npy"</span>

    <span class="token keyword">return</span> label_array<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>  <span class="token comment">#取label_array矩阵的所有行，最后一列</span>


<span class="token comment">#生成多个独立的窗口，仅包含特征</span>
<span class="token keyword">def</span> <span class="token function">time_window_slicing_sample_save</span> <span class="token punctuation">(</span>input_array<span class="token punctuation">,</span> sequence_length<span class="token punctuation">,</span> stride<span class="token punctuation">,</span> index<span class="token punctuation">,</span> sample_dir_path<span class="token punctuation">,</span> sequence_cols<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">'''


    '''</span>
    <span class="token comment"># generate labels</span>
    window_lst <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>  <span class="token comment"># a python list to hold the windows</span>

    input_temp <span class="token operator">=</span> input_array<span class="token punctuation">[</span>input_array<span class="token punctuation">[</span><span class="token string">'unit'</span><span class="token punctuation">]</span> <span class="token operator">==</span> index<span class="token punctuation">]</span><span class="token punctuation">[</span>sequence_cols<span class="token punctuation">]</span><span class="token punctuation">.</span>values
    <span class="token keyword">print</span> <span class="token punctuation">(</span><span class="token string">"Unit%s input array shape: "</span> <span class="token operator">%</span>index<span class="token punctuation">,</span> input_temp<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
    num_samples <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span><span class="token punctuation">(</span>input_temp<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">-</span> sequence_length<span class="token punctuation">)</span><span class="token operator">/</span>stride<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">1</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_samples<span class="token punctuation">)</span><span class="token punctuation">:</span>
        window <span class="token operator">=</span> input_temp<span class="token punctuation">[</span>i<span class="token operator">*</span>stride<span class="token punctuation">:</span>i<span class="token operator">*</span>stride <span class="token operator">+</span> sequence_length<span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span>  <span class="token comment"># each individual window</span>
        window_lst<span class="token punctuation">.</span>append<span class="token punctuation">(</span>window<span class="token punctuation">)</span>

    sample_array <span class="token operator">=</span> np<span class="token punctuation">.</span>dstack<span class="token punctuation">(</span>window_lst<span class="token punctuation">)</span><span class="token punctuation">.</span>astype<span class="token punctuation">(</span>np<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
    <span class="token comment"># sample_array = np.dstack(window_lst)</span>
    <span class="token keyword">print</span> <span class="token punctuation">(</span><span class="token string">"sample_array.shape"</span><span class="token punctuation">,</span> sample_array<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>

    <span class="token comment"># np.save(os.path.join(sample_dir_path, 'Unit%s_samples_win%s_str%s' %(str(int(index)), sequence_length, stride)),</span>
    <span class="token comment">#         sample_array)  # save the file as "outfile_name.npy"</span>


    <span class="token keyword">return</span> sample_array


<span class="token comment">#准备数据，包含滑窗处理和归一化处理后的训练集和测试集</span>
<span class="token keyword">class</span> <span class="token class-name">Input_Gen</span><span class="token punctuation">(</span><span class="token builtin">object</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">'''
    class for data preparation (sequence generator)
    '''</span>

    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> df_train<span class="token punctuation">,</span> df_test<span class="token punctuation">,</span> cols_normalize<span class="token punctuation">,</span> sequence_length<span class="token punctuation">,</span> sequence_cols<span class="token punctuation">,</span> sample_dir_path<span class="token punctuation">,</span>
                 unit_index<span class="token punctuation">,</span> sampling<span class="token punctuation">,</span> stride<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">'''

        '''</span>
        <span class="token comment"># self.__logger = logging.getLogger('data preparation for using it as the network input')</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"the number of input signals: "</span><span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>cols_normalize<span class="token punctuation">)</span><span class="token punctuation">)</span>
        min_max_scaler <span class="token operator">=</span> preprocessing<span class="token punctuation">.</span>MinMaxScaler<span class="token punctuation">(</span>feature_range<span class="token operator">=</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># 定义归一化的范围是（-1,1）</span>
        norm_df <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>min_max_scaler<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>df_train<span class="token punctuation">[</span>cols_normalize<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token comment">#norm_df是归一化后的值</span>
                               columns<span class="token operator">=</span>cols_normalize<span class="token punctuation">,</span>
                               index<span class="token operator">=</span>df_train<span class="token punctuation">.</span>index<span class="token punctuation">)</span>
        join_df <span class="token operator">=</span> df_train<span class="token punctuation">[</span>df_train<span class="token punctuation">.</span>columns<span class="token punctuation">.</span>difference<span class="token punctuation">(</span>cols_normalize<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>norm_df<span class="token punctuation">)</span>
        df_train <span class="token operator">=</span> join_df<span class="token punctuation">.</span>reindex<span class="token punctuation">(</span>columns<span class="token operator">=</span>df_train<span class="token punctuation">.</span>columns<span class="token punctuation">)</span> <span class="token comment">#重新设置索引，此时的df_train为归一化后的值</span>

        norm_test_df <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>min_max_scaler<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>df_test<span class="token punctuation">[</span>cols_normalize<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> columns<span class="token operator">=</span>cols_normalize<span class="token punctuation">,</span>
                                    index<span class="token operator">=</span>df_test<span class="token punctuation">.</span>index<span class="token punctuation">)</span>
        test_join_df <span class="token operator">=</span> df_test<span class="token punctuation">[</span>df_test<span class="token punctuation">.</span>columns<span class="token punctuation">.</span>difference<span class="token punctuation">(</span>cols_normalize<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>norm_test_df<span class="token punctuation">)</span>
        df_test <span class="token operator">=</span> test_join_df<span class="token punctuation">.</span>reindex<span class="token punctuation">(</span>columns<span class="token operator">=</span>df_test<span class="token punctuation">.</span>columns<span class="token punctuation">)</span>
        df_test <span class="token operator">=</span> df_test<span class="token punctuation">.</span>reset_index<span class="token punctuation">(</span>drop<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>df_train <span class="token operator">=</span> df_train
        self<span class="token punctuation">.</span>df_test <span class="token operator">=</span> df_test

        <span class="token keyword">print</span> <span class="token punctuation">(</span>self<span class="token punctuation">.</span>df_train<span class="token punctuation">)</span>
        <span class="token keyword">print</span> <span class="token punctuation">(</span>self<span class="token punctuation">.</span>df_test<span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>cols_normalize <span class="token operator">=</span> cols_normalize
        self<span class="token punctuation">.</span>sequence_length <span class="token operator">=</span> sequence_length
        self<span class="token punctuation">.</span>sequence_cols <span class="token operator">=</span> sequence_cols
        self<span class="token punctuation">.</span>sample_dir_path <span class="token operator">=</span> sample_dir_path
        self<span class="token punctuation">.</span>unit_index <span class="token operator">=</span> np<span class="token punctuation">.</span>float64<span class="token punctuation">(</span>unit_index<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>sampling <span class="token operator">=</span> sampling
        self<span class="token punctuation">.</span>stride <span class="token operator">=</span> stride


    <span class="token keyword">def</span> <span class="token function">seq_gen</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">'''
        concatenate vectors for NNs
        :param :
        :param :
        :return:
        '''</span>
        <span class="token comment">#对不同的编号发动机逐个取特征和标签</span>
        <span class="token keyword">if</span> <span class="token builtin">any</span><span class="token punctuation">(</span>index <span class="token operator">==</span> self<span class="token punctuation">.</span>unit_index <span class="token keyword">for</span> index <span class="token keyword">in</span> self<span class="token punctuation">.</span>df_train<span class="token punctuation">[</span><span class="token string">'unit'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>unique<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token comment">#训练集</span>
            <span class="token keyword">print</span> <span class="token punctuation">(</span><span class="token string">"Unit for Train"</span><span class="token punctuation">)</span>
            label_array <span class="token operator">=</span> time_window_slicing_label_save<span class="token punctuation">(</span>self<span class="token punctuation">.</span>df_train<span class="token punctuation">,</span> self<span class="token punctuation">.</span>sequence_length<span class="token punctuation">,</span>
                                           self<span class="token punctuation">.</span>stride<span class="token punctuation">,</span> self<span class="token punctuation">.</span>unit_index<span class="token punctuation">,</span> self<span class="token punctuation">.</span>sample_dir_path<span class="token punctuation">,</span> sequence_cols<span class="token operator">=</span><span class="token string">'RUL'</span><span class="token punctuation">)</span>
            sample_array <span class="token operator">=</span> time_window_slicing_sample_save<span class="token punctuation">(</span>self<span class="token punctuation">.</span>df_train<span class="token punctuation">,</span> self<span class="token punctuation">.</span>sequence_length<span class="token punctuation">,</span>
                                           self<span class="token punctuation">.</span>stride<span class="token punctuation">,</span> self<span class="token punctuation">.</span>unit_index<span class="token punctuation">,</span> self<span class="token punctuation">.</span>sample_dir_path<span class="token punctuation">,</span> sequence_cols<span class="token operator">=</span>self<span class="token punctuation">.</span>cols_normalize<span class="token punctuation">)</span>

        <span class="token keyword">else</span><span class="token punctuation">:</span><span class="token comment">#测试集</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Unit for Test"</span><span class="token punctuation">)</span>
            label_array <span class="token operator">=</span> time_window_slicing_label_save<span class="token punctuation">(</span>self<span class="token punctuation">.</span>df_test<span class="token punctuation">,</span> self<span class="token punctuation">.</span>sequence_length<span class="token punctuation">,</span>
                                           self<span class="token punctuation">.</span>stride<span class="token punctuation">,</span> self<span class="token punctuation">.</span>unit_index<span class="token punctuation">,</span> self<span class="token punctuation">.</span>sample_dir_path<span class="token punctuation">,</span> sequence_cols<span class="token operator">=</span><span class="token string">'RUL'</span><span class="token punctuation">)</span>
            sample_array <span class="token operator">=</span> time_window_slicing_sample_save<span class="token punctuation">(</span>self<span class="token punctuation">.</span>df_test<span class="token punctuation">,</span> self<span class="token punctuation">.</span>sequence_length<span class="token punctuation">,</span>
                                           self<span class="token punctuation">.</span>stride<span class="token punctuation">,</span> self<span class="token punctuation">.</span>unit_index<span class="token punctuation">,</span> self<span class="token punctuation">.</span>sample_dir_path<span class="token punctuation">,</span> sequence_cols<span class="token operator">=</span>self<span class="token punctuation">.</span>cols_normalize<span class="token punctuation">)</span>

        <span class="token comment"># sample_split_lst = np.array_split(sample_array, 3, axis=2)</span>
        <span class="token comment"># print (sample_split_lst[0].shape)</span>
        <span class="token comment"># print(sample_split_lst[1].shape)</span>
        <span class="token comment"># print(sample_split_lst[2].shape)</span>

        <span class="token comment"># label_split_lst = np.array_split(label_array, 3, axis=0)</span>
        <span class="token comment"># print (label_split_lst[0].shape)</span>
        <span class="token comment"># print(label_split_lst[1].shape)</span>
        <span class="token comment"># print(label_split_lst[2].shape)</span>

        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"sample_array.shape"</span><span class="token punctuation">,</span> sample_array<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"label_array.shape"</span><span class="token punctuation">,</span> label_array<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>

        
        <span class="token comment">#以压缩的.npz 格式将多个数组保存到一个文件中，保存在 ./N-CMAPSS/Samples_whole  目录下</span>
        np<span class="token punctuation">.</span>savez_compressed<span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>self<span class="token punctuation">.</span>sample_dir_path<span class="token punctuation">,</span> <span class="token string">'Unit%s_win%s_str%s_smp%s'</span> <span class="token operator">%</span><span class="token punctuation">(</span><span class="token builtin">str</span><span class="token punctuation">(</span><span class="token builtin">int</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>unit_index<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>sequence_length<span class="token punctuation">,</span> self<span class="token punctuation">.</span>stride<span class="token punctuation">,</span> self<span class="token punctuation">.</span>sampling<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                         sample<span class="token operator">=</span>sample_array<span class="token punctuation">,</span> label<span class="token operator">=</span>label_array<span class="token punctuation">)</span>
        <span class="token keyword">print</span> <span class="token punctuation">(</span><span class="token string">"unit saved"</span><span class="token punctuation">)</span>

        <span class="token keyword">return</span>

</code></pre> 
<h6>
<a id="inference_cnn_aggrpy_440"></a>inference_cnn_aggr.py</h6> 
<pre><code class="prism language-python"><span class="token triple-quoted-string string">'''
DL models (FNN, 1D CNN and CNN-LSTM) evaluation on N-CMAPSS
12.07.2021
Hyunho Mo
hyunho.mo@unitn.it
'''</span>
<span class="token comment">## Import libraries in python</span>
<span class="token keyword">import</span> gc
<span class="token keyword">import</span> argparse
<span class="token keyword">import</span> os
<span class="token keyword">import</span> json
<span class="token keyword">import</span> logging
<span class="token keyword">import</span> sys
<span class="token keyword">import</span> h5py
<span class="token keyword">import</span> time
<span class="token keyword">import</span> matplotlib
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd
<span class="token keyword">import</span> seaborn <span class="token keyword">as</span> sns
<span class="token keyword">from</span> pandas <span class="token keyword">import</span> DataFrame
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
<span class="token keyword">from</span> matplotlib <span class="token keyword">import</span> gridspec
<span class="token keyword">import</span> math
<span class="token keyword">import</span> random
<span class="token keyword">from</span> random <span class="token keyword">import</span> shuffle
<span class="token keyword">from</span> tqdm<span class="token punctuation">.</span>keras <span class="token keyword">import</span> TqdmCallback

seed <span class="token operator">=</span> <span class="token number">0</span>
random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span>seed<span class="token punctuation">)</span>

<span class="token keyword">import</span> importlib
<span class="token keyword">from</span> scipy<span class="token punctuation">.</span>stats <span class="token keyword">import</span> randint<span class="token punctuation">,</span> expon<span class="token punctuation">,</span> uniform
<span class="token keyword">import</span> sklearn <span class="token keyword">as</span> sk
<span class="token keyword">from</span> sklearn <span class="token keyword">import</span> svm
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>utils <span class="token keyword">import</span> shuffle
<span class="token keyword">from</span> sklearn <span class="token keyword">import</span> metrics
<span class="token keyword">from</span> sklearn <span class="token keyword">import</span> preprocessing
<span class="token keyword">from</span> sklearn <span class="token keyword">import</span> pipeline
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>metrics <span class="token keyword">import</span> mean_squared_error
<span class="token keyword">from</span> math <span class="token keyword">import</span> sqrt
<span class="token keyword">from</span> tqdm <span class="token keyword">import</span> tqdm
<span class="token keyword">import</span> scipy<span class="token punctuation">.</span>stats <span class="token keyword">as</span> stats
<span class="token comment"># from sklearn.utils.testing import ignore_warnings</span>
<span class="token comment"># from sklearn.exceptions import ConvergenceWarning</span>
<span class="token comment"># import keras</span>
<span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tf
<span class="token keyword">print</span><span class="token punctuation">(</span>tf<span class="token punctuation">.</span>__version__<span class="token punctuation">)</span>
<span class="token comment"># import keras.backend as K</span>
<span class="token keyword">import</span> tensorflow<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>backend <span class="token keyword">as</span> K
<span class="token keyword">from</span> tensorflow<span class="token punctuation">.</span>keras <span class="token keyword">import</span> backend
<span class="token keyword">from</span> tensorflow<span class="token punctuation">.</span>keras <span class="token keyword">import</span> optimizers
<span class="token keyword">from</span> tensorflow<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>models <span class="token keyword">import</span> Sequential<span class="token punctuation">,</span> load_model<span class="token punctuation">,</span> Model
<span class="token keyword">from</span> tensorflow<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers <span class="token keyword">import</span> Input<span class="token punctuation">,</span> Dense<span class="token punctuation">,</span> Flatten<span class="token punctuation">,</span> Dropout<span class="token punctuation">,</span> Embedding
<span class="token keyword">from</span> tensorflow<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers <span class="token keyword">import</span> BatchNormalization<span class="token punctuation">,</span> Activation<span class="token punctuation">,</span> LSTM<span class="token punctuation">,</span> TimeDistributed<span class="token punctuation">,</span> Bidirectional
<span class="token keyword">from</span> tensorflow<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers <span class="token keyword">import</span> Conv1D
<span class="token keyword">from</span> tensorflow<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers <span class="token keyword">import</span> MaxPooling1D
<span class="token keyword">from</span> tensorflow<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers <span class="token keyword">import</span> concatenate
<span class="token keyword">from</span> tensorflow<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>callbacks <span class="token keyword">import</span> EarlyStopping<span class="token punctuation">,</span> ModelCheckpoint<span class="token punctuation">,</span> LearningRateScheduler


<span class="token keyword">from</span> tensorflow<span class="token punctuation">.</span>python<span class="token punctuation">.</span>framework<span class="token punctuation">.</span>convert_to_constants <span class="token keyword">import</span>  convert_variables_to_constants_v2_as_graph

<span class="token keyword">from</span> tensorflow<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>initializers <span class="token keyword">import</span> GlorotNormal<span class="token punctuation">,</span> GlorotUniform

initializer <span class="token operator">=</span> GlorotNormal<span class="token punctuation">(</span>seed<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
<span class="token comment"># initializer = GlorotUniform(seed=0)</span>

<span class="token keyword">from</span> utils<span class="token punctuation">.</span>data_preparation_unit <span class="token keyword">import</span> df_all_creator<span class="token punctuation">,</span> df_train_creator<span class="token punctuation">,</span> df_test_creator<span class="token punctuation">,</span> Input_Gen
<span class="token keyword">from</span> utils<span class="token punctuation">.</span>dnn <span class="token keyword">import</span> one_dcnn<span class="token punctuation">,</span>CNNBranch


<span class="token comment"># import tensorflow.compat.v1 as tf</span>
<span class="token comment"># tf.disable_v2_behavior()</span>

<span class="token comment"># Ignore tf err log</span>
pd<span class="token punctuation">.</span>options<span class="token punctuation">.</span>mode<span class="token punctuation">.</span>chained_assignment <span class="token operator">=</span> <span class="token boolean">None</span>  <span class="token comment"># default='warn'</span>


<span class="token comment"># from tensorflow.compat.v1 import ConfigProto</span>
<span class="token comment"># from tensorflow.compat.v1 import InteractiveSession</span>
<span class="token comment"># config = ConfigProto()</span>
<span class="token comment"># config.gpu_options.allow_growth = True</span>
<span class="token comment"># session = InteractiveSession(config=config)</span>

<span class="token comment">#gpus = tf.config.experimental.list_physical_devices('GPU')</span>
<span class="token comment">#for gpu in gpus:</span>
<span class="token comment">#    tf.config.experimental.set_memory_growth(gpu, True)</span>

<span class="token comment"># tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)</span>
<span class="token comment"># tf.get_logger().setLevel(logging.ERROR)</span>



<span class="token comment"># tf.config.set_visible_devices([], 'GPU')</span>

<span class="token comment"># &lt;editor-fold desc="定义数据集、模型路径"&gt;</span>
current_dir <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>dirname<span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>abspath<span class="token punctuation">(</span>__file__<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>current_dir<span class="token punctuation">)</span>
data_filedir <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>current_dir<span class="token punctuation">,</span> <span class="token string">'N-CMAPSS'</span><span class="token punctuation">)</span>    <span class="token comment"># os.path.join是拼接路径，可以传入多个路径</span>
data_filepath <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>current_dir<span class="token punctuation">,</span> <span class="token string">'N-CMAPSS'</span><span class="token punctuation">,</span> <span class="token string">'N-CMAPSS_DS02-006.h5'</span><span class="token punctuation">)</span>
sample_dir_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>data_filedir<span class="token punctuation">,</span> <span class="token string">'Samples_whole'</span><span class="token punctuation">)</span>

<span class="token comment">#定义要保存的模型</span>
<span class="token comment"># model_temp_path = os.path.join(current_dir, 'Models', 'oned_cnn_rep.h5')   #首先定义好模型名称和保存的路径</span>
model_temp_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>current_dir<span class="token punctuation">,</span> <span class="token string">'Models'</span><span class="token punctuation">,</span> <span class="token string">'CNNBranch_rep.h5'</span><span class="token punctuation">)</span>
tf_temp_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>current_dir<span class="token punctuation">,</span> <span class="token string">'TF_Model_tf'</span><span class="token punctuation">)</span>

pic_dir <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>current_dir<span class="token punctuation">,</span> <span class="token string">'Figures'</span><span class="token punctuation">)</span>  <span class="token comment"># 存训练损失 、学习率变化图</span>
<span class="token comment"># &lt;/editor-fold&gt;</span>


<span class="token keyword">def</span> <span class="token function">load_part_array</span> <span class="token punctuation">(</span>sample_dir_path<span class="token punctuation">,</span> unit_num<span class="token punctuation">,</span> win_len<span class="token punctuation">,</span> stride<span class="token punctuation">,</span> part_num<span class="token punctuation">)</span><span class="token punctuation">:</span>
    filename <span class="token operator">=</span>  <span class="token string">'Unit%s_win%s_str%s_part%s.npz'</span> <span class="token operator">%</span><span class="token punctuation">(</span><span class="token builtin">str</span><span class="token punctuation">(</span><span class="token builtin">int</span><span class="token punctuation">(</span>unit_num<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> win_len<span class="token punctuation">,</span> stride<span class="token punctuation">,</span> part_num<span class="token punctuation">)</span>
    filepath <span class="token operator">=</span>  os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>sample_dir_path<span class="token punctuation">,</span> filename<span class="token punctuation">)</span>
    loaded <span class="token operator">=</span> np<span class="token punctuation">.</span>load<span class="token punctuation">(</span>filepath<span class="token punctuation">)</span>
    <span class="token keyword">return</span> loaded<span class="token punctuation">[</span><span class="token string">'sample'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> loaded<span class="token punctuation">[</span><span class="token string">'label'</span><span class="token punctuation">]</span>

<span class="token triple-quoted-string string">'''
整理sample和label，转换成可训练的形状
'''</span>
<span class="token keyword">def</span> <span class="token function">load_part_array_merge</span> <span class="token punctuation">(</span>sample_dir_path<span class="token punctuation">,</span> unit_num<span class="token punctuation">,</span> win_len<span class="token punctuation">,</span> win_stride<span class="token punctuation">,</span> partition<span class="token punctuation">)</span><span class="token punctuation">:</span>
    sample_array_lst <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    label_array_lst <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token keyword">print</span> <span class="token punctuation">(</span><span class="token string">"Unit: "</span><span class="token punctuation">,</span> unit_num<span class="token punctuation">)</span>
    <span class="token keyword">for</span> part <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>partition<span class="token punctuation">)</span><span class="token punctuation">:</span>
      <span class="token keyword">print</span> <span class="token punctuation">(</span><span class="token string">"Part."</span><span class="token punctuation">,</span> part<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span>
      sample_array<span class="token punctuation">,</span> label_array <span class="token operator">=</span> load_part_array <span class="token punctuation">(</span>sample_dir_path<span class="token punctuation">,</span> unit_num<span class="token punctuation">,</span> win_len<span class="token punctuation">,</span> win_stride<span class="token punctuation">,</span> part<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span>
      sample_array_lst<span class="token punctuation">.</span>append<span class="token punctuation">(</span>sample_array<span class="token punctuation">)</span>
      label_array_lst<span class="token punctuation">.</span>append<span class="token punctuation">(</span>label_array<span class="token punctuation">)</span>
    sample_array <span class="token operator">=</span> np<span class="token punctuation">.</span>dstack<span class="token punctuation">(</span>sample_array_lst<span class="token punctuation">)</span>  <span class="token comment">#按深度方向拼接</span>
    label_array <span class="token operator">=</span> np<span class="token punctuation">.</span>concatenate<span class="token punctuation">(</span>label_array_lst<span class="token punctuation">)</span>
    sample_array <span class="token operator">=</span> sample_array<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span> <span class="token punctuation">(</span><span class="token string">"sample_array.shape"</span><span class="token punctuation">,</span> sample_array<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
    <span class="token keyword">print</span> <span class="token punctuation">(</span><span class="token string">"label_array.shape"</span><span class="token punctuation">,</span> label_array<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
    <span class="token keyword">return</span> sample_array<span class="token punctuation">,</span> label_array

<span class="token comment">#加载Samples_whole目录下的npz文件</span>
<span class="token keyword">def</span> <span class="token function">load_array</span> <span class="token punctuation">(</span>sample_dir_path<span class="token punctuation">,</span> unit_num<span class="token punctuation">,</span> win_len<span class="token punctuation">,</span> stride<span class="token punctuation">)</span><span class="token punctuation">:</span>
    filename <span class="token operator">=</span>  <span class="token string">'Unit%s_win%s_str%s_smp10.npz'</span> <span class="token operator">%</span><span class="token punctuation">(</span><span class="token builtin">str</span><span class="token punctuation">(</span><span class="token builtin">int</span><span class="token punctuation">(</span>unit_num<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> win_len<span class="token punctuation">,</span> stride<span class="token punctuation">)</span>
    filepath <span class="token operator">=</span>  os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>sample_dir_path<span class="token punctuation">,</span> filename<span class="token punctuation">)</span>
    loaded <span class="token operator">=</span> np<span class="token punctuation">.</span>load<span class="token punctuation">(</span>filepath<span class="token punctuation">)</span>

    <span class="token keyword">return</span> loaded<span class="token punctuation">[</span><span class="token string">'sample'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> loaded<span class="token punctuation">[</span><span class="token string">'label'</span><span class="token punctuation">]</span>    <span class="token comment">#为什么要transpose？</span>

<span class="token keyword">def</span> <span class="token function">rmse</span><span class="token punctuation">(</span>y_true<span class="token punctuation">,</span> y_pred<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> backend<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>backend<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>backend<span class="token punctuation">.</span>square<span class="token punctuation">(</span>y_pred <span class="token operator">-</span> y_true<span class="token punctuation">)</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment">#打乱窗口之间的顺序，防止过拟合</span>
<span class="token keyword">def</span> <span class="token function">shuffle_array</span><span class="token punctuation">(</span>sample_array<span class="token punctuation">,</span> label_array<span class="token punctuation">)</span><span class="token punctuation">:</span>
    ind_list <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span><span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>sample_array<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"ind_list befor: "</span><span class="token punctuation">,</span> ind_list<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">10</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"ind_list befor: "</span><span class="token punctuation">,</span> ind_list<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">10</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    ind_list <span class="token operator">=</span> shuffle<span class="token punctuation">(</span>ind_list<span class="token punctuation">)</span>  <span class="token comment">#随机排序</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"ind_list after: "</span><span class="token punctuation">,</span> ind_list<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">10</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"ind_list after: "</span><span class="token punctuation">,</span> ind_list<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">10</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Shuffeling in progress"</span><span class="token punctuation">)</span>
    shuffle_sample <span class="token operator">=</span> sample_array<span class="token punctuation">[</span>ind_list<span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span>
    shuffle_label <span class="token operator">=</span> label_array<span class="token punctuation">[</span>ind_list<span class="token punctuation">,</span><span class="token punctuation">]</span>
    <span class="token keyword">return</span> shuffle_sample<span class="token punctuation">,</span> shuffle_label

<span class="token comment">#绘制损失函数</span>
<span class="token keyword">def</span> <span class="token function">figsave</span><span class="token punctuation">(</span>history<span class="token punctuation">,</span> win_len<span class="token punctuation">,</span> win_stride<span class="token punctuation">,</span> bs<span class="token punctuation">,</span> lr<span class="token punctuation">,</span> sub<span class="token punctuation">)</span><span class="token punctuation">:</span>
    fig_acc <span class="token operator">=</span> plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">15</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>history<span class="token punctuation">.</span>history<span class="token punctuation">[</span><span class="token string">'loss'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>history<span class="token punctuation">.</span>history<span class="token punctuation">[</span><span class="token string">'val_loss'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'Training'</span><span class="token punctuation">,</span> fontsize<span class="token operator">=</span><span class="token number">24</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'loss'</span><span class="token punctuation">,</span> fontdict<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token string">'fontsize'</span><span class="token punctuation">:</span> <span class="token number">18</span><span class="token punctuation">}</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'epoch'</span><span class="token punctuation">,</span> fontdict<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token string">'fontsize'</span><span class="token punctuation">:</span> <span class="token number">18</span><span class="token punctuation">}</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'Training loss'</span><span class="token punctuation">,</span> <span class="token string">'Validation loss'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> loc<span class="token operator">=</span><span class="token string">'upper left'</span><span class="token punctuation">,</span> fontsize<span class="token operator">=</span><span class="token number">18</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span> <span class="token punctuation">(</span><span class="token string">"saving file:training loss figure"</span><span class="token punctuation">)</span>
    fig_acc<span class="token punctuation">.</span>savefig<span class="token punctuation">(</span>pic_dir <span class="token operator">+</span> <span class="token string">"/training_w%s_s%s_bs%s_sub%s_lr%s.png"</span> <span class="token operator">%</span><span class="token punctuation">(</span><span class="token builtin">int</span><span class="token punctuation">(</span>win_len<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token builtin">int</span><span class="token punctuation">(</span>win_stride<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token builtin">int</span><span class="token punctuation">(</span>bs<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token builtin">int</span><span class="token punctuation">(</span>sub<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token builtin">str</span><span class="token punctuation">(</span>lr<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span>


<span class="token comment"># 计算浮点运算次数</span>
<span class="token keyword">def</span> <span class="token function">get_flops</span><span class="token punctuation">(</span>model<span class="token punctuation">)</span><span class="token punctuation">:</span>
    concrete <span class="token operator">=</span> tf<span class="token punctuation">.</span>function<span class="token punctuation">(</span><span class="token keyword">lambda</span> inputs<span class="token punctuation">:</span> model<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span><span class="token punctuation">)</span>
    concrete_func <span class="token operator">=</span> concrete<span class="token punctuation">.</span>get_concrete_function<span class="token punctuation">(</span>
        <span class="token punctuation">[</span>tf<span class="token punctuation">.</span>TensorSpec<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">*</span>inputs<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token keyword">for</span> inputs <span class="token keyword">in</span> model<span class="token punctuation">.</span>inputs<span class="token punctuation">]</span><span class="token punctuation">)</span>
    frozen_func<span class="token punctuation">,</span> graph_def <span class="token operator">=</span> convert_variables_to_constants_v2_as_graph<span class="token punctuation">(</span>concrete_func<span class="token punctuation">)</span>
    <span class="token keyword">with</span> tf<span class="token punctuation">.</span>Graph<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>as_default<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">as</span> graph<span class="token punctuation">:</span>
        tf<span class="token punctuation">.</span>graph_util<span class="token punctuation">.</span>import_graph_def<span class="token punctuation">(</span>graph_def<span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">''</span><span class="token punctuation">)</span>
        run_meta <span class="token operator">=</span> tf<span class="token punctuation">.</span>compat<span class="token punctuation">.</span>v1<span class="token punctuation">.</span>RunMetadata<span class="token punctuation">(</span><span class="token punctuation">)</span>
        opts <span class="token operator">=</span> tf<span class="token punctuation">.</span>compat<span class="token punctuation">.</span>v1<span class="token punctuation">.</span>profiler<span class="token punctuation">.</span>ProfileOptionBuilder<span class="token punctuation">.</span>float_operation<span class="token punctuation">(</span><span class="token punctuation">)</span>
        flops <span class="token operator">=</span> tf<span class="token punctuation">.</span>compat<span class="token punctuation">.</span>v1<span class="token punctuation">.</span>profiler<span class="token punctuation">.</span>profile<span class="token punctuation">(</span>graph<span class="token operator">=</span>graph<span class="token punctuation">,</span> run_meta<span class="token operator">=</span>run_meta<span class="token punctuation">,</span> cmd<span class="token operator">=</span><span class="token string">"op"</span><span class="token punctuation">,</span> options<span class="token operator">=</span>opts<span class="token punctuation">)</span>
        <span class="token keyword">return</span> flops<span class="token punctuation">.</span>total_float_ops




<span class="token keyword">def</span> <span class="token function">scheduler</span><span class="token punctuation">(</span>epoch<span class="token punctuation">,</span> lr<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">if</span> epoch <span class="token operator">==</span> <span class="token number">30</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"lr decay by 10"</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> lr <span class="token operator">*</span> <span class="token number">0.1</span>
    <span class="token keyword">elif</span> epoch <span class="token operator">==</span> <span class="token number">70</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"lr decay by 10"</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> lr <span class="token operator">*</span> <span class="token number">0.1</span>
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> lr


<span class="token comment">#释放内存</span>
<span class="token keyword">def</span> <span class="token function">release_list</span><span class="token punctuation">(</span>a<span class="token punctuation">)</span><span class="token punctuation">:</span>
   <span class="token keyword">del</span> a<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">]</span>  <span class="token comment">#del a[:]会删除列表中的所有元素，但是不会删除列表a</span>
   <span class="token keyword">del</span> a

units_index_train <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">2.0</span><span class="token punctuation">,</span> <span class="token number">5.0</span><span class="token punctuation">,</span> <span class="token number">10.0</span><span class="token punctuation">,</span> <span class="token number">16.0</span><span class="token punctuation">,</span> <span class="token number">18.0</span><span class="token punctuation">,</span> <span class="token number">20.0</span><span class="token punctuation">]</span>
units_index_test <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">11.0</span><span class="token punctuation">,</span> <span class="token number">14.0</span><span class="token punctuation">,</span> <span class="token number">15.0</span><span class="token punctuation">]</span>



<span class="token keyword">def</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># current_dir = os.path.dirname(os.path.abspath(__file__))</span>
    parser <span class="token operator">=</span> argparse<span class="token punctuation">.</span>ArgumentParser<span class="token punctuation">(</span>description<span class="token operator">=</span><span class="token string">'sample creator'</span><span class="token punctuation">)</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'-w'</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">50</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'sequence length'</span><span class="token punctuation">,</span> required<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token comment">#滑窗长度</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'-s'</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'stride of filter'</span><span class="token punctuation">)</span>  <span class="token comment">#步长</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'-f'</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'number of filter'</span><span class="token punctuation">)</span>  <span class="token comment">#卷积核数量</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'-k'</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'size of kernel'</span><span class="token punctuation">)</span>    <span class="token comment">#卷积核大小</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'-bs'</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'batch size'</span><span class="token punctuation">)</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'-ep'</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">30</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'max epoch'</span><span class="token punctuation">)</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'-pt'</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">20</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'patience'</span><span class="token punctuation">)</span> <span class="token comment"># 相当于早停率</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'-vs'</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">float</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'validation split'</span><span class="token punctuation">)</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'-lr'</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">float</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">0.001</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'learning rate'</span><span class="token punctuation">)</span> <span class="token comment">#初试学习率</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'-sub'</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'subsampling stride'</span><span class="token punctuation">)</span> <span class="token comment">#重采样 取1/10</span>


    args <span class="token operator">=</span> parser<span class="token punctuation">.</span>parse_args<span class="token punctuation">(</span><span class="token punctuation">)</span>

    win_len <span class="token operator">=</span> args<span class="token punctuation">.</span>w   <span class="token comment">#滑窗长度</span>
    win_stride <span class="token operator">=</span> args<span class="token punctuation">.</span>s
    partition <span class="token operator">=</span> <span class="token number">3</span>
    n_filters <span class="token operator">=</span> args<span class="token punctuation">.</span>f
    kernel_size <span class="token operator">=</span> args<span class="token punctuation">.</span>k
    lr <span class="token operator">=</span> args<span class="token punctuation">.</span>lr
    bs <span class="token operator">=</span> args<span class="token punctuation">.</span>bs
    ep <span class="token operator">=</span> args<span class="token punctuation">.</span>ep
    pt <span class="token operator">=</span> args<span class="token punctuation">.</span>pt
    vs <span class="token operator">=</span> args<span class="token punctuation">.</span>vs
    sub <span class="token operator">=</span> args<span class="token punctuation">.</span>sub

    <span class="token comment"># beta_1 beta_2分别表示一阶、二阶矩估计的指数衰减率通常设为接近1的数</span>
    amsgrad <span class="token operator">=</span> optimizers<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>learning_rate<span class="token operator">=</span>lr<span class="token punctuation">,</span> beta_1<span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">,</span> beta_2<span class="token operator">=</span><span class="token number">0.999</span><span class="token punctuation">,</span> epsilon<span class="token operator">=</span><span class="token number">1e-07</span><span class="token punctuation">,</span> amsgrad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">'Adam'</span><span class="token punctuation">)</span>
    rmsop <span class="token operator">=</span> optimizers<span class="token punctuation">.</span>RMSprop<span class="token punctuation">(</span>learning_rate<span class="token operator">=</span>lr<span class="token punctuation">,</span> rho<span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">,</span> momentum<span class="token operator">=</span><span class="token number">0.0</span><span class="token punctuation">,</span> epsilon<span class="token operator">=</span><span class="token number">1e-07</span><span class="token punctuation">,</span> centered<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>
                               name<span class="token operator">=</span><span class="token string">'RMSprop'</span><span class="token punctuation">)</span>

    <span class="token comment">#训练集 sample、label</span>
    train_units_samples_lst <span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span>
    train_units_labels_lst <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>

    <span class="token keyword">for</span> index <span class="token keyword">in</span> units_index_train<span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Load data index: "</span><span class="token punctuation">,</span> index<span class="token punctuation">)</span>
        sample_array<span class="token punctuation">,</span> label_array <span class="token operator">=</span> load_array <span class="token punctuation">(</span>sample_dir_path<span class="token punctuation">,</span> index<span class="token punctuation">,</span> win_len<span class="token punctuation">,</span> win_stride<span class="token punctuation">)</span>
        <span class="token comment">#sample_array, label_array = shuffle_array(sample_array, label_array)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"sample_array.shape"</span><span class="token punctuation">,</span> sample_array<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"label_array.shape"</span><span class="token punctuation">,</span> label_array<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
        sample_array <span class="token operator">=</span> sample_array<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">:</span>sub<span class="token punctuation">]</span> <span class="token comment"># 以多少步长取数据 sub表示步长，如果是-1，就倒序取数，这里的sub为10，意思是隔10行取一条数据</span>
        label_array <span class="token operator">=</span> label_array<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">:</span>sub<span class="token punctuation">]</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"sub sample_array.shape"</span><span class="token punctuation">,</span> sample_array<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"sub label_array.shape"</span><span class="token punctuation">,</span> label_array<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
        train_units_samples_lst<span class="token punctuation">.</span>append<span class="token punctuation">(</span>sample_array<span class="token punctuation">)</span>
        train_units_labels_lst<span class="token punctuation">.</span>append<span class="token punctuation">(</span>label_array<span class="token punctuation">)</span>

    sample_array <span class="token operator">=</span> np<span class="token punctuation">.</span>concatenate<span class="token punctuation">(</span>train_units_samples_lst<span class="token punctuation">)</span>  <span class="token comment">#为了解决内存不足，在训练单元中每10次采样1次，相当于把训练集缩小10倍</span>
    label_array <span class="token operator">=</span> np<span class="token punctuation">.</span>concatenate<span class="token punctuation">(</span>train_units_labels_lst<span class="token punctuation">)</span>
    <span class="token keyword">print</span> <span class="token punctuation">(</span><span class="token string">"samples are aggregated"</span><span class="token punctuation">)</span>

    release_list<span class="token punctuation">(</span>train_units_samples_lst<span class="token punctuation">)</span>
    release_list<span class="token punctuation">(</span>train_units_labels_lst<span class="token punctuation">)</span>
    train_units_samples_lst <span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span>
    train_units_labels_lst <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Memory released"</span><span class="token punctuation">)</span>  <span class="token comment"># 释放内存</span>

    <span class="token comment">#sample_array, label_array = shuffle_array(sample_array, label_array)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"samples are shuffled"</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"sample_array.shape"</span><span class="token punctuation">,</span> sample_array<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"label_array.shape"</span><span class="token punctuation">,</span> label_array<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>

    <span class="token keyword">print</span> <span class="token punctuation">(</span><span class="token string">"train sample dtype"</span><span class="token punctuation">,</span> sample_array<span class="token punctuation">.</span>dtype<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"train label dtype"</span><span class="token punctuation">,</span> label_array<span class="token punctuation">.</span>dtype<span class="token punctuation">)</span>


    <span class="token comment"># input_temp = Input(shape=(sample_array.shape[1], sample_array.shape[2]),name='kernel_size%s' %str(int(kernel_size)))</span>
    <span class="token comment"># #------</span>
    <span class="token comment"># one_d_cnn = one_dcnn(n_filters, kernel_size, sample_array, initializer)</span>
    <span class="token comment"># cnn_out = one_d_cnn(input_temp)</span>
    <span class="token comment"># x = cnn_out</span>
    <span class="token comment"># # x = Dropout(0.5)(x)</span>
    <span class="token comment"># main_output = Dense(1, activation='linear', kernel_initializer=initializer, name='main_output')(x)</span>
    <span class="token comment"># one_d_cnn_model = Model(inputs=input_temp, outputs=main_output)</span>

    <span class="token comment"># model = Model(inputs=[input_1, input_2], outputs=main_output)</span>

    <span class="token comment"># &lt;editor-fold desc="调用模型"&gt;</span>
    <span class="token comment"># DCNN（深度卷积）网络</span>
    one_d_cnn_model <span class="token operator">=</span> one_dcnn<span class="token punctuation">(</span>n_filters<span class="token punctuation">,</span> kernel_size<span class="token punctuation">,</span> sample_array<span class="token punctuation">,</span> initializer<span class="token punctuation">)</span>

    <span class="token keyword">print</span><span class="token punctuation">(</span>one_d_cnn_model<span class="token punctuation">.</span>summary<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    one_d_cnn_model<span class="token punctuation">.</span><span class="token builtin">compile</span><span class="token punctuation">(</span>loss<span class="token operator">=</span><span class="token string">'mean_squared_error'</span><span class="token punctuation">,</span> optimizer<span class="token operator">=</span>amsgrad<span class="token punctuation">,</span> metrics<span class="token operator">=</span><span class="token punctuation">[</span>rmse<span class="token punctuation">,</span> <span class="token string">'mae'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

    <span class="token comment"># CNNBranch_model=CNNBranch(n_filters, win_len, 20,win_stride, kernel_size, 5)</span>
    <span class="token comment">#</span>
    <span class="token comment"># print(CNNBranch_model.summary())</span>

    start <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>

    lr_scheduler <span class="token operator">=</span> LearningRateScheduler<span class="token punctuation">(</span>scheduler<span class="token punctuation">)</span>

    <span class="token comment"># 模型训练</span>
    <span class="token triple-quoted-string string">'''
    此处保存最优模型到制定路径下面，并且提前命名.h5文件名称。
     save_best_only=True 只在模型被认为是目前最好时保存。如果 filepath 不包含格式化选项，例如 {epoch}，则新保存的更好模型将覆盖之前保存的模型。
    '''</span>
    one_d_cnn_model<span class="token punctuation">.</span><span class="token builtin">compile</span><span class="token punctuation">(</span>loss<span class="token operator">=</span><span class="token string">'mean_squared_error'</span><span class="token punctuation">,</span> optimizer<span class="token operator">=</span>amsgrad<span class="token punctuation">,</span> metrics<span class="token operator">=</span><span class="token string">'mae'</span><span class="token punctuation">)</span>
    history <span class="token operator">=</span> one_d_cnn_model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>sample_array<span class="token punctuation">,</span> label_array<span class="token punctuation">,</span> epochs<span class="token operator">=</span>ep<span class="token punctuation">,</span> batch_size<span class="token operator">=</span>bs<span class="token punctuation">,</span> validation_split<span class="token operator">=</span>vs<span class="token punctuation">,</span> verbose<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span>
                      callbacks <span class="token operator">=</span> <span class="token punctuation">[</span>EarlyStopping<span class="token punctuation">(</span>monitor<span class="token operator">=</span><span class="token string">'val_loss'</span><span class="token punctuation">,</span> min_delta<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> patience<span class="token operator">=</span>pt<span class="token punctuation">,</span> verbose<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> mode<span class="token operator">=</span><span class="token string">'min'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                    ModelCheckpoint<span class="token punctuation">(</span>model_temp_path<span class="token punctuation">,</span> monitor<span class="token operator">=</span><span class="token string">'val_loss'</span><span class="token punctuation">,</span> save_best_only<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> mode<span class="token operator">=</span><span class="token string">'min'</span><span class="token punctuation">,</span> verbose<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
                      <span class="token punctuation">)</span>


    <span class="token comment">#CNNBranch</span>
    <span class="token comment"># CNNBranch_model.compile(loss='mean_squared_error', optimizer=amsgrad, metrics='mae')</span>
    <span class="token comment"># history = CNNBranch_model.fit(sample_array, label_array, epochs=ep, batch_size=bs, validation_split=vs, verbose=2,</span>
    <span class="token comment">#                   callbacks = [EarlyStopping(monitor='val_loss', min_delta=0, patience=pt, verbose=1, mode='min'),</span>
    <span class="token comment">#                                 ModelCheckpoint(model_temp_path, monitor='val_loss', save_best_only=True, mode='min', verbose=1)]</span>
    <span class="token comment">#                   )</span>
    <span class="token comment"># &lt;/editor-fold&gt;</span>


    <span class="token comment"># TqdmCallback(verbose=2)</span>
    <span class="token comment"># one_d_cnn_model.save(tf_temp_path,save_format='tf')</span>
    figsave<span class="token punctuation">(</span>history<span class="token punctuation">,</span> win_len<span class="token punctuation">,</span> win_stride<span class="token punctuation">,</span> bs<span class="token punctuation">,</span> lr<span class="token punctuation">,</span> sub<span class="token punctuation">)</span>

   <span class="token comment">#FLOPs：注意s小写，是floating point operations的缩写（s表复数），意指浮点运算数，理解为计算量。可以用来衡量算法/模型的复杂度。</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"The FLOPs is:{}"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>get_flops<span class="token punctuation">(</span>one_d_cnn_model<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> flush<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    <span class="token comment"># print("The FLOPs is:{}".format(get_flops(CNNBranch_model)), flush=True)</span>
    num_train <span class="token operator">=</span> sample_array<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
    end <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>
    training_time <span class="token operator">=</span> end <span class="token operator">-</span> start
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Training time: "</span><span class="token punctuation">,</span> training_time<span class="token punctuation">)</span>


    <span class="token comment">### Test (inference after training)  测试集</span>
    start <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>

    output_lst <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    truth_lst <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>

    <span class="token keyword">for</span> index <span class="token keyword">in</span> units_index_test<span class="token punctuation">:</span>
        <span class="token keyword">print</span> <span class="token punctuation">(</span><span class="token string">"test idx: "</span><span class="token punctuation">,</span> index<span class="token punctuation">)</span>
        sample_array<span class="token punctuation">,</span> label_array <span class="token operator">=</span> load_array<span class="token punctuation">(</span>sample_dir_path<span class="token punctuation">,</span> index<span class="token punctuation">,</span> win_len<span class="token punctuation">,</span> win_stride<span class="token punctuation">)</span>
        <span class="token comment"># estimator = load_model(tf_temp_path, custom_objects={'rmse':rmse})</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"sample_array.shape"</span><span class="token punctuation">,</span> sample_array<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"label_array.shape"</span><span class="token punctuation">,</span> label_array<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
        sample_array <span class="token operator">=</span> sample_array<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">:</span>sub<span class="token punctuation">]</span>
        label_array <span class="token operator">=</span> label_array<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">:</span>sub<span class="token punctuation">]</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"sub sample_array.shape"</span><span class="token punctuation">,</span> sample_array<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"sub label_array.shape"</span><span class="token punctuation">,</span> label_array<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>

        estimator <span class="token operator">=</span> load_model<span class="token punctuation">(</span>model_temp_path<span class="token punctuation">)</span>  <span class="token comment">#加载训练好的最优模型</span>

        y_pred_test <span class="token operator">=</span> estimator<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>sample_array<span class="token punctuation">)</span>  <span class="token comment">#用训练好的模型对测试数据sample_array进行预测,输入：sample_array， 输出：RUL值</span>
        output_lst<span class="token punctuation">.</span>append<span class="token punctuation">(</span>y_pred_test<span class="token punctuation">)</span> <span class="token comment"># RUL预测值</span>
        truth_lst<span class="token punctuation">.</span>append<span class="token punctuation">(</span>label_array<span class="token punctuation">)</span>  <span class="token comment">#真实值</span>

    <span class="token keyword">print</span><span class="token punctuation">(</span>output_lst<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>truth_lst<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shape<span class="token punctuation">)</span>

    <span class="token keyword">print</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>concatenate<span class="token punctuation">(</span>output_lst<span class="token punctuation">)</span><span class="token punctuation">.</span>shape<span class="token punctuation">)</span> <span class="token comment">#合并三个测试发动机的RUL 一共12524行</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>concatenate<span class="token punctuation">(</span>truth_lst<span class="token punctuation">)</span><span class="token punctuation">.</span>shape<span class="token punctuation">)</span>

    output_array <span class="token operator">=</span> np<span class="token punctuation">.</span>concatenate<span class="token punctuation">(</span>output_lst<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span>
    trytg_array <span class="token operator">=</span> np<span class="token punctuation">.</span>concatenate<span class="token punctuation">(</span>truth_lst<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>output_array<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>trytg_array<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
    rms <span class="token operator">=</span> sqrt<span class="token punctuation">(</span>mean_squared_error<span class="token punctuation">(</span>output_array<span class="token punctuation">,</span> trytg_array<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment">#打印测试集的RMSE值</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>rms<span class="token punctuation">)</span>
    rms <span class="token operator">=</span> <span class="token builtin">round</span><span class="token punctuation">(</span>rms<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span> <span class="token comment">#保留两位小数</span>

    end <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>
    inference_time <span class="token operator">=</span> end <span class="token operator">-</span> start
    num_test <span class="token operator">=</span> output_array<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>  <span class="token comment">#测试集总单元数</span>

    <span class="token comment">#绘制测试集上的预测值与真实值分布图</span>
    <span class="token keyword">for</span> idx <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>units_index_test<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span>output_lst<span class="token punctuation">[</span>idx<span class="token punctuation">]</span><span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span>truth_lst<span class="token punctuation">[</span>idx<span class="token punctuation">]</span><span class="token punctuation">)</span>
        fig_verify <span class="token operator">=</span> plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">24</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>output_lst<span class="token punctuation">[</span>idx<span class="token punctuation">]</span><span class="token punctuation">,</span> color<span class="token operator">=</span><span class="token string">"green"</span><span class="token punctuation">)</span>
        plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>truth_lst<span class="token punctuation">[</span>idx<span class="token punctuation">]</span><span class="token punctuation">,</span> color<span class="token operator">=</span><span class="token string">"red"</span><span class="token punctuation">,</span> linewidth<span class="token operator">=</span><span class="token number">2.0</span><span class="token punctuation">)</span>
        plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'Unit%s inference'</span> <span class="token operator">%</span><span class="token builtin">str</span><span class="token punctuation">(</span><span class="token builtin">int</span><span class="token punctuation">(</span>units_index_test<span class="token punctuation">[</span>idx<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> fontsize<span class="token operator">=</span><span class="token number">30</span><span class="token punctuation">)</span>
        plt<span class="token punctuation">.</span>yticks<span class="token punctuation">(</span>fontsize<span class="token operator">=</span><span class="token number">20</span><span class="token punctuation">)</span>
        plt<span class="token punctuation">.</span>xticks<span class="token punctuation">(</span>fontsize<span class="token operator">=</span><span class="token number">20</span><span class="token punctuation">)</span>
        plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'RUL'</span><span class="token punctuation">,</span> fontdict<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token string">'fontsize'</span><span class="token punctuation">:</span> <span class="token number">24</span><span class="token punctuation">}</span><span class="token punctuation">)</span>
        plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'Timestamps'</span><span class="token punctuation">,</span> fontdict<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token string">'fontsize'</span><span class="token punctuation">:</span> <span class="token number">24</span><span class="token punctuation">}</span><span class="token punctuation">)</span>
        plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'Predicted'</span><span class="token punctuation">,</span> <span class="token string">'Truth'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> loc<span class="token operator">=</span><span class="token string">'upper right'</span><span class="token punctuation">,</span> fontsize<span class="token operator">=</span><span class="token number">28</span><span class="token punctuation">)</span>
        plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
        fig_verify<span class="token punctuation">.</span>savefig<span class="token punctuation">(</span>pic_dir <span class="token operator">+</span> <span class="token string">"/unit%s_test_w%s_s%s_bs%s_lr%s_sub%s_rmse-%s.png"</span> <span class="token operator">%</span><span class="token punctuation">(</span><span class="token builtin">str</span><span class="token punctuation">(</span><span class="token builtin">int</span><span class="token punctuation">(</span>units_index_test<span class="token punctuation">[</span>idx<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                                                              <span class="token builtin">int</span><span class="token punctuation">(</span>win_len<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token builtin">int</span><span class="token punctuation">(</span>win_stride<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token builtin">int</span><span class="token punctuation">(</span>bs<span class="token punctuation">)</span><span class="token punctuation">,</span>
                                                                                    <span class="token builtin">str</span><span class="token punctuation">(</span>lr<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token builtin">int</span><span class="token punctuation">(</span>sub<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token builtin">str</span><span class="token punctuation">(</span>rms<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"The FLOPs is:{}"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>get_flops<span class="token punctuation">(</span>one_d_cnn_model<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> flush<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span> <span class="token comment">#浮点运算数，理解为计算量。可以用来衡量算法/模型的复杂度</span>
    <span class="token comment"># print("The FLOPs is:{}".format(get_flops(CNNBranch_model)), flush=True)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"wind length_%s,  win stride_%s"</span> <span class="token operator">%</span><span class="token punctuation">(</span><span class="token builtin">str</span><span class="token punctuation">(</span>win_len<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token builtin">str</span><span class="token punctuation">(</span>win_stride<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"# Training samples: "</span><span class="token punctuation">,</span> num_train<span class="token punctuation">)</span> <span class="token comment">#训练集，6台发动机，共52608行数据</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"# Inference samples: "</span><span class="token punctuation">,</span> num_test<span class="token punctuation">)</span> <span class="token comment">#测试集，3台发动机，共12524 行数据</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Training time: "</span><span class="token punctuation">,</span> training_time<span class="token punctuation">)</span>  <span class="token comment">#训练时间</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Inference time: "</span><span class="token punctuation">,</span> inference_time<span class="token punctuation">)</span>  <span class="token comment">#预测时间</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Result in RMSE: "</span><span class="token punctuation">,</span> rms<span class="token punctuation">)</span>


<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>
    main<span class="token punctuation">(</span><span class="token punctuation">)</span>

</code></pre> 
<h6>
<a id="_859"></a>实验结果图</h6> 
<p><img src="https://images2.imgbox.com/af/d7/XqjvjjrW_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/1b/16/s0mJIp88_o.png" alt="unit11_test_w50_s1_bs256_lr0.001_sub10_rmse-5.78.png"></p>
                </div>
                
                

		</div>
	</article>
</main>




			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程小白.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://www.w3counter.com/tracker.js?id=150625"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>
	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>