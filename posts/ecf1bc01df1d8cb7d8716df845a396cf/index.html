<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<title>两万字讲解k8S监控利器Prometheus的使用 - 编程小白</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程小白" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程小白</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">两万字讲解k8S监控利器Prometheus的使用</h1>
			
		</header>
		<div class="content post__content clearfix">
			


                <div id="content_views" class="markdown_views prism-atom-one-dark">
                    
                        
                    
                    <h1>
<a id="Prometheus_1"></a>Prometheus的使用</h1> 
<p>本文参考阳明大佬的文章<br> 地址：https://www.qikqiak.com/k8strain/monitor/prometheus/#_5</p> 
<p></p>
<div class="toc">
 <h3>文章目录</h3>
 <ul>
<li><a href="#Prometheus_1">Prometheus的使用</a></li>
<li>
<ul>
<li><a href="#_10">一、简介</a></li>
<li><a href="#_34">二、安装</a></li>
<li><a href="#_36">三、使用</a></li>
<li>
<ul>
<li><a href="#31_37">3.1、应用监控</a></li>
<li><a href="#32_exporter__129">3.2、使用 exporter 监控</a></li>
<li><a href="#33_230">3.3、监控集群节点</a></li>
<li><a href="#34_353">3.4、服务发现</a></li>
<li><a href="#35_444">3.5、容器监控</a></li>
<li><a href="#36_apiserver_497">3.6、监控 apiserver</a></li>
<li><a href="#37_Pod_542">3.7、监控 Pod</a></li>
</ul>
  </li>
</ul>
 </li>
</ul>
</div>
<p></p> 
<p>我们知道监控是保证系统运行必不可少的功能，特别是对于 Kubernetes 这种比较庞大的系统来说，监控报警更是不可或缺，我们需要时刻了解系统的各种运行指标，也需要时刻了解我们的 Pod 的各种指标，更需要在出现问题的时候有报警信息通知到我们。</p> 
<p>在早期的版本中 Kubernetes 提供了 heapster、influxDB、grafana 的组合来监控系统，在现在的版本中已经移除掉了 heapster，现在更加流行的监控工具是 Prometheus，Prometheus 是 Google 内部监控报警系统的开源版本，是 Google SRE 思想在其内部不断完善的产物，它的存在是为了更快和高效的发现问题，快速的接入速度，简单灵活的配置都很好的解决了这一切，而且是已经毕业的 CNCF 项目。</p> 
<h2>
<a id="_10"></a>一、简介</h2> 
<p>Prometheus 最初是 SoundCloud 构建的开源系统监控和报警工具，是一个独立的开源项目，于2016年加入了 CNCF 基金会，作为继 Kubernetes 之后的第二个托管项目。Prometheus 相比于其他传统监控工具主要有以下几个特点：</p> 
<ol>
<li>具有由 metric 名称和键/值对标识的时间序列数据的多维数据模型</li>
<li>有一个灵活的查询语言</li>
<li>不依赖分布式存储，只和本地磁盘有关</li>
<li>通过 HTTP 的服务拉取时间序列数据</li>
<li>也支持推送的方式来添加时间序列数据</li>
<li>还支持通过服务发现或静态配置发现目标</li>
<li>多种图形和仪表板支持</li>
</ol> 
<p>Prometheus 由多个组件组成，但是其中有些组件是可选的：</p> 
<ul>
<li>Prometheus Server：用于抓取指标、存储时间序列数据</li>
<li>exporter：暴露指标让任务来抓</li>
<li>pushgateway：push 的方式将指标数据推送到该网关</li>
<li>alertmanager：处理报警的报警组件 adhoc：用于数据查询<br> 大多数 Prometheus 组件都是用 Go 编写的，因此很容易构建和部署为静态的二进制文件。下图是 Prometheus 官方提供的架构及其一些相关的生态系统组件：</li>
</ul> 
<p><img src="https://images2.imgbox.com/79/39/Y4ucBl8G_o.png" alt="在这里插入图片描述"></p> 
<p>整体流程比较简单，Prometheus 直接接收或者通过中间的 Pushgateway 网关被动获取指标数据，在本地存储所有的获取的指标数据，并对这些数据进行一些规则整理，用来生成一些聚合数据或者报警信息，Grafana 或者其他工具用来可视化这些数据。</p> 
<h2>
<a id="_34"></a>二、安装</h2> 
<p>关于安装请参考我之前的文章：<a href="https://blog.csdn.net/weixin_43143310/article/details/119711207?spm=1001.2014.3001.5502">八步安装K8S普罗米修斯</a></p> 
<h2>
<a id="_36"></a>三、使用</h2> 
<h3>
<a id="31_37"></a>3.1、应用监控</h3> 
<p>对于普通应用只需要能够提供一个满足 prometheus 格式要求的 /metrics 接口就可以让 Prometheus 来接管监控，比如 Kubernetes 集群中非常重要的 CoreDNS 插件，一般默认情况下就开启了 /metrics 接口：</p> 
<pre><code class="prism language-yaml">$ kubectl get cm coredns <span class="token punctuation">-</span>n kube<span class="token punctuation">-</span>system <span class="token punctuation">-</span>o yaml
<span class="token key atrule">apiVersion</span><span class="token punctuation">:</span> v1
<span class="token key atrule">data</span><span class="token punctuation">:</span>
  <span class="token key atrule">Corefile</span><span class="token punctuation">:</span> <span class="token punctuation">|</span><span class="token scalar string">
    .:53 {
        errors
        health
        ready
        kubernetes cluster.local in-addr.arpa ip6.arpa {
           pods insecure
           fallthrough in-addr.arpa ip6.arpa
           ttl 30
        }
        prometheus :9153
        forward . /etc/resolv.conf
        cache 30
        loop
        reload
        loadbalance
    }</span>
<span class="token key atrule">kind</span><span class="token punctuation">:</span> ConfigMap
<span class="token key atrule">metadata</span><span class="token punctuation">:</span>
  <span class="token key atrule">creationTimestamp</span><span class="token punctuation">:</span> <span class="token string">"2019-11-08T11:59:49Z"</span>
  <span class="token key atrule">name</span><span class="token punctuation">:</span> coredns
  <span class="token key atrule">namespace</span><span class="token punctuation">:</span> kube<span class="token punctuation">-</span>system
  <span class="token key atrule">resourceVersion</span><span class="token punctuation">:</span> <span class="token string">"188"</span>
  <span class="token key atrule">selfLink</span><span class="token punctuation">:</span> /api/v1/namespaces/kube<span class="token punctuation">-</span>system/configmaps/coredns
  <span class="token key atrule">uid</span><span class="token punctuation">:</span> 21966186<span class="token punctuation">-</span>c2d9<span class="token punctuation">-</span>467a<span class="token punctuation">-</span>b87f<span class="token punctuation">-</span>d061c5c9e4d7
</code></pre> 
<p>上面 ConfigMap 中 prometheus :9153 就是开启 prometheus 的插件：<br> 我们可以先尝试手动访问下 /metrics 接口，如果能够手动访问到那证明接口是没有任何问题的：</p> 
<pre><code class="prism language-yaml">$ curl http<span class="token punctuation">:</span>//10.244.1.15<span class="token punctuation">:</span>9153/metrics
<span class="token comment"># HELP coredns_build_info A metric with a constant '1' value labeled by version, revision, and goversion from which CoreDNS was built.</span>
<span class="token comment"># TYPE coredns_build_info gauge</span>
coredns_build_info<span class="token punctuation">{<!-- --></span>goversion="go1.12.8"<span class="token punctuation">,</span>revision="795a3eb"<span class="token punctuation">,</span>version="1.6.2"<span class="token punctuation">}</span> 1
<span class="token comment"># HELP coredns_cache_hits_total The count of cache hits.</span>
<span class="token comment"># TYPE coredns_cache_hits_total counter</span>
coredns_cache_hits_total<span class="token punctuation">{<!-- --></span>server="dns<span class="token punctuation">:</span>//<span class="token punctuation">:</span>53"<span class="token punctuation">,</span>type="success"<span class="token punctuation">}</span> 4
<span class="token comment"># HELP coredns_cache_misses_total The count of cache misses.</span>
<span class="token comment"># TYPE coredns_cache_misses_total counter</span>
coredns_cache_misses_total<span class="token punctuation">{<!-- --></span>server="dns<span class="token punctuation">:</span>//<span class="token punctuation">:</span>53"<span class="token punctuation">}</span> 15
<span class="token comment"># HELP coredns_cache_size The number of elements in the cache.</span>
<span class="token comment"># TYPE coredns_cache_size gauge</span>
coredns_cache_size<span class="token punctuation">{<!-- --></span>server="dns<span class="token punctuation">:</span>//<span class="token punctuation">:</span>53"<span class="token punctuation">,</span>type="denial"<span class="token punctuation">}</span> 5
coredns_cache_size<span class="token punctuation">{<!-- --></span>server="dns<span class="token punctuation">:</span>//<span class="token punctuation">:</span>53"<span class="token punctuation">,</span>type="success"<span class="token punctuation">}</span> 4
<span class="token punctuation">...</span><span class="token punctuation">...</span>
</code></pre> 
<p>我们可以看到可以正常访问到，从这里可以看到 CoreDNS 的监控数据接口是正常的了，然后我们就可以将这个 /metrics 接口配置到 prometheus.yml 中去了，直接加到默认的 prometheus 这个 job 下面：(prome-cm.yaml)</p> 
<pre><code class="prism language-yaml"><span class="token key atrule">apiVersion</span><span class="token punctuation">:</span> v1
<span class="token key atrule">kind</span><span class="token punctuation">:</span> ConfigMap
<span class="token key atrule">metadata</span><span class="token punctuation">:</span>
  <span class="token key atrule">name</span><span class="token punctuation">:</span> prometheus<span class="token punctuation">-</span>config
  <span class="token key atrule">namespace</span><span class="token punctuation">:</span> kube<span class="token punctuation">-</span>mon
<span class="token key atrule">data</span><span class="token punctuation">:</span>
  <span class="token key atrule">prometheus.yml</span><span class="token punctuation">:</span> <span class="token punctuation">|</span><span class="token scalar string">
    global:
      scrape_interval: 15s
      scrape_timeout: 15s</span>

    <span class="token key atrule">scrape_configs</span><span class="token punctuation">:</span>
    <span class="token punctuation">-</span> <span class="token key atrule">job_name</span><span class="token punctuation">:</span> <span class="token string">'prometheus'</span>
      <span class="token key atrule">static_configs</span><span class="token punctuation">:</span>
        <span class="token punctuation">-</span> <span class="token key atrule">targets</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">'localhost:9090'</span><span class="token punctuation">]</span>

    <span class="token punctuation">-</span> <span class="token key atrule">job_name</span><span class="token punctuation">:</span> <span class="token string">'coredns'</span>
      <span class="token key atrule">static_configs</span><span class="token punctuation">:</span>
        <span class="token punctuation">-</span> <span class="token key atrule">targets</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">'10.244.1.15:9153'</span><span class="token punctuation">,</span> <span class="token string">'10.244.2.127:9153'</span><span class="token punctuation">]</span>
</code></pre> 
<p>现在我们重新更新这个 ConfigMap 资源对象：</p> 
<pre><code class="prism language-shell">$ kubectl apply -f prometheus-cm.yaml
configmap/prometheus-config configured
</code></pre> 
<p>现在 Prometheus 的配置文件内容已经更改了，隔一会儿被挂载到 Pod 中的 prometheus.yml 文件也会更新，由于我们之前的 Prometheus 启动参数中添加了 --web.enable-lifecycle 参数，所以现在我们只需要执行一个 reload 命令即可让配置生效：</p> 
<pre><code class="prism language-shell">$ kubectl get pods -n kube-mon -o wide
NAME                          READY   STATUS    RESTARTS   AGE   IP             NODE         NOMINATED NODE   READINESS GATES
prometheus-79b8774f68-7m8zr   <span class="token number">1</span>/1     Running   <span class="token number">0</span>          28m   <span class="token number">10.244</span>.3.174   ydzs-node3   <span class="token operator">&lt;</span>none<span class="token operator">&gt;</span>           <span class="token operator">&lt;</span>none<span class="token operator">&gt;</span>
$ <span class="token function">curl</span> -X POST <span class="token string">"http://10.244.3.174:9090/-/reload"</span>
</code></pre> 
<blockquote> 
 <p>热更新：由于 ConfigMap 通过 Volume 的形式挂载到 Pod 中去的热更新需要一定的间隔时间才会生效，所以需要稍微等一小会儿。</p> 
</blockquote> 
<p>这个时候我们再去看 Prometheus 的 Dashboard 中查看采集的目标数据：<br> <img src="https://images2.imgbox.com/03/3a/sPeRF7wd_o.png" alt="在这里插入图片描述"></p> 
<p>到这里我们就在 Prometheus 上配置了第一个 Kubernetes 应用。</p> 
<h3>
<a id="32_exporter__129"></a>3.2、使用 exporter 监控</h3> 
<p>上面我们也说过有一些应用可能没有自带 /metrics 接口供 Prometheus 使用，在这种情况下，我们就需要利用 exporter 服务来为 Prometheus 提供指标数据了。Prometheus 官方为许多应用就提供了对应的 exporter 应用，也有许多第三方的实现，我们可以前往官方网站进行查看：exporters，当然如果你的应用本身也没有 exporter 实现，那么就要我们自己想办法去实现一个 /metrics 接口了，只要你能提供一个合法的 /metrics 接口，Prometheus 就可以监控你的应用。</p> 
<p>比如我们这里通过一个 redis-exporter 的服务来监控 redis 服务，对于这类应用，我们一般会以 sidecar 的形式和主应用部署在同一个 Pod 中，比如我们这里来部署一个 redis 应用，并用 redis-exporter 的方式来采集监控数据供 Prometheus 使用，如下资源清单文件：（prome-redis.yaml）</p> 
<pre><code class="prism language-yaml"><span class="token key atrule">apiVersion</span><span class="token punctuation">:</span> apps/v1
<span class="token key atrule">kind</span><span class="token punctuation">:</span> Deployment
<span class="token key atrule">metadata</span><span class="token punctuation">:</span>
  <span class="token key atrule">name</span><span class="token punctuation">:</span> redis
  <span class="token key atrule">namespace</span><span class="token punctuation">:</span> kube<span class="token punctuation">-</span>mon
<span class="token key atrule">spec</span><span class="token punctuation">:</span>
  <span class="token key atrule">selector</span><span class="token punctuation">:</span>
    <span class="token key atrule">matchLabels</span><span class="token punctuation">:</span>
      <span class="token key atrule">app</span><span class="token punctuation">:</span> redis
  <span class="token key atrule">template</span><span class="token punctuation">:</span>
    <span class="token key atrule">metadata</span><span class="token punctuation">:</span>
      <span class="token key atrule">annotations</span><span class="token punctuation">:</span>
        <span class="token key atrule">prometheus.io/scrape</span><span class="token punctuation">:</span> <span class="token string">"true"</span>
        <span class="token key atrule">prometheus.io/port</span><span class="token punctuation">:</span> <span class="token string">"9121"</span>
      <span class="token key atrule">labels</span><span class="token punctuation">:</span>
        <span class="token key atrule">app</span><span class="token punctuation">:</span> redis
    <span class="token key atrule">spec</span><span class="token punctuation">:</span>
      <span class="token key atrule">containers</span><span class="token punctuation">:</span>
      <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> redis
        <span class="token key atrule">image</span><span class="token punctuation">:</span> redis<span class="token punctuation">:</span><span class="token number">4</span>
        <span class="token key atrule">resources</span><span class="token punctuation">:</span>
          <span class="token key atrule">requests</span><span class="token punctuation">:</span>
            <span class="token key atrule">cpu</span><span class="token punctuation">:</span> 100m
            <span class="token key atrule">memory</span><span class="token punctuation">:</span> 100Mi
        <span class="token key atrule">ports</span><span class="token punctuation">:</span>
        <span class="token punctuation">-</span> <span class="token key atrule">containerPort</span><span class="token punctuation">:</span> <span class="token number">6379</span>
      <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> redis<span class="token punctuation">-</span>exporter
        <span class="token key atrule">image</span><span class="token punctuation">:</span> oliver006/redis_exporter<span class="token punctuation">:</span>latest
        <span class="token key atrule">resources</span><span class="token punctuation">:</span>
          <span class="token key atrule">requests</span><span class="token punctuation">:</span>
            <span class="token key atrule">cpu</span><span class="token punctuation">:</span> 100m
            <span class="token key atrule">memory</span><span class="token punctuation">:</span> 100Mi
        <span class="token key atrule">ports</span><span class="token punctuation">:</span>
        <span class="token punctuation">-</span> <span class="token key atrule">containerPort</span><span class="token punctuation">:</span> <span class="token number">9121</span>
<span class="token punctuation">---</span>
<span class="token key atrule">kind</span><span class="token punctuation">:</span> Service
<span class="token key atrule">apiVersion</span><span class="token punctuation">:</span> v1
<span class="token key atrule">metadata</span><span class="token punctuation">:</span>
  <span class="token key atrule">name</span><span class="token punctuation">:</span> redis
  <span class="token key atrule">namespace</span><span class="token punctuation">:</span> kube<span class="token punctuation">-</span>mon
<span class="token key atrule">spec</span><span class="token punctuation">:</span>
  <span class="token key atrule">selector</span><span class="token punctuation">:</span>
    <span class="token key atrule">app</span><span class="token punctuation">:</span> redis
  <span class="token key atrule">ports</span><span class="token punctuation">:</span>
  <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> redis
    <span class="token key atrule">port</span><span class="token punctuation">:</span> <span class="token number">6379</span>
    <span class="token key atrule">targetPort</span><span class="token punctuation">:</span> <span class="token number">6379</span>
  <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> prom
    <span class="token key atrule">port</span><span class="token punctuation">:</span> <span class="token number">9121</span>
    <span class="token key atrule">targetPort</span><span class="token punctuation">:</span> <span class="token number">9121</span>
</code></pre> 
<p>可以看到上面我们在 redis 这个 Pod 中包含了两个容器，一个就是 redis 本身的主应用，另外一个容器就是 redis_exporter。现在直接创建上面的应用：</p> 
<pre><code class="prism language-shell">$ kubectl apply -f prome-redis.yaml
deployment.apps/redis created
service/redis created
</code></pre> 
<p>创建完成后，我们可以看到 redis 的 Pod 里面包含有两个容器：</p> 
<pre><code class="prism language-shell">$ kubectl get pods -n kube-mon
NAME                          READY   STATUS    RESTARTS   AGE
prometheus-79b8774f68-7m8zr   <span class="token number">1</span>/1     Running   <span class="token number">0</span>          54m
redis-7c8bdd45cc-ssjbz        <span class="token number">2</span>/2     Running   <span class="token number">0</span>          2m1s
$ kubectl get svc -n kube-mon
NAME         TYPE        CLUSTER-IP     EXTERNAL-IP   PORT<span class="token punctuation">(</span>S<span class="token punctuation">)</span>             AGE
prometheus   NodePort    <span class="token number">10.96</span>.194.29   <span class="token operator">&lt;</span>none<span class="token operator">&gt;</span>        <span class="token number">9090</span>:30980/TCP      15h
redis        ClusterIP   <span class="token number">10.110</span>.14.69   <span class="token operator">&lt;</span>none<span class="token operator">&gt;</span>        <span class="token number">6379</span>/TCP,9121/TCP   2m14s
</code></pre> 
<p>我们访问测试一下：</p> 
<pre><code class="prism language-shell">$ <span class="token function">curl</span> <span class="token number">10.110</span>.14.69:9121/metrics
<span class="token comment"># HELP go_gc_duration_seconds A summary of the GC invocation durations.</span>
<span class="token comment"># TYPE go_gc_duration_seconds summary</span>
go_gc_duration_seconds<span class="token punctuation">{<!-- --></span>quantile<span class="token operator">=</span><span class="token string">"0"</span><span class="token punctuation">}</span> <span class="token number">0</span>
go_gc_duration_seconds<span class="token punctuation">{<!-- --></span>quantile<span class="token operator">=</span><span class="token string">"0.25"</span><span class="token punctuation">}</span> <span class="token number">0</span>
go_gc_duration_seconds<span class="token punctuation">{<!-- --></span>quantile<span class="token operator">=</span><span class="token string">"0.5"</span><span class="token punctuation">}</span> <span class="token number">0</span>
go_gc_duration_seconds<span class="token punctuation">{<!-- --></span>quantile<span class="token operator">=</span><span class="token string">"0.75"</span><span class="token punctuation">}</span> <span class="token number">0</span>
go_gc_duration_seconds<span class="token punctuation">{<!-- --></span>quantile<span class="token operator">=</span><span class="token string">"1"</span><span class="token punctuation">}</span> <span class="token number">0</span>
go_gc_duration_seconds_sum <span class="token number">0</span>
go_gc_duration_seconds_count <span class="token number">0</span>
<span class="token punctuation">..</span><span class="token punctuation">..</span><span class="token punctuation">..</span>
<span class="token comment"># HELP redis_up Information about the Redis instance</span>
<span class="token comment"># TYPE redis_up gauge</span>
redis_up <span class="token number">1</span>
<span class="token comment"># HELP redis_uptime_in_seconds uptime_in_seconds metric</span>
<span class="token comment"># TYPE redis_uptime_in_seconds gauge</span>
redis_uptime_in_seconds <span class="token number">100</span>
</code></pre> 
<p>同样的，现在我们只需要更新 Prometheus 的配置文件：</p> 
<pre><code class="prism language-yaml"><span class="token punctuation">-</span> <span class="token key atrule">job_name</span><span class="token punctuation">:</span> <span class="token string">'redis'</span>
  <span class="token key atrule">static_configs</span><span class="token punctuation">:</span>
  <span class="token punctuation">-</span> <span class="token key atrule">targets</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">'redis:9121'</span><span class="token punctuation">]</span>
</code></pre> 
<p>由于我们这里是通过 Service 去配置的 redis 服务，当然直接配置 Pod IP 也是可以的，因为和 Prometheus 处于同一个 namespace，所以我们直接使用 servicename 即可。配置文件更新后，重新加载</p> 
<h3>
<a id="33_230"></a>3.3、监控集群节点</h3> 
<p>前面我们和大家学习了怎样用 Promethues 来监控 Kubernetes 集群中的应用，但是对于 Kubernetes 集群本身的监控也是非常重要的，我们需要时时刻刻了解集群的运行状态。</p> 
<p>对于集群的监控一般我们需要考虑以下几个方面：</p> 
<ul>
<li> <p>Kubernetes 节点的监控：比如节点的 cpu、load、disk、memory 等指标</p> </li>
<li> <p>内部系统组件的状态：比如 kube-scheduler、kube-controller-manager、- kubedns/coredns 等组件的详细运行状态</p> </li>
<li> <p>编排级的 metrics：比如 Deployment 的状态、资源请求、调度和 API 延迟等数据指标<br> Kubernetes 集群的监控方案目前主要有以下几种方案：</p> </li>
<li> <p>Heapster：Heapster 是一个集群范围的监控和数据聚合工具，以 Pod 的形式运行在集群中。 heapster 除了 Kubelet/cAdvisor 之外，我们还可以向 Heapster 添加其他指标源数据，比如 kube-state-metrics，需要注意的是 Heapster 已经被废弃了，后续版本中会使用 metrics-server 代替。</p> </li>
<li> <p>cAdvisor：cAdvisor 是 Google 开源的容器资源监控和性能分析工具，它是专门为容器而生，本身也支持 Docker 容器。</p> </li>
<li> <p>kube-state-metrics：kube-state-metrics 通过监听 API Server 生成有关资源对象的状态指标，比如 Deployment、Node、Pod，需要注意的是 kube-state-metrics 只是简单提供一个 metrics 数据，并不会存储这些指标数据，所以我们可以使用 Prometheus 来抓取这些数据然后存储。</p> </li>
<li> <p>metrics-server：metrics-server 也是一个集群范围内的资源数据聚合工具，是 Heapster 的替代品，同样的，metrics-server 也只是显示数据，并不提供数据存储服务。<br> 不过 kube-state-metrics 和 metrics-server 之间还是有很大不同的，二者的主要区别如下：</p> </li>
</ul> 
<p>kube-state-metrics 主要关注的是业务相关的一些元数据，比如 Deployment、Pod、副本状态等<br> metrics-server 主要关注的是资源度量 API 的实现，比如 CPU、文件描述符、内存、请求延时等指标。</p> 
<p>监控节点其实我们已经有很多非常成熟的方案了，比如 Nagios、zabbix，甚至我们自己来收集数据也可以，我们这里通过 Prometheus 来采集节点的监控指标数据，可以通过 node_exporter 来获取，顾名思义，node_exporter 就是抓取用于采集服务器节点的各种运行指标，目前 node_exporter 支持几乎所有常见的监控点，比如 conntrack，cpu，diskstats，filesystem，loadavg，meminfo，netstat 等，详细的监控点列表可以参考其 Github 仓库。</p> 
<p>我们可以通过 DaemonSet 控制器来部署该服务，这样每一个节点都会自动运行一个这样的 Pod，如果我们从集群中删除或者添加节点后，也会进行自动扩展。</p> 
<p>在部署 node-exporter 的时候有一些细节需要注意，如下资源清单文件：(prome-node-exporter.yaml)</p> 
<pre><code class="prism language-yaml"><span class="token key atrule">apiVersion</span><span class="token punctuation">:</span> apps/v1
<span class="token key atrule">kind</span><span class="token punctuation">:</span> DaemonSet
<span class="token key atrule">metadata</span><span class="token punctuation">:</span>
  <span class="token key atrule">name</span><span class="token punctuation">:</span> node<span class="token punctuation">-</span>exporter
  <span class="token key atrule">namespace</span><span class="token punctuation">:</span> kube<span class="token punctuation">-</span>mon
  <span class="token key atrule">labels</span><span class="token punctuation">:</span>
    <span class="token key atrule">app</span><span class="token punctuation">:</span> node<span class="token punctuation">-</span>exporter
<span class="token key atrule">spec</span><span class="token punctuation">:</span>
  <span class="token key atrule">selector</span><span class="token punctuation">:</span>
    <span class="token key atrule">matchLabels</span><span class="token punctuation">:</span>
      <span class="token key atrule">app</span><span class="token punctuation">:</span> node<span class="token punctuation">-</span>exporter
  <span class="token key atrule">template</span><span class="token punctuation">:</span>
    <span class="token key atrule">metadata</span><span class="token punctuation">:</span>
      <span class="token key atrule">labels</span><span class="token punctuation">:</span>
        <span class="token key atrule">app</span><span class="token punctuation">:</span> node<span class="token punctuation">-</span>exporter
    <span class="token key atrule">spec</span><span class="token punctuation">:</span>
      <span class="token key atrule">hostPID</span><span class="token punctuation">:</span> <span class="token boolean important">true</span>
      <span class="token key atrule">hostIPC</span><span class="token punctuation">:</span> <span class="token boolean important">true</span>
      <span class="token key atrule">hostNetwork</span><span class="token punctuation">:</span> <span class="token boolean important">true</span>
      <span class="token key atrule">nodeSelector</span><span class="token punctuation">:</span>
        <span class="token key atrule">kubernetes.io/os</span><span class="token punctuation">:</span> linux
      <span class="token key atrule">containers</span><span class="token punctuation">:</span>
      <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> node<span class="token punctuation">-</span>exporter
        <span class="token key atrule">image</span><span class="token punctuation">:</span> prom/node<span class="token punctuation">-</span>exporter<span class="token punctuation">:</span>v0.18.1
        <span class="token key atrule">args</span><span class="token punctuation">:</span>
        <span class="token punctuation">-</span> <span class="token punctuation">-</span><span class="token punctuation">-</span>web.listen<span class="token punctuation">-</span>address=$(HOSTIP)<span class="token punctuation">:</span><span class="token number">9100</span>
        <span class="token punctuation">-</span> <span class="token punctuation">-</span><span class="token punctuation">-</span>path.procfs=/host/proc
        <span class="token punctuation">-</span> <span class="token punctuation">-</span><span class="token punctuation">-</span>path.sysfs=/host/sys
        <span class="token punctuation">-</span> <span class="token punctuation">-</span><span class="token punctuation">-</span>path.rootfs=/host/root
        <span class="token punctuation">-</span> <span class="token punctuation">-</span><span class="token punctuation">-</span>collector.filesystem.ignored<span class="token punctuation">-</span>mount<span class="token punctuation">-</span>points=^/(dev<span class="token punctuation">|</span>proc<span class="token punctuation">|</span>sys<span class="token punctuation">|</span>var/lib/docker/.+)($<span class="token punctuation">|</span>/)
        <span class="token punctuation">-</span> <span class="token punctuation">-</span><span class="token punctuation">-</span>collector.filesystem.ignored<span class="token punctuation">-</span>fs<span class="token punctuation">-</span>types=^(autofs<span class="token punctuation">|</span>binfmt_misc<span class="token punctuation">|</span>cgroup<span class="token punctuation">|</span>configfs<span class="token punctuation">|</span>debugfs<span class="token punctuation">|</span>devpts<span class="token punctuation">|</span>devtmpfs<span class="token punctuation">|</span>fusectl<span class="token punctuation">|</span>hugetlbfs<span class="token punctuation">|</span>mqueue<span class="token punctuation">|</span>overlay<span class="token punctuation">|</span>proc<span class="token punctuation">|</span>procfs<span class="token punctuation">|</span>pstore<span class="token punctuation">|</span>rpc_pipefs<span class="token punctuation">|</span>securityfs<span class="token punctuation">|</span>sysfs<span class="token punctuation">|</span>tracefs)$
        <span class="token key atrule">ports</span><span class="token punctuation">:</span>
        <span class="token punctuation">-</span> <span class="token key atrule">containerPort</span><span class="token punctuation">:</span> <span class="token number">9100</span>
        <span class="token key atrule">env</span><span class="token punctuation">:</span>
        <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> HOSTIP
          <span class="token key atrule">valueFrom</span><span class="token punctuation">:</span>
            <span class="token key atrule">fieldRef</span><span class="token punctuation">:</span>
              <span class="token key atrule">fieldPath</span><span class="token punctuation">:</span> status.hostIP
        <span class="token key atrule">resources</span><span class="token punctuation">:</span>
          <span class="token key atrule">requests</span><span class="token punctuation">:</span>
            <span class="token key atrule">cpu</span><span class="token punctuation">:</span> 150m
            <span class="token key atrule">memory</span><span class="token punctuation">:</span> 180Mi
          <span class="token key atrule">limits</span><span class="token punctuation">:</span>
            <span class="token key atrule">cpu</span><span class="token punctuation">:</span> 150m
            <span class="token key atrule">memory</span><span class="token punctuation">:</span> 180Mi
        <span class="token key atrule">securityContext</span><span class="token punctuation">:</span>
          <span class="token key atrule">runAsNonRoot</span><span class="token punctuation">:</span> <span class="token boolean important">true</span>
          <span class="token key atrule">runAsUser</span><span class="token punctuation">:</span> <span class="token number">65534</span>
        <span class="token key atrule">volumeMounts</span><span class="token punctuation">:</span>
        <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> proc
          <span class="token key atrule">mountPath</span><span class="token punctuation">:</span> /host/proc
        <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> sys
          <span class="token key atrule">mountPath</span><span class="token punctuation">:</span> /host/sys
        <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> root
          <span class="token key atrule">mountPath</span><span class="token punctuation">:</span> /host/root
          <span class="token key atrule">mountPropagation</span><span class="token punctuation">:</span> HostToContainer
          <span class="token key atrule">readOnly</span><span class="token punctuation">:</span> <span class="token boolean important">true</span>
      <span class="token key atrule">tolerations</span><span class="token punctuation">:</span>
      <span class="token punctuation">-</span> <span class="token key atrule">operator</span><span class="token punctuation">:</span> <span class="token string">"Exists"</span>
      <span class="token key atrule">volumes</span><span class="token punctuation">:</span>
      <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> proc
        <span class="token key atrule">hostPath</span><span class="token punctuation">:</span>
          <span class="token key atrule">path</span><span class="token punctuation">:</span> /proc
      <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> dev
        <span class="token key atrule">hostPath</span><span class="token punctuation">:</span>
          <span class="token key atrule">path</span><span class="token punctuation">:</span> /dev
      <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> sys
        <span class="token key atrule">hostPath</span><span class="token punctuation">:</span>
          <span class="token key atrule">path</span><span class="token punctuation">:</span> /sys
      <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> root
        <span class="token key atrule">hostPath</span><span class="token punctuation">:</span>
          <span class="token key atrule">path</span><span class="token punctuation">:</span> /
</code></pre> 
<p>由于我们要获取到的数据是主机的监控指标数据，而我们的 node-exporter 是运行在容器中的，所以我们在 Pod 中需要配置一些 Pod 的安全策略，这里我们就添加了 hostPID: true、hostIPC: true、hostNetwork: true 3个策略，用来使用主机的 PID namespace、IPC namespace 以及主机网络，这些 namespace 就是用于容器隔离的关键技术，要注意这里的 namespace 和集群中的 namespace 是两个完全不相同的概念。</p> 
<p>另外我们还将主机的 /dev、/proc、/sys这些目录挂载到容器中，这些因为我们采集的很多节点数据都是通过这些文件夹下面的文件来获取到的，比如我们在使用 top 命令可以查看当前 cpu 使用情况，数据就来源于文件 /proc/stat，使用 free 命令可以查看当前内存使用情况，其数据来源是来自 /proc/meminfo 文件。</p> 
<p>另外由于我们集群使用的是 kubeadm 搭建的，所以如果希望 master 节点也一起被监控，则需要添加相应的容忍，然后直接创建上面的资源对象：</p> 
<pre><code class="prism language-shell">$ kubectl apply -f prome-node-exporter.yaml
daemonset.apps/node-exporter created
$ kubectl get pods -n kube-mon -l <span class="token assign-left variable">app</span><span class="token operator">=</span>node-exporter -o wide
NAME                  READY   STATUS    RESTARTS   AGE    IP             NODE          NOMINATED NODE   READINESS GATES
node-exporter-cd2cq   <span class="token number">1</span>/1     Running   <span class="token number">0</span>          107s   <span class="token number">10.151</span>.30.57   ydzs-node3    <span class="token operator">&lt;</span>none<span class="token operator">&gt;</span>           <span class="token operator">&lt;</span>none<span class="token operator">&gt;</span>
node-exporter-l6jv6   <span class="token number">1</span>/1     Running   <span class="token number">0</span>          107s   <span class="token number">10.151</span>.30.23   ydzs-node2    <span class="token operator">&lt;</span>none<span class="token operator">&gt;</span>           <span class="token operator">&lt;</span>none<span class="token operator">&gt;</span>
node-exporter-qv4x5   <span class="token number">1</span>/1     Running   <span class="token number">0</span>          107s   <span class="token number">10.151</span>.30.59   ydzs-node4    <span class="token operator">&lt;</span>none<span class="token operator">&gt;</span>           <span class="token operator">&lt;</span>none<span class="token operator">&gt;</span>
node-exporter-vbbhc   <span class="token number">1</span>/1     Running   <span class="token number">0</span>          107s   <span class="token number">10.151</span>.30.11   ydzs-master   <span class="token operator">&lt;</span>none<span class="token operator">&gt;</span>           <span class="token operator">&lt;</span>none<span class="token operator">&gt;</span>
node-exporter-wlgnz   <span class="token number">1</span>/1     Running   <span class="token number">0</span>          107s   <span class="token number">10.151</span>.30.22   ydzs-node1    <span class="token operator">&lt;</span>none<span class="token operator">&gt;</span>           <span class="token operator">&lt;</span>none<span class="token operator">&gt;</span>
</code></pre> 
<p>部署完成后，我们可以看到在5个节点上都运行了一个 Pod，由于我们指定了 hostNetwork=true，所以在每个节点上就会绑定一个端口 9100，我们可以通过这个端口去获取到监控指标数据：</p> 
<pre><code class="prism language-shell">$ <span class="token function">curl</span> <span class="token number">10.151</span>.30.11:9100/metrics
<span class="token punctuation">..</span>.
node_filesystem_device_error<span class="token punctuation">{<!-- --></span>device<span class="token operator">=</span><span class="token string">"shm"</span>,fstype<span class="token operator">=</span><span class="token string">"tmpfs"</span>,mountpoint<span class="token operator">=</span><span class="token string">"/rootfs/var/lib/docker/containers/aefe8b1b63c3aa5f27766053ec817415faf8f6f417bb210d266fef0c2da64674/shm"</span><span class="token punctuation">}</span> <span class="token number">1</span>
node_filesystem_device_error<span class="token punctuation">{<!-- --></span>device<span class="token operator">=</span><span class="token string">"shm"</span>,fstype<span class="token operator">=</span><span class="token string">"tmpfs"</span>,mountpoint<span class="token operator">=</span><span class="token string">"/rootfs/var/lib/docker/containers/c8652ca72230496038a07e4fe4ee47046abb5f88d9d2440f0c8a923d5f3e133c/shm"</span><span class="token punctuation">}</span> <span class="token number">1</span>
node_filesystem_device_error<span class="token punctuation">{<!-- --></span>device<span class="token operator">=</span><span class="token string">"tmpfs"</span>,fstype<span class="token operator">=</span><span class="token string">"tmpfs"</span>,mountpoint<span class="token operator">=</span><span class="token string">"/dev"</span><span class="token punctuation">}</span> <span class="token number">0</span>
node_filesystem_device_error<span class="token punctuation">{<!-- --></span>device<span class="token operator">=</span><span class="token string">"tmpfs"</span>,fstype<span class="token operator">=</span><span class="token string">"tmpfs"</span>,mountpoint<span class="token operator">=</span><span class="token string">"/dev/shm"</span><span class="token punctuation">}</span> <span class="token number">0</span>
</code></pre> 
<h3>
<a id="34_353"></a>3.4、服务发现</h3> 
<p>由于我们这里每个节点上面都运行了 node-exporter 程序，如果我们通过一个 Service 来将数据收集到一起用静态配置的方式配置到 Prometheus 去中，就只会显示一条数据，我们得自己在指标数据中去过滤每个节点的数据，当然我们也可以手动的把所有节点用静态的方式配置到 Prometheus 中去，但是以后要新增或者去掉节点的时候就还得手动去配置，那么有没有一种方式可以让 Prometheus 去自动发现我们节点的 node-exporter 程序，并且按节点进行分组呢？这就是 Prometheus 里面非常重要的<strong>服务发现</strong>功能了。</p> 
<p>在 Kubernetes 下，Promethues 通过与 Kubernetes API 集成，主要支持5中服务发现模式，分别是：Node、Service、Pod、Endpoints、Ingress。</p> 
<p>我们通过 kubectl 命令可以很方便的获取到当前集群中的所有节点信息：</p> 
<pre><code class="prism language-shell">$ kubectl get nodes
NAME          STATUS   ROLES    AGE   VERSION
ydzs-master   Ready    master   33d   v1.16.2
ydzs-node1    Ready    <span class="token operator">&lt;</span>none<span class="token operator">&gt;</span>   33d   v1.16.2
ydzs-node2    Ready    <span class="token operator">&lt;</span>none<span class="token operator">&gt;</span>   33d   v1.16.2
ydzs-node3    Ready    <span class="token operator">&lt;</span>none<span class="token operator">&gt;</span>   31d   v1.16.2
ydzs-node4    Ready    <span class="token operator">&lt;</span>none<span class="token operator">&gt;</span>   31d   v1.16.2
</code></pre> 
<p>但是要让 Prometheus 也能够获取到当前集群中的所有节点信息的话，我们就需要利用 Node 的服务发现模式，同样的，在 prometheus.yml 文件中配置如下的 job 任务即可：</p> 
<pre><code class="prism language-shell">- job_name: <span class="token string">'kubernetes-nodes'</span>
  kubernetes_sd_configs:
  - role: node
</code></pre> 
<p>配置生效后，我们再去 prometheus 的 dashboard 中查看 Targets 是否能够正常抓取数据，访问http://任意节点IP:30980：<br> <img src="https://images2.imgbox.com/7a/7e/3cGqfcul_o.png" alt="在这里插入图片描述"><br> 我们可以看到上面的 kubernetes-nodes 这个 job 任务已经自动发现了我们5个 node 节点，但是在获取数据的时候失败了，出现了类似于下面的错误信息：</p> 
<pre><code>server returned HTTP status 400 Bad Request
</code></pre> 
<p>这个是因为 prometheus 去发现 Node 模式的服务的时候，访问的端口默认是10250，而默认是需要认证的 https 协议才有权访问的，但实际上我们并不是希望让去访问10250端口的 /metrics 接口，而是 node-exporter 绑定到节点的 9100 端口，所以我们应该<strong>将这里的 10250 替换成 9100</strong>，但是应该怎样替换呢？<br> 这里我们就需要使用到 Prometheus 提供的 relabel_configs 中的 replace 能力了，relabel 可以在 Prometheus 采集数据之前，通过 Target 实例的 Metadata 信息，动态重新写入 Label 的值。除此之外，我们还能根据 Target 实例的 Metadata 信息选择是否采集或者忽略该 Target 实例。比如我们这里就可以去匹配 <strong>address</strong> 这个 Label 标签，然后替换掉其中的端口，如果你不知道有哪些 Label 标签可以操作的话，可以将鼠标?移动到 Targets 的标签区域，其中显示的 Before relabeling 区域都是我们可以操作的标签：<br> <img src="https://images2.imgbox.com/94/ab/bygBOAEj_o.png" alt="在这里插入图片描述"><br> 现在我们来替换掉端口，修改 ConfigMap：</p> 
<pre><code class="prism language-shell">- job_name: <span class="token string">'kubernetes-nodes'</span>
  kubernetes_sd_configs:
  - role: node
  relabel_configs:
  - source_labels: <span class="token punctuation">[</span>__address__<span class="token punctuation">]</span>
    regex: <span class="token string">'(.*):10250'</span>
    replacement: <span class="token string">'<span class="token variable">${1}</span>:9100'</span>
    target_label: __address__
    action: replace
</code></pre> 
<p>这里就是一个正则表达式，去匹配 <strong>address</strong> 这个标签，然后将 host 部分保留下来，port 替换成了 9100，现在我们重新更新配置文件，执行 reload 操作，然后再去看 Prometheus 的 Dashboard 的 Targets 路径下面 kubernetes-nodes 这个 job 任务是否正常了：<br> <img src="https://images2.imgbox.com/92/c3/xCLsO8vE_o.png" alt="在这里插入图片描述"><br> 我们可以看到现在已经正常了，但是还有一个问题就是我们采集的指标数据 Label 标签就只有一个节点的 hostname，这对于我们在进行监控分组分类查询的时候带来了很多不方便的地方，要是我们能够将集群中 Node 节点的 Label 标签也能获取到就很好了。这里我们可以通过 labelmap 这个属性来将 Kubernetes 的 Label 标签添加为 Prometheus 的指标数据的标签：</p> 
<pre><code class="prism language-shell">- job_name: <span class="token string">'kubernetes-nodes'</span>
  kubernetes_sd_configs:
  - role: node
  relabel_configs:
  - source_labels: <span class="token punctuation">[</span>__address__<span class="token punctuation">]</span>
    regex: <span class="token string">'(.*):10250'</span>
    replacement: <span class="token string">'<span class="token variable">${1}</span>:9100'</span>
    target_label: __address__
    action: replace
  - action: labelmap
    regex: __meta_kubernetes_node_label_<span class="token punctuation">(</span>.+<span class="token punctuation">)</span>
</code></pre> 
<p>添加了一个 action 为 labelmap，正则表达式是 _<em>meta_kubernetes_node_label</em>(.+) 的配置，这里的意思就是表达式中匹配都的数据也添加到指标数据的 Label 标签中去。</p> 
<p>对于 kubernetes_sd_configs 下面可用的元信息标签如下：</p> 
<ol>
<li>__meta_kubernetes_node_name：节点对象的名称</li>
<li>_meta_kubernetes_node_label：节点对象中的每个标签</li>
<li>_meta_kubernetes_node_annotation：来自节点对象的每个注释</li>
<li>_meta_kubernetes_node_address：每个节点地址类型的第一个地址（如果存在）<br> 关于 kubernets_sd_configs 更多信息可以查看官方文档<a href="https://prometheus.io/docs/prometheus/latest/configuration/configuration/#%3Ckubernetes_sd_config%3E">kubernetes_sd_config</a><br> 另外由于 kubelet 也自带了一些监控指标数据，就上面我们提到的 <strong>10250 端口</strong>，所以我们这里也把 kubelet 的监控任务也一并配置上：</li>
</ol> 
<pre><code class="prism language-yaml"><span class="token punctuation">-</span> <span class="token key atrule">job_name</span><span class="token punctuation">:</span> <span class="token string">'kubernetes-kubelet'</span>
  <span class="token key atrule">kubernetes_sd_configs</span><span class="token punctuation">:</span>
  <span class="token punctuation">-</span> <span class="token key atrule">role</span><span class="token punctuation">:</span> node
  <span class="token key atrule">scheme</span><span class="token punctuation">:</span> https
  <span class="token key atrule">tls_config</span><span class="token punctuation">:</span>
    <span class="token key atrule">ca_file</span><span class="token punctuation">:</span> /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
    <span class="token key atrule">insecure_skip_verify</span><span class="token punctuation">:</span> <span class="token boolean important">true</span>
  <span class="token key atrule">bearer_token_file</span><span class="token punctuation">:</span> /var/run/secrets/kubernetes.io/serviceaccount/token
  <span class="token key atrule">relabel_configs</span><span class="token punctuation">:</span>
  <span class="token punctuation">-</span> <span class="token key atrule">action</span><span class="token punctuation">:</span> labelmap
    <span class="token key atrule">regex</span><span class="token punctuation">:</span> __meta_kubernetes_node_label_(.+)
</code></pre> 
<p>但是这里需要特别注意的是这里必须使用 https 协议访问，这样就必然需要提供证书，我们这里是通过配置 insecure_skip_verify: true 来跳过了证书校验，但是除此之外，要访问集群的资源，还必须要有对应的权限才可以，也就是对应的 ServiceAccount 棒的 权限允许才可以，我们这里部署的 prometheus 关联的 ServiceAccount 对象前面我们已经提到过了，这里我们只需要将 Pod 中自动注入的 /var/run/secrets/kubernetes.io/serviceaccount/ca.crt 和 /var/run/secrets/kubernetes.io/serviceaccount/token 文件配置上，就可以获取到对应的权限了。</p> 
<p>现在我们再去更新下配置文件，执行 reload 操作，让配置生效，然后访问 Prometheus 的 Dashboard 查看 Targets 路径：<br> <img src="https://images2.imgbox.com/13/fb/y6xpwwfT_o.png" alt="在这里插入图片描述"><br> 现在可以看到我们上面添加的 kubernetes-kubelet 和 kubernetes-nodes 这两个 job 任务都已经配置成功了，而且二者的 Labels 标签都和集群的 node 节点标签保持一致了。</p> 
<p>现在我们就可以切换到 Graph 路径下面查看采集的一些指标数据了，比如查询 node_load1 指标：<br> <img src="https://images2.imgbox.com/58/b6/yuZ94YJX_o.png" alt="在这里插入图片描述"><br> 我们可以看到将5个节点对应的 node_load1 指标数据都查询出来了，同样的，我们还可以使用 PromQL 语句来进行更复杂的一些聚合查询操作，还可以根据我们的 Labels 标签对指标数据进行聚合，比如我们这里只查询 ydzs-node3 节点的数据，可以使用表达式 node_load1{instance=“ydzs-node3”} 来进行查询：<br> <img src="https://images2.imgbox.com/e9/f2/tiul9oPS_o.png" alt="在这里插入图片描述"></p> 
<h3>
<a id="35_444"></a>3.5、容器监控</h3> 
<p>说到容器监控我们自然会想到 cAdvisor，我们前面也说过cAdvisor已经内置在了 kubelet 组件之中，所以我们不需要单独去安装，cAdvisor 的数据路径为 /api/v1/nodes//proxy/metrics，同样我们这里使用 node 的服务发现模式，因为每一个节点下面都有 kubelet，自然都有 cAdvisor 采集到的数据指标，配置如下</p> 
<pre><code class="prism language-shell">- job_name: <span class="token string">'kubernetes-cadvisor'</span>
  kubernetes_sd_configs:
  - role: node
  scheme: https
  tls_config:
    ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
  bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
  relabel_configs:
  - action: labelmap
    regex: __meta_kubernetes_node_label_<span class="token punctuation">(</span>.+<span class="token punctuation">)</span>
  - target_label: __address__
    replacement: kubernetes.default.svc:443
  - source_labels: <span class="token punctuation">[</span>__meta_kubernetes_node_name<span class="token punctuation">]</span>
    regex: <span class="token punctuation">(</span>.+<span class="token punctuation">)</span>
    target_label: __metrics_path__
    replacement: /api/v1/nodes/<span class="token variable">${1}</span>/proxy/metrics/cadvisor
</code></pre> 
<p>上面的配置和我们之前配置 node-exporter 的时候几乎是一样的，区别是我们这里使用了 https 的协议，另外需要注意的是配置了 ca.cart 和 token 这两个文件，这两个文件是 Pod 启动后自动注入进来的，通过这两个文件我们可以在 Pod 中访问 apiserver，比如我们这里的 <strong>address</strong> 不再是 nodeip 了，而是 kubernetes 在集群中的服务地址，然后加上__metrics_path__ 的访问路径 /api/v1/nodes/${1}/proxy/metrics/cadvisor，因为我们现在是通过 kubernetes 的 apiserver 地址去进行访问的，现在同样更新下配置，然后查看 Targets 路径：<br> <img src="https://images2.imgbox.com/8b/f8/XVxDJhQt_o.png" alt="在这里插入图片描述"><br> 我们可以切换到 Graph 路径下面查询容器相关数据，比如我们这里来查询集群中所有 Pod 的 CPU 使用情况，kubelet 中的 cAdvisor 采集的指标和含义，可以查看 Monitoring cAdvisor with Prometheus 说明，其中有一项：</p> 
<pre><code>container_cpu_usage_seconds_total   Counter     Cumulative cpu time consumed    seconds
</code></pre> 
<p>container_cpu_usage_seconds_total 是容器累计使用的 CPU 时间，用它除以 CPU 的总时间，就可以得到容器的 CPU 使用率了：</p> 
<p>首先计算容器的 CPU 占用时间，由于节点上的 CPU 有多个，所以需要将容器在每个 CPU 上占用的时间累加起来，Pod 在 1m 内累积使用的 CPU 时间为：(根据 pod 和 namespace 进行分组查询)</p> 
<pre><code>sum(rate(container_cpu_usage_seconds_total{image!="",pod!=""}[1m])) by (namespace, pod)
</code></pre> 
<blockquote> 
 <p><strong>metrics 变化</strong><br> <strong>在 Kubernetes 1.16 版本中移除了 cadvisor metrics 的 pod_name 和 container_name 这两个标签，改成了 pod 和 container。</strong><br> “Removed cadvisor metric labels pod_name and container_name to match instrumentation guidelines. Any Prometheus queries that match pod_name and container_name labels (e.g. cadvisor or kubelet probe metrics) must be updated to use pod and container instead. (#80376, @ehashman)”</p> 
</blockquote> 
<p>然后计算 CPU 的总时间，这里的 CPU 数量是容器分配到的 CPU 数量，container_spec_cpu_quota 是容器的 CPU 配额，它的值是容器指定的 CPU 个数 * 100000，所以 Pod 在 1s 内 CPU 的总时间为：Pod 的 CPU 核数 * 1s：</p> 
<pre><code>sum(container_spec_cpu_quota{image!="", pod!=""}) by(namespace, pod) / 100000
</code></pre> 
<p>由于 container_spec_cpu_quota 是容器的 CPU 配额，所以只有配置了 resource-limit CPU 的 Pod 才可以获得该指标数据。</p> 
<pre><code>(sum(rate(container_cpu_usage_seconds_total{image!="",pod!=""}[1m])) by (namespace, pod))
/
(sum(container_spec_cpu_quota{image!="", pod!=""}) by(namespace, pod) / 100000) * 100
</code></pre> 
<p><img src="https://images2.imgbox.com/71/cc/wysWfwQa_o.png" alt="在这里插入图片描述"><br> Pod 内存使用率的计算就简单多了，直接用内存实际使用量除以内存限制使用量即可：</p> 
<pre><code>sum(container_memory_rss{image!=""}) by(namespace, pod) / sum(container_spec_memory_limit_bytes{image!=""}) by(namespace, pod) * 100 != +inf
</code></pre> 
<p><img src="https://images2.imgbox.com/3c/12/oYy1mOhj_o.png" alt="在这里插入图片描述"></p> 
<h3>
<a id="36_apiserver_497"></a>3.6、监控 apiserver</h3> 
<p>apiserver 作为 Kubernetes 最核心的组件，当然他的监控也是非常有必要的，对于 apiserver 的监控我们可以直接通过 kubernetes 的 Service 来获取：</p> 
<pre><code class="prism language-shell">$ kubectl get svc
NAME             TYPE           CLUSTER-IP       EXTERNAL-IP             PORT<span class="token punctuation">(</span>S<span class="token punctuation">)</span>          AGE
kubernetes       ClusterIP      <span class="token number">10.96</span>.0.1        <span class="token operator">&lt;</span>none<span class="token operator">&gt;</span>                  <span class="token number">443</span>/TCP          33d
</code></pre> 
<p>上面这个 Service 就是我们集群的 apiserver 在集群内部的 Service 地址，要自动发现 Service 类型的服务，我们就需要用到 role 为 Endpoints 的 kubernetes_sd_configs，我们可以在 ConfigMap 对象中添加上一个 Endpoints 类型的服务的监控任务：</p> 
<pre><code class="prism language-shell">- job_name: <span class="token string">'kubernetes-apiservers'</span>
  kubernetes_sd_configs:
  - role: endpoints
</code></pre> 
<p>上面这个任务是定义的一个类型为 endpoints 的 kubernetes_sd_configs ，添加到 Prometheus 的 ConfigMap 的配置文件中，然后更新配置：</p> 
<pre><code class="prism language-shell">$ kubectl apply -f prometheus-cm.yaml
configmap/prometheus-config configured
隔一会儿执行reload操作
$ <span class="token function">curl</span> -X POST <span class="token string">"http://10.244.3.174:9090/-/reload"</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/d3/20/IQztf0qj_o.png" alt="在这里插入图片描述"><br> 我们可以看到 kubernetes-apiservers 下面出现了很多实例，这是因为这里我们使用的是 Endpoints 类型的服务发现，所以 Prometheus 把所有的 Endpoints 服务都抓取过来了，同样的，上面我们需要的服务名为 kubernetes 这个 apiserver 的服务也在这个列表之中，那么我们应该怎样来过滤出这个服务来呢？还记得前面的 relabel_configs 吗？没错，同样我们需要使用这个配置，只是我们这里不是使用 replace 这个动作了，而是 keep，就是只把符合我们要求的给保留下来，哪些才是符合我们要求的呢？我们可以把鼠标放置在任意一个 target 上，可以查看到Before relabeling里面所有的元数据，比如我们要过滤的服务是 default 这个 namespace 下面，服务名为 kubernetes 的元数据，所以这里我们就可以根据对应的 __meta_kubernetes_namespace 和 __meta_kubernetes_service_name 这两个元数据来 relabel，另外由于 kubernetes 这个服务对应的端口是 443，需要使用 https 协议，所以这里我们需要使用 https 的协议，对应的就需要将 ca 证书配置上，如下所示：</p> 
<pre><code class="prism language-shell">- job_name: <span class="token string">'kubernetes-apiservers'</span>
  kubernetes_sd_configs:
  - role: endpoints
  scheme: https
  tls_config:
    ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
  bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
  relabel_configs:
  - source_labels: <span class="token punctuation">[</span>__meta_kubernetes_namespace, __meta_kubernetes_service_name, __meta_kubernetes_endpoint_port_name<span class="token punctuation">]</span>
    action: keep
    regex: default<span class="token punctuation">;</span>kubernetes<span class="token punctuation">;</span>https
</code></pre> 
<p><img src="https://images2.imgbox.com/e6/05/6HPlpGMj_o.png" alt="在这里插入图片描述"></p> 
<p>现在可以看到 kubernetes-apiserver 这个任务下面只有 apiserver 这一个实例了，证明我们的 relabel 是成功的，现在我们切换到 Graph 路径下面查看下采集到的数据，比如查询 apiserver 的总的请求数：<br> <img src="https://images2.imgbox.com/a8/38/hNuCZdBm_o.png" alt="在这里插入图片描述"><br> 这样我们就完成了对 Kubernetes APIServer 的监控。</p> 
<p>另外如果我们要来监控其他系统组件，比如 kube-controller-manager、kube-scheduler 的话应该怎么做呢？由于 apiserver 服务 namespace 在 default 使用默认的 Service kubernetes，而其余组件服务在 kube-system 这个 namespace 下面，如果我们想要来监控这些组件的话，需要手动创建单独的 Service，其中 kube-sheduler 的指标数据端口为 10251，kube-controller-manager 对应的端口为 10252，大家可以尝试下自己来配置下这几个系统组件。</p> 
<h3>
<a id="37_Pod_542"></a>3.7、监控 Pod</h3> 
<p>上面的 apiserver 实际上就是一种特殊的 Endpoints，现在我们同样来配置一个任务用来专门发现普通类型的 Endpoint，其实就是 Service 关联的 Pod 列表：</p> 
<pre><code class="prism language-shell">- job_name: <span class="token string">'kubernetes-endpoints'</span>
  kubernetes_sd_configs:
  - role: endpoints
  relabel_configs:
  - source_labels: <span class="token punctuation">[</span>__meta_kubernetes_service_annotation_prometheus_io_scrape<span class="token punctuation">]</span>
    action: keep
    regex: <span class="token boolean">true</span>
  - source_labels: <span class="token punctuation">[</span>__meta_kubernetes_service_annotation_prometheus_io_scheme<span class="token punctuation">]</span>
    action: replace
    target_label: __scheme__
    regex: <span class="token punctuation">(</span>https?<span class="token punctuation">)</span>
  - source_labels: <span class="token punctuation">[</span>__meta_kubernetes_service_annotation_prometheus_io_path<span class="token punctuation">]</span>
    action: replace
    target_label: __metrics_path__
    regex: <span class="token punctuation">(</span>.+<span class="token punctuation">)</span>
  - source_labels: <span class="token punctuation">[</span>__address__, __meta_kubernetes_service_annotation_prometheus_io_port<span class="token punctuation">]</span>
    action: replace
    target_label: __address__
    regex: <span class="token punctuation">(</span><span class="token punctuation">[</span>^:<span class="token punctuation">]</span>+<span class="token punctuation">)</span><span class="token punctuation">(</span>?::<span class="token punctuation"></span>d+<span class="token punctuation">)</span>?<span class="token punctuation">;</span><span class="token punctuation">(</span><span class="token punctuation"></span>d+<span class="token punctuation">)</span>
    replacement: <span class="token variable">$1</span><span class="token builtin class-name">:</span><span class="token variable">$2</span>
  - action: labelmap
    regex: __meta_kubernetes_service_label_<span class="token punctuation">(</span>.+<span class="token punctuation">)</span>
  - source_labels: <span class="token punctuation">[</span>__meta_kubernetes_namespace<span class="token punctuation">]</span>
    action: replace
    target_label: kubernetes_namespace
  - source_labels: <span class="token punctuation">[</span>__meta_kubernetes_service_name<span class="token punctuation">]</span>
    action: replace
    target_label: kubernetes_name
  - source_labels: <span class="token punctuation">[</span>__meta_kubernetes_pod_name<span class="token punctuation">]</span>
    action: replace
    target_label: kubernetes_pod_name
</code></pre> 
<p>注意我们这里在 relabel_configs 区域做了大量的配置，特别是第一个保留__meta_kubernetes_service_annotation_prometheus_io_scrape 为 true 的才保留下来，这就是说要想自动发现集群中的 Endpoint，就需要我们在 Service 的 annotation 区域添加 prometheus.io/scrape=true 的声明，现在我们先将上面的配置更新，查看下效果：<br> <img src="https://images2.imgbox.com/6a/2d/KIMnCwqN_o.png" alt="在这里插入图片描述"><br> 我们可以看到 kubernetes-endpoints 这一个任务下面只发现了两个服务，这是因为我们在 relabel_configs 中过滤了 annotation 有 prometheus.io/scrape=true 的 Service，而现在我们系统中只有这样一个 kube-dns 服务符合要求，该 Service 下面有两个实例，所以出现了两个实例：</p> 
<pre><code class="prism language-shell">$ kubectl get svc kube-dns -n kube-system -o yaml
apiVersion: v1
kind: Service
metadata:
  annotations:
    prometheus.io/port: <span class="token string">"9153"</span>  <span class="token comment"># metrics 接口的端口</span>
    prometheus.io/scrape: <span class="token string">"true"</span>  <span class="token comment"># 这个注解可以让prometheus自动发现</span>
  creationTimestamp: <span class="token string">"2019-11-08T11:59:50Z"</span>
  labels:
    k8s-app: kube-dns
    kubernetes.io/cluster-service: <span class="token string">"true"</span>
    kubernetes.io/name: KubeDNS
  name: kube-dns
  namespace: kube-system
</code></pre> 
<p>现在我们在之前创建的 redis 这个 Service 中添加上 prometheus.io/scrape=true 这个 annotation：(prome-redis.yaml)</p> 
<pre><code class="prism language-shell">kind: Service
apiVersion: v1
metadata:
  name: redis
  namespace: kube-mon
  annotations:
    prometheus.io/scrape: <span class="token string">"true"</span>
    prometheus.io/port: <span class="token string">"9121"</span>
spec:
  selector:
    app: redis
  ports:
  - name: redis
    port: <span class="token number">6379</span>
    targetPort: <span class="token number">6379</span>
  - name: prom
    port: <span class="token number">9121</span>
    targetPort: <span class="token number">9121</span>
</code></pre> 
<p>由于 redis 服务的 metrics 接口在 9121 这个 redis-exporter 服务上面，所以我们还需要添加一个 prometheus.io/port=9121 这样的 annotations，然后更新这个 Service：</p> 
<pre><code class="prism language-shell">$ kubectl apply -f prome-redis.yaml
deployment.apps <span class="token string">"redis"</span> unchanged
<span class="token function">service</span> <span class="token string">"redis"</span> changed
</code></pre> 
<p>更新完成后，去 Prometheus 查看 Targets 路径，可以看到 redis 服务自动出现在了 kubernetes-endpoints 这个任务下面：<br> <img src="https://images2.imgbox.com/d8/96/no0YsSNZ_o.png" alt="在这里插入图片描述"></p>
                </div>
                
                

		</div>
	</article>
</main>




			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程小白.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://www.w3counter.com/tracker.js?id=150625"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>
	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>