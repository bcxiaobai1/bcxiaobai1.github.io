<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<title>计算机视觉之迁移学习中的微调(fine tuning) - 编程小白</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程小白" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程小白</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">计算机视觉之迁移学习中的微调(fine tuning)</h1>
			
		</header>
		<div class="content post__content clearfix">
			


                <div id="content_views" class="htmledit_views">
                    <p>        现在的数据集越来越大，都是大模型的训练，参数都早已超过亿级，面对如此大的训练集，绝大部分用户的硬件配置达不到，那有没有一种方法让这些训练好的大型数据集的参数，迁移到自己的一个目标训练数据集当中呢？比如使用最广泛的图像数据集ImageNet，超过1000万张的图像和1000个分类，这些耗费大量时间人力物力而训练出来的参数，为我所用？<br><br> 答案是肯定的，就是接下来说的<span style="color:#be191c"><span style="background-color:#fef2f0">微调(fine tuning)</span></span>，顾名思义就是细微的调节将这个已训练好的模型参数迁移过来，或者说复制(不是完全拷贝，故有点区别，所以叫微调)过来，最后再对自己的模型进行训练。<br> 比如说我们的一个数据集是想找出图片中的热狗，但ImageNet数据集的图像大多于此无关，那迁移过来的参数有用吗？有用，<span style="color:#b95514">因为在训练ImageNet中抽取的特征，如：边缘、纹理、形状等，对于识别物体都有同样的效果。</span></p> 
<p>如何从源数据集迁移到目标数据集呢？方法就是将除了输出层的其余层的参数复制(做了微调)到目标数据集的除了输出层的其余层。而对于目标数据集的输出层，我们随机初始化该层的模型参数，然后将整个目标数据集重新训练一遍即可。</p> 
<p>我们<a class="link-info" href="https://download.csdn.net/download/weixin_41896770/87088824" title="下载热狗数据集">下载热狗数据集</a>，来识别图像中的热狗的一个示例：</p> 
<pre><code class="language-python">import d2lzh as d2l
from mxnet import gluon,init,nd
from mxnet.gluon import data as gdata,loss as gloss,model_zoo
from mxnet.gluon import utils as gutils
import os
import zipfile
#下载热狗数据集（如果超时等下载不了，就直接手动下载再解压）
#解压之后是hotdog目录，里面是train和test目录，分别都有hotdog和not-hotdog目录，存放热狗和非热狗(和热狗长的像的，比如香蕉之类)的图像
data_dir='../data'
fname=gutils.download('https://apache-mxnet.s3-accelerate.amazonaws.com/gluon/dataset/hotdog.zip')
with zipfile.ZipFile(fname,'r') as z:
     z.extractall(data_dir)</code></pre> 
<p>当然如果遇到权限错误，比如我的是C盘存放，使用<span style="color:#be191c">管理员权限的命令行</span>执行即可。<br><span style="color:#be191c"><span style="background-color:#fef2f0">PermissionError: [WinError 5] 拒绝访问。: '..\data\hotdog'</span></span></p> 
<p> 数据集下载下来了，我们先来显示正类图像（热狗）和负类图像（非热狗），熟悉下这个数据集，代码如下：</p> 
<pre><code class="language-python">train_imgs=gdata.vision.ImageFolderDataset(os.path.join(data_dir,'hotdog/train'))
test_imgs=gdata.vision.ImageFolderDataset(os.path.join(data_dir,'hotdog/test'))
#print(len(train_imgs),len(test_imgs))#2000,800

#print(train_imgs[0])#...&lt;NDArray 144x122x3 @cpu(0)&gt;, 0)(高,宽,通道)和标签值，0是热狗，1是非热狗
#print(train_imgs.items[0])#('../data\hotdog/train\hotdog\0.png', 0)
hotdogs=[train_imgs[i][0] for i in range(8)]
not_hotdogs=[test_imgs[-i][0] for i in range(8)]
d2l.show_images(hotdogs+not_hotdogs,2,8,scale=1.5)
d2l.plt.show()</code></pre> 
<p style="text-align:center"><img alt="" src="https://images2.imgbox.com/fc/6d/6ZXMYGYU_o.png"></p> 
<p>从画布中显示的图像可以看出，都是些大小和宽高比都不一样的热狗与非热狗图。</p> 
<h2>训练模型前的图像增广</h2> 
<p>        在训练时，先从图像中裁剪出随机大小和随机高宽比的一块区域，然后将该区域缩放到高宽为224像素的输入。测试时，我们将图像的高宽缩放到256像素，然后从中裁剪出高宽为224的中心区域作为输入。此外，我们对颜色通道做标准化，就是每个数值减去所有数值的均值，再除以标准差。</p> 
<pre><code class="language-python"># 对颜色通道做标准化处理
normalize = gdata.vision.transforms.Normalize(
    [0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # 均值,方差
train_augs = gdata.vision.transforms.Compose([gdata.vision.transforms.RandomResizedCrop(224), gdata.vision.transforms.RandomFlipLeftRight(),
                                              gdata.vision.transforms.ToTensor(), normalize])
test_augs = gdata.vision.transforms.Compose([gdata.vision.transforms.Resize(256), gdata.vision.transforms.CenterCrop(224),
                                             gdata.vision.transforms.ToTensor(), normalize])</code></pre> 
<h2>定义和初始化模型</h2> 
<p>使用ImageNet数据集上预训练的ResNet-18作为源模型。预训练模型的参数，将下载到：<span style="color:#fe2c24"><span style="background-color:#fbd4d0">C:UsersTony.mxnetmodels</span></span>里面的<span style="color:#be191c"><span style="background-color:#fef2f0">resnet18_v2-8aacf80f.params</span></span>参数文件</p> 
<pre><code class="language-python">pretrained_net = model_zoo.vision.resnet18_v2(pretrained=True)
#包含两个成员变量：features和output
#打印output输出层看下，输出1000类的全连接层
print(pretrained_net.features)#Dense(512 -&gt; 1000, linear)</code></pre> 
<p>接下来新建目标模型，其定义和预训练的源模型一样，只不过将最后的输出数修改为目标数据集的类别数，因为features中的模型参数是已经在ImageNet数据集上预训练得到的，已经足够好，所以只需要使用较小的学习率来微调这些参数。对于output中的模型参数我们采用随机初始化，一般需要更大的学习率（10倍学习率）从头训练。</p> 
<pre><code class="language-python">finetune_net=model_zoo.vision.resnet18_v2(classes=2)
finetune_net.features=pretrained_net.features
finetune_net.output.initialize(init.Xavier())
finetune_net.output.collect_params().setattr('lr_mult',10)</code></pre> 
<h2>微调模型</h2> 
<p>定义一个使用微调的训练函数，便于多次调用：</p> 
<pre><code class="language-python">def train_fine_tuning(net,learning_rate,batch_size=128,num_epochs=5):
    train_iter=gdata.DataLoader(train_imgs.transform_first(train_augs),batch_size,shuffle=True)
    test_iter=gdata.DataLoader(test_imgs.transform_first(test_augs),batch_size)
    ctx=d2l.try_all_gpus()
    net.collect_params().reset_ctx(ctx)
    net.hybridize()
    loss=gloss.SoftmaxCrossEntropyLoss()
    trainer=gluon.Trainer(net.collect_params(),'sgd',{'learning_rate':learning_rate,'wd':0.001})
    d2l.train(train_iter,test_iter,net,loss,trainer,ctx,num_epochs)</code></pre> 
<p>我们以小的学习率0.01微调获得预训练模型参数，然后以10倍学习率从头训练目标模型的输出层参数，当然本人配置不是很好，批处理大小就弄小点，不然内存溢出。</p> 
<pre><code class="language-python">train_fine_tuning(finetune_net,0.01,32)
'''
(pygpu) C:UsersTony&gt;python p.py
training on [gpu(0)]
epoch 1, loss 1.5428, train acc 0.815, test acc 0.594, time 28.9 sec
epoch 2, loss 0.7645, train acc 0.864, test acc 0.921, time 24.9 sec
epoch 3, loss 0.5352, train acc 0.882, test acc 0.921, time 24.8 sec
epoch 4, loss 0.4242, train acc 0.882, test acc 0.774, time 24.8 sec
epoch 5, loss 0.3898, train acc 0.893, test acc 0.917, time 24.9 sec
'''</code></pre> 
<p>作为对比，定义一个相同模型，但是将它所有模型参数都是初始化为随机值，由于需要从头训练，学习率大点0.1。</p> 
<pre><code class="language-python">scratch_net=model_zoo.vision.resnet18_v2(classes=2)
scratch_net.initialize(init=init.Xavier())
train_fine_tuning(scratch_net,0.1,32)
'''
(pygpu) C:UsersTony&gt;python p.py
training on [gpu(0)]
epoch 1, loss 0.5667, train acc 0.750, test acc 0.818, time 27.9 sec
epoch 2, loss 0.4731, train acc 0.795, test acc 0.824, time 25.0 sec
epoch 3, loss 0.4109, train acc 0.818, test acc 0.854, time 24.9 sec
epoch 4, loss 0.3790, train acc 0.828, test acc 0.812, time 24.9 sec
epoch 5, loss 0.4080, train acc 0.826, test acc 0.853, time 24.9 sec
'''</code></pre> 
<p>如果不微调，直接使用源模型参数，将会怎么样呢？</p> 
<pre><code class="language-python">finetune_net = model_zoo.vision.resnet18_v2(classes=2)
finetune_net.features=pretrained_net.features
finetune_net.features.collect_params().setattr('grad_req', 'null')
finetune_net.output.initialize(init.Xavier())
finetune_net.output.collect_params().setattr('lr_mult', 10)</code></pre> 
<p>测试几次的效果，loss效果比较差，精度还好，不稳定性要大点，可能是小数据集容易过拟合的原因，不知道伙伴们测试的效果如何？</p> 
<h2>模型前缀不一样</h2> 
<p>我们也可以将微调得到的最终参数保存起来</p> 
<pre><code class="language-python">finetune_net.collect_params().save('hotdog.params')</code></pre> 
<p>然后我们加载保存的参数看下：</p> 
<pre><code class="language-python">mynet=model_zoo.vision.resnet18_v2(classes=2)
mynet.collect_params().load('hotdog.params')
train_fine_tuning(mynet, 0.01, 32)</code></pre> 
<p><span style="color:#fe2c24">出现如下错误：</span></p> 
<blockquote> 
 <p>AssertionError: Parameter 'resnetv22_batchnorm0_gamma' is missing in file 'hotdog.params', which contains parameters: 'resnetv20_batchnorm0_gamma', 'resnetv20_batchnorm0_beta', 'resnetv20_batchnorm0_running_mean', ..., 'resnetv20_batchnorm2_running_mean', 'resnetv20_batchnorm2_running_var', 'resnetv21_dense0_weight', 'resnetv21_dense0_bias'. <span style="color:#be191c"><span style="background-color:#fef2f0">Please make sure source and target networks have the same prefix.</span></span></p> 
</blockquote> 
<p>很明显里面的前缀名不一致，这个就是没有固定前缀，在训练模型的时候都是动态递增的前缀，所以我们需要固定前缀，这样在加载的时候就指定前缀就好了<br><strong>训练的时候，指定前缀：</strong></p> 
<pre><code class="language-python">pretrained_net = model_zoo.vision.resnet18_v2(pretrained=True,prefix='res_')
finetune_net = model_zoo.vision.resnet18_v2(classes=2,prefix='res_')
finetune_net.features=pretrained_net.features
finetune_net.output.initialize(init.Xavier())
finetune_net.output.collect_params().setattr('lr_mult', 10)</code></pre> 
<p><strong>加载的时候，同样指定前缀即可：</strong></p> 
<pre><code class="language-python">mynet=model_zoo.vision.resnet18_v2(classes=2,prefix='res_')
mynet.collect_params().load('hotdog.params')
#print(mynet)</code></pre> 
<p>然后看下效果：</p> 
<pre><code class="language-python">train_fine_tuning(mynet, 0.01, 32)
'''
(pygpu) C:UsersTony&gt;python p.py
training on [gpu(0)]
epoch 1, loss 0.1788, train acc 0.933, test acc 0.939, time 28.0 sec
epoch 2, loss 0.1303, train acc 0.947, test acc 0.926, time 25.7 sec
epoch 3, loss 0.1398, train acc 0.948, test acc 0.943, time 25.7 sec
epoch 4, loss 0.1236, train acc 0.953, test acc 0.939, time 25.1 sec
epoch 5, loss 0.1157, train acc 0.955, test acc 0.941, time 25.1 sec
'''</code></pre> 
<h2>ImageNet中热狗</h2> 
<p>目前的输出层我们使用的是随机初始化，现在我们将ImageNet数据集中的热狗这个类的权重参数应用到我们的初始化里面来，看下有什么效果：</p> 
<pre><code class="language-python">weight=pretrained_net.output.weight
hotdog_w=nd.split(weight.data(),1000,axis=0)[713]
output_init=nd.concat(hotdog_w,-hotdog_w,dim=0)#将热狗的权重分一个负类的代表非热狗
print(output_init)
'''
[[-0.07650785  0.02459255  0.00455526 ... -0.06427797 -0.01825024
  -0.02214353]
 [ 0.07650785 -0.02459255 -0.00455526 ...  0.06427797  0.01825024
   0.02214353]]
&lt;NDArray 2x512 @cpu(0)&gt;
'''
finetune_net.output.initialize(init.Constant(output_init))#加载ImageNet里的热狗权重参数(增加一个负类)
finetune_net.output.collect_params().setattr('lr_mult', 10)
train_fine_tuning(finetune_net, 0.01, 32)
'''
training on [gpu(0)]
[12:41:37] c:jenkinsworkspacemxnet-tagmxnetsrcoperatornncudnn./cudnn_algoreg-inl.h:97: Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)
epoch 1, loss 1.3655, train acc 0.804, test acc 0.818, time 27.9 sec
epoch 2, loss 0.6536, train acc 0.875, test acc 0.902, time 25.0 sec
epoch 3, loss 0.5011, train acc 0.885, test acc 0.934, time 25.1 sec
epoch 4, loss 0.3031, train acc 0.913, test acc 0.922, time 25.0 sec
epoch 5, loss 0.2167, train acc 0.917, test acc 0.924, time 24.9 sec
'''</code></pre>
                </div>

		</div>
	</article>
</main>




			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程小白.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://www.w3counter.com/tracker.js?id=150625"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>
	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>