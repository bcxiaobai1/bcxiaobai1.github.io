<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<title>hadoop从零搭建一个集群 - 编程小白</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程小白" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程小白</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">hadoop从零搭建一个集群</h1>
			
		</header>
		<div class="content post__content clearfix">
			


                <div id="content_views" class="htmledit_views">
                    <div>
 <span style="color:#333333">重要说明：一切安装时基于centos7</span>
</div> 
<div>
 <span style="color:#333333">1.linux最小化安装</span>
</div> 
<div> 
 <div> 
  <pre><code>安装完成linux最小化base，关闭base，重新克隆一个完整的系统，并命名为hadoop40</code></pre> 
 </div> 
</div> 
<div>
 <span style="color:#333333">2.配置主机，ip，hosts等文件</span>
</div> 
<div> 
 <div> 
  <pre><code>启动hadoop40，用root登录
==================================================
#配置静态ip
[root@base ~]# vi /etc/sysconfig/network-scripts/ifcfg-ens33
#默认属性
TYPE=Ethernet
PROXY_METHOD=none
BROWSER_ONLY=no
DEFROUTE=yes
IPV4_FAILURE_FATAL=no
IPV6INIT=yes
IPV6_AUTOCONF=yes
IPV6_DEFROUTE=yes
IPV6_FAILURE_FATAL=no
IPV6_ADDR_GEN_MODE=stable-privacy
NAME=ens33
UUID=60a2315f-9632-42ad-9fe0-e74d628c79ad
DEVICE=ens33
# 修改属性
ONBOOT=yes
BOOTPROTO=static
#新增属性
# 静态ip
IPADDR=192.168.1.40
# 默认网关，在虚拟机网络已配好
GATEWAY=192.168.1.2
DNS1=114.114.114.114
DNS2=8.8.8.8</code></pre> 
 </div> 
</div> 
<div>
 <span style="color:#333333">2.2</span>
 <span style="color:#333333">#配置主机名称</span> 
 <div> 
  <pre><code>#修改主机配置文件
[root@base ~]# vi /etc/hostname
[root@base ~]# cat /etc/hostname
hadoop40
2.3#配置hosts（映射主机名和ip关系）
配置hadoop40-43为hadoop集群备用
[root@base ~]# vi /etc/hosts
[root@base ~]# cat /etc/hosts
127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4
::1         localhost localhost.localdomain localhost6 localhost6.localdomain6
192.168.1.40 hadoop40
192.168.1.41 hadoop41
192.168.1.42 hadoop42
192.168.1.43 hadoop43
=========================================================
Windows上配置hosts主机
C:WindowsSystem32driversetc路径</code></pre> 
  <p></p> 
 </div> 
</div> 
<div>
 <span style="color:#333333">3.安装必要的软件工具</span>
</div> 
<div> 
 <div> 
  <pre><code>yum install -y epel-release
yum install -y psmisc nc net-tools rsync vim lrzsz ntp libzstd openssl-static tree iotop git


epel-release:EPEL是由 Fedora 社区打造，为 RHEL 及衍生发行版如 CentOS、Scientific Linux 等提供高质量软件包的项目。装上了 EPEL之后，就相当于添加了一个第三方源。官方的rpm repository提供的rpm包也不够丰富，很多时候需要自己编译那太辛苦了，而EPEL恰恰可以解决这两方面的问题。


psmisc:  命令：pstree  fuser  killall
nc:功能强大的网络工具
net-tools: netstat ifconfig
rsync:远程数据同步工具
vim:编辑器
lrzsz：下载上传小文件的工具
ntp：Network Time Protocol，网络时间协议，用来使计算机时间同步化的一种协议
libzstd：
openssl-static：证书相关的工具
tree：树的结构展示
iotop：命令是一个用来监视磁盘I/O使用状况的top类工具。iotop具有与top相似的UI，其中包括PID、用户、I/O、进程等相关信息。Linux下的IO统计工具如iostat，nmon等大多数是只能统计到per设备的读写情况，如果你想知道每个进程是如何使用IO的就比较麻烦，使用iotop命令可以很方便的查看

git:</code></pre> 
 </div> 
</div> 
<div>
 <span style="color:#333333">4.在linux上安装hadoop环境</span>
</div> 
<div>
 <span style="color:#333333">    4.0在linux上创建用户，并创建软件上传路径和安装路径，重启切换用户登录</span>
</div> 
<div> 
 <div> 
  <pre><code># 创建用户，并设置密码
[root@base ~]# useradd myhadoop
[root@base ~]# passwd myhadoop
更改用户 myhadoop 的密码 。
新的 密码：
无效的密码： 密码包含用户名在某些地方
重新输入新的 密码：
passwd：所有的身份验证令牌已经成功更新。
=====================================================
#为用户赋予root权限
[root@hadoop40 myhadoop]# visudo
[root@hadoop40 myhadoop]# cat /etc/sudoers
........
root    ALL=(ALL)     ALL
myhadoop  ALL=(ALL)    NOPASSWD:ALL
....
===================================================
#创建目录，并将所属组机所属主的权限交个myhadoop
[root@base ~]# cd /opt
[root@base opt]# ll
总用量 0
[root@base opt]# mkdir software
[root@base opt]# mkdir module
[root@base opt]# ll
总用量 0
drwxr-xr-x. 2 root root 6 11月 11 10:21 module
drwxr-xr-x. 2 root root 6 11月 11 10:21 software
[root@base opt]# chown myhadoop:myhadoop -R module/ software/
[root@base opt]# ll
总用量 0
drwxr-xr-x. 2 myhadoop myhadoop 6 11月 11 10:21 module
drwxr-xr-x. 2 myhadoop myhadoop 6 11月 11 10:21 software
[root@base opt]#</code></pre> 
 </div> 
 <div>
  <span style="color:#333333"><span style="background-color:#fbfaf8"><span style="color:#333333">#关闭防火墙，并关闭自启动</span></span></span>
 </div> 
 <div> 
  <pre><code>[myhadoop@hadoop40 ~]$ sudo systemctl stop firewalld
[myhadoop@hadoop40 ~]$ sudo systemctl disable firewalld
Removed symlink /etc/systemd/system/multi-user.target.wants/firewalld.service.
Removed symlink /etc/systemd/system/dbus-org.fedoraproject.FirewallD1.service.
[myhadoop@hadoop40 ~]$ sudo systemctl is-enabled firewalld
disabled
[myhadoop@hadoop40 ~]$</code></pre> 
 </div> 
 <div>
  <span style="color:#333333"><span style="background-color:#fbfaf8"><span style="color:#333333">#  重启系统，并换用myhadoop登录</span></span></span> 
  <pre><code>[root@base opt]#reboot
#使用myhadoop用户，重新登录
[myhadoop@hadoop40 ~]$ who
myhadoop pts/0        2021-11-11 10:27 (192.168.1.9)
[myhadoop@hadoop40 ~]$</code></pre> 
 </div> 
</div> 
<div></div> 
<div>
 <span style="color:#333333">    4.1安装jdk</span>
</div> 
<div> 
 <div> 
  <pre><code>#使用myhadoop用户登录xsftp上传jdk的安装包
[myhadoop@hadoop40 software]$ pwd
/opt/software
[myhadoop@hadoop40 software]$ ll
总用量 520600
-rw-rw-r--. 1 myhadoop myhadoop 338075860 11月 11 10:29 hadoop-3.1.3.tar.gz
-rw-rw-r--. 1 myhadoop myhadoop 195013152 11月 11 10:29 jdk-8u212-linux-x64.tar.gz
[myhadoop@hadoop40 software]$
===================================================================
# 解压jdk到module中
[myhadoop@hadoop40 software]$ tar -zxvf jdk-8u212-linux-x64.tar.gz -C /opt/module/
[myhadoop@hadoop40 jdk1.8.0_212]$ pwd
/opt/module/jdk1.8.0_212
==============================================================================
#配置jdk的环境变量
[myhadoop@hadoop40 jdk1.8.0_212]$ sudo vim /etc/profile.d/my_evn.sh
[myhadoop@hadoop40 jdk1.8.0_212]$ source /etc/profile.d/my_evn.sh
[myhadoop@hadoop40 jdk1.8.0_212]$ echo $PATH
/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/home/myhadoop/.local/bin:/home/myhadoop/bin:/opt/module/jdk1.8.0_212/bin
[myhadoop@hadoop40 jdk1.8.0_212]$ sudo cat /etc/profile.d/my_evn.sh
export JAVA_HOME=/opt/module/jdk1.8.0_212
export PATH=$PATH:$JAVA_HOME/bin
[myhadoop@hadoop40 jdk1.8.0_212]$
[myhadoop@hadoop40 jdk1.8.0_212]$ sudo vim /etc/profile.d/my_evn.sh
[myhadoop@hadoop40 jdk1.8.0_212]$ sudo cat /etc/profile.d/my_evn.sh
export JAVA_HOME=/opt/module/jdk1.8.0_212
# 刷新配置文件
[myhadoop@hadoop40 jdk1.8.0_212]$ source /etc/profile.d/my_evn.sh
-----------------------------------------------------
# 验证配置成功没
[myhadoop@hadoop40 jdk1.8.0_212]$ echo $PATH
/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/home/myhadoop/.local/bin:/home/myhadoop/bin:/opt/module/jdk1.8.0_212/bin
-------------------------------------------------------
export PATH=$PATH:$JAVA_HOME/bin
[myhadoop@hadoop40 jdk1.8.0_212]$</code></pre> 
 </div> 
</div> 
<div>
 <span style="color:#333333">    4.2安装hadoop</span>
</div> 
<div> 
 <div> 
  <pre><code># 上传hadoop安装包

# 解压hadoop到module上
tar -zxvf hadoop-3.1.3.tar.gz -C /opt/module/
[myhadoop@hadoop40 hadoop-3.1.3]$ pwd
/opt/module/hadoop-3.1.3
==========================================
# 配置环境变量
[myhadoop@hadoop40 hadoop-3.1.3]$ sudo vim /etc/profile.d/my_evn.sh
[myhadoop@hadoop40 hadoop-3.1.3]$ sudo cat /etc/profile.d/my_evn.sh
#java
export JAVA_HOME=/opt/module/jdk1.8.0_212
export PATH=$PATH:$JAVA_HOME/bin
#hadoop
export HADOOP_HOME=/opt/module/hadoop-3.1.3
export PATH=$PATH:$HADOOP_HOME/bin
export PATH=$PATH:$HADOOP_HOME/sbin
[myhadoop@hadoop40 hadoop-3.1.3]$
============================================
# 刷新配置文件
[myhadoop@hadoop40 hadoop-3.1.3]$ source /etc/profile.d/my_evn.sh
# 验证结果
[myhadoop@hadoop40 hadoop-3.1.3]$ hadoop version
Hadoop 3.1.3
Source code repository https://gitbox.apache.org/repos/asf/hadoop.git -r ba631c436b806728f8ec2f54ab1e289526c90579
Compiled by ztang on 2019-09-12T02:47Z
Compiled with protoc 2.5.0
From source with checksum ec785077c385118ac91aadde5ec9799
This command was run using /opt/module/hadoop-3.1.3/share/hadoop/common/hadoop-common-3.1.3.jar
[myhadoop@hadoop40 hadoop-3.1.3]$</code></pre> 
 </div> 
</div> 
<div></div> 
<div>
 <span style="color:#333333">5.hadoop本地模式跑一下</span> 
 <div> 
  <pre><code>#wordcount小案列
# cd 到用户myhadoop的根目录，创建input目录，创建aa.txt,并写入内容
[myhadoop@hadoop40 ~]$ cd /home/myhadoop
[myhadoop@hadoop40 ~]$ pwd
/home/myhadoop
[myhadoop@hadoop40 ~]$ mkdir input
[myhadoop@hadoop40 ~]$ vim input/aa.txt
[myhadoop@hadoop40 ~]$ cat input/aa.txt
aa bb cc dd
ss
dd
ff ff
gg
aa
bb cc
================================
# 启动单词统计小案列
[myhadoop@hadoop40 ~]$ hadoop jar $HADOOP_HOME/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.3.jar wordcount input out
===============
#结果
[myhadoop@hadoop40 ~]$ ll
总用量 0
drwxrwxr-x. 2 myhadoop myhadoop 20 11月 11 10:58 input
drwxr-xr-x. 2 myhadoop myhadoop 88 11月 11 10:59 out
[myhadoop@hadoop40 ~]$ cd out/
[myhadoop@hadoop40 out]$ ll
总用量 4
-rw-r--r--. 1 myhadoop myhadoop 35 11月 11 10:59 part-r-00000
-rw-r--r--. 1 myhadoop myhadoop  0 11月 11 10:59 _SUCCESS
[myhadoop@hadoop40 out]$ cat part-r-00000
aa    2
bb    2
cc    2
dd    2
ff    2
gg    1
ss    1
[myhadoop@hadoop40 out]$

# 各个hadoop组件启动（不做演示）</code></pre> 
  <p></p> 
 </div> 
</div> 
<div>
 <span style="color:#333333">6.hadoop分布式模式</span>
</div> 
<div>
 <span style="color:#333333">hadoop规划</span>
</div> 
<div> 
 <div></div> 
 <table border="1" style="width:520px"><tbody>
<tr>
<td> 
     <div></div> </td>
<td> 
     <div>
      <span style="color:#333333">hadoop41</span>
     </div> </td>
<td> 
     <div>
      hadoop42
     </div> </td>
<td> 
     <div>
      hadoop43
     </div> </td>
</tr>
<tr>
<td> 
     <div></div> </td>
<td>nn  dn</td>
<td> 
     <div>
      <span style="color:#333333">dn</span>
     </div> </td>
<td> 
     <div>
      2nn  dn
     </div> </td>
</tr>
<tr>
<td> 
     <div>
      yarn
     </div> </td>
<td> 
     <div>
      nd
     </div> </td>
<td> 
     <div>
      nd rm
     </div> </td>
<td> 
     <div>
      nd
     </div> </td>
</tr>
</tbody></table>
 <div></div> 
</div> 
<div>
 <span style="color:#333333">    6.1配置hadoop必要的配置文件5个</span>
</div> 
<div>
 <span style="color:#333333">        配置core-site.xml</span>
</div> 
<div> 
 <div> 
  <pre><code>&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;
&lt;configuration&gt;
&lt;!--指定HDFS中NameNode的地址 --&gt;
    &lt;property&gt;
        &lt;name&gt;fs.defaultFS&lt;/name&gt;
        &lt;value&gt;hdfs://hadoop41:8020&lt;/value&gt;
&lt;/property&gt;
&lt;!-- 指定Hadoop运行时产生文件的存储目录 --&gt;
    &lt;property&gt;
        &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;
        &lt;value&gt;/opt/module/hadoop-3.1.3/data&lt;/value&gt;
&lt;/property&gt;
&lt;!--  通过web界面操作hdfs的权限 --&gt;
&lt;property&gt;
        &lt;name&gt;hadoop.http.staticuser.user&lt;/name&gt;
        &lt;value&gt;myhadoop&lt;/value&gt;
&lt;/property&gt;
&lt;!-- 后面hive的兼容性配置  --&gt;
    &lt;property&gt;
        &lt;name&gt;hadoop.proxyuser.myhadoop.hosts&lt;/name&gt;
        &lt;value&gt;*&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;hadoop.proxyuser.myhadoop.groups&lt;/name&gt;
        &lt;value&gt;*&lt;/value&gt;
&lt;/property&gt;
&lt;/configduration&gt;</code></pre> 
 </div> 
</div> 
<div>
 # 具体命令
</div> 
<div> 
 <div> 
  <pre><code>[myhadoop@hadoop40 hadoop]$ pwd
/opt/module/hadoop-3.1.3/etc/hadoop
--------------------------------------
[myhadoop@hadoop40 hadoop]$ vim core-site.xml
[myhadoop@hadoop40 hadoop]$ cat core-site.xml
&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;
&lt;!-- Put site-specific property overrides in this file. --&gt;


&lt;configuration&gt;
&lt;!--指定HDFS中NameNode的地址 --&gt;
    &lt;property&gt;
        &lt;name&gt;fs.defaultFS&lt;/name&gt;
        &lt;value&gt;hdfs://hadoop41:8020&lt;/value&gt;
&lt;/property&gt;
&lt;!-- 指定Hadoop运行时产生文件的存储目录 --&gt;
    &lt;property&gt;
        &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;
        &lt;value&gt;/opt/module/hadoop-3.1.3/data&lt;/value&gt;
&lt;/property&gt;
&lt;!--  通过web界面操作hdfs的权限 --&gt;
&lt;property&gt;
        &lt;name&gt;hadoop.http.staticuser.user&lt;/name&gt;
        &lt;value&gt;myhadoop&lt;/value&gt;
&lt;/property&gt;
&lt;!-- 后面hive的兼容性配置  --&gt;
    &lt;property&gt;
        &lt;name&gt;hadoop.proxyuser.myhadoop.hosts&lt;/name&gt;
        &lt;value&gt;*&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;hadoop.proxyuser.myhadoop.groups&lt;/name&gt;
        &lt;value&gt;*&lt;/value&gt;
&lt;/property&gt;


&lt;/configuration&gt;
[myhadoop@hadoop40 hadoop]$</code></pre> 
  <p></p> 
 </div> 
 <div></div> 
</div> 
<div></div> 
<div>
 <span style="color:#333333">配置hdfs-site.xml</span>
</div> 
<div> 
 <div> 
  <pre><code>&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;

&lt;configuration&gt;
    &lt;property&gt;
        &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt;
        &lt;value&gt;hadoop43:9868&lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;</code></pre> 
  <p></p> 
 </div> 
 <div></div> 
 <div></div> 
</div> 
<div>
 <span style="color:#333333"># 具体命令</span>
</div> 
<div> 
 <div> 
  <pre><code>[myhadoop@hadoop40 hadoop]$ vim hdfs-site.xml
[myhadoop@hadoop40 hadoop]$ cat hdfs-site.xml
&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;

&lt;!-- Put site-specific property overrides in this file. --&gt;
&lt;configuration&gt;

    &lt;property&gt;
        &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt;
        &lt;value&gt;hadoop43:9868&lt;/value&gt;
    &lt;/property&gt;

&lt;/configuration&gt;
[myhadoop@hadoop40 hadoop]$</code></pre> 
 </div> 
</div> 
<div></div> 
<div>
 <span style="color:#333333">配置mopred-site.xml</span>
</div> 
<div> 
 <div> 
  <pre><code>&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;
&lt;configuration&gt;
&lt;!-- 指定MR运行在Yarn上 --&gt;
    &lt;property&gt;
        &lt;name&gt;mapreduce.framework.name&lt;/name&gt;
        &lt;value&gt;yarn&lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;</code></pre> 
  <p></p> 
 </div> 
</div> 
<div>
 <span style="color:#333333"># 具体命令</span>
</div> 
<div> 
 <div> 
  <pre><code>[myhadoop@hadoop40 hadoop]$ vim mapred-site.xml
[myhadoop@hadoop40 hadoop]$ cat mapred-site.xml
&lt;?xml version="1.0"?&gt;
&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;

&lt;!-- Put site-specific property overrides in this file. --&gt;
&lt;configuration&gt;
&lt;!-- 指定MR运行在Yarn上 --&gt;
    &lt;property&gt;
        &lt;name&gt;mapreduce.framework.name&lt;/name&gt;
        &lt;value&gt;yarn&lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;
[myhadoop@hadoop40 hadoop]$</code></pre> 
 </div> 
</div> 
<div>
 <span style="color:#333333">配置yarn-site.xml</span>
</div> 
<div> 
 <div> 
  <pre><code>&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;


&lt;configuration&gt;
&lt;!--  Reducer获取数据的方式--&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;
        &lt;value&gt;mapreduce_shuffle&lt;/value&gt;
&lt;/property&gt;
&lt;!--  指定YARN的ResourceManager的地址--&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;
        &lt;value&gt;hadoop42&lt;/value&gt;
&lt;/property&gt;
&lt;!-- 环境变量通过从NodeManagers的容器继承的环境属性，对于mapreduce应用程序，除了默认值 hadoop op_mapred_home应该被添加外。属性值 还有如下--&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.nodemanager.env-whitelist&lt;/name&gt;
&lt;value&gt;JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME&lt;/value&gt;
&lt;/property&gt;
&lt;!-- 解决Yarn在执行程序遇到超出虚拟内存限制，Container被kill  --&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.nodemanager.pmem-check-enabled&lt;/name&gt;
        &lt;value&gt;false&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.nodemanager.vmem-check-enabled&lt;/name&gt;
        &lt;value&gt;false&lt;/value&gt;
    &lt;/property&gt;
&lt;!-- 后面hive的兼容性配置  --&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.scheduler.minimum-allocation-mb&lt;/name&gt;
        &lt;value&gt;512&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.scheduler.maximum-allocation-mb&lt;/name&gt;
        &lt;value&gt;4096&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.nodemanager.resource.memory-mb&lt;/name&gt;
        &lt;value&gt;4096&lt;/value&gt;
&lt;/property&gt;

&lt;/configuration&gt;</code></pre> 
  <p></p> 
 </div> 
</div> 
<div>
 <span style="color:#333333"># 具体命令</span>
</div> 
<div> 
 <div> 
  <pre><code>[myhadoop@hadoop40 hadoop]$ vim yarn-site.xml
[myhadoop@hadoop40 hadoop]$ cat yarn-site.xml
&lt;?xml version="1.0"?&gt;

&lt;configuration&gt;

&lt;!--  Reducer获取数据的方式--&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;
        &lt;value&gt;mapreduce_shuffle&lt;/value&gt;
&lt;/property&gt;
&lt;!--  指定YARN的ResourceManager的地址--&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;
        &lt;value&gt;hadoop42&lt;/value&gt;
&lt;/property&gt;
&lt;!-- 环境变量通过从NodeManagers的容器继承的环境属性，对于mapreduce应用程序，除了默认值 hadoop op_mapred_home应该被添加外。属性值 还有如下--&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.nodemanager.env-whitelist&lt;/name&gt;
  &lt;value&gt;JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME&lt;/value&gt;
&lt;/property&gt;
&lt;!-- 解决Yarn在执行程序遇到超出虚拟内存限制，Container被kill  --&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.nodemanager.pmem-check-enabled&lt;/name&gt;
        &lt;value&gt;false&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.nodemanager.vmem-check-enabled&lt;/name&gt;
        &lt;value&gt;false&lt;/value&gt;
    &lt;/property&gt;
&lt;!-- 后面hive的兼容性配置  --&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.scheduler.minimum-allocation-mb&lt;/name&gt;
        &lt;value&gt;512&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.scheduler.maximum-allocation-mb&lt;/name&gt;
        &lt;value&gt;4096&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.nodemanager.resource.memory-mb&lt;/name&gt;
        &lt;value&gt;4096&lt;/value&gt;
   &lt;/property&gt;

&lt;/configuration&gt;
[myhadoop@hadoop40 hadoop]$</code></pre> 
  <p></p> 
 </div> 
</div> 
<div></div> 
<div>
 <span style="color:#333333">配置wokers</span>
</div> 
<div> 
 <div> 
  <pre><code>hadoop41
hadoop42
hadoop43</code></pre> 
 </div> 
</div> 
<div>
 <span style="color:#333333"># 具体命令</span>
</div> 
<div> 
 <div> 
  <pre><code>#这里的内容最好手写，怕复制是多复制了空格或者其他不显示的字符
[myhadoop@hadoop40 hadoop]$ vim workers
[myhadoop@hadoop40 hadoop]$ cat workers
hadoop41
hadoop42
hadoop43
[myhadoop@hadoop40 hadoop]$</code></pre> 
 </div> 
</div> 
<div>
 <span style="color:#333333">    6.2.配置ssh免密通讯    </span> 
 <pre><code># 关闭hadoop40主机，再克隆主机hadoop41，hadoop42,hadoop43
      #分别启动hadoop41，hadoop42，hadoop43，
# 修改主机名，修改静态ip
==================================
vim /etc/hostname
[myhadoop@hadoop41 ~]$ hostname
hadoop41
[myhadoop@hadoop41 ~]$
*****************************************************
vim /etc/sysconfig/network-scripts/ifc
[myhadoop@hadoop41 ~]$ sudo cat /etc/sysconfig/network-scripts/ifcfg-ens33
TYPE=Ethernet
PROXY_METHOD=none
BROWSER_ONLY=no
BOOTPROTO=static
DEFROUTE=yes
IPV4_FAILURE_FATAL=no
IPV6INIT=yes
IPV6_AUTOCONF=yes
IPV6_DEFROUTE=yes
IPV6_FAILURE_FATAL=no
IPV6_ADDR_GEN_MODE=stable-privacy
NAME=ens33
UUID=60a2315f-9632-42ad-9fe0-e74d628c79ad
DEVICE=ens33
ONBOOT=yes
IPADDR=192.168.1.41
GATEWAY=192.168.1.2
DNS1=114.114.114.114
DNS2=8.8.8.8
[myhadoop@hadoop41 ~]$</code></pre> 
 <div></div> 
 <div>
  <span style="color:#333333"><span style="background-color:#fbfaf8"><span style="color:#333333">#重启主机，配置ssh</span></span></span> 
  <pre><code># 配置ssh,(三次enter键，不输入任何东西)
========================
[myhadoop@hadoop41 ~]$ ssh-keygen -t rsa
Generating public/private rsa key pair.
Enter file in which to save the key (/home/myhadoop/.ssh/id_rsa):
Created directory '/home/myhadoop/.ssh'.
Enter passphrase (empty for no passphrase):
Enter same passphrase again:
Your identification has been saved in /home/myhadoop/.ssh/id_rsa.
Your public key has been saved in /home/myhadoop/.ssh/id_rsa.pub.
The key fingerprint is:
SHA256:h+TNs1/44FPIcmswi1gCbb1uSKMc2KQHFb1BVepIm78 myhadoop@hadoop41
The key's randomart image is:
+---[RSA 2048]----+
|    .+.....      |
|    . o  .       |
|   . ..+o        |
|  . o.+B.+       |
|   * o+ S.=. .   |
|  o + +.o.+o+..  |
|   o + B...*oo.  |
|    o o +..o++   |
|       .E  .o..  |
+----[SHA256]-----+
******************************************************** 复值公钥到对应的主机上
[myhadoop@hadoop41 ~]$ ssh-copy-id hadoop41
/usr/bin/ssh-copy-id: INFO: Source of key(s) to be installed: "/home/myhadoop/.ssh/id_rsa.pub"
The authenticity of host 'hadoop41 (192.168.1.41)' can't be established.
ECDSA key fingerprint is SHA256:qXwGkWeUQTyCeB/11yxU7S1O97QjnNQYIuOsZIrRREI.
ECDSA key fingerprint is MD5:cb:37:5a:78:4e:b3:dd:53:1d:fb:46:5f:28:97:8a:0b.
Are you sure you want to continue connecting (yes/no)? yes
/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed
/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys
myhadoop@hadoop41's password:


Number of key(s) added: 1


Now try logging into the machine, with:   "ssh 'hadoop41'"
and check to make sure that only the key(s) you wanted were added.

[myhadoop@hadoop41 ~]$
=================================================
#查看结果
[myhadoop@hadoop43 ~]$ ssh hadoop2
ssh: Could not resolve hostname hadoop2: Name or service not known
[myhadoop@hadoop43 ~]$ ssh hadoop42
Last login: Thu Nov 11 14:06:24 2021 from hadoop41
[myhadoop@hadoop42 ~]$ ssh hadoop41
Last failed login: Thu Nov 11 14:08:10 CST 2021 from hadoop42 on ssh:notty
There was 1 failed login attempt since the last successful login.
Last login: Thu Nov 11 13:57:01 2021 from 192.168.1.9
[myhadoop@hadoop41 ~]$ ssh hadoop43
Last login: Thu Nov 11 14:08:47 2021 from hadoop42
[myhadoop@hadoop43 ~]$ ssh hadoop41
Last login: Thu Nov 11 14:10:32 2021 from hadoop42
[myhadoop@hadoop41 ~]$</code></pre> 
 </div> 
 <div></div> 
</div> 
<div>
 <span style="color:#333333">    6.3编写脚本小工具rsync，jps</span>
</div> 
<div>
 <span style="color:#333333">    #编写清除hadoop数据的工具</span>
</div> 
<div> 
 <div> 
  <pre><code>[myhadoop@hadoop41 mybin]$ cat clear.sh
#!/bin/bash
#清除hadoop产生的数据
set -u
set -e

for host in hadoop41 hadoop42 hadoop43
do
    echo "========================== $host ======================"
    ssh $host rm -rf $HADOOP_HOME/data $HADOOP_HOME/logs
    ssh $host sudo rm -rf /tmp/*     
done
[myhadoop@hadoop41 mybin]$</code></pre> 
  <p></p> 
 </div> 
</div> 
<div>
 <span style="color:#333333">#编写同步分发文件的工具</span>
</div> 
<div> 
 <div> 
  <pre><code>[myhadoop@hadoop41 mybin]$ cat myrsync
#!/bin/bash
set -u
set -e
# 判断参数的个数
if [ $# -lt 1 ];then
    echo "Not Enough Arguement !"
    exit
fi
#遍历集群中的主机
for host in hadoop41 hadoop42 hadoop43
do
    echo "======================= $host ========================"
    for file in $@
    do            
        if [ -e $file ];then
            pdir=$(cd -P $(dirname $file);pwd)
            fname=$(basename $file)
            ssh $host "mkdir -p $pdir"
            rsync -av $pdir/$fname $host:$pdir
        else
            echo "$file does not exists!"
    done
done
[myhadoop@hadoop41 mybin]$</code></pre> 
  <p></p> 
 </div> 
</div> 
<div>
 <span style="color:#333333">#编写查看启动服务的工具</span> 
 <div> 
  <pre><code>[myhadoop@hadoop41 mybin]$ cat jpsall
#!/bin/bash
set -e
set -u


# 获取主机的上执行的任务
for host in hadoop41 hadoop42 hadoop43
do
    echo "======================= $host ==============================="
    ssh $host jps
done
[myhadoop@hadoop41 mybin]$

</code></pre> 
 </div> 
</div> 
<div>
 <span style="color:#333333">    6.4启动集群</span>
</div> 
<div>
   
</div> 
<div> 
 <div>
  <span style="color:#333333"><span style="background-color:#fbfaf8">  </span></span> 
  <pre><code># 格式化namenode（第一次启动集群需要格式化代码）
[myhadoop@hadoop41 mybin]$ hdfs namenode -format
****************************************************************
#启动namenode
[myhadoop@hadoop41 mybin]$ start-dfs.sh
Starting namenodes on [hadoop41]
Starting datanodes
hadoop42: WARNING: /opt/module/hadoop-3.1.3/logs does not exist. Creating.
hadoop43: WARNING: /opt/module/hadoop-3.1.3/logs does not exist. Creating.
Starting secondary namenodes [hadoop43]
[myhadoop@hadoop41 mybin]$
****************************************************************
#启动resoucemanager
[myhadoop@hadoop41 mybin]$ start-yarn.sh
Starting resourcemanager
Starting nodemanagers
[myhadoop@hadoop41 mybin]$
#验证结果
[myhadoop@hadoop41 mybin]$ jpsall
======================= hadoop41 ===============================
4551 DataNode
4392 NameNode
5000 Jps
4857 NodeManager
======================= hadoop42 ===============================
3361 NodeManager
3555 Jps
2853 DataNode
3045 ResourceManager
======================= hadoop43 ===============================
3104 Jps
2963 NodeManager
2756 DataNode
2873 SecondaryNameNode
[myhadoop@hadoop41 mybin]$</code></pre> 
 </div> 
</div> 
<div></div> 
<div>
 <span style="color:#333333">6.5浏览器验证，fds-du*.js的脚本61行有错误需要修改一下</span>
</div> 
<div> 
 <div>
  <span style="color:#333333"><span style="background-color:#fbfaf8">#浏览器验证地址</span></span> 
  <pre><code>#hdfs数据存储（namenode,datanode）
http://hadoop41:9870/dfshealth.html#tab-overview
#执行任务（yarn）
http://hadoop42:8088/cluster
#辅助节点日志
http://hadoop43:9868/status.html
# 日志服务器地址
http://hadoop41:19888/jobhistory </code></pre> 
 </div> 
</div> 
<div></div> 
<div> 
 <div>
  <span style="color:#333333"><span style="background-color:#fbfaf8">#hadoop3.1.3版本有点问题</span></span> 
  <pre><code>/opt/module/hadoop-3.1.3/share/hadoop/hdfs/webapps/static/dfs-dust.js
vim dfs-dust.js

查看dfs-dust.js的第61行
   'date_tostring' : function (v) {
      return moment(Number(v)).format('ddd MMM DD HH:mm:ss ZZ YYYY');
    },
并修改函数返回值如下：
'date_tostring' : function (v) {
  return new Date(Number(v)).toLocaleString();
},

**************************************************************
#修改完后同步分发一下
[myhadoop@hadoop41 share]$ myrsync hadoop/
======================= hadoop41 ========================
sending incremental file list


sent 16,133 bytes  received 88 bytes  10,814.00 bytes/sec
total size is 372,262,087  speedup is 22,949.39
======================= hadoop42 ========================
sending incremental file list
hadoop/hdfs/webapps/static/
hadoop/hdfs/webapps/static/dfs-dust.js


sent 16,882 bytes  received 146 bytes  34,056.00 bytes/sec
total size is 372,262,087  speedup is 21,861.76
======================= hadoop43 ========================
sending incremental file list
hadoop/hdfs/webapps/static/
hadoop/hdfs/webapps/static/dfs-dust.js


sent 16,882 bytes  received 146 bytes  34,056.00 bytes/sec
total size is 372,262,087  speedup is 21,861.76
[myhadoop@hadoop41 share]$</code></pre> 
 </div> 
</div> 
<div>
 <span style="color:#333333">    #执行小案列</span>
</div> 
<div> 
 <div> 
  <pre><code>在浏览器hadoop41上创建input目录并上传aa.txt
=========================================aa.txt内容
aa
dd
ds
ff ff
dd
gg asf
aa
aa dd
========================================
#在hadoop41后台上执行命令
[myhadoop@hadoop41 share]$ hadoop jar hadoop/mapreduce/hadoop-mapreduce-examples-3.1.3.jar wordcount /input /out
运行结果==================================
aa    3
asf    1
dd    3
ds    1
ff    2
gg    1
下图</code></pre> 
 </div> 
</div> 
<div></div> 
<div>
 <img alt="" height="709" src="https://images2.imgbox.com/e0/0e/VuDqUfAS_o.png" width="1200">
</div> 
<div></div> 
<div>
 <span style="color:#333333">    6.6配置历史服务器，配置日志汇聚</span>
</div> 
<div> 
 <div>
  <span style="color:#333333"><span style="background-color:#fbfaf8"># 日志服务器</span></span> 
  <pre><code># mapred-site.xml配置如下内容
&lt;!-- 历史服务器端地址 --&gt;
&lt;property&gt;
    &lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt;
    &lt;value&gt;hadoop41:10020&lt;/value&gt;
&lt;/property&gt;
&lt;!-- 历史服务器web端地址 --&gt;
&lt;property&gt;
    &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt;
    &lt;value&gt;hadoop41:19888&lt;/value&gt;
&lt;/property&gt;</code></pre> 
 </div> 
 <div>
  #查看配置的内容 
  <pre><code>[myhadoop@hadoop41 hadoop]$ vim mapred-site.xml
[myhadoop@hadoop41 hadoop]$ cat mapred-site.xml
&lt;?xml version="1.0"?&gt;
&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;

&lt;configuration&gt;
&lt;!-- 指定MR运行在Yarn上 --&gt;
    &lt;property&gt;
        &lt;name&gt;mapreduce.framework.name&lt;/name&gt;
        &lt;value&gt;yarn&lt;/value&gt;
    &lt;/property&gt;
&lt;!-- 历史服务器端地址 --&gt;
&lt;property&gt;
    &lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt;
    &lt;value&gt;hadoop41:10020&lt;/value&gt;
&lt;/property&gt;
&lt;!-- 历史服务器web端地址 --&gt;
&lt;property&gt;
    &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt;
    &lt;value&gt;hadoop41:19888&lt;/value&gt;
&lt;/property&gt;

&lt;/configuration&gt;
[myhadoop@hadoop41 hadoop]$ d
-----------------------------------------------
#分发到其他集群主机上
[myhadoop@hadoop41 hadoop]$ myrsync ./
======================= hadoop41 ========================
sending incremental file list


sent 865 bytes  received 13 bytes  1,756.00 bytes/sec
total size is 108,315  speedup is 123.37
======================= hadoop42 ========================
sending incremental file list
./
mapred-site.xml


sent 1,400 bytes  received 51 bytes  2,902.00 bytes/sec
total size is 108,315  speedup is 74.65
======================= hadoop43 ========================
sending incremental file list
./
mapred-site.xml


sent 1,400 bytes  received 51 bytes  2,902.00 bytes/sec
total size is 108,315  speedup is 74.65
[myhadoop@hadoop41 hadoop]$</code></pre> 
 </div> 
 <div>
  <span style="color:#333333"><span style="background-color:#fbfaf8">#启动历史服务器</span></span> 
  <pre><code>[myhadoop@hadoop41 hadoop]$ mapred --daemon start historyserver
[myhadoop@hadoop41 hadoop]$ jpsall
======================= hadoop41 ===============================
5504 JobHistoryServer
4551 DataNode
4392 NameNode
4857 NodeManager
5577 Jps
======================= hadoop42 ===============================
3361 NodeManager
3985 Jps
2853 DataNode
3045 ResourceManager
======================= hadoop43 ===============================
3442 Jps
2963 NodeManager
2756 DataNode
2873 SecondaryNameNode
[myhadoop@hadoop41 hadoop]$</code></pre> 
 </div> 
</div> 
<div>
 # 开启日志汇聚
</div> 
<div> 
 <div>
  <span style="color:#333333"><span style="background-color:#fbfaf8"># yarn-site.xml中新增如下内容</span></span>
 </div> 
 <div>
    
  <pre><code>&lt;!-- 开启日志聚集  --&gt;
&lt;property&gt;
    &lt;name&gt;yarn.log-aggregation-enable&lt;/name&gt;
    &lt;value&gt;true&lt;/value&gt;
&lt;/property&gt;
&lt;!-- 访问路径--&gt;
&lt;property&gt;
    &lt;name&gt;yarn.log.server.url&lt;/name&gt;
    &lt;value&gt;http://hadoop41:19888/jobhistory/logs&lt;/value&gt;
&lt;/property&gt;
&lt;!-- 保存的时间7天 --&gt;
&lt;property&gt;
    &lt;name&gt;yarn.log-aggregation.retain-seconds&lt;/name&gt;
    &lt;value&gt;604800&lt;/value&gt;
&lt;/property&gt;</code></pre> 
 </div> 
 <div>
  <span style="color:#333333"><span style="background-color:#fbfaf8"># 分发到其他主机上</span></span>
 </div> 
 <div> 
  <pre><code>[myhadoop@hadoop41 hadoop]$ myrsync ./
======================= hadoop41 ========================
sending incremental file list
sent 866 bytes  received 13 bytes  1,758.00 bytes/sec
total size is 108,653  speedup is 123.61
======================= hadoop42 ========================
sending incremental file list
./
yarn-site.xml
sent 1,921 bytes  received 57 bytes  1,318.67 bytes/sec
total size is 108,653  speedup is 54.93
======================= hadoop43 ========================
sending incremental file list
./
yarn-site.xml
sent 1,921 bytes  received 57 bytes  3,956.00 bytes/sec
total size is 108,653  speedup is 54.93
[myhadoop@hadoop41 hadoop]$
-----------------------------------------------------------------
#验证结果：
#重启集群，重新跑Wordcount案例，获得日志，点击日志任务编号，在浏览器上查看日志</code></pre> 
  <p></p> 
 </div> 
</div> 
<p></p>
                </div>

		</div>
	</article>
</main>




			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程小白.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://www.w3counter.com/tracker.js?id=150625"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>
	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>