<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<title>【Elasticsearch】学习笔记-p1（初识Elasticsearch） - 编程小白</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程小白" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程小白</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">【Elasticsearch】学习笔记-p1（初识Elasticsearch）</h1>
			
		</header>
		<div class="content post__content clearfix">
			


                <div id="content_views" class="markdown_views prism-github-gist">
                    
                        
                    
                    <p></p>
<div class="toc">
 <h3>文章目录</h3>
 <ul>
<li><a href="#Elasticsearch_3">初识Elasticsearch</a></li>
<li>
<ul>
<li><a href="#1ES_5">1.了解ES</a></li>
<li><a href="#2_13">2.倒排索引</a></li>
<li>
<ul>
<li><a href="#21__15">2.1 正向索引</a></li>
<li><a href="#22__34">2.2 倒排索引</a></li>
<li><a href="#23__69">2.3 正向和倒排</a></li>
</ul>
   </li>
<li><a href="#3es_95">3.es的一些概念</a></li>
<li>
<ul>
<li><a href="#31__97">3.1 文档和字段</a></li>
<li><a href="#32__105">3.2 索引和映射</a></li>
<li><a href="#33_mysql__elasticsearch_121">3.3 mysql 与 elasticsearch</a></li>
</ul>
   </li>
<li><a href="#4ElasticsearchkibanaIK_142">4.安装Elasticsearch、kibana、IK分词器</a></li>
<li>
<ul>
<li><a href="#41_Elasticsearch_144">4.1 部署单点Elasticsearch</a></li>
<li><a href="#42_kibana_205">4.2 部署kibana</a></li>
<li><a href="#43_IK_228">4.3 安装IK分词器</a></li>
</ul>
   </li>
<li><a href="#5_372">5.扩展和停用词典</a></li>
<li>
<ul>
<li><a href="#51__374">5.1 扩展词典</a></li>
<li><a href="#52__422">5.2 停用词典</a></li>
</ul>
  </li>
</ul>
 </li>
</ul>
</div>
<br> 视频指路?
<a href="https://www.bilibili.com/video/BV1LQ4y127n4">B站黑马微服务</a>超级推荐！！
<p></p> 
<h1>
<a id="Elasticsearch_3"></a>初识Elasticsearch</h1> 
<h2>
<a id="1ES_5"></a>1.了解ES</h2> 
<ul>
<li>
<code>elasticsearch</code>是一款非常强大的开源搜索引擎，具备非常多强大功能，可以帮助我们从海量数据中快速找到需要的内容</li>
<li>
<code>elasticsearch</code>结合<code>kibana</code>、<code>Logstash</code>、<code>Beats</code>，也就是<code>elastic stack（ELK）</code>。被广泛应用在日志数据分析、实时监控等领域</li>
<li>而<code>elasticsearch</code>是<code>elastic stack</code>的核心，负责存储、搜索、分析数据</li>
</ul> 
<p><img src="https://images2.imgbox.com/2c/2c/570Unasp_o.png" alt="img"></p> 
<h2>
<a id="2_13"></a>2.倒排索引</h2> 
<h3>
<a id="21__15"></a>2.1 正向索引</h3> 
<blockquote> 
 <p>倒排索引的概念是基于MySQL这样的正向索引而言的</p> 
</blockquote> 
<p>那么什么是正向索引呢？例如给下表（tb_goods）中的id创建索引：</p> 
<p><img src="https://images2.imgbox.com/33/c3/OMAqYCx4_o.png" alt="img"></p> 
<p>如果是根据 id 查询，那么直接走索引，查询速度非常快。</p> 
<p>但如果是基于 title 做模糊查询，只能是逐行扫描数据，流程如下：</p> 
<ol>
<li>用户搜索数据，条件是 title 符合 <code>"%手机%"</code>
</li>
<li>逐行获取数据，比如 id 为 1 的数据</li>
<li>判断数据中的 title 是否符合用户搜索条件</li>
<li>如果符合则放入结果集，不符合则丢弃。然后回到步骤1</li>
</ol> 
<p>逐行扫描，也就是全表扫描，随着数据量增加，其查询效率也会越来越低。当数据量达到数百万时，就是。。。</p> 
<h3>
<a id="22__34"></a>2.2 倒排索引</h3> 
<p>倒排索引中有两个非常重要的概念：</p> 
<ul>
<li>
<strong>文档</strong>（<code>Document</code>）：用来搜索的数据，其中的每一条数据就是一个文档。例如一个网页、一个商品信息</li>
<li>
<strong>词条</strong>（<code>Term</code>）：对文档数据或用户搜索数据，利用某种算法分词，得到的具备含义的词语就是词条。例如：我是中国人，就可以分为：我、是、中国人、中国、国人这样的几个词条</li>
</ul> 
<p><strong>创建倒排索引</strong>是对正向索引的一种特殊处理，流程如下：</p> 
<ul>
<li>将每一个文档的数据利用算法分词，得到一个个词条</li>
<li>创建表，每行数据包括词条、词条所在文档id、位置等信息</li>
<li>因为词条唯一性，可以给词条创建索引，例如hash表结</li>
</ul> 
<blockquote> 
 <p>举个栗子：</p> 
 <p>如图：</p> 
 <p><img src="https://images2.imgbox.com/9b/c6/SRY4q7uM_o.png" alt="img"></p> 
 <p>倒排索引的<strong>搜索流程</strong>如下（以搜索"华为手机"为例）：</p> 
 <p>1）用户输入条件<code>"华为手机"</code>进行搜索。</p> 
 <p>2）对用户输入内容<strong>分词</strong>，得到词条：<code>华为</code>、<code>手机</code>。</p> 
 <p>3）拿着词条在倒排索引中查找，可以得到包含词条的文档id：1、2、3。</p> 
 <p>4）拿着文档id到正向索引中查找具体文档。</p> 
 <p>如图：</p> 
 <p><img src="https://images2.imgbox.com/0e/89/BM2iyUCv_o.png" alt="img"></p> 
 <p>虽然要先查询倒排索引，再查询倒排索引，但是无论是词条、还是文档id都<strong>建立了索引，查询速度非常快</strong>！无需全表扫描。</p> 
</blockquote> 
<h3>
<a id="23__69"></a>2.3 正向和倒排</h3> 
<blockquote> 
 <p>那么为什么一个叫做正向索引，一个叫做倒排索引呢？</p> 
</blockquote> 
<ul>
<li>
<strong>正向索引</strong>是最传统的，根据id索引的方式。但根据词条查询时，必须先逐条获取每个文档，然后判断文档中是否包含所需要的词条，是<strong>根据文档找词条的过程</strong>。</li>
<li>而<strong>倒排索引</strong>则相反，是先找到用户要搜索的词条，根据词条得到保护词条的文档的id，然后根据id获取文档。是<strong>根据词条找文档的过程</strong>。</li>
</ul> 
<blockquote> 
 <p>正向索引和倒排索引各自的优缺点：</p> 
</blockquote> 
<p><strong>正向索引</strong>：</p> 
<ul>
<li>优点： 
  <ul>
<li>可以给多个字段创建索引</li>
<li>根据索引字段搜索、排序速度非常快</li>
</ul> </li>
<li>缺点： 
  <ul><li>根据非索引字段，或者索引字段中的部分词条查找时，只能全表扫描。</li></ul> </li>
</ul> 
<p><strong>倒排索引</strong>：</p> 
<ul>
<li>优点： 
  <ul><li>根据词条搜索、模糊搜索时，速度非常快</li></ul> </li>
<li>缺点： 
  <ul>
<li>只能给词条创建索引，而不是字段</li>
<li>无法根据字段做排序</li>
</ul> </li>
</ul> 
<h2>
<a id="3es_95"></a>3.es的一些概念</h2> 
<h3>
<a id="31__97"></a>3.1 文档和字段</h3> 
<p><code>elasticsearch</code> 是面向**文档（Document）**存储的，可以是数据库中的一条商品数据，一个订单信息。文档数据会被序列化为 <code>json</code> 格式后存储在elasticsearch中：</p> 
<p><a href="https://cdn.jsdelivr.net/gh/lexinhu/Image/img/2021/20210918212707.png"><img src="https://images2.imgbox.com/1c/79/KHBmbERU_o.png" alt="img"></a></p> 
<p>而 JSON 文档中往往包含很多的<strong>字段（Field）</strong>，类似于数据库中的列。</p> 
<h3>
<a id="32__105"></a>3.2 索引和映射</h3> 
<p><strong>索引（Index）</strong>，就是相同类型的文档的集合。</p> 
<p>例如：</p> 
<ul>
<li>所有用户文档，就可以组织在一起，称为用户的索引；</li>
<li>所有商品的文档，可以组织在一起，称为商品的索引；</li>
<li>所有订单的文档，可以组织在一起，称为订单的索引；</li>
</ul> 
<p><a href="https://cdn.jsdelivr.net/gh/lexinhu/Image/img/2021/20210918213357.png"><img src="https://images2.imgbox.com/7b/f5/YMp0ISos_o.png" alt="img"></a></p> 
<p>因此，我们可以把索引当做是数据库中的表。</p> 
<p>数据库的表会有约束信息，用来定义表的结构、字段的名称、类型等信息。因此，索引库中就有<strong>映射（mapping）</strong>，是索引中文档的字段约束信息，类似表的结构约束。</p> 
<h3>
<a id="33_mysql__elasticsearch_121"></a>3.3 mysql 与 elasticsearch</h3> 
<table>
<thead><tr>
<th align="left"><strong>MySQL</strong></th>
<th align="left"><strong>Elasticsearch</strong></th>
<th align="left"><strong>说明</strong></th>
</tr></thead>
<tbody>
<tr>
<td align="left">Table</td>
<td align="left">Index</td>
<td align="left">索引index，就是文档的集合，类似数据库的表table</td>
</tr>
<tr>
<td align="left">Row</td>
<td align="left">Document</td>
<td align="left">文档（Document），就是一条条的数据，类似数据库中的行（Row），文档都是JSON格式</td>
</tr>
<tr>
<td align="left">Column</td>
<td align="left">Field</td>
<td align="left">字段（Field），就是JSON文档中的字段，类似数据库中的列（Column）</td>
</tr>
<tr>
<td align="left">Schema</td>
<td align="left">Mapping</td>
<td align="left">Mapping（映射）是索引中文档的约束，例如字段类型约束。类似数据库的表结构（Schema）</td>
</tr>
<tr>
<td align="left">SQL</td>
<td align="left">DSL</td>
<td align="left">DSL是elasticsearch提供的JSON风格的请求语句，用来操作elasticsearch，实现CRUD</td>
</tr>
</tbody>
</table>
<ul>
<li>Mysql：擅长事务类型操作，可以确保数据的安全和一致性</li>
<li>Elasticsearch：擅长海量数据的搜索、分析、计算</li>
</ul> 
<p>因此在企业中，往往是两者结合使用：</p> 
<ul>
<li>对安全性要求较高的写操作，使用 MySQL 实现</li>
<li>对查询性能要求较高的搜索需求，使用 ELasticsearch 实现</li>
<li>两者再基于某种方式，实现数据的同步，保证一致性</li>
</ul> 
<p><a href="https://cdn.jsdelivr.net/gh/lexinhu/Image/img/2021/20210918213631.png"><img src="https://images2.imgbox.com/b3/22/OTLGdmIM_o.png" alt="img"></a></p> 
<h2>
<a id="4ElasticsearchkibanaIK_142"></a>4.安装Elasticsearch、kibana、IK分词器</h2> 
<h3>
<a id="41_Elasticsearch_144"></a>4.1 部署单点Elasticsearch</h3> 
<p>因为我们还需要部署kibana容器，因此需要让es和kibana容器互联。这里先创建一个网络：</p> 
<pre><code class="prism language-shell">docker network create es-net
</code></pre> 
<hr> 
<p>法一：可以直接pull（速度较慢）</p> 
<p>法二：用提供的镜像的tar包</p> 
<p>这里我们采用elasticsearch的7.12.1版本的镜像，这个镜像体积非常大，接近1G。不建议大家自己pull。</p> 
<p>这里演示法二，大家将其上传到虚拟机中，然后运行命令加载即可：</p> 
<pre><code class="prism language-shell"><span class="token comment"># 导入数据</span>
docker load -i es.tar
</code></pre> 
<p>同理还有<code>kibana</code>的tar包也需要这样做。</p> 
<hr> 
<p>运行docker命令，部署单点es：</p> 
<pre><code class="prism language-shell">docker run -d <span class="token punctuation"></span>
	--name es <span class="token punctuation"></span>
    -e <span class="token string">"ES_JAVA_OPTS=-Xms512m -Xmx512m"</span> <span class="token punctuation"></span>
    -e <span class="token string">"discovery.type=single-node"</span> <span class="token punctuation"></span>
    -v es-data:/usr/share/elasticsearch/data <span class="token punctuation"></span>
    -v es-plugins:/usr/share/elasticsearch/plugins <span class="token punctuation"></span>
    --privileged <span class="token punctuation"></span>
    --network es-net <span class="token punctuation"></span>
    -p <span class="token number">9200</span>:9200 <span class="token punctuation"></span>
    -p <span class="token number">9300</span>:9300 <span class="token punctuation"></span>
elasticsearch:7.12.1
</code></pre> 
<p>命令解释：</p> 
<ul>
<li>
<code>-e "cluster.name=es-docker-cluster"</code>：设置集群名称</li>
<li>
<code>-e "http.host=0.0.0.0"</code>：监听的地址，可以外网访问</li>
<li>
<code>-e "ES_JAVA_OPTS=-Xms512m -Xmx512m"</code>：内存大小</li>
<li>
<code>-e "discovery.type=single-node"</code>：非集群模式</li>
<li>
<code>-v es-data:/usr/share/elasticsearch/data</code>：挂载逻辑卷，绑定es的数据目录</li>
<li>
<code>-v es-logs:/usr/share/elasticsearch/logs</code>：挂载逻辑卷，绑定es的日志目录</li>
<li>
<code>-v es-plugins:/usr/share/elasticsearch/plugins</code>：挂载逻辑卷，绑定es的插件目录</li>
<li>
<code>--privileged</code>：授予逻辑卷访问权</li>
<li>
<code>--network es-net</code> ：加入一个名为es-net的网络中</li>
<li>
<code>-p 9200:9200</code>：端口映射配置</li>
</ul> 
<p>在浏览器中输入：http://192.168.150.101:9200 （需要改成自己虚拟机的ip）即可看到elasticsearch的响应结果：</p> 
<p><img src="https://images2.imgbox.com/91/5e/eJFhT0p5_o.png" alt="[外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-JShkYUaM-1637146335818)(file://C:Users30287DesktopJava%E5%AD%A6%E4%B9%A0%E8%A7%86%E9%A2%91day05-Elasticsearch01%E8%B5%84%E6%96%99assetsimage-20210506101053676.png?lastModify=1637140674)]"></p> 
<h3>
<a id="42_kibana_205"></a>4.2 部署kibana</h3> 
<p>运行docker命令，部署kibana：</p> 
<pre><code class="prism language-shell">docker run -d <span class="token punctuation"></span>
--name kibana <span class="token punctuation"></span>
-e <span class="token assign-left variable">ELASTICSEARCH_HOSTS</span><span class="token operator">=</span>http://es:9200 <span class="token punctuation"></span>
--network<span class="token operator">=</span>es-net <span class="token punctuation"></span>
-p <span class="token number">5601</span>:5601  <span class="token punctuation"></span>
kibana:7.12.1
</code></pre> 
<p>命令解释：</p> 
<ul>
<li>
<code>--network es-net</code> ：加入一个名为es-net的网络中，与elasticsearch在同一个网络中</li>
<li>
<code>-e ELASTICSEARCH_HOSTS=http://es:9200"</code>：设置elasticsearch的地址，因为kibana已经与elasticsearch在一个网络，因此可以用容器名直接访问elasticsearch</li>
<li>
<code>-p 5601:5601</code>：端口映射配置</li>
</ul> 
<p>此时，在浏览器输入地址访问：http://192.168.150.101:5601，即可看到结果</p> 
<p><img src="https://images2.imgbox.com/9c/94/XhJGrDzc_o.png" alt="img"></p> 
<h3>
<a id="43_IK_228"></a>4.3 安装IK分词器</h3> 
<blockquote> 
 <p>在线安装IK插件（较慢）：</p> 
 <pre><code class="prism language-shell"><span class="token comment"># 进入容器内部</span>
docker <span class="token builtin class-name">exec</span> -it elasticsearch /bin/bash

<span class="token comment"># 在线下载并安装</span>
./bin/elasticsearch-plugin  <span class="token function">install</span> https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v7.12.1/elasticsearch-analysis-ik-7.12.1.zip

<span class="token comment">#退出</span>
<span class="token builtin class-name">exit</span>
<span class="token comment">#重启容器</span>
docker restart elasticsearch
</code></pre> 
</blockquote> 
<p>这里演示离线安装iK插件：</p> 
<p><strong>查看数据卷目录</strong>：</p> 
<p>安装插件需要知道<code>elasticsearch</code>的<code>plugins</code>目录位置，而我们用了数据卷挂载，因此需要查看<code>elasticsearch</code>的数据卷目录，通过下面命令查看：</p> 
<pre><code class="prism language-shell">docker volume inspect es-plugins
</code></pre> 
<p>显示结果：</p> 
<pre><code class="prism language-xshell">[
    {
        "CreatedAt": "2022-05-06T10:06:34+08:00",
        "Driver": "local",
        "Labels": null,
        "Mountpoint": "/var/lib/docker/volumes/es-plugins/_data",
        "Name": "es-plugins",
        "Options": null,
        "Scope": "local"
    }
]
</code></pre> 
<p>说明plugins目录被挂载到了：<code>/var/lib/docker/volumes/es-plugins/_data</code>这个目录中。</p> 
<p><strong>将准备好的文件夹上传到es容器的插件数据卷中</strong>：</p> 
<p>也就是<code>/var/lib/docker/volumes/es-plugins/_data</code>：</p> 
<p><img src="https://images2.imgbox.com/64/1e/KxGOEsXB_o.png" alt="img"></p> 
<p><strong>重启容器</strong>：</p> 
<pre><code class="prism language-shell">docker restart es
</code></pre> 
<p><strong>IK分词器包含两种模式：</strong></p> 
<ul>
<li>
<code>ik_smart</code>：智能切分，粗粒度</li>
<li>
<code>ik_max_word</code>：最细切分，细粒度</li>
</ul> 
<p>我们在上面的 Kibana 控制台测试</p> 
<pre><code class="prism language-json"><span class="token constant">GET</span> <span class="token operator">/</span>_analyze
<span class="token punctuation">{<!-- --></span>
  <span class="token string">"analyzer"</span><span class="token operator">:</span> <span class="token string">"ik_max_word"</span><span class="token punctuation">,</span>
  <span class="token string">"text"</span><span class="token operator">:</span> <span class="token string">"黑马程序员学习java太棒了"</span>
<span class="token punctuation">}</span>
</code></pre> 
<p>结果：</p> 
<pre><code class="prism language-json"><span class="token punctuation">{<!-- --></span>
  <span class="token string">"tokens"</span> <span class="token operator">:</span> <span class="token punctuation">[</span>
    <span class="token punctuation">{<!-- --></span>
      <span class="token string">"token"</span> <span class="token operator">:</span> <span class="token string">"黑马"</span><span class="token punctuation">,</span>
      <span class="token string">"start_offset"</span> <span class="token operator">:</span> <span class="token number">0</span><span class="token punctuation">,</span>
      <span class="token string">"end_offset"</span> <span class="token operator">:</span> <span class="token number">2</span><span class="token punctuation">,</span>
      <span class="token string">"type"</span> <span class="token operator">:</span> <span class="token string">"CN_WORD"</span><span class="token punctuation">,</span>
      <span class="token string">"position"</span> <span class="token operator">:</span> <span class="token number">0</span>
    <span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token punctuation">{<!-- --></span>
      <span class="token string">"token"</span> <span class="token operator">:</span> <span class="token string">"程序员"</span><span class="token punctuation">,</span>
      <span class="token string">"start_offset"</span> <span class="token operator">:</span> <span class="token number">2</span><span class="token punctuation">,</span>
      <span class="token string">"end_offset"</span> <span class="token operator">:</span> <span class="token number">5</span><span class="token punctuation">,</span>
      <span class="token string">"type"</span> <span class="token operator">:</span> <span class="token string">"CN_WORD"</span><span class="token punctuation">,</span>
      <span class="token string">"position"</span> <span class="token operator">:</span> <span class="token number">1</span>
    <span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token punctuation">{<!-- --></span>
      <span class="token string">"token"</span> <span class="token operator">:</span> <span class="token string">"程序"</span><span class="token punctuation">,</span>
      <span class="token string">"start_offset"</span> <span class="token operator">:</span> <span class="token number">2</span><span class="token punctuation">,</span>
      <span class="token string">"end_offset"</span> <span class="token operator">:</span> <span class="token number">4</span><span class="token punctuation">,</span>
      <span class="token string">"type"</span> <span class="token operator">:</span> <span class="token string">"CN_WORD"</span><span class="token punctuation">,</span>
      <span class="token string">"position"</span> <span class="token operator">:</span> <span class="token number">2</span>
    <span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token punctuation">{<!-- --></span>
      <span class="token string">"token"</span> <span class="token operator">:</span> <span class="token string">"员"</span><span class="token punctuation">,</span>
      <span class="token string">"start_offset"</span> <span class="token operator">:</span> <span class="token number">4</span><span class="token punctuation">,</span>
      <span class="token string">"end_offset"</span> <span class="token operator">:</span> <span class="token number">5</span><span class="token punctuation">,</span>
      <span class="token string">"type"</span> <span class="token operator">:</span> <span class="token string">"CN_CHAR"</span><span class="token punctuation">,</span>
      <span class="token string">"position"</span> <span class="token operator">:</span> <span class="token number">3</span>
    <span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token punctuation">{<!-- --></span>
      <span class="token string">"token"</span> <span class="token operator">:</span> <span class="token string">"学习"</span><span class="token punctuation">,</span>
      <span class="token string">"start_offset"</span> <span class="token operator">:</span> <span class="token number">5</span><span class="token punctuation">,</span>
      <span class="token string">"end_offset"</span> <span class="token operator">:</span> <span class="token number">7</span><span class="token punctuation">,</span>
      <span class="token string">"type"</span> <span class="token operator">:</span> <span class="token string">"CN_WORD"</span><span class="token punctuation">,</span>
      <span class="token string">"position"</span> <span class="token operator">:</span> <span class="token number">4</span>
    <span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token punctuation">{<!-- --></span>
      <span class="token string">"token"</span> <span class="token operator">:</span> <span class="token string">"java"</span><span class="token punctuation">,</span>
      <span class="token string">"start_offset"</span> <span class="token operator">:</span> <span class="token number">7</span><span class="token punctuation">,</span>
      <span class="token string">"end_offset"</span> <span class="token operator">:</span> <span class="token number">11</span><span class="token punctuation">,</span>
      <span class="token string">"type"</span> <span class="token operator">:</span> <span class="token string">"ENGLISH"</span><span class="token punctuation">,</span>
      <span class="token string">"position"</span> <span class="token operator">:</span> <span class="token number">5</span>
    <span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token punctuation">{<!-- --></span>
      <span class="token string">"token"</span> <span class="token operator">:</span> <span class="token string">"太棒了"</span><span class="token punctuation">,</span>
      <span class="token string">"start_offset"</span> <span class="token operator">:</span> <span class="token number">11</span><span class="token punctuation">,</span>
      <span class="token string">"end_offset"</span> <span class="token operator">:</span> <span class="token number">14</span><span class="token punctuation">,</span>
      <span class="token string">"type"</span> <span class="token operator">:</span> <span class="token string">"CN_WORD"</span><span class="token punctuation">,</span>
      <span class="token string">"position"</span> <span class="token operator">:</span> <span class="token number">6</span>
    <span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token punctuation">{<!-- --></span>
      <span class="token string">"token"</span> <span class="token operator">:</span> <span class="token string">"太棒"</span><span class="token punctuation">,</span>
      <span class="token string">"start_offset"</span> <span class="token operator">:</span> <span class="token number">11</span><span class="token punctuation">,</span>
      <span class="token string">"end_offset"</span> <span class="token operator">:</span> <span class="token number">13</span><span class="token punctuation">,</span>
      <span class="token string">"type"</span> <span class="token operator">:</span> <span class="token string">"CN_WORD"</span><span class="token punctuation">,</span>
      <span class="token string">"position"</span> <span class="token operator">:</span> <span class="token number">7</span>
    <span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token punctuation">{<!-- --></span>
      <span class="token string">"token"</span> <span class="token operator">:</span> <span class="token string">"了"</span><span class="token punctuation">,</span>
      <span class="token string">"start_offset"</span> <span class="token operator">:</span> <span class="token number">13</span><span class="token punctuation">,</span>
      <span class="token string">"end_offset"</span> <span class="token operator">:</span> <span class="token number">14</span><span class="token punctuation">,</span>
      <span class="token string">"type"</span> <span class="token operator">:</span> <span class="token string">"CN_CHAR"</span><span class="token punctuation">,</span>
      <span class="token string">"position"</span> <span class="token operator">:</span> <span class="token number">8</span>
    <span class="token punctuation">}</span>
  <span class="token punctuation">]</span>
<span class="token punctuation">}</span>
</code></pre> 
<h2>
<a id="5_372"></a>5.扩展和停用词典</h2> 
<h3>
<a id="51__374"></a>5.1 扩展词典</h3> 
<p>随着互联网的发展，“造词运动”也越发的频繁。出现了很多新的词语，在原有的词汇列表中并不存在。比如：“奥力给”，“传智播客” 等。</p> 
<p>所以我们的词汇也需要不断的更新，IK分词器提供了扩展词汇的功能。</p> 
<p>1）打开IK分词器config目录：</p> 
<p><img src="https://images2.imgbox.com/79/85/nS7B7rrL_o.png" alt="[外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-IGQnktY1-1637146335824)(C:Users30287DesktopJava学习视频day05-Elasticsearch01资料assetsimage-20210506112225508.png)]"></p> 
<p>2）在<code>IKAnalyzer.cfg.xml</code>配置文件内容添加：</p> 
<pre><code class="prism language-xml"><span class="token prolog">&lt;?xml version="1.0" encoding="UTF-8"?&gt;</span>
<span class="token doctype"><span class="token punctuation">&lt;!</span><span class="token doctype-tag">DOCTYPE</span> <span class="token name">properties</span> <span class="token name">SYSTEM</span> <span class="token string">"http://java.sun.com/dtd/properties.dtd"</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>properties</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>comment</span><span class="token punctuation">&gt;</span></span>IK Analyzer 扩展配置<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>comment</span><span class="token punctuation">&gt;</span></span>
        <span class="token comment">&lt;!--用户可以在这里配置自己的扩展字典 *** 添加扩展词典--&gt;</span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>entry</span> <span class="token attr-name">key</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>ext_dict<span class="token punctuation">"</span></span><span class="token punctuation">&gt;</span></span>ext.dic<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>entry</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>properties</span><span class="token punctuation">&gt;</span></span>
</code></pre> 
<p>3）新建一个 <code>ext.dic</code>，可以参考config目录下复制一个配置文件进行修改</p> 
<pre><code class="prism language-properties">传智播客
奥力给
</code></pre> 
<p>4）重启elasticsearch</p> 
<pre><code class="prism language-sh">docker restart es
</code></pre> 
<p>日志中已经成功加载ext.dic配置文件</p> 
<p>5）测试效果：</p> 
<pre><code class="prism language-json"><span class="token constant">GET</span> <span class="token operator">/</span>_analyze
<span class="token punctuation">{<!-- --></span>
  <span class="token string">"analyzer"</span><span class="token operator">:</span> <span class="token string">"ik_max_word"</span><span class="token punctuation">,</span>
  <span class="token string">"text"</span><span class="token operator">:</span> <span class="token string">"传智播客Java就业超过90%,奥力给！"</span>
<span class="token punctuation">}</span>
</code></pre> 
<h3>
<a id="52__422"></a>5.2 停用词典</h3> 
<p>在互联网项目中，在网络间传输的速度很快，所以很多语言是不允许在网络上传递的，如：关于宗教、政治等敏感词语，那么我们在搜索时也应该忽略当前词汇。</p> 
<p>IK分词器也提供了强大的停用词功能，让我们在索引时就直接忽略当前的停用词汇表中的内容。</p> 
<p>1）<code>IKAnalyzer.cfg.xml</code>配置文件内容添加：</p> 
<pre><code class="prism language-xml"><span class="token prolog">&lt;?xml version="1.0" encoding="UTF-8"?&gt;</span>
<span class="token doctype"><span class="token punctuation">&lt;!</span><span class="token doctype-tag">DOCTYPE</span> <span class="token name">properties</span> <span class="token name">SYSTEM</span> <span class="token string">"http://java.sun.com/dtd/properties.dtd"</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>properties</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>comment</span><span class="token punctuation">&gt;</span></span>IK Analyzer 扩展配置<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>comment</span><span class="token punctuation">&gt;</span></span>
        <span class="token comment">&lt;!--用户可以在这里配置自己的扩展字典--&gt;</span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>entry</span> <span class="token attr-name">key</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>ext_dict<span class="token punctuation">"</span></span><span class="token punctuation">&gt;</span></span>ext.dic<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>entry</span><span class="token punctuation">&gt;</span></span>
         <span class="token comment">&lt;!--用户可以在这里配置自己的扩展停止词字典  *** 添加停用词词典--&gt;</span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>entry</span> <span class="token attr-name">key</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>ext_stopwords<span class="token punctuation">"</span></span><span class="token punctuation">&gt;</span></span>stopword.dic<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>entry</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>properties</span><span class="token punctuation">&gt;</span></span>
</code></pre> 
<p>3）在 <code>stopword.dic</code> 添加停用词</p> 
<pre><code class="prism language-properties">xxx
</code></pre> 
<p>4）重启elasticsearch</p> 
<pre><code class="prism language-sh"># 重启服务
docker restart elasticsearch
docker restart kibana

# 查看 日志
docker logs -f elasticsearch
</code></pre> 
<p>日志中已经成功加载stopword.dic配置文件</p> 
<p>5）测试效果：</p> 
<pre><code class="prism language-json"><span class="token constant">GET</span> <span class="token operator">/</span>_analyze
<span class="token punctuation">{<!-- --></span>
  <span class="token string">"analyzer"</span><span class="token operator">:</span> <span class="token string">"ik_max_word"</span><span class="token punctuation">,</span>
  <span class="token string">"text"</span><span class="token operator">:</span> <span class="token string">"传智播客Java就业率超过95%,xxx都点赞,奥力给！"</span>
<span class="token punctuation">}</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/61/48/xerieZC9_o.png" alt="在这里插入图片描述"><br> 最后喜欢的小伙伴，记得三连哦！???</p>
                </div>
                
                

		</div>
	</article>
</main>




			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程小白.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://www.w3counter.com/tracker.js?id=150625"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>
	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>