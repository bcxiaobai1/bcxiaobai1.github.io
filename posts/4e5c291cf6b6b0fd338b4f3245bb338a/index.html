<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<title>k8s入门教程详解(一) - 编程小白</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程小白" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程小白</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">k8s入门教程详解(一)</h1>
			
		</header>
		<div class="content post__content clearfix">
			


                <div id="content_views" class="markdown_views prism-atom-one-light">
                    
                        
                    
                    <p></p>
<div class="toc">
 <h3>文章目录</h3>
 <ul>
<li><a href="#Kubernetes___1">Kubernetes 入门教程详解(一)</a></li>
<li>
<ul>
<li><a href="#_Kubernetes__2">一、 Kubernetes 概述</a></li>
<li>
<ul>
<li><a href="#1_K8S__4">1. K8S 发展历史由来</a></li>
<li><a href="#2K8S_12">2.K8S官网</a></li>
<li><a href="#2K8S__21">2.K8S 是什么</a></li>
<li><a href="#3_K8s__35">3. K8s 优势及特点</a></li>
<li>
<ul>
<li><a href="#31_K8S_37">3.1 K8S优势</a></li>
<li><a href="#32_K8S__46">3.2 K8S 特点</a></li>
</ul>
    </li>
<li><a href="#4_K8s__53">4. K8s 集群架构与组件</a></li>
<li>
<ul>
<li><a href="#41_K8s__55">4.1 K8s 集群架构</a></li>
<li><a href="#42_K8s__113">4.2 K8s 核心组件详细说明</a></li>
</ul>
    </li>
<li><a href="#5_K8s__182">5. K8s 核心概念</a></li>
<li>
<ul>
<li><a href="#51_Master__184">5.1 Master 集群控制节点</a></li>
<li><a href="#52_Node__188">5.2 Node 工作负载节点</a></li>
<li><a href="#53_Pod_kubernetes_192">5.3 Pod kubernetes的最小控制单元</a></li>
<li><a href="#54_Controller_Pod_208">5.4 Controller 控制器Pod</a></li>
<li>
<ul>
<li><a href="#541_Replication_ControllerRC_Pod_226">5.4.1 复制控制器（Replication Controller，RC）--- 确保预期的Pod副本数量</a></li>
<li><a href="#542_Replica_SetRS_Pod_236">5.4.2 副本集（Replica Set，RS）--- 确保预期的Pod副本数量</a></li>
<li><a href="#543_HPA_252">5.4.3 HPA</a></li>
<li><a href="#544_StatefulSet__266">5.4.4 StatefulSet ---为了解决有状态服务的问题</a></li>
<li><a href="#545_Deployment_284">5.4.5 部署(Deployment)</a></li>
<li><a href="#546_JobCron_Job__297">5.4.6 Job、Cron Job 负责批处理任务</a></li>
</ul>
     </li>
<li><a href="#55_Service_311">5.5 服务发现（Service）</a></li>
<li><a href="#56_Lable__327">5.6 Lable 标签</a></li>
<li><a href="#57_Ingress_346">5.7 Ingress</a></li>
<li><a href="#58_NameSpace__360">5.8 NameSpace 命名空间</a></li>
</ul>
    </li>
<li><a href="#6K8S__377">6.K8S 的网络通讯方式</a></li>
<li>
<ul>
<li><a href="#61_Pod_localhost_383">6.1 同一个Pod 内的多个容器之间通讯:localhost</a></li>
<li><a href="#62_PodOverlay_Network_388">6.2 各个Pod之间的通讯:Overlay Network</a></li>
<li><a href="#63_Pod_Service_IptablesLVS_427">6.3 Pod 与Service 之间的通讯:各节点的Iptables(LVS转发)</a></li>
<li><a href="#64__431">6.4 通讯总结</a></li>
</ul>
    </li>
<li><a href="#7K8s_446">7.K8s里面的三张网络</a></li>
</ul>
   </li>
<li><a href="#_458">二、总结</a></li>
</ul>
 </li>
</ul>
</div>
<p></p> 
<h1>
<a id="Kubernetes___1"></a>Kubernetes 入门教程详解(一)</h1> 
<h2>
<a id="_Kubernetes__2"></a>一、 Kubernetes 概述</h2> 
<h3>
<a id="1_K8S__4"></a>1. K8S 发展历史由来</h3> 
<ul>
<li> <p>它前生是 谷歌的Borg 系统，后经过Go 语言重写,在 2014 年开源了 Kubernetes 项目,并捐献给CNCF 基金会开源,即<code>Kubernetes。</code></p> </li>
<li> <p>它之所以简称 ‘k8s’,因为<code>Kubernetes</code>中间有 8个字母</p> </li>
<li> <p><img src="https://images2.imgbox.com/55/23/2cXy0GL3_o.png" alt="在这里插入图片描述"></p> </li>
</ul> 
<h3>
<a id="2K8S_12"></a>2.K8S官网</h3> 
<ul>
<li>
<strong>kubernetes的github地址：</strong> 
  <ul><li><code>https://github.com/kubernetes/kubernetes</code></li></ul> </li>
<li>
<strong>kubernetes官方站点：</strong> 
  <ul>
<li>英文官方网址:<code>https://kubernetes.io/</code>
</li>
<li>z中文官方网站:<code>https://kubernetes.io/zh/</code>
</li>
<li>英文官方文档:<code>https://kubernetes.io/docs/</code>
</li>
</ul> </li>
</ul> 
<h3>
<a id="2K8S__21"></a>2.K8S 是什么</h3> 
<ul>
<li> <p><code>Kubernetes</code> 是一个可移植的、可扩展的<mark>开源平台</mark>，用于<code>管理容器化的工作负载和服务，可促进声明式配置和自动化</code>。 Kubernetes 拥有一个庞大且快速增长的生态系统。Kubernetes 的服务、支持和工具广泛可用。</p> </li>
<li> <p><code>Kubernetes</code> 这个名字源于希腊语，意为“舵手”或“飞行员”</p> </li>
<li> <p><a href="https://kubernetes.io/">官网</a>:https://kubernetes.io/</p> </li>
<li> <p><a href="https://github.com/kubernetes/kubernetes">GitHub</a>：https://github.com/kubernetes/kubernetes</p> </li>
<li> <p>具有 <code>轻量级</code>、<code>消耗资源小</code>、<code>开源</code>、<code>弹性伸缩</code>、<code>负载均衡(IPVS)</code>的特点</p> </li>
</ul> 
<h3>
<a id="3_K8s__35"></a>3. K8s 优势及特点</h3> 
<h4>
<a id="31_K8S_37"></a>3.1 K8S优势</h4> 
<ul>
<li>自动装箱，水平扩展，自我修复</li>
<li>服务发现和负载均衡</li>
<li>自动发布和回滚</li>
<li>集中化配置管理和密钥管理</li>
<li>存储编排</li>
<li>批处理：提供一次性任务，定时任务；满足批量数据处理和分析的场景</li>
</ul> 
<h4>
<a id="32_K8S__46"></a>3.2 K8S 特点</h4> 
<ul>
<li>
<strong>可移植</strong>: 支持公有云，私有云，混合云，多重云（multi-cloud）</li>
<li>
<strong>可扩展</strong>: 可根据业务流量情况快速扩展kubernetes集群的节点数量。</li>
<li>
<strong>自愈</strong>: 自动发布，自动重启，自动复制，自动扩展</li>
<li>
<strong>进程协同</strong>：利用复合应用保证应用和容器一对一的模型。</li>
</ul> 
<h3>
<a id="4_K8s__53"></a>4. K8s 集群架构与组件</h3> 
<h4>
<a id="41_K8s__55"></a>4.1 K8s 集群架构</h4> 
<ul>
<li> <p><strong>集群架构</strong></p> <pre><code class="prism language-shell">Kubernetes集群包含有节点代理<span class="token variable"><span class="token variable">`</span>kubelet<span class="token variable">`</span></span>和<span class="token variable"><span class="token variable">`</span>Master组件<span class="token variable">`</span></span><span class="token punctuation">(</span>APIs, scheduler, etc<span class="token punctuation">)</span>，一切都基于分布式的存储系统。

一个kubernetes集群主要是由 控制节点<span class="token punctuation">(</span>master<span class="token punctuation">)</span>、工作节点<span class="token punctuation">(</span>node<span class="token punctuation">)</span>构成，每个节点上都会安装不同的组件。
下面这张图是Kubernetes的架构图。
</code></pre> </li>
<li> <p><img src="https://images2.imgbox.com/45/28/4FZLaFQi_o.png" alt="在这里插入图片描述"></p> 
  <blockquote> 
   <p><strong>控制节点：</strong></p> 
   <p>ApiServer : 资源操作的唯一入口，接收用户输入的命令，提供认证、授权、API注册和发现等机制</p> 
   <p>Scheduler : 负责集群资源调度，按照预定的调度策略将Pod调度到相应的node节点上</p> 
   <p>ControllerManager : 负责维护集群的状态，比如程序部署安排、故障检测、自动扩展、滚动更新等</p> 
   <p>Etcd ：负责存储集群中各种资源对象的信息(默认的数据库，自己可以配置修改的，比如配mysql)</p> 
  </blockquote> 
  <blockquote> 
   <p><strong>工作节点Node</strong>:</p> 
   <p>Kubelet : 负责维护容器的生命周期，即通过控制docker，来创建、更新、销毁容器</p> 
   <p>KubeProxy : 负责提供集群内部的服务发现和负载均衡</p> 
   <p>Docker : 负责节点上容器的各种操作</p> 
  </blockquote> </li>
<li>
</li>
</ul> 
<pre><code class="prism language-shell"><span class="token comment"># 大致工作原理</span>
kubectl 和web UI接入我们master节点后，scheduler调度器将任务交给api server， 通过api server 把任务写入 etcd 存储服务器,然后交给node节点执行
控制器，它们就是维护我们的副本的数目的或者叫做我们的期望值的，一旦它的副本数不满足我们的期望值，replication controller就会将它改写成 我们的期望值<span class="token punctuation">(</span>创建或删除Pod数<span class="token punctuation">)</span>


<span class="token comment"># 以安装nginx服务说明K8S组件调用关系：</span>
首先要明确，一旦kubernetes环境启动之后，master和node都会将自身的信息存储到etcd数据库中

<span class="token number">1</span>. 一个nginx服务的安装请求会首先被发送到master节点的apiServer组件

<span class="token number">2</span>. apiServer组件会调用scheduler组件来决定到底应该把这个服务安装到哪个node节点上
   在此时，Scheduler调度器会从etcd中读取各个node节点的信息，然后按照一定的算法进行选择，并将结果告知apiServer，分发给那个node

<span class="token number">3</span>. apiServer调用controller-manager<span class="token punctuation">(</span>控制器<span class="token punctuation">)</span>去调度Node节点安装nginx服务

<span class="token number">4</span>. kubelet接收到指令后，会通知docker，然后由docker来启动一个nginx的pod
   pod是kubernetes的最小操作单元，容器必须跑在pod中，此时nginx服务就已经跑起来了。
   
<span class="token number">5</span>. 一个nginx服务就运行了，如果需要访问nginx，就需要通过kube-proxy来对pod产生访问的代理
</code></pre> 
<h4>
<a id="42_K8s__113"></a>4.2 K8s 核心组件详细说明</h4> 
<ul>
<li> <p><strong>核心组件说明</strong></p> <pre><code class="prism language-shell"><span class="token comment">#控制器，它们就是维护我们的副本的数目的或者叫做我们的期望值的，一旦它的副本数不满足我们的期望值，replication controller就会将它改写成 我们的期望值</span>

<span class="token comment"># api  一切服务的访问入口，压力很大，为了减轻压力，每个请求下面就可以生成缓存</span>

<span class="token comment"># etcd 是 paxos 键值对采用go 语言编写的键值对 数据库。</span>
etcd 的官方 将它 定位成一个 可信赖的分布式键值存储服务器，它能够为整个分布式集群存储一些关键数据，协助分布式集群的正常运转。
	可信赖：本身可以完成集群化
	分布式：扩容缩非常方便
	正常运转：保存我们的整个分布式集群的需要持久化的配置文件、配置信息，一旦我们的集群死亡后，我们可以借助到etcd 里面的一些信息，进行数据恢复

	ectd 里面有2个版本，一个是 v2版，一个是v3版。v2版会将数据全部写入 内存中，v3 版本会引入本地卷的持久化操作<span class="token punctuation">(</span>关机以后并不会造成数据损坏<span class="token punctuation">)</span>
	推荐使用kubernetes 集群中etcd v3,
	V1.11包含之前自带的的etcd是不支持V3的。
	
ETCD 键值数据库 是基于HTTP，进行的C/S开发的，
他有 这些组件
	Raft:存储我们的读写信息的<span class="token punctuation">(</span>所有的信息都存在这里<span class="token punctuation">)</span>
	WAL:预写日志：为了防止Raft里面的信息出现损坏，还有WAL预写日志
	（如果想对里面的数据进行更改，需要先生成一个日志，WAL先存一下，并且会定时的对这些日志进行完整的备份<span class="token punctuation">[</span>完整+临时备份<span class="token punctuation">]</span>）
	Entry:
	Snapshot:日志备份<span class="token punctuation">{<!-- --></span>完整备份+增量备份<span class="token punctuation">}</span>
   

<span class="token comment"># node 节点：安装 kubelet 、kube proxy、 container(Docker)</span>
在Node节点上实现Pod网络代理，维护网络规则和四层负载均衡工作。
kubelet：会跟我们的CRI（C 容器；R 运行环境<span class="token punctuation">;</span> I 接口）---这里就是我们的Dokcer表现形式 。它会和我们的Docker进行交互，操作Docker去创建对应的容器<span class="token punctuation">[</span>就是Kubelet维持我们Pod的生命周期<span class="token punctuation">]</span>

Kube proxy:相当于SVC，可以进行负载操作。也就意味着如何实现Pod与Pod之间如何访问，包括负载均衡。它的默认操作时firewall，操作防火墙，实现对Pod的映射。<span class="token punctuation">(</span>新版本中还支持IPVS 实现负载均衡<span class="token punctuation">)</span>

<span class="token comment"># 总结这些节点</span>
api server:所有服务访问统一入口
CrontrollerManager:维持副本期望数
Scheduler:负责介绍任务，选择合适的节点进行分配任务。
etcd：键值对数据库，存储K8S集群所有重要信息<span class="token punctuation">(</span>持久化<span class="token punctuation">)</span>
kubelet:直接跟容器引擎交互实现容器 的 生命周期管理
kube-proxy:负责写入规则至iptables<span class="token punctuation">(</span>firewall<span class="token punctuation">)</span>、ipvs<span class="token punctuation">(</span>负载均衡<span class="token punctuation">)</span> 实现服务映射访问的
</code></pre> </li>
<li> <p><strong>其它组件介绍</strong></p> <pre><code class="prism language-shell"><span class="token comment">#CoreDNS :</span>
	可以为集群中的svc 创建一个域名IP的对应关系解析

<span class="token comment">#Dashboard:</span>
	给k8s提供一个B/S 结构访问体系

<span class="token comment">#Ingress controller：</span>
	官方实现了四层代理，Ingress 可以实现七层代理

<span class="token comment">#Federation:</span>
	提供一个可以跨越集群中心多k8s 统一管理功能

<span class="token comment">#Prometheus：</span>
	提供k8s 集群的监控能力

<span class="token comment">#ELK:</span>
	提供k8s 集群日志 统一 分析接入平台
</code></pre> </li>
</ul> 
<h3>
<a id="5_K8s__182"></a>5. K8s 核心概念</h3> 
<h4>
<a id="51_Master__184"></a>5.1 Master 集群控制节点</h4> 
<ul><li>每个集群至少一个master节点负责集群的管理</li></ul> 
<h4>
<a id="52_Node__188"></a>5.2 Node 工作负载节点</h4> 
<ul><li>由masster 分配容器到这些node节点上，然后node 节点上的docker 负责容器运行</li></ul> 
<h4>
<a id="53_Pod_kubernetes_192"></a>5.3 Pod kubernetes的最小控制单元</h4> 
<ul>
<li> <p>**自主式pod **</p> <pre><code class="prism language-shell">Pod是在K8s集群中运行部署应用或服务的最小单元<span class="token punctuation">(</span>原子单元<span class="token punctuation">)</span>，它是可以支持多容器的。

只要我们定义了一个Pod,它就会自动启动一个容器---pause的网络栈。也就意味着同一个Pod 容器间的端口不能冲突
一个Pod里封装了很多个容器，他们共用一个pause，共用存储卷
</code></pre> </li>
<li> <p><img src="https://images2.imgbox.com/53/bc/kSk4CW0B_o.png" alt="在这里插入图片描述"></p> </li>
</ul> 
<h4>
<a id="54_Controller_Pod_208"></a>5.4 Controller 控制器Pod</h4> 
<ul>
<li> <p>控制器，通过它来实现对pod的管理，比如启动pod、停止pod、伸缩pod的数量等等</p> </li>
<li> <p>K8S内核提供了众多的pod控制器，常用的有:</p> <pre><code class="prism language-shell">Deployment  部署<span class="token punctuation">(</span>暴露在最外面的<span class="token punctuation">)</span>
DaemonSet   要求每一个运行节点都启动一个
ReplicaSet

StatefulSet

Job
Cronjob
</code></pre> </li>
</ul> 
<h5>
<a id="541_Replication_ControllerRC_Pod_226"></a>5.4.1 复制控制器（Replication Controller，RC）— 确保预期的Pod副本数量</h5> 
<ul><li> <p><strong>RC 控制器</strong></p> <pre><code class="prism language-shell">Replication Control1er 用来确保容器应用的副本数始终保持在用户定义的副本数，即如果有容器异常退出，会自动创建新的Pod 来替代<span class="token punctuation">;</span>而如果异常多出来的容器也会自动回收。在新版本的Kubernetes 中建议使用ReplicaSet来取代 ReplicationControl1e
</code></pre> </li></ul> 
<h5>
<a id="542_Replica_SetRS_Pod_236"></a>5.4.2 副本集（Replica Set，RS）— 确保预期的Pod副本数量</h5> 
<ul>
<li> <p><strong>RS副本集</strong></p> <pre><code class="prism language-shell">ReplicaSet跟Replication Controller没有本质的不同，只是名字不一样，并且ReplicaSet支持集合式的selector
虽然ReplicaSet可以独立使用，但一般还是建议使用

Deployment来自动管理ReplicaSet ,这样就无需担心跟其他机制的不兼容问题（比如 ReplicaSet不支持rolling update <span class="token punctuation">{<!-- --></span>滚动更新<span class="token punctuation">}</span>但 Deployment支持<span class="token punctuation">)</span>
</code></pre> </li>
<li> <p><img src="https://images2.imgbox.com/7f/74/4MfFJpZx_o.png" alt="在这里插入图片描述"></p> </li>
</ul> 
<h5>
<a id="543_HPA_252"></a>5.4.3 HPA</h5> 
<ul>
<li> <p><strong>HPA</strong></p> <pre><code>HPA监控我们的RS，当我们的CPU达到80后（CPU&gt;=80）,他就会新建Pod,最多创建10个，最少保留2个。
如果高于80，就创建，小于80不在创建。
</code></pre> </li>
<li> <p><img src="https://images2.imgbox.com/16/c4/tqy9beZ4_o.png" alt="在这里插入图片描述"></p> </li>
</ul> 
<h5>
<a id="544_StatefulSet__266"></a>5.4.4 StatefulSet —为了解决有状态服务的问题</h5> 
<ul><li> <p><strong>StatefulSet</strong></p> <pre><code>StatefulSet是为了解决有状态服务的问题(对应 Deployments 和 ReplicaSets是为无状态服务而设计)，

其应用场景包括:
 1.稳定的持久化存储，即 Pod重新调度后还是能访问到相同的持久化数据，基于PVC来实现
 2.稳定的网络标志，即 Pod重新调度后其 PodName和 HostName不变，基于 Headless Service(即没有Cluster IP的Service )来实现

3.有序部署，有序扩展，即 Pod是有顺序的，在部署或者扩展的时候要依据定义的顺序依次依次进行(即从О到N-1，在下一个Pod运行之前所有之前的 Pod必须都是Running 和 Ready状态)，基于init containers来实现

4.有序收缩,有序删除（即从N-1到0&gt;
</code></pre> </li></ul> 
<h5>
<a id="545_Deployment_284"></a>5.4.5 部署(Deployment)</h5> 
<ul><li> <p><strong>Deployment</strong></p> <pre><code class="prism language-shell">DaemonSet确保全部<span class="token punctuation">(</span>或者一些<span class="token punctuation">)</span>Node 上运行一个Pod 的副本。当有Node加入集群时，也会为他们新增一个Pod 。当有Node从集群移除时，这些 Pod 也会被回收。删除 DaemonSet将会删除它创建的所有Pod
运行集群存储daemon，例如在每个Node 上运行glusterd、cepho.
在每个Node上运行日志收集daemon，例如fluentd、logstash。
在每个Node上运行监控daemon，例如Prometheus Node Exporter
</code></pre> </li></ul> 
<h5>
<a id="546_JobCron_Job__297"></a>5.4.6 Job、Cron Job 负责批处理任务</h5> 
<ul><li> <p><strong>Job、Cron Job</strong></p> <pre><code class="prism language-shell"> Job 负责批处理任务，即仅执行一次的任务，它保证批处理任务的一个或多个Pod 成功结束
 
 Cron Job管理基于时间的 Job，即:
	 在给定时间点只运行一次
	 周期性地在给定时间点运行
</code></pre> </li></ul> 
<h4>
<a id="55_Service_311"></a>5.5 服务发现（Service）</h4> 
<ul>
<li> <p>pod 对外服务的统一入口，可以维护同一类的多个Pod</p> <pre><code>在K8S里，虽然每个POD都会被分一个单独的IP地址，但这个IP地址会随着POD的销毁而消失，Service 就是来解决这个问题的核心概念

一个service 可以看作一组提供相同服务的Pod的对外访问接口
Service 作用于哪些Pod 是通过标签选择器来定义的

一个 Service 在 Kubernetes 中是一个 REST 对象，和 Pod 类似。 像所有的 REST 对象一样， Service 定义可以基于 POST 方式，请求 apiserver 创建新的实例。
</code></pre> </li>
<li> <p><img src="https://images2.imgbox.com/1c/9d/LaRRYhwh_o.png" alt="在这里插入图片描述"></p> </li>
</ul> 
<h4>
<a id="56_Lable__327"></a>5.6 Lable 标签</h4> 
<ul>
<li> <p>标签，用于对Pod进行分类，同一类POD会拥有相同的标签</p> </li>
<li> <p>附加到某个资源上，用于关联对象、查询和筛选</p> <pre><code>给资源打上标签后，可以使用标签选择器过滤指定的标签
标签选择器目前有2个：一个是基于 等值关系(等于、不等于)
				一个是 基于集合关系(属于、不属于、存在)
许多资源支持内嵌标签选择器 字段
	matchLabels
	matchExpressions
	
一个合法的标签应该是 字母和数字、下划线、虚线"-"、点"." 开头和结尾必须是字母或数字的形式组成。标签值最多63个字符
</code></pre> </li>
</ul> 
<h4>
<a id="57_Ingress_346"></a>5.7 Ingress</h4> 
<ul>
<li> <p>Ingress是授权入站连接到达集群服务的规则集合。</p> </li>
<li> <p>在K8S集群里，工作在应用层，对外暴露接口。</p> </li>
<li> <p>可以调动不同业务域，不同URL访问路径的业务流量</p> <pre><code>你可以给Ingress配置提供外部可访问的URL、负载均衡、SSL、基于名称的虚拟主机等。用户通过POST Ingress资源到API server的方式来请求ingress。 Ingress controller负责实现Ingress，通常使用负载平衡器，它还可以配置边界路由和其他前端，这有助于以HA方式处理流量。
</code></pre> </li>
</ul> 
<h4>
<a id="58_NameSpace__360"></a>5.8 NameSpace 命名空间</h4> 
<ul><li> <p><strong>用来隔离pod 的运行环境</strong></p> <pre><code>随着项目怎多，人员增加，集群规模的扩大，需要一种能够隔离K8S内各种"资源"，都应该有自己的"名称"。
Kubernetes可以使用Namespaces（命名空间）创建多个虚拟集群。
Namespace为名称提供了一个范围。资源的Names在Namespace中具有唯一性。

不同名称空间的内部"资源" ，名称可以相同，相同名称空间内的同种 "资源"，"名称"不能相同
合理的使用K8S的名称空间，使得集群管理员能够更好的对付交付 到K8S里的服务进行分类管理和浏览
K8S里默认存在的名称空间有 default、kube-system、kube-public
查询k8s 里特定"资源" 要带上相应 的名称空间
</code></pre> </li></ul> 
<h3>
<a id="6K8S__377"></a>6.K8S 的网络通讯方式</h3> 
<ul>
<li>K8S 的网络模型 假定了所有POD都在一个可以直接连通的扁平的网络空间(扁平化:所有的POD都可以通过对方的IP互相访问)，在这里GCE(Google Compute Engine) 里面是现成的网络模型.</li>
<li>K8S假定这个网络模型已经存在，而在私有云里搭建K8S集群，就不能假定这个网络已经存在了。</li>
<li>所以，我们需要个网段假设，将不同节点上的Docker容器之间的互相访问先打通，然后在运行Kubernetes</li>
</ul> 
<h4>
<a id="61_Pod_localhost_383"></a>6.1 同一个Pod 内的多个容器之间通讯:localhost</h4> 
<ul>
<li>同一个Pod 内部通讯，共享一个网络命名空间，共享一个linux协议栈</li>
<li>
</li>
</ul> 
<h4>
<a id="62_PodOverlay_Network_388"></a>6.2 各个Pod之间的通讯:Overlay Network</h4> 
<ul>
<li> <p>不同机器，上面运行的Docker容器IP一定不能冲突，</p> </li>
<li> <p><img src="https://images2.imgbox.com/a3/aa/qgCEpBMf_o.png" alt="在这里插入图片描述"></p> <pre><code># 在k8s中，其实我们的谷歌没有对自己的k8s做了很强定义，它允许我们通过CNI接口，去接入我们自己的想要达到的一个网络方案。

# 其中Flannel 使我们在k8s里最常用的一种解决网络扁平化的一种方案，符合我们CNI接口。

# Flannel是CoreOS团队针对Kubernetes设计的一个网络规划服务，简单来说，它的功能是让集群中的不同节点主机创建的 Docker容器都具有全集群唯一的虚拟IP地址。而且它还能在这些IP地址之间建立一个覆盖网络（Overlay Network)，通过这个覆盖网络，将数据包原封不动地传递到目标容器内。

# 不同物理机器上面运行的Docker 容器IP一定不能冲突。在Docker里面我们可以修改配置文件，修改网段。那么Flannel是怎么解决的。

# 这里有2台物理主机，运行了4个Pod。一台物理机上运行了webapp2、webapp1 2个Pod ，另一台物理主机上运行了 webapp3、Backend 2个接点。他们的网络架构是 Backend(前端接点)、webapp1、webapp2、webapp3，所有流量访问到Backend上，它去经过自己的网关去处理，把什么样的请求分配到什么样的服务上。

# 这样就意味着。webapp2 和backend通讯，就需要跨主机通讯了，以及 webapp3 和backend通讯，就是2个同主机的不同Pod通讯了。2种不同的通信到底如何解决？

# 首先在我们真实服务器上，我们会安装一个Flanneld的守护进程，这个进程会监听一个端口，这个端口用于后续监听接受或转发数据包 的一个端口。一旦这个Flanneld 进程启动后，它会开启一个 Flanneld 0 的网桥，网桥Flanneld 0 专门会手机网桥Docker0 转发出来的数据报文。然后Docker0 会分发自己的IP到对应的pod上，

# 如果是同一台主机上 的两个Pod 互相通信，它走的是Docker0网桥。

# 如何跨主机，通过对方的IP直接到达？

# 假设 webapp2 与Backend 通讯，源地址是10.1.15.2/24 目标地址是 10.1.20.3/24。
因为不是同一个网段，所以首先 webapp2 会发送 自己的网关Docker0 10.1.15.1/24,然后 Flannel0 10.1.15.0/16 接受docker0 的报文，然后发送给Flanneld进程。此时Flanneld进程会从 etcd 获取路由，并写入当前的主机路由，经过Flanneld封装 后发送。Flanneld 封装数据包 先mac封装，然后 封装 源IP 192.168.10.11 目的IP 192.168.10.12 ,接着封装UDP协议，在封装 源IP 10.1.15.2 目的IP 10.1.20.3。然后发送到 物理机 192.168.10.12 上面的Flannel0 ，Flanneld 进程会截取报文。然后会拆封，然后转发到 Docker0,看到的是源地址是10.1.15.2/24 目标是 10.1.20.3的地址的数据包。然后发给Blackend
</code></pre> </li>
<li> <p>ETCD 之 Flannel提供说明：</p> 
  <ul>
<li>存储管理 Flannel 可分配的 IP地址段资源(也就意味着Flannel 在启动后，会向etcd 插入可以分配的网段，并记录分配的pod地址，防止 已分配的网段再次被利用，造成地址冲突)</li>
<li>监控ETCD中每个Pod 的实际地址，并在内存中建立维护Pod节点路由表</li>
</ul> </li>
</ul> 
<h4>
<a id="63_Pod_Service_IptablesLVS_427"></a>6.3 Pod 与Service 之间的通讯:各节点的Iptables(LVS转发)</h4> 
<ul><li>
<strong>Pod 致Service 的网络</strong>:目前基于性能考虑，全部为iptables 维护和转发</li></ul> 
<h4>
<a id="64__431"></a>6.4 通讯总结</h4> 
<ul>
<li> <p>通在同一台机器，由Docker0网桥直接转发请求只Pod2，不需要进过Flannel</p> </li>
<li> <p><strong>Podl至 Pod2：</strong></p> 
  <ul>
<li>Podl与 Pod2不在同一台主机，Pod的地址是与docker0在同一个网段的，但dockerO网段与宿主机网卡是两个完全不同的IP网段，并且不同Node之间的通信只能通过宿主机的物理网卡进行。将Pod的IP和所在Node的IP关联起来，通过这个关联让Pod可以互相访问</li>
<li>Pod1 与 Pod2在同一台机器，由 Docker0网桥直接转发请求至 Pod2，不需要经过 Flannel 演示</li>
</ul> </li>
<li> <p><strong>Pod 致Service 的网络</strong>:目前基于性能考虑，全部为iptables 维护和转发</p> </li>
<li> <p><strong>Pod 到外网</strong>: Pod 向外网发送请求，查找路由表，转发数据包到 宿主机的网卡，宿主网卡完成路由选择后，iptables执行Masqureade，把源IP 更改为宿主网卡的IP，然后想外网服务器发送请求。</p> </li>
<li> <p><strong>外网发送Pod</strong>: service</p> </li>
</ul> 
<h3>
<a id="7K8s_446"></a>7.K8s里面的三张网络</h3> 
<ul>
<li> <p><strong>三种网络</strong></p> </li>
<li> <p><img src="https://images2.imgbox.com/ef/87/cyY2B37p_o.png" alt="在这里插入图片描述"></p> <pre><code># 节点网络 就是我们真实的物理网卡
# Pod 和service 都是虚拟网络
</code></pre> </li>
</ul> 
<h2>
<a id="_458"></a>二、总结</h2> 
<ul><li>K8S概念很是复杂，这里先简单的介绍下k8s基础概念，后续接着更新k8s 部署，已及更深参次的介绍k8s。初次里面涉及的概念，一定要搞清楚，偶尔面试会被问到</li></ul>
                </div>
                
                

		</div>
	</article>
</main>




			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程小白.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://www.w3counter.com/tracker.js?id=150625"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>
	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>