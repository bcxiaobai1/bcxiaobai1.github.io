<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<title>机器学习之自然语言处理——中文分词jieba库详解（代码&#43;原理） - 编程小白</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程小白" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程小白</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">机器学习之自然语言处理——中文分词jieba库详解（代码&#43;原理）</h1>
			
		</header>
		<div class="content post__content clearfix">
			


                <div id="content_views" class="markdown_views prism-atom-one-dark">
                    
                        
                    
                    <p></p>
<div class="toc">
 <h3>目录</h3>
 <ul>
<li><a href="#_1">文本分类概述</a></li>
<li>
<ul>
<li><a href="#_3">文本分类的应用</a></li>
<li><a href="#_26">文本分类的挑战</a></li>
<li><a href="#_41">文本分类的算法应用</a></li>
</ul>
  </li>
<li><a href="#_50">文本分类所需知识</a></li>
<li>
<ul>
<li>
<ul>
<li><a href="#jieba_51">中文分词神器-jieba</a></li>
<li>
<ul>
<li><a href="#jieba_63">jieba分词的三种模式</a></li>
<li><a href="#_107">词性标注</a></li>
<li><a href="#_126">载入词典（不分词）</a></li>
<li><a href="#_166">词典中删除词语（不显示）</a></li>
<li><a href="#_199">停用词过滤</a></li>
<li><a href="#_218">调整词语的词频</a></li>
</ul>
    </li>
<li><a href="#_262">关键词提取</a></li>
<li>
<ul>
<li><a href="#TFIDF_265">基于TF-IDF算法的关键词提取</a></li>
<li><a href="#_TextRank__308">基于 TextRank 算法的关键词抽取</a></li>
</ul>
    </li>
<li><a href="#_329">返回词语在原文的起止位置（论文常用算法）</a></li>
<li><a href="#_370">词频统计（附智能程序）</a></li>
</ul>
   </li>
<li><a href="#_402">每文一语</a></li>
</ul>
 </li>
</ul>
</div>
<p></p> 
<h1>
<a id="_1"></a>文本分类概述</h1> 
<h2>
<a id="_3"></a>文本分类的应用</h2> 
<p>在大数据时代，网络上的文本数据日益增长。采用文本分类技术对海量数据进行科学地组织和管理显得尤为重要。</p> 
<p>文本作为分布最广、数据量最大的信息载体，如何对这些数据进行有效地组织和管理是亟待解决的难题。</p> 
<p>文本分类是自然语言处理任务中的一项基础性工作，其目的是对文本资源进行整理和归类，同时其也是解决文本信息过载问题的关键环节。</p> 
<p>文本分类按照任务类型的不同可划分为问题分类、主题分类以及情感分类。</p> 
<p>常用于数字化图书馆、舆情分析、新闻推荐、邮件过滤等领域，为文本资源的查询、检索提供了有力支撑，是当前的主要研究热点之一。<br> <img src="https://images2.imgbox.com/e0/9e/F7tYfaTd_o.png" alt="在这里插入图片描述"><br> 问题分类在问答系统 ( Question AnsweringSystem) 中起着重要作用，提高问题分类的准确率有助于构建更加鲁棒的 QA 系统。</p> 
<p>在图书情报领域，专利、图书、期刊论文、学术新闻等跨类型学术资源的自动组织与分类是数字化图书馆的关键技术，有利于工业企业、科研院所的研究人员更快地掌握各类前沿动态。</p> 
<p>随着移动互联网的发展，人们获取信息的方式发生了变化，由单纯的信息检索转变为“搜索 + 推荐”的双引擎模式。但无论是搜索还是推荐，其背后都离不开机器对内容的理解能力。</p> 
<p>文本作为网络上分布最广、数据量最大的信息载体，准确的分类标签为资源检索和新闻资讯的个性化推荐提供了有力支撑，使得推荐的信息能够尽可能地满足千人千面的用户需求。</p> 
<p>情感分类(情感极性分析) 是文本分类的重要分支。如在社交媒体中，对用户评论的情感倾向进行分析( 积极、消极等) 。情感极性分析能帮助企业理解用户消费习惯、分析热点话题和危机舆情监控，为企业提供有力的决策支持。此外，情感分析技术还可以用在商品和服务领域。例如对产品、电影、图书评论的情感分类。</p> 
<p>智能手机的普及促进了在线即时消息和短信使用的增长。将文本分类技术应用于邮件检测和短信过滤任务，可以帮助人们快速筛选有用信息。</p> 
<h2>
<a id="_26"></a>文本分类的挑战</h2> 
<p><img src="https://images2.imgbox.com/58/4d/ju2GwVwt_o.png" alt="在这里插入图片描述"><br> <strong>(1) 数据标注瓶颈。</strong><br> 数据和算法是推动人工智能向前发展的主要动力。高质量的标记数据有助于提升文本分类的准确率。然而，网络上存在大量杂乱无章的无标签数据，依赖人工标注的成本高，效率低。无监督数据的特征学习和半监督学习自动标注过程中的噪音剔除是当前的研究热点和难点。</p> 
<p><strong>(2) 深度学习的可解释性。</strong><br> 深度学习模型在特征提取，语义挖掘方面有着独特的优势，在文本分类任务中取得了不俗的成绩。然而，深度学习是一个黑盒模型，其训练过程难以复现，隐语义和输出结果的可解释性较差。例如，结合迁移学习理论的文本分类方法，初始预训练的语言模型学习到哪些知识，在参数迁移、特征迁移、针对目标域的训练数据和分类任务进行微调时，保留了哪些特征，我们很难了解。这使得模型的改进与优化失去了明确的指引，也大大加深了研究人员调参的难度。</p> 
<p><strong>(3) 跨语种或多语种的文本分类。</strong><br> 在经济全球化的大背景下，跨语言的文本分类在跨国组织和企业中的应用越来越多。将在源语言中训练的分类模型应用于另一种语言( 目标语言) 的分类任务，其挑战性在于源语言数据的特征空间与目标语言数据之间缺乏重叠。各国的语言、文字包含不同的语言学特征，这无疑加大了跨语言文本分类的难度。</p> 
<p>当前，基于机器翻译技术的跨语言文本分类方法过于依赖双语词典和平行语料，在一些小语种上的表现较差。通过跨语言文本表示技术和迁移学习方法训练得到独立于语言的分类模型是未来的重点研究方向。</p> 
<p>目前自然语言的处理，在文本分类上的技术研究，已经不断地在成熟发展，这方面的生态也在不断地扩张和壮大。</p> 
<h2>
<a id="_41"></a>文本分类的算法应用</h2> 
<p>(1) <strong>对传统方法进行优化</strong>如常用机器学习模型的改进; 传统的机器学习算法、特征提取方法与深度学习模型的融合。</p> 
<p><strong>(2) 新理论、新方法的提出</strong>如将图卷积神经网络( Graph Convolutional Networks ) 应 用于文本分类任务。</p> 
<p>(3) 引入知识库、<strong>知识图谱等结构化的外部知识</strong>，优化文本表示和预训练的语言模型，进而提升文本分类的性能。</p> 
<p>目前相对于比较成熟的还是机器学习构建文本分类，也比较的简单易懂，在逻辑上通过基本的算法调整，在算法上结合逻辑的优化，机器学习和深度学习将在自然语言处理有着极大地生长空间！</p> 
<h1>
<a id="_50"></a>文本分类所需知识</h1> 
<h3>
<a id="jieba_51"></a>中文分词神器-jieba</h3> 
<p>汉字具有源远流长的文化底蕴，如何利用逻辑性极强的机器来理解具有诗情画意的中文汉字，我们都知道在古代是没有标点符号的，那么人们是通过什么来进行断句的呢？</p> 
<p>古文从来没有标点，古人读书，首先要学会“句读”，所以“习六书，明句读”是读书人的基本功。简而言之就是根据文章的意思和固定的格式以及对应的词义进行断句。这也要求知识分子需要从小锻炼自己的读书能力，随着时代的发展和进步，人们的生活步伐必须要跟进社会的进步，标点符号慢慢的走进了人们的视野，“16世纪时,小马努蒂乌斯提出了一套正规的标点符号系统。主要符号源于希腊语法家们所用的小点,但常常改变其含义。</p> 
<p>断句在自然语言处理中，显得十分重要，因为我们需要根据文本分词组成的一个大的迭代对象进行词的向量化，所以我们介绍一种python第三方库——jieba，中文分词的神器！<br> <img src="https://images2.imgbox.com/72/5a/wEaMfpDR_o.png" alt="在这里插入图片描述"></p> 
<p>Jieba库是优秀的中文分词第三方库，中文文本需要通过分词获得单个的词语。</p> 
<p>Jieba库的分词原理：利用一个中文词库，确定汉字之间的关联概率，汉字间概率大的组成词组，形成分词结果。除了分词，用户还可以添加自定义的词组。</p> 
<h4>
<a id="jieba_63"></a>jieba分词的三种模式</h4> 
<p>精确模式：就是把一段文本精确地切分成若干个中文单词，若干个中文单词之间经过组合，就精确地还原为之前的文本。<strong>其中不存在冗余单词。</strong></p> 
<p>全模式：将一段文本中所有可能的词语都扫描出来，可能有一段文本它可以切分成不同的模式，或者有不同的角度来切分变成不同的词语，<strong>在全模式下，Jieba库会将各种不同的组合都挖掘出来。分词后的信息再组合起来会有冗余，不再是原来的文本。</strong></p> 
<p>搜索引擎模式：在精确模式基础上，对发现的那些长的词语，我们会对它再次切分，进而适合搜索引擎对短词语的索引和搜索。<strong>也有冗余。</strong><br> <img src="https://images2.imgbox.com/d8/a5/QbmOYXoH_o.png" alt="在这里插入图片描述">jieba.cut_for_search 方法接受两个参数：需要分词的字符串；是否使用 HMM 模型。</p> 
<p>该方法适合用于搜索引擎构建倒排索引的分词，粒度比较细</p> 
<p>使用搜索引擎模型，有限公司被分词为：有限 公司</p> 
<p><strong>jieba库的一般函数</strong></p> 
<p><img src="https://images2.imgbox.com/e1/a2/rp4hA9ik_o.png" alt="在这里插入图片描述"><strong>案例：</strong><br> <img src="https://images2.imgbox.com/80/fb/m6JXfhWh_o.png" alt="在这里插入图片描述"><br> cut()函数有4个参数：</p> 
<p><strong>第一个参数：待分词文本</strong></p> 
<p><strong>cut_all：设置使用全模式(True)还是精确模式(False)； 默认False<br> use_paddle：控制是否使用Paddle模式进行分词<br> HMM：控制是否使用HMM模式识别新词</strong></p> 
<p>use_paddle参数可以设置开启paddle模式</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> jieba
<span class="token keyword">import</span> paddle
str1 <span class="token operator">=</span> <span class="token string">'我来到了西北皇家理工学院，发现这儿真不错'</span>
<span class="token comment">#jieba.enable_paddle()   已经停用</span>
paddle<span class="token punctuation">.</span>enable_static<span class="token punctuation">(</span><span class="token punctuation">)</span>
seg_list <span class="token operator">=</span> jieba<span class="token punctuation">.</span>cut<span class="token punctuation">(</span>str1<span class="token punctuation">,</span> use_paddle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>  <span class="token comment">#使用paddle模式进行分词</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Paddle模式分词结果：'</span><span class="token punctuation">,</span> <span class="token string">'/'</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>seg_list<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<pre><code class="prism language-python"><span class="token triple-quoted-string string">'''
Paddle模式分词结果： 
我/来到/了/西北/皇家/理工学院/，/发现/这儿/真不错
'''</span>
</code></pre> 
<p>一般的，lcut比较的常用，大多用于分词</p> 
<h4>
<a id="_107"></a>词性标注</h4> 
<p>通常中文里面的词性大多都已经在下面列举出来了<br> <img src="https://images2.imgbox.com/79/2f/w24XQrHC_o.png" alt="在这里插入图片描述"></p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> jieba
<span class="token keyword">import</span> jieba<span class="token punctuation">.</span>posseg <span class="token keyword">as</span> pseg
<span class="token comment">#jieba.enable_paddle()</span>
str2 <span class="token operator">=</span> <span class="token string">'上海自来水来自海上'</span>
seg_list <span class="token operator">=</span> pseg<span class="token punctuation">.</span>cut<span class="token punctuation">(</span>str2<span class="token punctuation">,</span> use_paddle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>  <span class="token comment">#使用posseg进行分词</span>
<span class="token keyword">for</span> seg<span class="token punctuation">,</span> flag <span class="token keyword">in</span> seg_list<span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>seg<span class="token punctuation">,</span> flag<span class="token punctuation">)</span>
</code></pre> 
<blockquote> 
 <p>上海 ns<br> 自来水 l<br> 来自 v<br> 海上 s</p> 
</blockquote> 
<h4>
<a id="_126"></a>载入词典（不分词）</h4> 
<p>可以指定自己自定义的词典，以便包含 jieba 词库里没有的词。虽然jieba 有新词识别能力，但是自行添加新词可以保证更高的正确率</p> 
<p>这个文件需要自己根据自己的使用场景进行测试，这里提供一个</p> 
<pre><code class="prism language-python">ieba<span class="token punctuation">.</span>load_userdict<span class="token punctuation">(</span>file_name<span class="token punctuation">)</span> <span class="token comment"># file_name 为文件类对象或自定义词典的路径</span>
</code></pre> 
<p>词典格式和 dict.txt 一样，一个词占一行；每一行分三部分：词语、词频（可省略）、词性（可省略），<strong>用空格隔开，顺序不可颠倒。</strong><br> <img src="https://images2.imgbox.com/4e/ca/FNPJ3kiB_o.png" alt="在这里插入图片描述"><br> <a href="https://download.csdn.net/download/weixin_47723732/39157262?spm=1001.2014.3001.5503"><strong>有需要的可以点击此处下载</strong></a></p> 
<p>file_name 若为路径或二进制方式打开的文件，则文件必须为 UTF-8 编码。</p> 
<p>词频省略时使用自动计算的能保证分出该词的词频。</p> 
<pre><code class="prism language-python">jieba<span class="token punctuation">.</span>add_word<span class="token punctuation">(</span>word<span class="token punctuation">,</span> freq<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> tag<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span> 和 del_word<span class="token punctuation">(</span>word<span class="token punctuation">)</span> 可在程序中动态修改词典。

jieba<span class="token punctuation">.</span>suggest_freq<span class="token punctuation">(</span>segment<span class="token punctuation">,</span> tune<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span> 可调节单个词语的词频，使其能（或不能）被分出来。

注意：自动计算的词频在使用 HMM 新词发现功能时可能无效
</code></pre> 
<pre><code class="prism language-python">jieba<span class="token punctuation">.</span>add_word<span class="token punctuation">(</span><span class="token string">'铃儿响叮当'</span><span class="token punctuation">)</span>
jieba<span class="token punctuation">.</span>add_word<span class="token punctuation">(</span><span class="token string">'让世界充满爱'</span><span class="token punctuation">)</span>
jieba<span class="token punctuation">.</span>add_word<span class="token punctuation">(</span><span class="token string">'迅雷不及掩耳之势'</span><span class="token punctuation">)</span>
lcut_res <span class="token operator">=</span> jieba<span class="token punctuation">.</span>lcut<span class="token punctuation">(</span>test_content<span class="token punctuation">,</span> cut_all<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> HMM<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'[添加自定义词语]：'</span><span class="token punctuation">,</span> lcut_res<span class="token punctuation">)</span>
</code></pre> 
<blockquote> 
 <p>[添加自定义词语]：</p> 
 <hr> 
 <p>[‘迅雷’, ‘迅雷不及’, ‘迅雷不及掩耳’, ‘不及’, ‘掩耳’, ‘掩耳盗铃’,‘铃儿响叮当’, ‘响叮当’, ‘叮当’, ‘当仁不让’, ‘不让’, ‘让世界充满爱’, ‘世界’, ‘充满’, ‘爱’, ‘之’, ‘势’]</p> 
</blockquote> 
<p>add_word()有三个参数，分别是添加的词语、词频和词性，词频和词性可以省略。</p> 
<p>添加自定义词语后，自定义词语如果能匹配到，就会返回到分词结果中。如果自定义词语在待分词语句中没有连续的匹配结果，分词结果中不会体现。</p> 
<h4>
<a id="_166"></a>词典中删除词语（不显示）</h4> 
<pre><code class="prism language-python">jieba<span class="token punctuation">.</span>del_word<span class="token punctuation">(</span><span class="token string">'不及'</span><span class="token punctuation">)</span>
jieba<span class="token punctuation">.</span>del_word<span class="token punctuation">(</span><span class="token string">'不让'</span><span class="token punctuation">)</span>
jieba<span class="token punctuation">.</span>del_word<span class="token punctuation">(</span><span class="token string">'之'</span><span class="token punctuation">)</span>
lcut_res <span class="token operator">=</span> jieba<span class="token punctuation">.</span>lcut<span class="token punctuation">(</span>test_content<span class="token punctuation">,</span> cut_all<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> HMM<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'[删除词语]：'</span><span class="token punctuation">,</span> lcut_res<span class="token punctuation">)</span>
</code></pre> 
<blockquote> 
 <p>[删除词语]：</p> 
 <hr> 
 <p>[‘迅雷’, ‘迅雷不及’, ‘迅雷不及掩耳’, ‘掩耳’, ‘掩耳盗铃’, ‘儿’, ‘响叮当’, ‘叮当’,‘当仁不让’, ‘世界’, ‘充满’, ‘爱’, ‘之’, ‘势’]</p> 
</blockquote> 
<p>删除的词语一般是语气助词、逻辑连接词等，这些词对于文本分析没有实际意义，反而会成为干扰。</p> 
<p>在设置删除的词语后，结果中不再有删除的词语，但对于单个字，会独立成词，所以删除后在结果中也还存在。</p> 
<p>怎么理解这句话呢，我们看看一个实际的例子！</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> jieba
jieba<span class="token punctuation">.</span>load_userdict<span class="token punctuation">(</span><span class="token string">'用户词典.txt'</span><span class="token punctuation">)</span>
jieba<span class="token punctuation">.</span>del_word<span class="token punctuation">(</span><span class="token string">'一低头'</span><span class="token punctuation">)</span>
seg_list <span class="token operator">=</span> jieba<span class="token punctuation">.</span>cut<span class="token punctuation">(</span><span class="token string">'心灵感应般地蓦然回首，才能撞见那一低头的温柔；也最是那一低头的温柔，似一朵水莲花不胜凉风的娇羞；也最是那一抹娇羞，才能让两人携手共白首。'</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'删除自定义词时的精确模式分词结果：n'</span><span class="token punctuation">,</span> <span class="token string">'/'</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>seg_list<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<blockquote> 
 <p>删除自定义词时的精确模式分词结果：</p> 
 <hr> 
 <p>心灵感应/般地/蓦然回首/，/才能/撞见/那一/低头/的/温柔/；/也/最/是/那/一/低头/的/温柔/，/似/一朵/水莲花/不胜/凉风/的/娇羞/；/也/最/是/那/一抹/娇羞/，/才能/让/两人/携手/共/白首/。</p> 
</blockquote> 
<p>一低头，动态删除，但是没有意味着我把“一低头”真正的在这个词库里面删除了，而是分解了，组合为其他的词组了</p> 
<h4>
<a id="_199"></a>停用词过滤</h4> 
<p>当然，这里我们还可以是用过滤词，也就是停用词进行对一些无用删除，过滤，就像下面的这个一样</p> 
<pre><code class="prism language-python"><span class="token comment">#启动停用词过滤</span>
<span class="token keyword">import</span> jieba
<span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">'stopwords.txt'</span><span class="token punctuation">,</span> <span class="token string">'r+'</span><span class="token punctuation">,</span> encoding <span class="token operator">=</span> <span class="token string">'utf-8'</span><span class="token punctuation">)</span><span class="token keyword">as</span> fp<span class="token punctuation">:</span>
    stopwords <span class="token operator">=</span> fp<span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">'n'</span><span class="token punctuation">)</span>  <span class="token comment">#将停用词词典的每一行停用词作为列表中的一个元素</span>
word_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>  <span class="token comment">#用于存储过滤停用词后的分词结果</span>
text <span class="token operator">=</span> <span class="token string">'商务部4月23日发布的数据显示，一季度，全国农产品网络零售额达936.8亿元，增长31.0%；电商直播超过400万场。电商给农民带来了新的机遇。'</span>
seg_list <span class="token operator">=</span> jieba<span class="token punctuation">.</span>cut<span class="token punctuation">(</span>text<span class="token punctuation">)</span>
<span class="token keyword">for</span> seg <span class="token keyword">in</span> seg_list<span class="token punctuation">:</span>
    <span class="token keyword">if</span> seg <span class="token keyword">not</span> <span class="token keyword">in</span> stopwords<span class="token punctuation">:</span>
        word_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>seg<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'启用停用词过滤时的分词结果：n'</span><span class="token punctuation">,</span> <span class="token string">'/'</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>word_list<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/30/63/itiFD1Ts_o.png" alt="在这里插入图片描述"><a href="https://download.csdn.net/download/weixin_47723732/39157229?spm=1001.2014.3001.5503"><strong>有需要的可以点击此处下载</strong></a></p> 
<h4>
<a id="_218"></a>调整词语的词频</h4> 
<p>调整词语的词频，调整其在结果中被分出来的可能性，使分词结果满足预期。</p> 
<p>分两种情况，一种是将分词结果中的一个长词拆分成多个词，另一种是将分词结果中的多个词组成一个词。</p> 
<pre><code class="prism language-python">lcut_res <span class="token operator">=</span> jieba<span class="token punctuation">.</span>lcut<span class="token punctuation">(</span>test_content<span class="token punctuation">,</span> cut_all<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> HMM<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'[设置前]：'</span><span class="token punctuation">,</span> lcut_res<span class="token punctuation">)</span>
jieba<span class="token punctuation">.</span>suggest_freq<span class="token punctuation">(</span><span class="token string">'让世界充满爱'</span><span class="token punctuation">,</span> <span class="token boolean">True</span><span class="token punctuation">)</span>
lcut_res <span class="token operator">=</span> jieba<span class="token punctuation">.</span>lcut<span class="token punctuation">(</span>test_content<span class="token punctuation">,</span> cut_all<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> HMM<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'[设置后]：'</span><span class="token punctuation">,</span> lcut_res<span class="token punctuation">)</span>
</code></pre> 
<blockquote> 
 <p>[设置前]： [‘迅雷不及’, ‘掩耳盗铃’, ‘儿’, ‘响’, ‘叮’, ‘当仁不让’, ‘世界’, ‘充满’, ‘爱’, ‘之’, ‘势’]<br> [设置后]： [‘迅雷不及’, ‘掩耳盗铃’, ‘儿’, ‘响叮当’, ‘仁’, ‘不’, ‘让世界充满爱’, ‘之’, ‘势’]</p> 
</blockquote> 
<p>再来一个案例，让理解变得更加深刻：</p> 
<pre><code class="prism language-python">
 他<span class="token operator">/</span>认为<span class="token operator">/</span>未来<span class="token operator">/</span>几年<span class="token operator">/</span>健康<span class="token operator">/</span>产业<span class="token operator">/</span>在<span class="token operator">/</span>GDP<span class="token operator">/</span>中将<span class="token operator">/</span>占<span class="token operator">/</span>比<span class="token operator">/</span>第一<span class="token operator">/</span>。

</code></pre> 
<pre><code class="prism language-python"><span class="token comment">#修改词频</span>
<span class="token keyword">import</span> jieba
str3 <span class="token operator">=</span> <span class="token string">'他认为未来几年健康产业在GDP中将占比第一。'</span>
jieba<span class="token punctuation">.</span>suggest_freq<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token string">'中'</span><span class="token punctuation">,</span> <span class="token string">'将'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token boolean">True</span><span class="token punctuation">)</span>   <span class="token comment">#修改词频  强制“中将”</span>
jieba<span class="token punctuation">.</span>suggest_freq<span class="token punctuation">(</span><span class="token string">'占比'</span><span class="token punctuation">,</span> <span class="token boolean">True</span><span class="token punctuation">)</span>         <span class="token comment">#强制让“占比”作为一次词</span>
seg_list <span class="token operator">=</span> jieba<span class="token punctuation">.</span>cut<span class="token punctuation">(</span>str3<span class="token punctuation">,</span> HMM<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'精确模式分词结果：n'</span><span class="token punctuation">,</span> <span class="token string">'/'</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>seg_list<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<pre><code class="prism language-python">
 他<span class="token operator">/</span>认为<span class="token operator">/</span>未来<span class="token operator">/</span>几年<span class="token operator">/</span>健康<span class="token operator">/</span>产业<span class="token operator">/</span>在<span class="token operator">/</span>GDP<span class="token operator">/</span>中<span class="token operator">/</span>将<span class="token operator">/</span>占比<span class="token operator">/</span>第一<span class="token operator">/</span>。

</code></pre> 
<p>我们的思路有很多种，比如我们可以将这些不需要分词，使用jieba.addword()加入到里面，但是有时候的效果并不好，如果我们采用这样的模式，可能效果更加的好！</p> 
<p>例如：<br> <img src="https://images2.imgbox.com/10/02/F1FzwDKU_o.png" alt="在这里插入图片描述"><br> <strong>方法有很多，“条条大路通罗马”，需要的时候可以多去尝试一下，这些方法，看效果最终谁比较的凸出明显！</strong></p> 
<h3>
<a id="_262"></a>关键词提取</h3> 
<p>关键词提取使用jieba中的analyse模块，基于两种不同的算法，提供了两个不同的方法。</p> 
<h4>
<a id="TFIDF_265"></a>基于TF-IDF算法的关键词提取</h4> 
<pre><code class="prism language-python">jieba<span class="token punctuation">.</span>analyse<span class="token punctuation">.</span>extract_tags<span class="token punctuation">(</span>sentence<span class="token punctuation">,</span> topK<span class="token operator">=</span><span class="token number">20</span><span class="token punctuation">,</span> withWeight<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> allowPOS<span class="token operator">=</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
sentence 为待提取的文本
topK 为返回几个 TF<span class="token operator">/</span>IDF 权重最大的关键词，默认值为 <span class="token number">20</span>
withWeight 为是否一并返回关键词权重值，默认值为 <span class="token boolean">False</span>
</code></pre> 
<pre><code class="prism language-python">allowPOS 仅包括指定词性的词，默认值为空，即不筛选
jieba<span class="token punctuation">.</span>analyse<span class="token punctuation">.</span>TFIDF<span class="token punctuation">(</span>idf_path<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span> 新建 TFIDF 实例，idf_path 为 IDF 频率文件
jieba<span class="token punctuation">.</span>analyse<span class="token punctuation">.</span>set_idf_path<span class="token punctuation">(</span>file_name<span class="token punctuation">)</span> <span class="token comment"># file_name为自定义语料库的路径</span>
jieba<span class="token punctuation">.</span>analyse<span class="token punctuation">.</span>set_stop_words<span class="token punctuation">(</span>file_name<span class="token punctuation">)</span> <span class="token comment"># file_name为自定义语料库的路径</span>
</code></pre> 
<p><strong>案例代码</strong></p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> jieba<span class="token punctuation">.</span>analyse
sentence<span class="token operator">=</span><span class="token triple-quoted-string string">'''在克鲁伊夫时代，巴萨联赛中完成四连冠，后三个冠军都是在末轮逆袭获得的。在91//92赛季，巴萨末轮前落后皇马1分，结果皇马客场不敌特内里费使得巴萨逆转。一年之后，巴萨用几乎相同的方式逆袭，皇马还是末轮输给了特内里费。在93/94赛季中，巴萨末轮落后拉科1分。巴萨末轮5比2屠杀塞维利亚，拉科则0比0战平瓦伦西亚，巴萨最终在积分相同的情况下靠直接交锋时的战绩优势夺冠。神奇的是，拉科球员久基齐在终场前踢丢点球，这才有巴萨的逆袭。
巴萨上一次压哨夺冠，发生在09/10赛季中。末轮前巴萨领先皇马1分，只要赢球就夺冠。末轮中巴萨4比0大胜巴拉多利德，皇马则与对手踢平。巴萨以99分的佳绩创下五大联赛积分记录，皇马则以96分成为了悲情的史上最强亚军。
在48/49赛季中，巴萨末轮2比1拿下同城死敌西班牙人，以2分优势夺冠。52/53赛季，巴萨末轮3比0战胜毕巴，以2分优势力压瓦伦西亚夺冠。在59/60赛季，巴萨末轮5比0大胜萨拉戈萨。皇马巴萨积分相同，巴萨靠直接交锋时的战绩优势夺冠。'''</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>jieba<span class="token punctuation">.</span>analyse<span class="token punctuation">.</span>extract_tags<span class="token punctuation">(</span>sentence<span class="token punctuation">,</span> topK<span class="token operator">=</span><span class="token number">20</span><span class="token punctuation">,</span> withWeight<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> allowPOS<span class="token operator">=</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>jieba<span class="token punctuation">.</span>analyse<span class="token punctuation">.</span>extract_tags<span class="token punctuation">(</span>sentence<span class="token punctuation">,</span> topK<span class="token operator">=</span><span class="token number">20</span><span class="token punctuation">,</span> withWeight<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> allowPOS<span class="token operator">=</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>jieba<span class="token punctuation">.</span>analyse<span class="token punctuation">.</span>extract_tags<span class="token punctuation">(</span>sentence<span class="token punctuation">,</span> topK<span class="token operator">=</span><span class="token number">20</span><span class="token punctuation">,</span> withWeight<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> allowPOS<span class="token operator">=</span><span class="token punctuation">(</span><span class="token string">'i'</span><span class="token punctuation">,</span><span class="token string">'n'</span><span class="token punctuation">,</span><span class="token string">'f'</span><span class="token punctuation">,</span><span class="token string">'s'</span><span class="token punctuation">,</span><span class="token string">'t'</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<pre><code class="prism language-python"><span class="token punctuation">[</span><span class="token string">'巴萨'</span><span class="token punctuation">,</span> <span class="token string">'末轮'</span><span class="token punctuation">,</span> <span class="token string">'皇马'</span><span class="token punctuation">,</span> <span class="token string">'夺冠'</span><span class="token punctuation">,</span> <span class="token string">'赛季'</span><span class="token punctuation">,</span> <span class="token string">'拉科'</span><span class="token punctuation">,</span> <span class="token string">'内里费'</span><span class="token punctuation">,</span> <span class="token string">'积分'</span><span class="token punctuation">,</span> <span class="token string">'逆袭'</span><span class="token punctuation">,</span> <span class="token string">'瓦伦西亚'</span><span class="token punctuation">,</span> <span class="token string">'优势'</span><span class="token punctuation">,</span> <span class="token string">'大胜'</span><span class="token punctuation">,</span> <span class="token string">'联赛'</span><span class="token punctuation">,</span> <span class="token string">'相同'</span><span class="token punctuation">,</span> <span class="token string">'战绩'</span><span class="token punctuation">,</span> <span class="token string">'交锋'</span><span class="token punctuation">,</span> <span class="token string">'四连冠'</span><span class="token punctuation">,</span> <span class="token string">'多利德'</span><span class="token punctuation">,</span> <span class="token string">'落后'</span><span class="token punctuation">,</span> <span class="token string">'克鲁伊夫'</span><span class="token punctuation">]</span>
<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token string">'巴萨'</span><span class="token punctuation">,</span> <span class="token number">1.2181461971020409</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'末轮'</span><span class="token punctuation">,</span> <span class="token number">0.7319245409938775</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'皇马'</span><span class="token punctuation">,</span> <span class="token number">0.5362676344</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'夺冠'</span><span class="token punctuation">,</span> <span class="token number">0.42225835063265305</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'赛季'</span><span class="token punctuation">,</span> <span class="token number">0.39762426810693874</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'拉科'</span><span class="token punctuation">,</span> <span class="token number">0.2471207792387755</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'内里费'</span><span class="token punctuation">,</span> <span class="token number">0.18912486601360545</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'积分'</span><span class="token punctuation">,</span> <span class="token number">0.1691336641957143</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'逆袭'</span><span class="token punctuation">,</span> <span class="token number">0.16264989799863944</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'瓦伦西亚'</span><span class="token punctuation">,</span> <span class="token number">0.16264989799863944</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'优势'</span><span class="token punctuation">,</span> <span class="token number">0.15362255099918368</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'大胜'</span><span class="token punctuation">,</span> <span class="token number">0.12660622859646256</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'联赛'</span><span class="token punctuation">,</span> <span class="token number">0.12398892393455782</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'相同'</span><span class="token punctuation">,</span> <span class="token number">0.12255595193938776</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'战绩'</span><span class="token punctuation">,</span> <span class="token number">0.12077275008340135</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'交锋'</span><span class="token punctuation">,</span> <span class="token number">0.11605496086870748</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'四连冠'</span><span class="token punctuation">,</span> <span class="token number">0.09456243300680273</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'多利德'</span><span class="token punctuation">,</span> <span class="token number">0.09456243300680273</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'落后'</span><span class="token punctuation">,</span> <span class="token number">0.09077944490340135</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'克鲁伊夫'</span><span class="token punctuation">,</span> <span class="token number">0.08708888002244898</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token string">'末轮'</span><span class="token punctuation">,</span> <span class="token number">2.2989937505576923</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'皇马'</span><span class="token punctuation">,</span> <span class="token number">1.5159873510923079</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'赛季'</span><span class="token punctuation">,</span> <span class="token number">1.1240532194561537</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'内里费'</span><span class="token punctuation">,</span> <span class="token number">0.5346414481538462</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'优势'</span><span class="token punctuation">,</span> <span class="token number">0.43427913455538464</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'战绩'</span><span class="token punctuation">,</span> <span class="token number">0.34141527427423074</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'交锋'</span><span class="token punctuation">,</span> <span class="token number">0.32807844707115386</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'压哨'</span><span class="token punctuation">,</span> <span class="token number">0.2298993750557692</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'赢球'</span><span class="token punctuation">,</span> <span class="token number">0.2298993750557692</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'力压'</span><span class="token punctuation">,</span> <span class="token number">0.2298993750557692</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'终场'</span><span class="token punctuation">,</span> <span class="token number">0.22506640528076924</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'战平'</span><span class="token punctuation">,</span> <span class="token number">0.22120735344615383</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'悲情'</span><span class="token punctuation">,</span> <span class="token number">0.21173665180961537</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'点球'</span><span class="token punctuation">,</span> <span class="token number">0.20620430426153843</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'佳绩'</span><span class="token punctuation">,</span> <span class="token number">0.19894864597115386</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'客场'</span><span class="token punctuation">,</span> <span class="token number">0.1913352679498077</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'球员'</span><span class="token punctuation">,</span> <span class="token number">0.1652386529725</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'冠军'</span><span class="token punctuation">,</span> <span class="token number">0.14683416229307691</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'战胜'</span><span class="token punctuation">,</span> <span class="token number">0.14229592272</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'领先'</span><span class="token punctuation">,</span> <span class="token number">0.13591626767673076</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
</code></pre> 
<pre><code class="prism language-python"><span class="token comment"># 基于TF-IDF算法的关键词提取</span>
<span class="token keyword">from</span> jieba <span class="token keyword">import</span> analyse
text <span class="token operator">=</span> <span class="token string">'记者日前从中国科学院南京地质古生物研究所获悉，该所早期生命研究团队与美国学者合作，在中国湖北三峡地区的石板滩生物群中，发现了4种形似树叶的远古生物。这些“树叶”实际上是形态奇特的早期动物，它们生活在远古海洋底部。相关研究成果已发表在古生物学国际专业期刊《古生物学杂志》上。'</span>
keywords <span class="token operator">=</span> analyse<span class="token punctuation">.</span>extract_tags<span class="token punctuation">(</span>text<span class="token punctuation">,</span> topK<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> withWeight<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> allowPOS<span class="token operator">=</span><span class="token punctuation">(</span><span class="token string">'n'</span><span class="token punctuation">,</span> <span class="token string">'v'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>keywords<span class="token punctuation">)</span>
</code></pre> 
<pre><code class="prism language-python"><span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token string">'古生物学'</span><span class="token punctuation">,</span> <span class="token number">0.783184303024</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'树叶'</span><span class="token punctuation">,</span> <span class="token number">0.6635900468544</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'生物群'</span><span class="token punctuation">,</span> <span class="token number">0.43238540794400004</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'古生物'</span><span class="token punctuation">,</span> <span class="token number">0.38124919198039997</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'期刊'</span><span class="token punctuation">,</span> <span class="token number">0.36554014868720003</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'石板'</span><span class="token punctuation">,</span> <span class="token number">0.34699723913040004</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'形似'</span><span class="token punctuation">,</span> <span class="token number">0.3288202017184</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'研究成果'</span><span class="token punctuation">,</span> <span class="token number">0.3278758070928</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'团队'</span><span class="token punctuation">,</span> <span class="token number">0.2826627565264</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'获悉'</span><span class="token punctuation">,</span> <span class="token number">0.28072960723920004</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
</code></pre> 
<h4>
<a id="_TextRank__308"></a>基于 TextRank 算法的关键词抽取</h4> 
<p>两种方法的区别是默认提取的词性不同</p> 
<p>当然算法不同，结果可能有差异</p> 
<pre><code class="prism language-python">jieba<span class="token punctuation">.</span>analyse<span class="token punctuation">.</span>textrank<span class="token punctuation">(</span>sentance<span class="token punctuation">,</span> topK<span class="token operator">=</span><span class="token number">20</span><span class="token punctuation">,</span> withWeight<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> allowPOS<span class="token operator">=</span><span class="token punctuation">(</span><span class="token string">'ns'</span><span class="token punctuation">,</span> <span class="token string">'n'</span><span class="token punctuation">,</span> <span class="token string">'vn'</span><span class="token punctuation">,</span> <span class="token string">'v'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<pre><code class="prism language-python"><span class="token comment"># 基于TextRank算法的关键词提取</span>
<span class="token keyword">from</span> jieba <span class="token keyword">import</span> analyse
text <span class="token operator">=</span> <span class="token string">'记者日前从中国科学院南京地质古生物研究所获悉，该所早期生命研究团队与美国学者合作，在中国湖北三峡地区的石板滩生物群中，发现了4种形似树叶的远古生物。这些“树叶”实际上是形态奇特的早期动物，它们生活在远古海洋底部。相关研究成果已发表在古生物学国际专业期刊《古生物学杂志》上。'</span>
keywords <span class="token operator">=</span> analyse<span class="token punctuation">.</span>textrank<span class="token punctuation">(</span>text<span class="token punctuation">,</span> topK<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> withWeight<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> allowPOS<span class="token operator">=</span><span class="token punctuation">(</span><span class="token string">'n'</span><span class="token punctuation">,</span> <span class="token string">'v'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>keywords<span class="token punctuation">)</span>
</code></pre> 
<pre><code class="prism language-python"><span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token string">'古生物学'</span><span class="token punctuation">,</span> <span class="token number">1.0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'树叶'</span><span class="token punctuation">,</span> <span class="token number">0.8797803471074045</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'形似'</span><span class="token punctuation">,</span> <span class="token number">0.6765568513591282</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'专业'</span><span class="token punctuation">,</span> <span class="token number">0.6684901270801065</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'生物'</span><span class="token punctuation">,</span> <span class="token number">0.648692596888148</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'发表'</span><span class="token punctuation">,</span> <span class="token number">0.6139083953888275</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'生物群'</span><span class="token punctuation">,</span> <span class="token number">0.59981945604977</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'期刊'</span><span class="token punctuation">,</span> <span class="token number">0.5651065025924439</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'国际'</span><span class="token punctuation">,</span> <span class="token number">0.5642917600351786</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'获悉'</span><span class="token punctuation">,</span> <span class="token number">0.5620719278559326</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
</code></pre> 
<h3>
<a id="_329"></a>返回词语在原文的起止位置（论文常用算法）</h3> 
<p>返回词语在原文的起止位置使用jieba中的Tokenize模块，实际调用时使用tokenize()方法。<br> 注意，输入参数只接受 unicode</p> 
<pre><code class="prism language-python"><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'默认模式'</span><span class="token punctuation">)</span>
<span class="token keyword">for</span> tk <span class="token keyword">in</span> jieba<span class="token punctuation">.</span>tokenize<span class="token punctuation">(</span><span class="token string">u'华夏文明是一个经久不衰的文明'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"word %st start: %2d t end:%2d"</span> <span class="token operator">%</span> <span class="token punctuation">(</span>tk<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>tk<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>tk<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'搜索模式'</span><span class="token punctuation">)</span>
<span class="token keyword">for</span> tk <span class="token keyword">in</span> jieba<span class="token punctuation">.</span>tokenize<span class="token punctuation">(</span><span class="token string">u'华夏文明是一个经久不衰的文明'</span><span class="token punctuation">,</span> mode<span class="token operator">=</span><span class="token string">'search'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"word %st start: %2d t end:%2d"</span> <span class="token operator">%</span> <span class="token punctuation">(</span>tk<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>tk<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>tk<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

</code></pre> 
<pre><code class="prism language-python">默认模式
word 华夏	 start<span class="token punctuation">:</span>  <span class="token number">0</span> 	 end<span class="token punctuation">:</span> <span class="token number">2</span>
word 文明	 start<span class="token punctuation">:</span>  <span class="token number">2</span> 	 end<span class="token punctuation">:</span> <span class="token number">4</span>
word 是	     start<span class="token punctuation">:</span>  <span class="token number">4</span> 	 end<span class="token punctuation">:</span> <span class="token number">5</span>
word 一个	 start<span class="token punctuation">:</span>  <span class="token number">5</span> 	 end<span class="token punctuation">:</span> <span class="token number">7</span>
word 经久不衰 start<span class="token punctuation">:</span>  <span class="token number">7</span> 	 end<span class="token punctuation">:</span><span class="token number">11</span>
word 的	     start<span class="token punctuation">:</span> <span class="token number">11</span> 	 end<span class="token punctuation">:</span><span class="token number">12</span>
word 文明	 start<span class="token punctuation">:</span> <span class="token number">12</span> 	 end<span class="token punctuation">:</span><span class="token number">14</span>

<span class="token operator">**</span><span class="token operator">**</span><span class="token operator">**</span><span class="token operator">**</span><span class="token operator">**</span><span class="token operator">**</span><span class="token operator">**</span><span class="token operator">**</span><span class="token operator">**</span><span class="token operator">**</span><span class="token operator">**</span><span class="token operator">**</span><span class="token operator">**</span><span class="token operator">**</span><span class="token operator">**</span><span class="token operator">**</span><span class="token operator">**</span><span class="token operator">*</span>

搜索模式

word 华夏	 start<span class="token punctuation">:</span>  <span class="token number">0</span> 	 end<span class="token punctuation">:</span> <span class="token number">2</span>
word 文明	 start<span class="token punctuation">:</span>  <span class="token number">2</span> 	 end<span class="token punctuation">:</span> <span class="token number">4</span>
word 是	     start<span class="token punctuation">:</span>  <span class="token number">4</span> 	 end<span class="token punctuation">:</span> <span class="token number">5</span>
word 一个	 start<span class="token punctuation">:</span>  <span class="token number">5</span> 	 end<span class="token punctuation">:</span> <span class="token number">7</span>
word 经久	 start<span class="token punctuation">:</span>  <span class="token number">7</span> 	 end<span class="token punctuation">:</span> <span class="token number">9</span>
word 不衰	 start<span class="token punctuation">:</span>  <span class="token number">9</span> 	 end<span class="token punctuation">:</span><span class="token number">11</span>
word 经久不衰 start<span class="token punctuation">:</span>  <span class="token number">7</span> 	 end<span class="token punctuation">:</span><span class="token number">11</span>
word 的	     start<span class="token punctuation">:</span> <span class="token number">11</span> 	 end<span class="token punctuation">:</span><span class="token number">12</span>
word 文明	 start<span class="token punctuation">:</span> <span class="token number">12</span> 	 end<span class="token punctuation">:</span><span class="token number">14</span>

</code></pre> 
<h3>
<a id="_370"></a>词频统计（附智能程序）</h3> 
<pre><code class="prism language-python"><span class="token keyword">import</span> jieba
text <span class="token operator">=</span> <span class="token string">'蒸馍馍锅锅蒸馍馍，馍馍蒸了一锅锅，馍馍搁上桌桌，桌桌上面有馍馍。'</span>
<span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">'stopwords.txt'</span><span class="token punctuation">,</span> <span class="token string">'r+'</span><span class="token punctuation">,</span> encoding <span class="token operator">=</span> <span class="token string">'utf-8'</span><span class="token punctuation">)</span><span class="token keyword">as</span> fp<span class="token punctuation">:</span>
    stopwords <span class="token operator">=</span> fp<span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">'n'</span><span class="token punctuation">)</span>    <span class="token comment">#加载停用词</span>
word_dict <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span><span class="token punctuation">}</span>                           <span class="token comment">#用于存储词频统计结果的词典</span>
jieba<span class="token punctuation">.</span>suggest_freq<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token string">'桌桌'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token boolean">True</span><span class="token punctuation">)</span>        <span class="token comment">#让“桌桌”作为一个词</span>
seg_list <span class="token operator">=</span> jieba<span class="token punctuation">.</span>cut<span class="token punctuation">(</span>text<span class="token punctuation">)</span>
<span class="token keyword">for</span> seg <span class="token keyword">in</span> seg_list<span class="token punctuation">:</span>
    <span class="token keyword">if</span> seg <span class="token keyword">not</span> <span class="token keyword">in</span> stopwords<span class="token punctuation">:</span>
        <span class="token keyword">if</span> seg <span class="token keyword">in</span> word_dict<span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            word_dict<span class="token punctuation">[</span>seg<span class="token punctuation">]</span> <span class="token operator">+=</span> <span class="token number">1</span>     <span class="token comment">#存在则词频+1</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            word_dict<span class="token punctuation">[</span>seg<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">1</span>      <span class="token comment">#不存在则存入键值对</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>word_dict<span class="token punctuation">)</span>
</code></pre> 
<pre><code class="prism language-python"><span class="token punctuation">{<!-- --></span><span class="token string">'蒸'</span><span class="token punctuation">:</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token string">'馍馍'</span><span class="token punctuation">:</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token string">'锅锅'</span><span class="token punctuation">:</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token string">'一锅'</span><span class="token punctuation">:</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token string">'锅'</span><span class="token punctuation">:</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token string">'搁'</span><span class="token punctuation">:</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token string">'桌桌'</span><span class="token punctuation">:</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token string">'上面'</span><span class="token punctuation">:</span> <span class="token number">1</span><span class="token punctuation">}</span>
</code></pre> 
<p>这里博主也写好了一个智能词云算法，包括生成词云和词频，并且可以自定义展示的词组的格式，一键化输入，只需要用户输出文本路径即可（首先需要将文本复制到txt文件中，然后在讲绝对路径输入即可），看依稀下面的演示视频吧！需要的可以自己点击下面的链接下载！</p> 
<p><a href="https://download.csdn.net/download/weixin_47723732/85437425"><strong>点击此处下载</strong></a></p> 
<p></p>
<div class="csdn-video-box">
 
 <p>智能分词算法</p>
</div>
<p></p> 
<p>分词完成之后，后续就是如何使用分词好的结果进行构建词向量了！</p> 
<h2>
<a id="_402"></a>每文一语</h2> 
<blockquote> 
 <p>你要相信你走过的每一步都算数！</p> 
</blockquote>
                </div>
                
                

		</div>
	</article>
</main>




			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程小白.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://www.w3counter.com/tracker.js?id=150625"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>
	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>