<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<title>自己动手实现一个全连接神经网络模型 - 编程小白</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程小白" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程小白</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">自己动手实现一个全连接神经网络模型</h1>
			
		</header>
		<div class="content post__content clearfix">
			


                <div id="content_views" class="markdown_views prism-atom-one-dark">
                    
                        
                    
                    <p></p>
<div class="toc">
 <h3>自己动手实现一个全连接神经网络模型</h3>
 <ul>
<li><a href="#_1">代码实现</a></li>
<li>
<ul>
<li><a href="#_2">激活函数函数实现</a></li>
<li><a href="#_35">单层网络实现</a></li>
<li><a href="#_91">全连接神经网络模型实现</a></li>
<li><a href="#_169">数据集加载</a></li>
<li><a href="#_200">进行训练与预测</a></li>
<li><a href="#_226">模型性能统计</a></li>
</ul>
  </li>
<li><a href="#_231">数学推导</a></li>
<li>
<ul>
<li><a href="#_233">梯度下降</a></li>
<li><a href="#_256">链式求导法则</a></li>
</ul>
  </li>
<li><a href="#_291">写在最后</a></li>
</ul>
</div>
<p></p> 
<h1>
<a id="_1"></a>代码实现</h1> 
<h2>
<a id="_2"></a>激活函数函数实现</h2> 
<p>神经网络模型中常用的激活函数有Sigmoid, Relu, Tan，本文对首先对各个激活函数机器激活函数求偏导进行实现：</p> 
<pre><code class="prism language-python"><span class="token comment">#各个激活函数实现</span>
<span class="token keyword">def</span> <span class="token function">no_activate</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
	<span class="token keyword">return</span> x
	
<span class="token keyword">def</span> <span class="token function">relu</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> np<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> x<span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">sigmoid</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> <span class="token number">1</span> <span class="token operator">/</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">+</span> np<span class="token punctuation">.</span>exp<span class="token punctuation">(</span><span class="token operator">-</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">tan</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> np<span class="token punctuation">.</span>tanh<span class="token punctuation">(</span>x<span class="token punctuation">)</span>

<span class="token comment">#各个激活函数的求偏导实现</span>
<span class="token keyword">def</span> <span class="token function">no_activate_derive</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
	<span class="token keyword">return</span> <span class="token number">1</span>
	
<span class="token keyword">def</span> <span class="token function">relu_derive</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
    result <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros_like<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    result<span class="token punctuation">[</span>x <span class="token operator">&gt;</span> <span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">1</span>

    <span class="token keyword">return</span> result

<span class="token keyword">def</span> <span class="token function">sigmoid_derive</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> sigmoid<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token operator">*</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">-</span>sigmoid<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">tan_derive</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> <span class="token number">1</span> <span class="token operator">-</span> x<span class="token operator">**</span><span class="token number">2</span>
</code></pre> 
<h2>
<a id="_35"></a>单层网络实现</h2> 
<p>构造单层类，通过组合，可以非常方便地创建任意形状地神经网络。</p> 
<pre><code class="prism language-python"><span class="token comment">#单层模型</span>
<span class="token keyword">class</span> <span class="token class-name">Layer</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> input_num<span class="token punctuation">,</span> output_num<span class="token punctuation">,</span> activate_func<span class="token punctuation">,</span> activate_derive_func<span class="token punctuation">,</span> weight <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span> bias <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment">#初始化w参数</span>
        <span class="token comment">#self.weights = np.random.normal(loc=0, scale=1, size=(input_num, output_num))</span>
        self<span class="token punctuation">.</span>weights  <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>input_num<span class="token punctuation">,</span> output_num<span class="token punctuation">)</span> <span class="token operator">*</span> np<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">/</span>output_num<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>bias <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> output_num<span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token number">0.1</span>
        <span class="token comment">#初始化b参数</span>
        <span class="token comment">#self.bias = np.zeros(shape=(output_num)).reshape(1, output_num)</span>
        <span class="token comment">#对于w的偏导</span>
        self<span class="token punctuation">.</span>dw <span class="token operator">=</span> <span class="token boolean">None</span>  
        <span class="token comment">#对于b的偏导</span>
        self<span class="token punctuation">.</span>db <span class="token operator">=</span> <span class="token boolean">None</span>
        self<span class="token punctuation">.</span>activate_func <span class="token operator">=</span> activate_func
        self<span class="token punctuation">.</span>activate_derive_func <span class="token operator">=</span> activate_derive_func
        self<span class="token punctuation">.</span>x <span class="token operator">=</span> <span class="token boolean">None</span>
        self<span class="token punctuation">.</span>z <span class="token operator">=</span> <span class="token boolean">None</span>
        self<span class="token punctuation">.</span>cache <span class="token operator">=</span> <span class="token boolean">None</span>

    
    <span class="token comment">#前向传播算法</span>
    <span class="token keyword">def</span> <span class="token function">foward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token builtin">input</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment">#缓存输入值</span>
        self<span class="token punctuation">.</span>x <span class="token operator">=</span> <span class="token builtin">input</span>
        <span class="token comment">#计算z = wx+b</span>
        z <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>weights<span class="token punctuation">)</span> <span class="token operator">+</span> self<span class="token punctuation">.</span>bias
         <span class="token comment">#缓存z值,后续反向传播中求导需要用到</span>
        self<span class="token punctuation">.</span>z <span class="token operator">=</span> z
        <span class="token comment">#进行激活，并缓存激活值</span>
        activate_value <span class="token operator">=</span> self<span class="token punctuation">.</span>activate_func<span class="token punctuation">(</span>z<span class="token punctuation">)</span>
       
        <span class="token keyword">return</span> activate_value

    <span class="token comment">#反向传播算法</span>
    <span class="token keyword">def</span> <span class="token function">backward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token builtin">input</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment">#对z求导 (dz矩阵的shape为 1 * output_num)</span>
        dz <span class="token operator">=</span> <span class="token builtin">input</span> <span class="token operator">*</span> self<span class="token punctuation">.</span>activate_derive_func<span class="token punctuation">(</span>self<span class="token punctuation">.</span>z<span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span>dz<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
        <span class="token comment">#对w进行求导(dw矩阵的shape为input_num * output_num)</span>
        self<span class="token punctuation">.</span>dw <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>self<span class="token punctuation">.</span>x<span class="token punctuation">.</span>T<span class="token punctuation">,</span> dz<span class="token punctuation">)</span>
        <span class="token comment">#对b进行求导(db的shape为1 * output_num)</span>
        self<span class="token punctuation">.</span>db <span class="token operator">=</span> dz
        <span class="token comment">#缓存本层的求导中间值，作为反向传播中下一层的输入值</span>
        self<span class="token punctuation">.</span>cache <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>dz<span class="token punctuation">,</span> self<span class="token punctuation">.</span>weights<span class="token punctuation">.</span>T<span class="token punctuation">)</span>

        <span class="token keyword">return</span> self<span class="token punctuation">.</span>cache
        
    <span class="token comment">#更新w参数与b参数</span>
    <span class="token keyword">def</span> <span class="token function">update</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> learning_rate<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>weights <span class="token operator">-=</span> learning_rate <span class="token operator">*</span> self<span class="token punctuation">.</span>dw
        self<span class="token punctuation">.</span>bias <span class="token operator">-=</span> learning_rate <span class="token operator">*</span> self<span class="token punctuation">.</span>db
</code></pre> 
<h2>
<a id="_91"></a>全连接神经网络模型实现</h2> 
<p>构造网络模型，网络模型类与单层类是组合关系</p> 
<pre><code class="prism language-python"><span class="token comment">#神经网络模型</span>
<span class="token keyword">class</span> <span class="token class-name">NeuralNetwork</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> learning_rate<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>layers <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        self<span class="token punctuation">.</span>learning_rate <span class="token operator">=</span> learning_rate

    <span class="token comment">#增加一层网络</span>
    <span class="token keyword">def</span> <span class="token function">add_layer</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> layer<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>append<span class="token punctuation">(</span>layer<span class="token punctuation">)</span>
    
    <span class="token comment">#前向传导</span>
    <span class="token keyword">def</span> <span class="token function">forwar_calcuate</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment">#逐层前向传播</span>
        <span class="token keyword">for</span> layer <span class="token keyword">in</span> self<span class="token punctuation">.</span>layers<span class="token punctuation">:</span>
            x <span class="token operator">=</span> layer<span class="token punctuation">.</span>foward<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token keyword">return</span> x

    <span class="token comment">#反向传播</span>
    <span class="token keyword">def</span> <span class="token function">backward_calculate</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">:</span>
    	<span class="token comment">#先进行一遍前向传播</span>
        output <span class="token operator">=</span> self<span class="token punctuation">.</span>forwar_calcuate<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        output <span class="token operator">=</span> output <span class="token operator">-</span> y
        
        <span class="token comment">#反向遍历整个网络，对每一层做backward操作</span>
        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">reversed</span><span class="token punctuation">(</span><span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>layers<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            layer <span class="token operator">=</span> self<span class="token punctuation">.</span>layers<span class="token punctuation">[</span>i<span class="token punctuation">]</span>
            output <span class="token operator">=</span> layer<span class="token punctuation">.</span>backward<span class="token punctuation">(</span>output<span class="token punctuation">)</span>
		
		<span class="token comment">#更新每一层的w参数和b参数，使其更接近真实值</span>
        <span class="token keyword">for</span> layer <span class="token keyword">in</span> self<span class="token punctuation">.</span>layers<span class="token punctuation">:</span>
            layer<span class="token punctuation">.</span>update<span class="token punctuation">(</span>self<span class="token punctuation">.</span>learning_rate<span class="token punctuation">)</span> 

    <span class="token comment">#训练</span>
    <span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x_train<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>
    	<span class="token comment">#先将数据进行one-hot转换，方便训练</span>
        y_one_hot <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span>y_train<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        y_one_hot<span class="token punctuation">[</span>np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>y_train<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> y_train<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">1</span>
        mses <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
		
		<span class="token comment">#进行epochs次迭代训练</span>
        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>
            y_predict <span class="token operator">=</span> self<span class="token punctuation">.</span>forwar_calcuate<span class="token punctuation">(</span>x_train<span class="token punctuation">)</span>
            <span class="token comment">#每次迭代之后都记录一下误差均值</span>
            mse <span class="token operator">=</span> np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>np<span class="token punctuation">.</span>square<span class="token punctuation">(</span>y_one_hot <span class="token operator">-</span> y_predict<span class="token punctuation">)</span><span class="token punctuation">)</span>
            mses<span class="token punctuation">.</span>append<span class="token punctuation">(</span>mse<span class="token punctuation">)</span>
            <span class="token comment">#每迭代10次打印一遍误差均值</span>
            <span class="token keyword">if</span> i <span class="token operator">%</span> <span class="token number">10</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
                <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'epcho:{}, mse:{}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>i<span class="token punctuation">,</span> mse<span class="token punctuation">)</span><span class="token punctuation">)</span>
                <span class="token comment">#pass</span>
			<span class="token comment">#逐个数据进行训练（可优化为batch训练方式）</span>
            <span class="token keyword">for</span> j <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>x_train<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                self<span class="token punctuation">.</span>backward_calculate<span class="token punctuation">(</span>x_train<span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> y_one_hot<span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

        plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>mses<span class="token punctuation">)</span>

    <span class="token comment">#打印模型预测准确率</span>
    <span class="token keyword">def</span> <span class="token function">accurancy</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x_test<span class="token punctuation">,</span> y_test<span class="token punctuation">)</span><span class="token punctuation">:</span>
        y_test_one_hot <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span>y_test<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        y_test_one_hot<span class="token punctuation">[</span>np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>y_test<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> y_test<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">1</span>
        y_predict_one_hot <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros_like<span class="token punctuation">(</span>y_test_one_hot<span class="token punctuation">)</span>

        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>x_test<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            y_predict <span class="token operator">=</span> self<span class="token punctuation">.</span>forwar_calcuate<span class="token punctuation">(</span>x_test<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span>
            y_predict_one_hot<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>np<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>y_predict<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">1</span>
        
        right_count <span class="token operator">=</span> <span class="token number">0</span>
        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>x_test<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">if</span> <span class="token punctuation">(</span>y_predict_one_hot<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">==</span> y_test_one_hot<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">all</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                right_count <span class="token operator">+=</span> <span class="token number">1</span>

        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"network auccurency:{}"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>right_count <span class="token operator">/</span> <span class="token builtin">len</span><span class="token punctuation">(</span>x_test<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<p>到此一个任意层的神经网络模型就实现完毕，下面我们利用sklearn提供的数据集对这个神经网络进行验证。</p> 
<h2>
<a id="_169"></a>数据集加载</h2> 
<pre><code class="prism language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> os
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
<span class="token comment">#这里使用make_moons数据集</span>
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> make_moons
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> train_test_split
<span class="token operator">%</span>matplotlib inline

SAMPLE_COUNT <span class="token operator">=</span> <span class="token number">3000</span>

<span class="token comment">#加载数据集（首次调用需要从远程下载数据集，会比较慢）</span>
x<span class="token punctuation">,</span> y <span class="token operator">=</span> make_moons<span class="token punctuation">(</span>n_samples<span class="token operator">=</span>SAMPLE_COUNT<span class="token punctuation">,</span> noise<span class="token operator">=</span><span class="token number">0.2</span><span class="token punctuation">)</span>
<span class="token comment">#这里将数据集分为训练集与测试集，训练时采用训练集数据进行训练，验证时采用测试集数据进行验证</span>
x_train<span class="token punctuation">,</span> x_test<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> y_test <span class="token operator">=</span> train_test_split<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">,</span> test_size<span class="token operator">=</span><span class="token number">0.2</span><span class="token punctuation">)</span>
x_train<span class="token punctuation">.</span>shape<span class="token punctuation">,</span> y_train<span class="token punctuation">.</span>shape<span class="token punctuation">,</span> x_test<span class="token punctuation">.</span>shape<span class="token punctuation">,</span> y_test<span class="token punctuation">.</span>shape

<span class="token comment">#利用matplotlib绘制图形</span>
<span class="token keyword">def</span> <span class="token function">make_plot</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">,</span> plot_name<span class="token punctuation">,</span> file_name <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    plt<span class="token punctuation">.</span>style<span class="token punctuation">.</span>use<span class="token punctuation">(</span><span class="token string">'dark_background'</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">,</span><span class="token number">12</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span>plot_name<span class="token punctuation">,</span> fontsize <span class="token operator">=</span> <span class="token number">30</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>x<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> x<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> c <span class="token operator">=</span> y<span class="token punctuation">.</span>ravel<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> s<span class="token operator">=</span><span class="token number">40</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<p>我们先来看下数据集中的数据分布<br> <img src="https://images2.imgbox.com/43/70/uiWTHWrl_o.png" alt=""><br> 通过数据分布图可以看出，该数据是典型的线性不可分数据，而我们的目标就是给定输入<br> (x1(横轴), x2(纵轴))，能供通过神经网络实例准确预测出类别(黄色or紫色)。</p> 
<h2>
<a id="_200"></a>进行训练与预测</h2> 
<p>接下来我们就开始利用整个网络模型进行数据训练吧：</p> 
<pre><code class="prism language-python"><span class="token comment">#初始化神经网络中的每一层网络</span>
layer1 <span class="token operator">=</span> Layer<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">25</span><span class="token punctuation">,</span> sigmoid<span class="token punctuation">,</span> sigmoid_derive<span class="token punctuation">)</span>
layer2 <span class="token operator">=</span> Layer<span class="token punctuation">(</span><span class="token number">25</span><span class="token punctuation">,</span> <span class="token number">50</span><span class="token punctuation">,</span> sigmoid<span class="token punctuation">,</span> sigmoid_derive<span class="token punctuation">)</span>
layer3 <span class="token operator">=</span> Layer<span class="token punctuation">(</span><span class="token number">50</span><span class="token punctuation">,</span> <span class="token number">25</span><span class="token punctuation">,</span> sigmoid<span class="token punctuation">,</span> sigmoid_derive<span class="token punctuation">)</span>
layer4 <span class="token operator">=</span> Layer<span class="token punctuation">(</span><span class="token number">25</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> sigmoid<span class="token punctuation">,</span> sigmoid_derive<span class="token punctuation">)</span>

<span class="token comment">#设置学习率为0.01</span>
network <span class="token operator">=</span> NeuralNetwork<span class="token punctuation">(</span><span class="token number">0.01</span><span class="token punctuation">)</span>

<span class="token comment">#构造神经网络(2 * 25 * 50 * 25 * 2 层神经网络模型，激活函数使用sigmoid激活函数)</span>
network<span class="token punctuation">.</span>add_layer<span class="token punctuation">(</span>layer1<span class="token punctuation">)</span>
network<span class="token punctuation">.</span>add_layer<span class="token punctuation">(</span>layer2<span class="token punctuation">)</span>
network<span class="token punctuation">.</span>add_layer<span class="token punctuation">(</span>layer3<span class="token punctuation">)</span>
network<span class="token punctuation">.</span>add_layer<span class="token punctuation">(</span>layer4<span class="token punctuation">)</span>

<span class="token comment">#打印图像</span>
make_plot<span class="token punctuation">(</span>x_train<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> <span class="token string">"moon plot"</span><span class="token punctuation">)</span>

<span class="token comment">#进行训练(迭代500次)</span>
network<span class="token punctuation">.</span>train<span class="token punctuation">(</span>x_train<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> <span class="token number">500</span><span class="token punctuation">)</span>
<span class="token comment">#利用测试集测试准确率</span>
network<span class="token punctuation">.</span>accurancy<span class="token punctuation">(</span>x_test<span class="token punctuation">,</span> y_test<span class="token punctuation">)</span>
</code></pre> 
<h2>
<a id="_226"></a>模型性能统计</h2> 
<p>准确率与误差统计（横轴为迭代次数，纵轴为误差值）：<br> <img src="https://images2.imgbox.com/b3/f3/de55obuo_o.png" alt="在这里插入图片描述"><br> 由上图可以看到，经过500次迭代后，我们这个模型对于测试集上的数据预测，准确率达到了97%以上，当然通过调整学习率，也许可以让模型的性能变得更加优秀，但是这不属于本文的讨论与实现范围了。</p> 
<h1>
<a id="_231"></a>数学推导</h1> 
<p>下面我们就结合代码来简单聊一下神经网络模型中用到的几个非常重要的数学性质。</p> 
<h2>
<a id="_233"></a>梯度下降</h2> 
<p>为了简化讨论，我们来拿单条数据预测为例。假设我们模型预测出来的数据为y，而该数据的真实标签值为t（注意，这里的y与t都为向量），那么y与t的误差我们可以用<br> <span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml">
     
      
       
        
         L
        
        
         o
        
        
         s
        
        
         s
        
        
         =
        
        
         (
        
        
         y
        
        
         −
        
        
         t
        
        
         
          )
         
         
          2
         
        
        
         /
        
        
         2
        
       
       
        Loss = (y-t)^2/2 
       
      
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.68333em;vertical-align: 0em"></span><span class="mord mathdefault">L</span><span class="mord mathdefault">o</span><span class="mord mathdefault">s</span><span class="mord mathdefault">s</span><span class="mspace" style="margin-right: 0.277778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em"></span></span><span class="base"><span class="strut" style="height: 1em;vertical-align: -0.25em"></span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right: 0.03588em">y</span><span class="mspace" style="margin-right: 0.222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right: 0.222222em"></span></span><span class="base"><span class="strut" style="height: 1.11411em;vertical-align: -0.25em"></span><span class="mord mathdefault">t</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.864108em"><span class="" style="margin-right: 0.05em"><span class="pstrut" style="height: 2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mord">/</span><span class="mord">2</span></span></span></span></span></span></p> 
<p>这里除以2完全是为了后面求导方便。模型训练的目标就是要让该值能够尽量小，而y又是关于模型参数w和b的函数，根据凸函数的性质，该表达式的最小值一定是在w和b的偏导数的值为0的产生。<br> <img src="https://images2.imgbox.com/6d/f1/Ej0rSoxb_o.png" alt="在这里插入图片描述"><br> 但遗憾的是，w和b关于y的偏导表达式我们无法通过数学解析式直接求出。但我们可以通过偏导函数的定义，找到一种迭代的方式，在每次迭代的过程中，通过不断调整w和b的值，逐步使表达式的值减小。那该如何调整w和b的值呢，我们知道偏导数的定义就是函数针对某个变量的变化率，那么只要我们的变量沿着该导数相反的方向变化，那么一定能让表达式的值逐渐靠近最小值，这就是梯度下降的原理。用公式来表达就是每次迭代过程中，让<br> <span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml">
     
      
       
        
         w
        
        
         =
        
        
         w
        
        
         −
        
        
         η
        
        
         ∗
        
        
         
          
           ∂
          
          
           L
          
          
           o
          
          
           s
          
          
           s
          
         
         
          
           ∂
          
          
           w
          
         
        
        
         （
        
        
         η
        
        
         为
        
        
         步
        
        
         长
        
        
         ，
        
        
         也
        
        
         称
        
        
         作
        
        
         学
        
        
         习
        
        
         率
        
        
         ）
        
       
       
         w= w -eta *frac{partial Loss}{partial w} （eta为步长，也称作学习率） 
       
      
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.43056em;vertical-align: 0em"></span><span class="mord mathdefault" style="margin-right: 0.02691em">w</span><span class="mspace" style="margin-right: 0.277778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em"></span></span><span class="base"><span class="strut" style="height: 0.66666em;vertical-align: -0.08333em"></span><span class="mord mathdefault" style="margin-right: 0.02691em">w</span><span class="mspace" style="margin-right: 0.222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right: 0.222222em"></span></span><span class="base"><span class="strut" style="height: 0.65972em;vertical-align: -0.19444em"></span><span class="mord mathdefault" style="margin-right: 0.03588em">η</span><span class="mspace" style="margin-right: 0.222222em"></span><span class="mbin">∗</span><span class="mspace" style="margin-right: 0.222222em"></span></span><span class="base"><span class="strut" style="height: 2.05744em;vertical-align: -0.686em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.37144em"><span class=""><span class="pstrut" style="height: 3em"></span><span class="mord"><span class="mord" style="margin-right: 0.05556em">∂</span><span class="mord mathdefault" style="margin-right: 0.02691em">w</span></span></span><span class=""><span class="pstrut" style="height: 3em"></span><span class="frac-line" style="border-bottom-width: 0.04em"></span></span><span class=""><span class="pstrut" style="height: 3em"></span><span class="mord"><span class="mord" style="margin-right: 0.05556em">∂</span><span class="mord mathdefault">L</span><span class="mord mathdefault">o</span><span class="mord mathdefault">s</span><span class="mord mathdefault">s</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.686em"><span class=""></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord cjk_fallback">（</span><span class="mord mathdefault" style="margin-right: 0.03588em">η</span><span class="mord cjk_fallback">为</span><span class="mord cjk_fallback">步</span><span class="mord cjk_fallback">长</span><span class="mord cjk_fallback">，</span><span class="mord cjk_fallback">也</span><span class="mord cjk_fallback">称</span><span class="mord cjk_fallback">作</span><span class="mord cjk_fallback">学</span><span class="mord cjk_fallback">习</span><span class="mord cjk_fallback">率</span><span class="mord cjk_fallback">）</span></span></span></span></span></span><br> <span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml">
     
      
       
        
         b
        
        
         =
        
        
         b
        
        
         −
        
        
         η
        
        
         ∗
        
        
         
          
           ∂
          
          
           L
          
          
           o
          
          
           s
          
          
           s
          
         
         
          
           ∂
          
          
           b
          
         
        
        
         （
        
        
         η
        
        
         为
        
        
         步
        
        
         长
        
        
         ，
        
        
         也
        
        
         称
        
        
         作
        
        
         学
        
        
         习
        
        
         率
        
        
         ）
        
       
       
         b= b -eta *frac{partial Loss}{partial b} （eta为步长，也称作学习率） 
       
      
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.69444em;vertical-align: 0em"></span><span class="mord mathdefault">b</span><span class="mspace" style="margin-right: 0.277778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em"></span></span><span class="base"><span class="strut" style="height: 0.77777em;vertical-align: -0.08333em"></span><span class="mord mathdefault">b</span><span class="mspace" style="margin-right: 0.222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right: 0.222222em"></span></span><span class="base"><span class="strut" style="height: 0.65972em;vertical-align: -0.19444em"></span><span class="mord mathdefault" style="margin-right: 0.03588em">η</span><span class="mspace" style="margin-right: 0.222222em"></span><span class="mbin">∗</span><span class="mspace" style="margin-right: 0.222222em"></span></span><span class="base"><span class="strut" style="height: 2.05744em;vertical-align: -0.686em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.37144em"><span class=""><span class="pstrut" style="height: 3em"></span><span class="mord"><span class="mord" style="margin-right: 0.05556em">∂</span><span class="mord mathdefault">b</span></span></span><span class=""><span class="pstrut" style="height: 3em"></span><span class="frac-line" style="border-bottom-width: 0.04em"></span></span><span class=""><span class="pstrut" style="height: 3em"></span><span class="mord"><span class="mord" style="margin-right: 0.05556em">∂</span><span class="mord mathdefault">L</span><span class="mord mathdefault">o</span><span class="mord mathdefault">s</span><span class="mord mathdefault">s</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.686em"><span class=""></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord cjk_fallback">（</span><span class="mord mathdefault" style="margin-right: 0.03588em">η</span><span class="mord cjk_fallback">为</span><span class="mord cjk_fallback">步</span><span class="mord cjk_fallback">长</span><span class="mord cjk_fallback">，</span><span class="mord cjk_fallback">也</span><span class="mord cjk_fallback">称</span><span class="mord cjk_fallback">作</span><span class="mord cjk_fallback">学</span><span class="mord cjk_fallback">习</span><span class="mord cjk_fallback">率</span><span class="mord cjk_fallback">）</span></span></span></span></span></span><br> 就可以逐步减小Loss的值了。在代码中</p> 
<pre><code class="prism language-python">    <span class="token comment">#更新w参数与b参数</span>
    <span class="token keyword">def</span> <span class="token function">update</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> learning_rate<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>weights <span class="token operator">-=</span> learning_rate <span class="token operator">*</span> self<span class="token punctuation">.</span>dw
        self<span class="token punctuation">.</span>bias <span class="token operator">-=</span> learning_rate <span class="token operator">*</span> self<span class="token punctuation">.</span>db
</code></pre> 
<p>就是在做这件事情。</p> 
<h2>
<a id="_256"></a>链式求导法则</h2> 
<p>说完梯度下降，我们再来聊聊链式求导法则。假设y是关于xn的函数，xn是关于xn-1的函数，xn-1是关于xn-2的函数…。链式求导法则定理是：<br> <span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml">
     
      
       
        
         
          
           ∂
          
          
           y
          
         
         
          
           ∂
          
          
           
            x
           
           
            1
           
          
         
        
        
         =
        
        
         
          
           ∂
          
          
           y
          
         
         
          
           ∂
          
          
           
            x
           
           
            n
           
          
         
        
        
         ∗
        
        
         
          
           ∂
          
          
           
            x
           
           
            n
           
          
         
         
          
           ∂
          
          
           
            x
           
           
            
             n
            
            
             −
            
            
             1
            
           
          
         
        
        
         ∗
        
        
         .
        
        
         .
        
        
         .
        
        
         .
        
        
         .
        
        
         .
        
        
         ∗
        
        
         
          
           ∂
          
          
           
            x
           
           
            2
           
          
         
         
          
           ∂
          
          
           
            x
           
           
            1
           
          
         
        
       
       
         frac{partial y}{partial x_1} = frac{partial y}{partial x_n} * frac{partial x_n}{partial x_{n-1}}*......* frac{partial x_2}{partial x_{1}} 
       
      
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 2.20744em;vertical-align: -0.836em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.37144em"><span class=""><span class="pstrut" style="height: 3em"></span><span class="mord"><span class="mord" style="margin-right: 0.05556em">∂</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.301108em"><span class="" style="margin-left: 0em;margin-right: 0.05em"><span class="pstrut" style="height: 2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em"><span class=""></span></span></span></span></span></span></span></span><span class=""><span class="pstrut" style="height: 3em"></span><span class="frac-line" style="border-bottom-width: 0.04em"></span></span><span class=""><span class="pstrut" style="height: 3em"></span><span class="mord"><span class="mord" style="margin-right: 0.05556em">∂</span><span class="mord mathdefault" style="margin-right: 0.03588em">y</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.836em"><span class=""></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right: 0.277778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em"></span></span><span class="base"><span class="strut" style="height: 2.20744em;vertical-align: -0.836em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.37144em"><span class=""><span class="pstrut" style="height: 3em"></span><span class="mord"><span class="mord" style="margin-right: 0.05556em">∂</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.151392em"><span class="" style="margin-left: 0em;margin-right: 0.05em"><span class="pstrut" style="height: 2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em"><span class=""></span></span></span></span></span></span></span></span><span class=""><span class="pstrut" style="height: 3em"></span><span class="frac-line" style="border-bottom-width: 0.04em"></span></span><span class=""><span class="pstrut" style="height: 3em"></span><span class="mord"><span class="mord" style="margin-right: 0.05556em">∂</span><span class="mord mathdefault" style="margin-right: 0.03588em">y</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.836em"><span class=""></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right: 0.222222em"></span><span class="mbin">∗</span><span class="mspace" style="margin-right: 0.222222em"></span></span><span class="base"><span class="strut" style="height: 2.26577em;vertical-align: -0.894331em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.37144em"><span class=""><span class="pstrut" style="height: 3em"></span><span class="mord"><span class="mord" style="margin-right: 0.05556em">∂</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.301108em"><span class="" style="margin-left: 0em;margin-right: 0.05em"><span class="pstrut" style="height: 2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">n</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.208331em"><span class=""></span></span></span></span></span></span></span></span><span class=""><span class="pstrut" style="height: 3em"></span><span class="frac-line" style="border-bottom-width: 0.04em"></span></span><span class=""><span class="pstrut" style="height: 3em"></span><span class="mord"><span class="mord" style="margin-right: 0.05556em">∂</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.151392em"><span class="" style="margin-left: 0em;margin-right: 0.05em"><span class="pstrut" style="height: 2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em"><span class=""></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.894331em"><span class=""></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right: 0.222222em"></span><span class="mbin">∗</span><span class="mspace" style="margin-right: 0.222222em"></span></span><span class="base"><span class="strut" style="height: 0.46528em;vertical-align: 0em"></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mspace" style="margin-right: 0.222222em"></span><span class="mbin">∗</span><span class="mspace" style="margin-right: 0.222222em"></span></span><span class="base"><span class="strut" style="height: 2.20744em;vertical-align: -0.836em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.37144em"><span class=""><span class="pstrut" style="height: 3em"></span><span class="mord"><span class="mord" style="margin-right: 0.05556em">∂</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.301108em"><span class="" style="margin-left: 0em;margin-right: 0.05em"><span class="pstrut" style="height: 2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em"><span class=""></span></span></span></span></span></span></span></span><span class=""><span class="pstrut" style="height: 3em"></span><span class="frac-line" style="border-bottom-width: 0.04em"></span></span><span class=""><span class="pstrut" style="height: 3em"></span><span class="mord"><span class="mord" style="margin-right: 0.05556em">∂</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.301108em"><span class="" style="margin-left: 0em;margin-right: 0.05em"><span class="pstrut" style="height: 2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em"><span class=""></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.836em"><span class=""></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></span><br> 我们知道在神经网络的正向传播中，每一层都是由一个wx+b的表达式以及激活函数组成。<br> 用数学表达式可以这么表达(以3层网络模型为例)：<br> <span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml">
     
      
       
        
         z
        
        
         1
        
        
         =
        
        
         
          w
         
         
          1
         
        
        
         x
        
        
         +
        
        
         b
        
        
         1
        
       
       
        z1 = w_{1}x+b1
       
      
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.64444em;vertical-align: 0em"></span><span class="mord mathdefault" style="margin-right: 0.04398em">z</span><span class="mord">1</span><span class="mspace" style="margin-right: 0.277778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em"></span></span><span class="base"><span class="strut" style="height: 0.73333em;vertical-align: -0.15em"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.301108em"><span class="" style="margin-left: -0.02691em;margin-right: 0.05em"><span class="pstrut" style="height: 2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em"><span class=""></span></span></span></span></span></span><span class="mord mathdefault">x</span><span class="mspace" style="margin-right: 0.222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.222222em"></span></span><span class="base"><span class="strut" style="height: 0.69444em;vertical-align: 0em"></span><span class="mord mathdefault">b</span><span class="mord">1</span></span></span></span></span></span> <span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml">
     
      
       
        
         a
        
        
         1
        
        
         =
        
        
         a
        
        
         c
        
        
         t
        
        
         i
        
        
         v
        
        
         a
        
        
         t
        
        
         e
        
        
         (
        
        
         z
        
        
         1
        
        
         )
        
       
       
        a1 = activate(z1)
       
      
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.64444em;vertical-align: 0em"></span><span class="mord mathdefault">a</span><span class="mord">1</span><span class="mspace" style="margin-right: 0.277778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em"></span></span><span class="base"><span class="strut" style="height: 1em;vertical-align: -0.25em"></span><span class="mord mathdefault">a</span><span class="mord mathdefault">c</span><span class="mord mathdefault">t</span><span class="mord mathdefault">i</span><span class="mord mathdefault" style="margin-right: 0.03588em">v</span><span class="mord mathdefault">a</span><span class="mord mathdefault">t</span><span class="mord mathdefault">e</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right: 0.04398em">z</span><span class="mord">1</span><span class="mclose">)</span></span></span></span></span></span><span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml">
     
      
       
        
         
          z
         
         
          2
         
        
        
         =
        
        
         
          w
         
         
          2
         
        
        
         
          a
         
         
          1
         
        
        
         +
        
        
         
          b
         
         
          2
         
        
       
       
         z_2 = w_2a_1 + b_2
       
      
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.58056em;vertical-align: -0.15em"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.04398em">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.301108em"><span class="" style="margin-left: -0.04398em;margin-right: 0.05em"><span class="pstrut" style="height: 2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.277778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em"></span></span><span class="base"><span class="strut" style="height: 0.73333em;vertical-align: -0.15em"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.301108em"><span class="" style="margin-left: -0.02691em;margin-right: 0.05em"><span class="pstrut" style="height: 2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em"><span class=""></span></span></span></span></span></span><span class="mord"><span class="mord mathdefault">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.301108em"><span class="" style="margin-left: 0em;margin-right: 0.05em"><span class="pstrut" style="height: 2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.222222em"></span></span><span class="base"><span class="strut" style="height: 0.84444em;vertical-align: -0.15em"></span><span class="mord"><span class="mord mathdefault">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.301108em"><span class="" style="margin-left: 0em;margin-right: 0.05em"><span class="pstrut" style="height: 2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em"><span class=""></span></span></span></span></span></span></span></span></span></span></span><span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml">
     
      
       
        
         
          a
         
         
          2
         
        
        
         =
        
        
         a
        
        
         c
        
        
         t
        
        
         i
        
        
         v
        
        
         a
        
        
         t
        
        
         e
        
        
         (
        
        
         
          z
         
         
          2
         
        
        
         )
        
       
       
        a_2 = activate(z_2)
       
      
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.58056em;vertical-align: -0.15em"></span><span class="mord"><span class="mord mathdefault">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.301108em"><span class="" style="margin-left: 0em;margin-right: 0.05em"><span class="pstrut" style="height: 2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.277778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em"></span></span><span class="base"><span class="strut" style="height: 1em;vertical-align: -0.25em"></span><span class="mord mathdefault">a</span><span class="mord mathdefault">c</span><span class="mord mathdefault">t</span><span class="mord mathdefault">i</span><span class="mord mathdefault" style="margin-right: 0.03588em">v</span><span class="mord mathdefault">a</span><span class="mord mathdefault">t</span><span class="mord mathdefault">e</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.04398em">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.301108em"><span class="" style="margin-left: -0.04398em;margin-right: 0.05em"><span class="pstrut" style="height: 2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em"><span class=""></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></span><span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml">
     
      
       
        
         
          z
         
         
          3
         
        
        
         =
        
        
         
          w
         
         
          3
         
        
        
         
          a
         
         
          2
         
        
        
         +
        
        
         
          b
         
         
          3
         
        
       
       
        z_3 = w_{3}a_2+b_3
       
      
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.58056em;vertical-align: -0.15em"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.04398em">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.301108em"><span class="" style="margin-left: -0.04398em;margin-right: 0.05em"><span class="pstrut" style="height: 2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.277778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em"></span></span><span class="base"><span class="strut" style="height: 0.73333em;vertical-align: -0.15em"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.301108em"><span class="" style="margin-left: -0.02691em;margin-right: 0.05em"><span class="pstrut" style="height: 2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">3</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em"><span class=""></span></span></span></span></span></span><span class="mord"><span class="mord mathdefault">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.301108em"><span class="" style="margin-left: 0em;margin-right: 0.05em"><span class="pstrut" style="height: 2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.222222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.222222em"></span></span><span class="base"><span class="strut" style="height: 0.84444em;vertical-align: -0.15em"></span><span class="mord"><span class="mord mathdefault">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.301108em"><span class="" style="margin-left: 0em;margin-right: 0.05em"><span class="pstrut" style="height: 2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em"><span class=""></span></span></span></span></span></span></span></span></span></span></span><span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml">
     
      
       
        
         
          a
         
         
          3
         
        
        
         =
        
        
         a
        
        
         c
        
        
         t
        
        
         i
        
        
         v
        
        
         a
        
        
         t
        
        
         e
        
        
         (
        
        
         
          z
         
         
          3
         
        
        
         )
        
       
       
        a_3 = activate(z_3)
       
      
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.58056em;vertical-align: -0.15em"></span><span class="mord"><span class="mord mathdefault">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.301108em"><span class="" style="margin-left: 0em;margin-right: 0.05em"><span class="pstrut" style="height: 2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.277778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em"></span></span><span class="base"><span class="strut" style="height: 1em;vertical-align: -0.25em"></span><span class="mord mathdefault">a</span><span class="mord mathdefault">c</span><span class="mord mathdefault">t</span><span class="mord mathdefault">i</span><span class="mord mathdefault" style="margin-right: 0.03588em">v</span><span class="mord mathdefault">a</span><span class="mord mathdefault">t</span><span class="mord mathdefault">e</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.04398em">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.301108em"><span class="" style="margin-left: -0.04398em;margin-right: 0.05em"><span class="pstrut" style="height: 2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em"><span class=""></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></span><span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml">
     
      
       
        
         L
        
        
         o
        
        
         s
        
        
         s
        
        
         =
        
        
         (
        
        
         
          a
         
         
          3
         
        
        
         −
        
        
         t
        
        
         
          )
         
         
          2
         
        
        
         /
        
        
         2
        
       
       
        Loss = (a_3-t)^2/2
       
      
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.68333em;vertical-align: 0em"></span><span class="mord mathdefault">L</span><span class="mord mathdefault">o</span><span class="mord mathdefault">s</span><span class="mord mathdefault">s</span><span class="mspace" style="margin-right: 0.277778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em"></span></span><span class="base"><span class="strut" style="height: 1em;vertical-align: -0.25em"></span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.301108em"><span class="" style="margin-left: 0em;margin-right: 0.05em"><span class="pstrut" style="height: 2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.222222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right: 0.222222em"></span></span><span class="base"><span class="strut" style="height: 1.11411em;vertical-align: -0.25em"></span><span class="mord mathdefault">t</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.864108em"><span class="" style="margin-right: 0.05em"><span class="pstrut" style="height: 2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mord">/</span><span class="mord">2</span></span></span></span></span></span>。<br> 我们的目标是对w1,w2,w3,b1,b2,b3关于Loss求偏导。显然，直接通过数学解析是肯定求不出来的，但是我们可以利用链式求导针求出各个参数的导数值，具体来说就是：<br> <span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml">
     
      
       
        
         （
        
        
         1
        
        
         ）
        
        
         
          
           ∂
          
          
           L
          
          
           o
          
          
           s
          
          
           s
          
         
         
          
           ∂
          
          
           
            w
           
           
            3
           
          
         
        
        
         =
        
        
         
          
           ∂
          
          
           L
          
          
           o
          
          
           s
          
          
           s
          
         
         
          
           ∂
          
          
           
            a
           
           
            3
           
          
         
        
        
         ∗
        
        
         
          
           ∂
          
          
           
            a
           
           
            3
           
          
         
         
          
           ∂
          
          
           
            z
           
           
            3
           
          
         
        
        
         ∗
        
        
         
          
           ∂
          
          
           
            z
           
           
            3
           
          
         
         
          
           ∂
          
          
           
            w
           
           
            3
           
          
         
        
       
       
         （1）frac{partial Loss}{partial w_3} = frac{partial Loss}{partial a_3} * frac{partial a_3}{partial z_3} * frac{partial z_3}{partial w_3} 
       
      
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 2.20744em;vertical-align: -0.836em"></span><span class="mord cjk_fallback">（</span><span class="mord">1</span><span class="mord cjk_fallback">）</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.37144em"><span class=""><span class="pstrut" style="height: 3em"></span><span class="mord"><span class="mord" style="margin-right: 0.05556em">∂</span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.301108em"><span class="" style="margin-left: -0.02691em;margin-right: 0.05em"><span class="pstrut" style="height: 2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em"><span class=""></span></span></span></span></span></span></span></span><span class=""><span class="pstrut" style="height: 3em"></span><span class="frac-line" style="border-bottom-width: 0.04em"></span></span><span class=""><span class="pstrut" style="height: 3em"></span><span class="mord"><span class="mord" style="margin-right: 0.05556em">∂</span><span class="mord mathdefault">L</span><span class="mord mathdefault">o</span><span class="mord mathdefault">s</span><span class="mord mathdefault">s</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.836em"><span class=""></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right: 0.277778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em"></span></span><span class="base"><span class="strut" style="height: 2.20744em;vertical-align: -0.836em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.37144em"><span class=""><span class="pstrut" style="height: 3em"></span><span class="mord"><span class="mord" style="margin-right: 0.05556em">∂</span><span class="mord"><span class="mord mathdefault">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.301108em"><span class="" style="margin-left: 0em;margin-right: 0.05em"><span class="pstrut" style="height: 2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em"><span class=""></span></span></span></span></span></span></span></span><span class=""><span class="pstrut" style="height: 3em"></span><span class="frac-line" style="border-bottom-width: 0.04em"></span></span><span class=""><span class="pstrut" style="height: 3em"></span><span class="mord"><span class="mord" style="margin-right: 0.05556em">∂</span><span class="mord mathdefault">L</span><span class="mord mathdefault">o</span><span class="mord mathdefault">s</span><span class="mord mathdefault">s</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.836em"><span class=""></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right: 0.222222em"></span><span class="mbin">∗</span><span class="mspace" style="margin-right: 0.222222em"></span></span><span class="base"><span class="strut" style="height: 2.20744em;vertical-align: -0.836em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.37144em"><span class=""><span class="pstrut" style="height: 3em"></span><span class="mord"><span class="mord" style="margin-right: 0.05556em">∂</span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.04398em">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.301108em"><span class="" style="margin-left: -0.04398em;margin-right: 0.05em"><span class="pstrut" style="height: 2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em"><span class=""></span></span></span></span></span></span></span></span><span class=""><span class="pstrut" style="height: 3em"></span><span class="frac-line" style="border-bottom-width: 0.04em"></span></span><span class=""><span class="pstrut" style="height: 3em"></span><span class="mord"><span class="mord" style="margin-right: 0.05556em">∂</span><span class="mord"><span class="mord mathdefault">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.301108em"><span class="" style="margin-left: 0em;margin-right: 0.05em"><span class="pstrut" style="height: 2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em"><span class=""></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.836em"><span class=""></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right: 0.222222em"></span><span class="mbin">∗</span><span class="mspace" style="margin-right: 0.222222em"></span></span><span class="base"><span class="strut" style="height: 2.20744em;vertical-align: -0.836em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.37144em"><span class=""><span class="pstrut" style="height: 3em"></span><span class="mord"><span class="mord" style="margin-right: 0.05556em">∂</span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.301108em"><span class="" style="margin-left: -0.02691em;margin-right: 0.05em"><span class="pstrut" style="height: 2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em"><span class=""></span></span></span></span></span></span></span></span><span class=""><span class="pstrut" style="height: 3em"></span><span class="frac-line" style="border-bottom-width: 0.04em"></span></span><span class=""><span class="pstrut" style="height: 3em"></span><span class="mord"><span class="mord" style="margin-right: 0.05556em">∂</span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.04398em">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.301108em"><span class="" style="margin-left: -0.04398em;margin-right: 0.05em"><span class="pstrut" style="height: 2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em"><span class=""></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.836em"><span class=""></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></span><br> 。其中右边的每一项我们都是可求的。<br> 同理：<br> <span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml">
     
      
       
        
         （
        
        
         2
        
        
         ）
        
        
         
          
           ∂
          
          
           L
          
          
           o
          
          
           s
          
          
           s
          
         
         
          
           ∂
          
          
           
            w
           
           
            2
           
          
         
        
        
         =
        
        
         
          
           ∂
          
          
           L
          
          
           o
          
          
           s
          
          
           s
          
         
         
          
           ∂
          
          
           
            a
           
           
            3
           
          
         
        
        
         ∗
        
        
         
          
           ∂
          
          
           
            a
           
           
            3
           
          
         
         
          
           ∂
          
          
           
            z
           
           
            3
           
          
         
        
        
         ∗
        
        
         
          
           ∂
          
          
           
            z
           
           
            3
           
          
         
         
          
           ∂
          
          
           
            a
           
           
            2
           
          
         
        
        
         ∗
        
        
         
          
           ∂
          
          
           
            a
           
           
            2
           
          
         
         
          
           ∂
          
          
           
            z
           
           
            2
           
          
         
        
        
         ∗
        
        
         
          
           ∂
          
          
           
            z
           
           
            2
           
          
         
         
          
           ∂
          
          
           
            w
           
           
            2
           
          
         
        
       
       
         （2）frac{partial Loss}{partial w_2} = frac{partial Loss}{partial a_3} * frac{partial a_3}{partial z_3} * frac{partial z_3}{partial a_2} * frac{partial a_2}{partial z_2} * frac{partial z_2}{partial w_2} 
       
      
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 2.20744em;vertical-align: -0.836em"></span><span class="mord cjk_fallback">（</span><span class="mord">2</span><span class="mord cjk_fallback">）</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.37144em"><span class=""><span class="pstrut" style="height: 3em"></span><span class="mord"><span class="mord" style="margin-right: 0.05556em">∂</span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.301108em"><span class="" style="margin-left: -0.02691em;margin-right: 0.05em"><span class="pstrut" style="height: 2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em"><span class=""></span></span></span></span></span></span></span></span><span class=""><span class="pstrut" style="height: 3em"></span><span class="frac-line" style="border-bottom-width: 0.04em"></span></span><span class=""><span class="pstrut" style="height: 3em"></span><span class="mord"><span class="mord" style="margin-right: 0.05556em">∂</span><span class="mord mathdefault">L</span><span class="mord mathdefault">o</span><span class="mord mathdefault">s</span><span class="mord mathdefault">s</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.836em"><span class=""></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right: 0.277778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em"></span></span><span class="base"><span class="strut" style="height: 2.20744em;vertical-align: -0.836em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.37144em"><span class=""><span class="pstrut" style="height: 3em"></span><span class="mord"><span class="mord" style="margin-right: 0.05556em">∂</span><span class="mord"><span class="mord mathdefault">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.301108em"><span class="" style="margin-left: 0em;margin-right: 0.05em"><span class="pstrut" style="height: 2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em"><span class=""></span></span></span></span></span></span></span></span><span class=""><span class="pstrut" style="height: 3em"></span><span class="frac-line" style="border-bottom-width: 0.04em"></span></span><span class=""><span class="pstrut" style="height: 3em"></span><span class="mord"><span class="mord" style="margin-right: 0.05556em">∂</span><span class="mord mathdefault">L</span><span class="mord mathdefault">o</span><span class="mord mathdefault">s</span><span class="mord mathdefault">s</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.836em"><span class=""></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right: 0.222222em"></span><span class="mbin">∗</span><span class="mspace" style="margin-right: 0.222222em"></span></span><span class="base"><span class="strut" style="height: 2.20744em;vertical-align: -0.836em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.37144em"><span class=""><span class="pstrut" style="height: 3em"></span><span class="mord"><span class="mord" style="margin-right: 0.05556em">∂</span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.04398em">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.301108em"><span class="" style="margin-left: -0.04398em;margin-right: 0.05em"><span class="pstrut" style="height: 2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em"><span class=""></span></span></span></span></span></span></span></span><span class=""><span class="pstrut" style="height: 3em"></span><span class="frac-line" style="border-bottom-width: 0.04em"></span></span><span class=""><span class="pstrut" style="height: 3em"></span><span class="mord"><span class="mord" style="margin-right: 0.05556em">∂</span><span class="mord"><span class="mord mathdefault">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.301108em"><span class="" style="margin-left: 0em;margin-right: 0.05em"><span class="pstrut" style="height: 2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em"><span class=""></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.836em"><span class=""></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right: 0.222222em"></span><span class="mbin">∗</span><span class="mspace" style="margin-right: 0.222222em"></span></span><span class="base"><span class="strut" style="height: 2.20744em;vertical-align: -0.836em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.37144em"><span class=""><span class="pstrut" style="height: 3em"></span><span class="mord"><span class="mord" style="margin-right: 0.05556em">∂</span><span class="mord"><span class="mord mathdefault">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.301108em"><span class="" style="margin-left: 0em;margin-right: 0.05em"><span class="pstrut" style="height: 2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em"><span class=""></span></span></span></span></span></span></span></span><span class=""><span class="pstrut" style="height: 3em"></span><span class="frac-line" style="border-bottom-width: 0.04em"></span></span><span class=""><span class="pstrut" style="height: 3em"></span><span class="mord"><span class="mord" style="margin-right: 0.05556em">∂</span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.04398em">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.301108em"><span class="" style="margin-left: -0.04398em;margin-right: 0.05em"><span class="pstrut" style="height: 2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em"><span class=""></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.836em"><span class=""></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right: 0.222222em"></span><span class="mbin">∗</span><span class="mspace" style="margin-right: 0.222222em"></span></span><span class="base"><span class="strut" style="height: 2.20744em;vertical-align: -0.836em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.37144em"><span class=""><span class="pstrut" style="height: 3em"></span><span class="mord"><span class="mord" style="margin-right: 0.05556em">∂</span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.04398em">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.301108em"><span class="" style="margin-left: -0.04398em;margin-right: 0.05em"><span class="pstrut" style="height: 2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em"><span class=""></span></span></span></span></span></span></span></span><span class=""><span class="pstrut" style="height: 3em"></span><span class="frac-line" style="border-bottom-width: 0.04em"></span></span><span class=""><span class="pstrut" style="height: 3em"></span><span class="mord"><span class="mord" style="margin-right: 0.05556em">∂</span><span class="mord"><span class="mord mathdefault">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.301108em"><span class="" style="margin-left: 0em;margin-right: 0.05em"><span class="pstrut" style="height: 2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em"><span class=""></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.836em"><span class=""></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right: 0.222222em"></span><span class="mbin">∗</span><span class="mspace" style="margin-right: 0.222222em"></span></span><span class="base"><span class="strut" style="height: 2.20744em;vertical-align: -0.836em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.37144em"><span class=""><span class="pstrut" style="height: 3em"></span><span class="mord"><span class="mord" style="margin-right: 0.05556em">∂</span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.301108em"><span class="" style="margin-left: -0.02691em;margin-right: 0.05em"><span class="pstrut" style="height: 2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em"><span class=""></span></span></span></span></span></span></span></span><span class=""><span class="pstrut" style="height: 3em"></span><span class="frac-line" style="border-bottom-width: 0.04em"></span></span><span class=""><span class="pstrut" style="height: 3em"></span><span class="mord"><span class="mord" style="margin-right: 0.05556em">∂</span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.04398em">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.301108em"><span class="" style="margin-left: -0.04398em;margin-right: 0.05em"><span class="pstrut" style="height: 2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em"><span class=""></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.836em"><span class=""></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></span><br> 剩下的b3,b2,b1,w1等参数也可以通过这种方法求出。通过观察，（2）式中有一部分的内容与（1）式中完全相同，因此我们在编写代码的过程中，在求（2）的过程中，完全可以利用（1）中已经求得的数据直接进行运算，这样能够大大减少重复计算。</p> 
<pre><code class="prism language-python">    <span class="token comment">#反向传播算法</span>
    <span class="token keyword">def</span> <span class="token function">backward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token builtin">input</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment">#对z求导 (dz矩阵的shape为 1 * output_num)</span>
        dz <span class="token operator">=</span> <span class="token builtin">input</span> <span class="token operator">*</span> self<span class="token punctuation">.</span>activate_derive_func<span class="token punctuation">(</span>self<span class="token punctuation">.</span>z<span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span>dz<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
        <span class="token comment">#对w进行求导(dw矩阵的shape为input_num * output_num)</span>
        self<span class="token punctuation">.</span>dw <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>self<span class="token punctuation">.</span>x<span class="token punctuation">.</span>T<span class="token punctuation">,</span> dz<span class="token punctuation">)</span>
        <span class="token comment">#对b进行求导(db的shape为1 * output_num)</span>
        self<span class="token punctuation">.</span>db <span class="token operator">=</span> dz
        <span class="token comment">#缓存本层的求导中间值，作为反向传播中下一层的输入值</span>
        self<span class="token punctuation">.</span>cache <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>dz<span class="token punctuation">,</span> self<span class="token punctuation">.</span>weights<span class="token punctuation">.</span>T<span class="token punctuation">)</span>

        <span class="token keyword">return</span> self<span class="token punctuation">.</span>cache
</code></pre> 
<p>具体在上面代码中，input就是我们在反向传播过程中，上一个求导表达式返回的数据就是（2）与（1）中重叠计算的部分。</p> 
<h1>
<a id="_291"></a>写在最后</h1> 
<p>虽然在目前的深度学习框架过程中，pytorch、tensorflow2.0、padlepadle这些框架都通过非常优雅的封装实现了自动求梯度，自动正向反向传播，甚至连参数设置对使用者来说都是透明的。但是我依然觉得不依赖任何框架的内容，完全手动实现一遍全连接神经网络的实现式非常有意义的。在这个过程中，非常有利于自己对于正向、反向传播以及超参数的设置，激活函数的选择等细节的理解。并且在后续使用框架编写神经网络的过程中，也能够更好地对目前市面上这些框架背后的原理有更深入的理解。而全连接网络也是后面理解卷积神经网络、对抗神经网络的基础。而目前人工智能中最热门的领域之一强化学习，也在跟深度学习绑定的越来越紧密，我们熟知的AlphaGo的强化学习算法，就是通过深度学习训练策略网络与价值网络，完成了超越人类顶级专家水准的学习。<br> 作为一名游戏从业人员，深度强化学习在游戏领域表现得也是越来越出彩，在了解到网易伏羲实验室的一些成果后，也坚定了自己向这个方向靠拢的决心，后面我也会通过不断地学习总结学习地方式，与大家分享探讨一些人工智能方面的理论知识与实践应用，而下一篇的内容我也规划好了，就是利用深度强化学习进行我们小的时候完的街机游戏的训练，不过市面上很多对于游戏的实现都是通过机器视觉，分析画面像素的方式进行，这种发放时虽然很通用（完全不用思考如何设置状态，状态就是三通道的像素），但一是训练速度慢，二是很难工业化落地。因此我还在探索一种通过自定义状态进行训练，也为今后能够将强化学习应用到mmorpg这种类型的游戏中打好基础。</p>
                </div>
                
                

		</div>
	</article>
</main>




			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程小白.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://www.w3counter.com/tracker.js?id=150625"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>
	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>