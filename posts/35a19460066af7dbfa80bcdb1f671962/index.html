<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<title>跨模态行人重识别：RGB-Infrared Cross-Modality Person Re-Identification 学习记录笔记 - 编程小白</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程小白" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程小白</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">跨模态行人重识别：RGB-Infrared Cross-Modality Person Re-Identification 学习记录笔记</h1>
			
		</header>
		<div class="content post__content clearfix">
			


                <div id="content_views" class="htmledit_views">
                    <p id="main-toc"><strong>目录</strong></p> 
<p id="%E5%8E%9F%E6%96%87%E9%93%BE%E6%8E%A5-toc" style="margin-left:0px"><a href="#%E5%8E%9F%E6%96%87%E9%93%BE%E6%8E%A5">原文链接</a></p> 
<p id="%C2%A0%E6%91%98%E8%A6%81%3A-toc" style="margin-left:0px"><a href="#%C2%A0%E6%91%98%E8%A6%81%3A"> 摘要:</a></p> 
<p id="%E4%BB%8B%E7%BB%8D%EF%BC%9A%C2%A0-toc" style="margin-left:0px"><a href="#%E4%BB%8B%E7%BB%8D%EF%BC%9A%C2%A0">1 介绍</a></p> 
<p id="%E6%95%B0%E6%8D%AE%E9%9B%86%EF%BC%9A-toc" style="margin-left:40px"><a href="#%E6%95%B0%E6%8D%AE%E9%9B%86%EF%BC%9A">1.1 数据集：</a></p> 
<p id="%E8%B4%A1%E7%8C%AE-toc" style="margin-left:40px"><a href="#%E8%B4%A1%E7%8C%AE">1.2 贡献</a></p> 
<p id="%E8%AF%84%E4%BC%B0%E5%8D%8F%E8%AE%AE-toc" style="margin-left:40px"><a href="#%E8%AF%84%E4%BC%B0%E5%8D%8F%E8%AE%AE">1.3 评估</a></p> 
<p id="%E8%B7%A8%E6%A8%A1%E6%80%81%E5%BB%BA%E6%A8%A1%E7%9A%84%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E6%AF%94%E8%BE%83-toc" style="margin-left:0px"><a href="#%E8%B7%A8%E6%A8%A1%E6%80%81%E5%BB%BA%E6%A8%A1%E7%9A%84%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E6%AF%94%E8%BE%83">2 网络结构比较</a></p> 
<p id="One-stream%20Structure-toc" style="margin-left:40px"><a href="#One-stream%20Structure">2.1 One-stream Structure</a></p> 
<p id="Two-stream%20Structure-toc" style="margin-left:40px"><a href="#Two-stream%20Structure">2.2 Two-stream Structure</a></p> 
<p id="%E9%9D%9E%E5%AF%B9%E7%A7%B0FC%E5%B1%82%E7%BB%93%E6%9E%84-toc" style="margin-left:40px"><a href="#%E9%9D%9E%E5%AF%B9%E7%A7%B0FC%E5%B1%82%E7%BB%93%E6%9E%84">2.3 Asymmetric FC layer structur</a></p> 
<p id="%C2%A0%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84-toc" style="margin-left:0px"><a href="#%C2%A0%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84">3 网络结构</a></p> 
<p id="3.1%20%E7%89%B9%E6%AE%8A%E6%83%85%E5%86%B5%E4%B8%8B%E5%8D%95%E6%B5%81%E5%92%8C%E5%8F%8C%E6%B5%81%E7%BB%93%E6%9E%84%E7%9A%84%E8%BF%9E%E6%8E%A5-toc" style="margin-left:40px"><a href="#3.1%20%E7%89%B9%E6%AE%8A%E6%83%85%E5%86%B5%E4%B8%8B%E5%8D%95%E6%B5%81%E5%92%8C%E5%8F%8C%E6%B5%81%E7%BB%93%E6%9E%84%E7%9A%84%E8%BF%9E%E6%8E%A5">3.1 单流和双流结构的连接</a></p> 
<p id="3.2%20%E4%B8%80%E8%88%AC%E6%83%85%E5%86%B5%E4%B8%8B%E7%9A%84%E5%8D%95%E6%B5%81%E7%BB%93%E6%9E%84%E5%88%86%E6%9E%90-toc" style="margin-left:40px"><a href="#3.2%20%E4%B8%80%E8%88%AC%E6%83%85%E5%86%B5%E4%B8%8B%E7%9A%84%E5%8D%95%E6%B5%81%E7%BB%93%E6%9E%84%E5%88%86%E6%9E%90">3.2 单流结构</a></p> 
<p id="3.3%20%E5%A4%87%E6%B3%A8%C2%A0-toc" style="margin-left:40px"><a href="#3.3%20%E5%A4%87%E6%B3%A8%C2%A0">3.3 备注 </a></p> 
<p id="4%C2%A0%E6%B7%B1%E5%BA%A6%E9%9B%B6%E5%A1%AB%E5%85%85-toc" style="margin-left:0px"><a href="#4%C2%A0%E6%B7%B1%E5%BA%A6%E9%9B%B6%E5%A1%AB%E5%85%85">4 深度零填充</a></p> 
<p id="4.1%20%E7%BD%91%E7%BB%9C%E8%BE%93%E5%85%A5%E5%88%86%E6%9E%90-toc" style="margin-left:40px"><a href="#4.1%20%E7%BD%91%E7%BB%9C%E8%BE%93%E5%85%A5%E5%88%86%E6%9E%90">4.1 网络输入分析</a></p> 
<p id="4.2%C2%A0RGB-IR%E6%B7%B1%E5%BA%A6%E9%9B%B6%E5%A1%AB%E5%85%85-toc" style="margin-left:40px"><a href="#4.2%C2%A0RGB-IR%E6%B7%B1%E5%BA%A6%E9%9B%B6%E5%A1%AB%E5%85%85">4.2 RGB-IR深度零填充</a></p> 
<p id="5%20%E5%AE%9E%E9%AA%8C-toc" style="margin-left:0px"><a href="#5%20%E5%AE%9E%E9%AA%8C">5 实验</a></p> 
<p id="5.1%20%E6%A8%A1%E5%9E%8B%E6%AF%94%E8%BE%83-toc" style="margin-left:40px"><a href="#5.1%20%E6%A8%A1%E5%9E%8B%E6%AF%94%E8%BE%83">5.1 模型比较</a></p> 
<p id="5.2%C2%A0%E6%A8%A1%E5%9E%8B%E6%AF%94%E8%BE%83%E4%B8%8E%E5%88%86%E6%9E%90-toc" style="margin-left:40px"><a href="#5.2%C2%A0%E6%A8%A1%E5%9E%8B%E6%AF%94%E8%BE%83%E4%B8%8E%E5%88%86%E6%9E%90">5.2 模型分析</a></p> 
<hr id="hr-toc">
<p></p> 
<p></p> 
<h1 id="%E5%8E%9F%E6%96%87%E9%93%BE%E6%8E%A5">原文链接</h1> 
<p>论文链接：<a class="link-info" href="https://openaccess.thecvf.com/content_ICCV_2017/papers/Wu_RGB-Infrared_Cross-Modality_Person_ICCV_2017_paper.pdf" title="RGB-Infrared Cross-Modality Person Re-Identification ">RGB-Infrared Cross-Modality Person Re-Identification </a></p> 
<p> 代码链接：<a class="link-info" href="https://github.com/InnovArul/rgb_IR_personreid" title="code">code</a></p> 
<p></p> 
<h1 id="%C2%A0%E6%91%98%E8%A6%81%3A"><strong> 摘要:</strong></h1> 
<p></p> 
<p>        目前大多数Re-ID都是基于 RGB 图像。但是有时RGB 图像并不适用，例如在黑暗的环境或夜间。在许多视觉系统中，红外 (IR) 成像变得必不可少。为此，需要将 RGB 图像与红外图像进行匹配，这些图像是异构的，具有非常不同的视觉特征。</p> 
<p>        评估了现有流行的跨域模型，包括三种常用的神经网络结构（单流、双流和非对称 FC 层）并分析它们之间的关系。提出了深度零填充，用于训练单流网络，使其自动进化网络中特定领域的节点，以进行跨模态匹配。</p> 
<p></p> 
<h1 id="%E4%BB%8B%E7%BB%8D%EF%BC%9A%C2%A0"><strong>1 介绍</strong></h1> 
<p>        由于大多数监控摄像机能够在黑暗中自动从RGB模式切换到IR模式。 分别在白天和夜间在两个室外场景中捕获的RGB图像和红外（IR）图像的示例。每两列中的图像都是同一个人的。由接收不同波长光的设备捕获，同一个人的RGB图像和红外图像看起来非常不同。</p> 
<div> 
 <p style="text-align:center"><img alt="" height="353" src="https://images2.imgbox.com/be/33/xL2oRil5_o.png" width="487">​</p> 
</div> 
<p></p> 
<p>         第一行的 RGB 图像具有三个包含可见光颜色信息的通道，而第三行的 IR 图像具有一个包含不可见光信息的通道。 因此，它们可以被视为异构数据。 其次，从成像原理来看，RGB和IR图像的波长范围不同。</p> 
<h2 id="%E6%95%B0%E6%8D%AE%E9%9B%86%EF%BC%9A"><strong>1.1 数据集：</strong></h2> 
<p>        包括来自 6 个摄像头的 491 个身份的 RGB 和 IR 图像，总共提供 287,628 个 RGB 图像和 15,792 张红外图像。包括两个红外线摄像机和四个RGB摄像机，利用Kinect V1在两个明亮的室内（房间1和房间2）采集相机1和相机2的RGB图像。对于每个人，至少有400个具有不同姿态和视点的连续RGB帧。摄像机3和摄像机6的IR图像在黑暗中由IR摄像机捕获，摄像机3放置在暗环境中的房间2中，而摄像机6放置在具有背景杂波的室外通道中。摄像机4和5是放置在两个室外场景中的RGB监视摄像机。</p> 
<p>        SYSU-MM01 数据集中有 491 个有效 ID。 我们有一个固定的分割，使用 296 个身份进行训练，99 个身份用于验证，96 个身份用于测试。 在训练过程中，所有相机中训练集中的 296 人的所有图像都可以应用。RGB相机的样品用于gallery set，IR摄像机的样品用于probe set。</p> 
<div> 
 <p style="text-align:center"><img alt="" height="150" src="https://images2.imgbox.com/47/cb/ii5RLkIn_o.png" width="474">​</p> 
</div> 
<h2 id="%E8%B4%A1%E7%8C%AE"><strong>1.2 贡献</strong></h2> 
<p>        （1）首次提出了支持RGB-IR交叉模态Re-ID研究的标准基准SYSU - MM01。进行了大量的实验来评估跨模态RGB-IR Re-ID的流行的基线深度学习体系结构。 (2) 分析了三种不同的网络结构(单流结构、双流结构和非对称FC层结构)，并分析了它们的有效性。 (3) 在RGB-IRRe-ID任务优化的单流网络中，提出了一种自动演化的域特定结构的深度零填充算法。</p> 
<h2 id="%E8%AF%84%E4%BC%B0%E5%8D%8F%E8%AE%AE"><strong>1.3 评估</strong></h2> 
<p>        对于RGB相机下的每个身份，我们随机选择一个/十个身份图像，以形成用于单张/多张设置的图库集。至于探针组，则使用所有图像。给定探测图像，通过计算探测图像和图库图像之间的相似性来进行匹配。在不同位置的摄像机之间进行匹配 ，相机2和相机3位于同一位置，因此相机3的探测图像跳过相机2的图库图像。</p> 
<p></p> 
<h1 id="%E8%B7%A8%E6%A8%A1%E6%80%81%E5%BB%BA%E6%A8%A1%E7%9A%84%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E6%AF%94%E8%BE%83"><strong>2 网络结构比较</strong></h1> 
<h2 id="One-stream%20Structure"><strong>2.1 One-stream Structure</strong></h2> 
<p>有单一输入，所有参数在整个网络中共享。</p> 
<div> 
 <p style="text-align:center"><img alt="" height="95" src="https://images2.imgbox.com/e3/b9/uKNBfS0q_o.png" width="598">​</p> 
</div> 
<p></p> 
<h2 id="Two-stream%20Structure"><strong>2.2 Two-stream Structure</strong></h2> 
<p>        有两个输入，对应于两个不同域中的数据。在较浅的层中，网络的参数是针对每个域的。在较深的层中，使用共享参数。与单流结构相比，双流结构实现了两件事：<strong>领域自适应</strong>和区分性特征学习。假设特定领域的网络可以提取不同领域的共享特征，然后共享网络可以提取区分特征进行匹配。</p> 
<div> 
 <p style="text-align:center"><img alt="" height="142" src="https://images2.imgbox.com/fc/63/io8odOWB_o.png" width="624">​</p> 
</div> 
<p id="%C2%A0%E9%A2%86%E5%9F%9F%E8%87%AA%E9%80%82%E5%BA%94"><strong> 领域自适应</strong></p> 
<p>        源域（source domain）表示与测试样本不同的领域，但是有丰富的监督信息，目标域（target domain）表示测试样本所在的领域，无标签或者只有少量标签。源域和目标域往往属于同一类任务，但是分布不同。</p> 
<p>        三种不同的领域自适应方法：1）样本自适应，对源域样本进行加权重采样，从而逼近目标域的分布。2）特征层面自适应，将源域和目标域投影到公共特征子空间。3）模型层面自适应，对源域误差函数进行修改，考虑目标域的误差。</p> 
<h2 id="%E9%9D%9E%E5%AF%B9%E7%A7%B0FC%E5%B1%82%E7%BB%93%E6%9E%84"><strong>2.3 Asymmetric FC layer structur</strong></h2> 
<p>该结构除最后一个FC层之外的几乎所有参数都共享。</p> 
<div> 
 <p style="text-align:center"><img alt="" height="134" src="https://images2.imgbox.com/42/34/J2wvT5tE_o.png" width="605">​</p> 
</div> 
<p></p> 
<h1 id="%C2%A0%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84"><strong>3 网络结构</strong></h1> 
<h2 id="3.1%20%E7%89%B9%E6%AE%8A%E6%83%85%E5%86%B5%E4%B8%8B%E5%8D%95%E6%B5%81%E5%92%8C%E5%8F%8C%E6%B5%81%E7%BB%93%E6%9E%84%E7%9A%84%E8%BF%9E%E6%8E%A5">3.1 单流和双流结构的连接</h2> 
<p>假设1：一个域选择子网络存在于网络中的某个地方，它可以自动选择相应域的样本作为输入，并且域选择子网络是固定的。</p> 
<p>在假设1下，我们首先给出了一个简单的例子，说明在前向传播中，单流网络可以作为双流网络。如图所示，左边是一个简化的双流网络：两个完全连接的网络，每个网络都有一个特定的层（蓝色和红色）和一个共享层（绿色）。</p> 
<div> 
 <p style="text-align:center"><img alt="" height="192" src="https://images2.imgbox.com/38/0a/ccmuu37S_o.png" width="601">​</p> 
</div> 
<p>        右边是单流网络，它可以有条件地等效于前向传播中的两个流，X其中有一个域选择子网络用于选择以下域特定结构。我们首先定义一些符号用于说X明。令Xd1 ∈ Rd和Xd2 ∈ Rd分别表示domain1和domain2的输入。我们将域指示符yind1定义为具有两个元素的向量，其值分别为 [1,0] T或 [0,1] T，表示域1或域2。令fsel(x，yind) 表示域选择子网络，实现以下功能:</p> 
<div> 
 <p style="text-align:center"><img alt="" height="72" src="https://images2.imgbox.com/91/42/Cwth3ECW_o.png" width="537">​</p> 
</div> 
<p>上式表明，如果域选择子网络是固定的，那么在前向传播中，二流网络可以用一流网络来表示。 </p> 
<p></p> 
<h2 id="3.2%20%E4%B8%80%E8%88%AC%E6%83%85%E5%86%B5%E4%B8%8B%E7%9A%84%E5%8D%95%E6%B5%81%E7%BB%93%E6%9E%84%E5%88%86%E6%9E%90">3.2 单流结构</h2> 
<p>        我们希望上面的假设不太可行。现在，我们放弃这个假设，并分析单流网络的特定于域的属性。对于跨模态匹配任务，由于域移位，特定于域的建模对于提取共享组件进行匹配非常重要。通常，在神经网络中，例如双流和不对称FC层结构，这是由特定于域的结构建模的。因此，我们打算分析单流网络中的域特定建模。</p> 
<div> 
 <p style="text-align:center"><img alt="" height="294" src="https://images2.imgbox.com/ac/65/ZjJrE2zn_o.png" width="463">​</p> 
</div> 
<p>        在每一层中，蓝色节点表示域1特定的节点，红色节点表示域2特定的节点，绿色节点表示共享节点，虚线节点表示零值。 </p> 
<p> 假设2：如图所示，对于处理两个域的输入的单流网络，我们将每层的输出节点分为三种类型：域1特定节点、域2特定节点和共享节点。分类取决于节点的响应是否特定于域。设x(l)d1和x(l)d2分别表示域1和域2的层l+1的输入。例如，x(0)d1和x(0)d2是整个网络的输入。设η(l)i表示层l中的第i个节点，fout（x(0),i,l）表示η(l)i与网络输入x(0)的输出，可以得到</p> 
<div> 
 <p style="text-align:center"><img alt="" height="47" src="https://images2.imgbox.com/0d/5d/jQTfPLhz_o.png" width="545">​</p> 
</div> 
<p>节点 η(l) i 的类型定义为 </p> 
<div> 
 <p style="text-align:center"><img alt="" height="98" src="https://images2.imgbox.com/94/8c/vbEVMHVU_o.png" width="543">​</p> 
</div> 
<p>        定义了一些用于分析的符号。 令 L 表示损失函数。 令 o(l+1) i 表示第 l + 1 层激活函数之前第 i 个节点的 输出，，x (l) 表示层l+1的输入，w (l) ，b (l) i表示权重和偏置参数，即o (l+1) i =(w (l) i) T * x (l) +b (l) i。使用上述定义的分类，在不丧失通用性的情况下，X（l）可分解为三个parts1 x（l）=[x(l)1 spe；x (l) 2 spe；x(l)s]其中三个组件分别表示domain1特定节点、domain2特定节点和共享节点。我们还可以将w (l) i表示为w (l) i = [w (l),1 spe;W (l),2 spe;W (l),S] 。  </p> 
<p>对于domain1，第l+1层的输出是</p> 
<div> 
 <p style="text-align:center"><img alt="" height="48" src="https://images2.imgbox.com/e7/a5/gstVAe5h_o.png" width="558">​</p> 
</div> 
<p>对于domain2，第l+1层的输出是  </p> 
<div> 
 <p style="text-align:center"><img alt="" height="66" src="https://images2.imgbox.com/d3/0a/hXI9xof2_o.png" width="545">​</p> 
</div> 
<p> 在反向传播过程中，对于domain1中的网络X(0) d1的输入</p> 
<div> 
 <p style="text-align:center"><img alt="" height="220" src="https://images2.imgbox.com/bc/8f/JiG7fXti_o.png" width="574">​</p> 
</div> 
<p>         通过以上分析，我们得出两个结论：（1）在前向传播中，如图所示，权重参数w(l)1spe i（蓝色连接）和w(l)2spe i（红色连接）仅对相应域的输入有影响，这与双流网络中的域特定参数相似。而对于w(l),si (绿色连接)，它对两个域都有影响，这与双流网络中的共享参数相似。因此，网络可以通过域特定节点隐式地控制域特定结构，并通过共享节点控制共享结构。在后向传播中，如果节点是特定于domain2的，并且输入在domain1中，则其对应的权重参数将不会被更新，因为梯度是零。这意味着其他领域的训练样本不会影响隐含领域特定结构。</p> 
<h2 id="3.3%20%E5%A4%87%E6%B3%A8%C2%A0">3.3 备注 </h2> 
<p>       备注1： 如果假设等式 (3) 定义的三种类型的节点存在于网络中，则单流网络可以隐式地学习和演化网络中的特定域和共享结构。</p> 
<p>         备注2： 考虑到双流结构和不对称FC层结构，它们是手动设计的，并且在训练过程中是固定的。而且，两个域的域特定结构是解耦的，而共享结构是完全相同的。相反，如果单流结构可以隐式学习该结构，则对应于不同域的隐式结构通过共享节点和共享偏置参数 (等式 (4) 和 (5)) 部分耦合，这可以为跨模态匹配任务的训练提供更多的灵活性。</p> 
<h1 id="4%C2%A0%E6%B7%B1%E5%BA%A6%E9%9B%B6%E5%A1%AB%E5%85%85">4 深度零填充</h1> 
<h2 id="4.1%20%E7%BD%91%E7%BB%9C%E8%BE%93%E5%85%A5%E5%88%86%E6%9E%90">4.1 网络输入分析</h2> 
<p>        双流网络和非对称FC层网络的结构是手动设计的，并且在训练过程中是固定的，而单流网络可以通过学习特定领域的节点来隐式地进化网络结构，这可能会产生更优化的结构。 为此，我们建议使用零填充输入来刺激特定领域的响应。 对于来自两个域 xd1 ∈ Rd 和 xd2 ∈ Rd 的输入，应用零填充，如下所示</p> 
<div> 
 <p style="text-align:center"><img alt="" height="60" src="https://images2.imgbox.com/a9/c9/VyrTuc4k_o.png" width="493">​</p> 
</div> 
<p>         如果我们将网络输入视为先验层（或称为第 0 层），那么根据我们在等式（3）中的定义，这样的先验层中的所有节点都将明确归类为域特定节点。 我们发现使用零填充作为网络输入，网络节点更可能成为特定于域的节点。在这里，我们继续第3.2节中的分析，在将激活函数σ（·）应用于等式（4）和（5）之后，我们得到：</p> 
<div> 
 <p style="text-align:center"><img alt="" height="100" src="https://images2.imgbox.com/54/d7/U3c9Rk0f_o.png" width="560">​</p> 
</div> 
<p> 深度零填充只会使神经网络在网络中扩展特定于领域的节点时更灵活，而不会强制扩展。</p> 
<h2 id="4.2%C2%A0RGB-IR%E6%B7%B1%E5%BA%A6%E9%9B%B6%E5%A1%AB%E5%85%85">4.2 RGB-IR深度零填充</h2> 
<p>        RGB-IR跨模态识别中，一个通道对应于卷积神经网络FC层的一个节点。对于图像，在通道级别执行零填充。如图所示，RGB图像被转换为灰度图像并放置在第一个通道中，然后零填充图像被放置在第二个通道中。对于红外图像，它被放置在第二个通道中，零填充图像被放置在第一个通道中。 </p> 
<div> 
 <p style="text-align:center"><img alt="" height="261" src="https://images2.imgbox.com/2b/24/ox2SKFkK_o.png" width="512">​</p> 
</div> 
<p>        为了证明深度零填充的有效性，实验中可视化了ResNet-6的特征图，比较深零填充和原始单通道输入之间的差异。在下图中，我们计算了数据集上50个不同人员的平均特征图，并显示了第一和第二卷积层的所有16个特征图。如等式 (3) 中定义的，我们可以对边界框指示的特定于域的通道进行分类。显然，与单通道输入相比，深度零填充有助于学习更多的特定于域的通道。</p> 
<div> 
 <p style="text-align:center"><img alt="" height="277" src="https://images2.imgbox.com/8b/a2/mK5GxyvK_o.png" width="558">​</p> 
</div> 
<p>        具有深零填充和单通道输入的ResNet-6的第一和第二卷积层的特征图。在每一层中，第一行显示RGB输入的特征图，第二行显示IR输入的特征图。很明显，通过深零填充学习的左侧域特定通道比通过单通道输入学习的通道要多得多。</p> 
<p>        为了量化网络中特定领域的节点，我们计算每一层中特定领域节点的比例。 根据等式（3）设置小（严格）阈值和大（松散）阈值以确定节点是否是特定于域的。 域特定节点的比例与层深度的关系如下图所示。可以观察到，域特定节点主要出现在较浅的层中。 网络在第 6 层之后更喜欢共享结构是合理的。使用深度零填充有助于生成更多特定于域的节点，而在大多数层中，没有零填充的比例较低。 补充提供了有关两个域各自比例的详细信息。</p> 
<div> 
 <p style="text-align:center"><img alt="" height="210" src="https://images2.imgbox.com/8d/90/VyFEc95h_o.png" width="595">​</p> 
</div> 
<p>        域特定节点的比例与层深度的关系。x轴表示从网络底部到顶部的层深度，y轴表示域特定节点的比例。严格阈值T=0.01 std  (x  (l) i)，松散阈值T=0.05 std  (x  (l) i)，  (std  (x  (l) i) 是第i层节点输出的标准差)。一般而言，使用深度零填充的域特定节点的比例高于不使用零填充的域特定节点的比例。 </p> 
<p><strong>通过深度零填充，网络可以更容易地学习特定于域的节点，并获得更好的性能。</strong></p> 
<h1 id="5%20%E5%AE%9E%E9%AA%8C">5 实验</h1> 
<p>        在 SYSU-MM01 数据集进行试验。</p> 
<h2 id="5.1%20%E6%A8%A1%E5%9E%8B%E6%AF%94%E8%BE%83">5.1 模型比较</h2> 
<p>深度模型。评估了四个深度模型，包括一流网络、双流网络、非对称FC层网络和建议的深度零填充方法（网络结构与一流网络相同）。在 ResNet [9] 中应用了残差块作为所有四种结构的基础卷积块。每个块的过滤器数量分别为 16、16、64、128、256 和 512。下一层是用作特征的 256 维的 FC 层。对于这四个网络，损失函数是和ResNet[9]一样的softmax loss，比较常用，比较稳定。所有的超参数都保持不变。对于前三个网络的输入，将图像转换为单通道灰度图像，并将尺寸调整为224×224。</p> 
<h2 id="5.2%C2%A0%E6%A8%A1%E5%9E%8B%E6%AF%94%E8%BE%83%E4%B8%8E%E5%88%86%E6%9E%90">5.2 模型分析</h2> 
<p><img alt="" height="719" src="https://images2.imgbox.com/1b/df/0g6PpCK6_o.png" width="1200">​</p> 
<p></p> 
<p>         所有基线模型，即具有跨域度量学习方法的手工特征，都表现不佳：即使是最佳情况的 rank-1 准确率也未能达到 10%。LOMO 特征包含丰富的颜色信息，在 RGB-RGB Re-ID 问题中表现非常出色。因此结果表明，在 RGB-IR 匹配中，由于不同的成像原理，颜色的辨别力大大降低。尽管身体形状和衣服纹理可用于识别人，但低级特征对于 RGBIR 跨模态行人 Re-ID 问题的判别力不够。然而，对于深度模型，室内搜索的最佳 rank-1 准确率可以达到 20.58%。</p> 
<p>        可以看到深度零填充优于双流网络和非对称 FC 层结构。 以单次设置下的全搜索模式下的rank-1准确率为例，深度零填充与双流/非对称FC层之间的差距为3.15%/5.50%。</p> 
<p>        单流网络可以在存在域指示符的情况下作为两流网络工作。因此，我们将两个额外的通道填充到输入图像中，作为域指示器。对于RGB图像，第一通道用等于255的所有像素填充，第二通道用0填充，而对于IR图像，第一通道用0填充，第二通道用255填充。此填充过程向网络明确提供了域指示符， 提出的深度零填充方法达到了最佳性能。具有域指示符的输入仅实现与原始单流网络性能相似的性能。性能比较如表所示：</p> 
<div> 
 <p style="text-align:center"><img alt="" height="178" src="https://images2.imgbox.com/90/10/EdmoEp5J_o.png" width="531">​</p> 
</div> 
<p>        </p>
                </div>

		</div>
	</article>
</main>




			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程小白.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://www.w3counter.com/tracker.js?id=150625"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>
	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>