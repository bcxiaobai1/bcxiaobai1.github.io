<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<title>Android基于opencv4.6.0实现人脸识别功能 - 编程小白</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程小白" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程小白</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Android基于opencv4.6.0实现人脸识别功能</h1>
			
		</header>
		<div class="content post__content clearfix">
			


        
                <div id="content_views" class="htmledit_views">
                    <h2 style="text-align:center">前言</h2> 
<p>步骤：</p> 
<p>1.整合opencv</p> 
<p>2.获取相机的SurfaceView传到native层去检测(亦或是不断的获取SurfaceView的Bitmap，传到native层)</p> 
<p>3.检测人脸，在本地保存人脸特征信息</p> 
<p><s>4.上传至后台(不实现)</s></p> 
<p>人脸识别实现的思路(例：人脸登录)</p> 
<p>1.人脸信息录入</p> 
<p>1.1获取相机的Bitmap，检测人脸(保证人脸信息比较精准) 人脸要足够大，当前范围内人脸只能有一张人脸，正常、眨眼睛、张嘴巴(3张人脸信息)</p> 
<p>1.2获取到人脸必须要保存人脸特征信息，然后上传至后台(后台会再次做算法优化)，保存到数据库</p> 
<p>2.人脸特征值匹配</p> 
<p>2.1获取相机的Bitmap，检测人脸(保证人脸信息比较精准) 人脸要足够大，当前范围内人脸只能有一张人脸，正常、眨眼睛、张嘴巴(3张人脸信息)</p> 
<p>2.2从后台去查询用户进行登录</p> 
<h2>一.Android Studio配置opencv</h2> 
<h3>1.opencv资源获取</h3> 
<p>opencv官网：<a href="https://opencv.org/" title="Home - OpenCV">Home - OpenCV</a> </p> 
<p>opencv最新的版本是4.6.0于2022年06月07日发布，4.6.0网址：<a href="https://opencv.org/opencv-4-6-0/" title="OpenCV 4.6.0 Is Now Available! - OpenCV">OpenCV 4.6.0 Is Now Available! - OpenCV</a></p> 
<p>opencv 4.6.0android sdk 下载链接<a href="https://nchc.dl.sourceforge.net/project/opencvlibrary/4.6.0/opencv-4.6.0-android-sdk.zip" title="https://nchc.dl.sourceforge.net/project/opencvlibrary/4.6.0/opencv-4.6.0-android-sdk.zip">https://nchc.dl.sourceforge.net/project/opencvlibrary/4.6.0/opencv-4.6.0-android-sdk.zip</a></p> 
<h3>2.解压opencv-4.6.0-android-sdk.zip文件</h3> 
<p>解压之后的文件夹:OpenCV-android-sdk</p> 
<p><img alt="" height="351" src="https://images2.imgbox.com/5e/ec/auRgIW2M_o.png" width="791"><span title="点击并拖拽以改变尺寸">​</span></p> 
<p><img alt="" height="241" src="https://images2.imgbox.com/5c/a5/OreZGCfl_o.png" width="924"><span title="点击并拖拽以改变尺寸">​</span></p> 
<p>samples： 所有与android相关的一些示例代码，基本全部是java代码，封装了很多功能(图片转成灰度，高斯模糊，边缘检测)</p> 
<p>sdk：所有的资源，so库，头文件，NDK自己动手写</p> 
<p>源码下载链接：<a href="https://github.com/opencv/opencv/archive/4.6.0.zip" title="https://github.com/opencv/opencv/archive/4.6.0.zip">https://github.com/opencv/opencv/archive/4.6.0.zip</a></p> 
<h3>3.新建Android项目(native c++)</h3> 
<p><img alt="" height="658" src="https://images2.imgbox.com/16/53/uQGCiCZe_o.png" width="916"></p> 
<p>C++ Standard 选择C++11</p> 
<p><img alt="" height="658" src="https://images2.imgbox.com/90/9e/nJbVDDMG_o.png" width="916"> </p> 
<p> 在main目录下新建jni文件夹</p> 
<p><img alt="" height="211" src="https://images2.imgbox.com/9e/90/o2aApi8w_o.png" width="332"></p> 
<p> 将OpenCV-android-sdksdknativejni下的include文件夹复制至项目中的jni文件夹下</p> 
<p><img alt="" height="522" src="https://images2.imgbox.com/dc/ba/LhvrPhJZ_o.png" width="780"></p> 
<p> <img alt="" height="264" src="https://images2.imgbox.com/6d/c9/40dqmerI_o.png" width="567"></p> 
<p> 将OpenCV-android-sdksdknativelibs下的armeabi-v7a文件夹复制至jni文件夹下</p> 
<p><img alt="" height="350" src="https://images2.imgbox.com/2f/90/p7qMpd81_o.png" width="793"></p> 
<p> <img alt="" height="221" src="https://images2.imgbox.com/f8/c7/tzTuhPo2_o.png" width="552"></p> 
<p> <strong>3.1配置CMakeLists.txt</strong></p> 
<p>引入头文件</p> 
<p><img alt="" height="330" src="https://images2.imgbox.com/35/a0/GjEGZLxP_o.png" width="756"></p> 
<p> 添加opencv库并设置目标属性(注意路径)</p> 
<p><img alt="" height="639" src="https://images2.imgbox.com/52/b5/iWZExeh1_o.png" width="953"></p> 
<p> 添加目标链接库opencv-lib</p> 
<p><img alt="" height="244" src="https://images2.imgbox.com/2a/68/2UpGq6i1_o.png" width="864"></p> 
<p> CMakeLists.txt内容：</p> 
<pre><code class="language-bash"># For more information about using CMake with Android Studio, read the
# documentation: https://d.android.com/studio/projects/add-native-code.html

# Sets the minimum version of CMake required to build the native library.

cmake_minimum_required(VERSION 3.10.2)

# Declares and names the project.

project("opencvtestapplication")
#需要引入我们头文件，以这个配置的目录为基准
include_directories(${CMAKE_SOURCE_DIR}/../jni/include)

# Creates and names a library, sets it as either STATIC
# or SHARED, and provides the relative paths to its source code.
# You can define multiple libraries, and CMake builds them for you.
# Gradle automatically packages shared libraries with your APK.

add_library( # Sets the name of the library.
             native-lib

             # Sets the library as a shared library.
             SHARED

             # Provides a relative path to your source file(s).
             native-lib.cpp )
# 添加opencv的库
add_library(
        opencv-lib
        SHARED
        IMPORTED)
set_target_properties(
        opencv-lib
        PROPERTIES IMPORTED_LOCATION
        ${CMAKE_SOURCE_DIR}/../jni/armeabi-v7a/libopencv_java4.so)

# Searches for a specified prebuilt library and stores the path as a
# variable. Because CMake includes system libraries in the search path by
# default, you only need to specify the name of the public NDK library
# you want to add. CMake verifies that the library exists before
# completing its build.

find_library( # Sets the name of the path variable.
              log-lib

              # Specifies the name of the NDK library that
              # you want CMake to locate.
              log )

# Specifies libraries CMake should link to your target library. You
# can link multiple libraries, such as libraries you define in this
# build script, prebuilt third-party libraries, or system libraries.

target_link_libraries( # Specifies the target library.
                       native-lib opencv-lib

                       # Links the target library to the log library
                       # included in the NDK.
                       ${log-lib} )</code></pre> 
<p><strong>3.2修改app下的build.gradle文件 只支持armv7</strong></p> 
<p><img alt="" height="535" src="https://images2.imgbox.com/62/dc/GU6em6U4_o.png" width="961"></p> 
<p> 同步运行项目至手机设备</p> 
<p>出现如下图所示错误：</p> 
<p><img alt="" height="239" src="https://images2.imgbox.com/e4/7a/YFiLEUVR_o.png" width="1176"></p> 
<p> java.lang.UnsatisfiedLinkError: dlopen failed: library "libc++_shared.so" not found</p> 
<p>解决方式如下：</p> 
<p>修改app下的build.gradle文件</p> 
<p><img alt="" height="525" src="https://images2.imgbox.com/d2/28/kVJdQ5mc_o.png" width="1200"></p> 
<p> 重新同步项目并运行项目至手机设备</p> 
<p><strong>3.3新建FaceDetection类</strong></p> 
<p>FaceDetection内容如下：</p> 
<pre><code class="language-java">package com.suoer.ndk.opencvtestapplication;

import android.graphics.Bitmap;

public class FaceDetection {
    // Used to load the 'native-lib' library on application startup.
    static {
        System.loadLibrary("native-lib");
    }
    /**
     * 检测人脸并保存人脸信息
     * @param faceBitmap
     */

    public native int faceDetectionSaveInfo(Bitmap faceBitmap);

    /**
     * 加载人脸识别的分类器文件
     * @param filePath
     */
    public native boolean loadCascade(String filePath);


}
</code></pre> 
<p><strong>3.4修改MainActivity类</strong></p> 
<p>因为需要拍照以及保存图片，所以需要权限处理。这里使用rxpermissions</p> 
<p>rxpermissions的具体使用请参照github链接：<a href="https://github.com/tbruyelle/RxPermissions" title="GitHub - tbruyelle/RxPermissions: Android runtime permissions powered by RxJava2">GitHub - tbruyelle/RxPermissions: Android runtime permissions powered by RxJava2</a></p> 
<p>因为保存图片是耗时操作，需要开启子线程完成，所以需要处理线程问题。这里使用rxandroid</p> 
<p>rxandroid的具体使用请参照github链接：<a href="https://github.com/ReactiveX/RxAndroid" title="GitHub - ReactiveX/RxAndroid: RxJava bindings for Android">GitHub - ReactiveX/RxAndroid: RxJava bindings for Android</a></p> 
<p>修改app下的build.gradle文件</p> 
<p><img alt="" height="343" src="https://images2.imgbox.com/3c/53/NECOqSuA_o.png" width="923"></p> 
<p> app下的build.gradle文件内容：</p> 
<pre><code class="language-bash">plugins {
    id 'com.android.application'
}

android {
    compileSdkVersion 32
    buildToolsVersion "32.0.0"

    defaultConfig {
        applicationId "com.suoer.ndk.opencvtestapplication"
        minSdkVersion 16
        targetSdkVersion 32
        versionCode 1
        versionName "1.0"

        testInstrumentationRunner "androidx.test.runner.AndroidJUnitRunner"
        externalNativeBuild {
            cmake {
                cppFlags "-std=c++11 -Wno-nonportable-include-path -Wno-deprecated-register -Wno-writable-strings"
                //远程下载
                arguments "-DANDROID_STL=c++_shared"

            }
        }
        ndk {
            abiFilters("armeabi-v7a")
        }
    }

    buildTypes {
        release {
            minifyEnabled false
            proguardFiles getDefaultProguardFile('proguard-android-optimize.txt'), 'proguard-rules.pro'
        }
    }
    externalNativeBuild {
        cmake {
            path "src/main/cpp/CMakeLists.txt"
            version "3.10.2"
        }
    }
    compileOptions {
        sourceCompatibility JavaVersion.VERSION_1_8
        targetCompatibility JavaVersion.VERSION_1_8
    }
}

dependencies {

    implementation 'androidx.appcompat:appcompat:1.1.0'
    implementation 'com.google.android.material:material:1.1.0'
    implementation 'androidx.constraintlayout:constraintlayout:1.1.3'
    testImplementation 'junit:junit:4.+'
    androidTestImplementation 'androidx.test.ext:junit:1.1.1'
    androidTestImplementation 'androidx.test.espresso:espresso-core:3.2.0'
    implementation 'com.github.tbruyelle:rxpermissions:0.12'
    implementation 'io.reactivex.rxjava3:rxandroid:3.0.0'
}</code></pre> 
<p>修改项目下的build.gradle文件</p> 
<p><img alt="" height="258" src="https://images2.imgbox.com/b1/2a/xLx0DI0G_o.png" width="1022"></p> 
<p> 项目下的build.gradle文件内容：</p> 
<pre><code class="language-bash">// Top-level build file where you can add configuration options common to all sub-projects/modules.
buildscript {
    repositories {
        google()
        jcenter()
    }
    dependencies {
        classpath "com.android.tools.build:gradle:4.1.0"

        // NOTE: Do not place your application dependencies here; they belong
        // in the individual module build.gradle files
    }
}

allprojects {
    repositories {
        google()
        jcenter()
        maven { url 'https://jitpack.io' }
        maven { url "https://oss.jfrog.org/libs-snapshot" }
    }
}

task clean(type: Delete) {
    delete rootProject.buildDir
}</code></pre> 
<p>修改AndroidManifest.xml添加权限</p> 
<p><img alt="" height="381" src="https://images2.imgbox.com/6b/26/MZGv6jmk_o.png" width="964"></p> 
<p> </p> 
<pre><code class="language-XML">    &lt;uses-permission android:name="android.permission.CAMERA" /&gt;
    &lt;uses-permission android:name="android.permission.READ_EXTERNAL_STORAGE"/&gt;
    &lt;uses-permission android:name="android.permission.WRITE_EXTERNAL_STORAGE"/&gt;</code></pre> 
<p>MainActivity类内容如下：</p> 
<pre><code class="language-java">package com.suoer.ndk.opencvtestapplication;

import android.Manifest;
import android.content.Context;
import android.content.pm.PackageManager;
import android.graphics.Bitmap;
import android.os.Bundle;
import android.util.Log;
import android.view.SurfaceView;
import android.view.View;
import android.view.Window;
import android.view.WindowManager;
import android.widget.Button;
import android.widget.ImageView;
import android.widget.Toast;

import com.suoer.ndk.opencvtestapplication.camerahandle.BitmapInterface;
import com.suoer.ndk.opencvtestapplication.camerahandle.CameraSurfaceHolder;
import com.suoer.ndk.opencvtestapplication.camerahandle.FrontCamera;
import com.suoer.ndk.opencvtestapplication.camerahandle.SaveImageTask;
import com.suoer.ndk.opencvtestapplication.camerahandle.SurfaceViewCallback;
import com.tbruyelle.rxpermissions3.RxPermissions;

import java.io.ByteArrayOutputStream;
import java.io.File;
import java.io.FileOutputStream;
import java.io.IOException;
import java.io.InputStream;

import androidx.appcompat.app.AppCompatActivity;
import io.reactivex.rxjava3.functions.Consumer;

public class MainActivity extends AppCompatActivity {
    private static final String TAG = "MainActivity";
    private SurfaceView mSurfaceView;
    private ImageView faceImg;
    private Button faceDetectionBtn;

    private FaceDetection mFaceDetection;
    private File mCascadeFile;

    private CameraSurfaceHolder mCameraSurfaceHolder=new CameraSurfaceHolder();
    private SurfaceViewCallback mSurfaceViewCallback;
    private FrontCamera mFrontCamera;



    @Override
    protected void onCreate(Bundle savedInstanceState) {
        super.onCreate(savedInstanceState);
        requestWindowFeature(Window.FEATURE_NO_TITLE);
        getWindow().addFlags(WindowManager.LayoutParams.FLAG_FULLSCREEN);
        initView();
        applyPermission();
        initFaceDetection();
    }

    private void initFaceDetection() {
        copyCascadeFile();
        mFaceDetection = new FaceDetection();
        if (mFaceDetection != null) {
            boolean load = mFaceDetection.loadCascade(mCascadeFile.getAbsolutePath());
            if (load) {
                Toast.makeText(this, "加载分类器文件成功！", Toast.LENGTH_SHORT).show();
            } else {
                Toast.makeText(this, "加载分类器文件失败！", Toast.LENGTH_SHORT).show();
            }
        }

    }

    //申请权限
    private void applyPermission() {
        if (!checkCameraHardware(this)) {
            return;
        }
        RxPermissions rxPermissions = new RxPermissions(this);
        rxPermissions.request(Manifest.permission.READ_EXTERNAL_STORAGE, Manifest.permission.WRITE_EXTERNAL_STORAGE, Manifest.permission.CAMERA).subscribe(new Consumer&lt;Boolean&gt;() {
            @Override
            public void accept(Boolean aBoolean) throws Throwable {
                if (aBoolean) {
                    Log.e(TAG, "accept: " + aBoolean);
                    faceDetectionBtn.setVisibility(View.VISIBLE);
                    mSurfaceView.setVisibility(View.VISIBLE);
                    //权限全部获取
                    initSurfaceViewPreView();


                }

            }
        });


    }

    private void initSurfaceViewPreView() {
        mCameraSurfaceHolder.setCameraSurfaceHolder(MainActivity.this, mSurfaceView);
        mSurfaceViewCallback = mCameraSurfaceHolder.mSurfaceViewCallback;
        if (mSurfaceViewCallback != null) {
            mFrontCamera = mSurfaceViewCallback.mFrontCamera;
        }
    }

    ;

    private void initView() {
        setContentView(R.layout.activity_main);
        mSurfaceView = findViewById(R.id.face_surfaceView);
        mSurfaceView.setVisibility(View.GONE);
        faceDetectionBtn = findViewById(R.id.faceDetectionBtn);
        faceImg = findViewById(R.id.faceImg);
        faceDetectionBtn.setOnClickListener(new View.OnClickListener() {
            @Override
            public void onClick(View v) {
                if (mFrontCamera != null) {
                    //拍照的时候进行人脸识别
                    mFrontCamera.takePicture(new BitmapInterface() {
                        @Override
                        public void setBitMap(Bitmap bitMap) {
                            if(bitMap==null){
                                Toast.makeText(MainActivity.this,"拍照失败！",Toast.LENGTH_SHORT).show();
                                return;
                            }
                            //人脸识别
                            int result = mFaceDetection.faceDetectionSaveInfo(bitMap);
                            if (result != 0) {
                                Toast.makeText(MainActivity.this, "检测人脸失败!", Toast.LENGTH_SHORT).show();
                                return;
                            }

                            faceImg.setVisibility(View.VISIBLE);
                            faceImg.setImageBitmap(bitMap);
                            byte[]data= bitmap2byte(bitMap);
                            //rxandroid实现开启子线程保存文件
                            new SaveImageTask(MainActivity.this,faceImg).saveImage(data);
                            //AsyncTask异步任务实现开启子线程保存文件
                            //new SaveImageAsyncTask(MainActivity.this,faceImg).execute(data);
                        }
                    });
                }


            }
        });

    }
    private byte[] bitmap2byte(Bitmap photoBitmap){
        创建对应的流对象
        ByteArrayOutputStream byteArrayOutputStream = new ByteArrayOutputStream();
        photoBitmap.compress(Bitmap.CompressFormat.JPEG,100,byteArrayOutputStream);//将流对象与Bitmap对象进行关联。
        byte [] array=byteArrayOutputStream.toByteArray();//使用流对象，将Bitmap对象转换为byte[]数组
        return array;

    }




    private void copyCascadeFile() {

        try {
            // load cascade file from application resources
            InputStream is = getResources().openRawResource(R.raw.lbpcascade_frontalface);
            File cascadeDir = getDir("cascade", Context.MODE_PRIVATE);
            mCascadeFile = new File(cascadeDir, "lbpcascade_frontalface.xml");
            if (mCascadeFile.exists()) return;
            FileOutputStream os = new FileOutputStream(mCascadeFile);

            byte[] buffer = new byte[4096];
            int bytesRead;
            while ((bytesRead = is.read(buffer)) != -1) {
                os.write(buffer, 0, bytesRead);
            }
            is.close();
            os.close();
            cascadeDir.delete();

        } catch (IOException e) {
            e.printStackTrace();
            Log.e(TAG, "Failed to load cascade. Exception thrown: " + e);
        }
    }

    /**
     * 检测是否存在摄像头
     *
     * @param context
     * @return
     */
    private boolean checkCameraHardware(Context context) {
        if (context.getPackageManager().hasSystemFeature(PackageManager.FEATURE_CAMERA)) {
            return true;
        } else {
            Toast.makeText(this, "不具备摄像头硬件", Toast.LENGTH_SHORT).show();
            return false;
        }
    }

}</code></pre> 
<p><br> 布局activity_main.xml</p> 
<pre><code class="language-XML">&lt;?xml version="1.0" encoding="utf-8"?&gt;
&lt;androidx.constraintlayout.widget.ConstraintLayout xmlns:android="http://schemas.android.com/apk/res/android"
    xmlns:app="http://schemas.android.com/apk/res-auto"
    xmlns:tools="http://schemas.android.com/tools"
    android:layout_width="match_parent"
    android:layout_height="match_parent"
    tools:context=".MainActivity"&gt;
    &lt;SurfaceView
        app:layout_constraintTop_toTopOf="@+id/faceDetectionBtn"
        android:id="@+id/face_surfaceView"
        android:layout_width="match_parent"
        android:layout_height="match_parent"/&gt;
    &lt;ImageView
        app:layout_constraintTop_toTopOf="@+id/faceDetectionBtn"
        android:visibility="gone"
        android:id="@+id/faceImg"
        android:src="@drawable/face"
        android:layout_width="match_parent"
        android:layout_height="match_parent"&gt;&lt;/ImageView&gt;
    &lt;Button
        android:visibility="gone"
        android:id="@+id/faceDetectionBtn"
        android:layout_width="match_parent"
        android:layout_height="wrap_content"
        android:text="人脸识别"
        app:layout_constraintBottom_toBottomOf="parent"
        app:layout_constraintLeft_toLeftOf="parent"
        app:layout_constraintRight_toRightOf="parent"
         /&gt;

&lt;/androidx.constraintlayout.widget.ConstraintLayout&gt;</code></pre> 
<p></p> 
<p><strong>3.5修改native-lib.cpp</strong></p> 
<pre><code class="language-cpp">#include &lt;jni.h&gt;
#include &lt;string&gt;
#include &lt;opencv2/opencv.hpp&gt;
#include &lt;android/bitmap.h&gt;
#include &lt;android/log.h&gt;
#include &lt;opencv2/imgcodecs/legacy/constants_c.h&gt;

#define TAG "JNI_LOG"
#define LOGE(...)__android_log_print(ANDROID_LOG_ERROR,TAG,__VA_ARGS__)
using namespace cv;
CascadeClassifier cascadeClassifier;


//使用命名空间
void bitmap2Mat(JNIEnv *env, Mat &amp;mat, jobject bitmap);

//mat转成bitmap
void mat2Bitmap(JNIEnv *env, Mat mat, jobject bitmap);

//bitmap转成mat
void bitmap2Mat(JNIEnv *env, Mat &amp;mat, jobject bitmap) {
//Mat里面有个type:CV_8UC4 刚好对上bitmap中的ARGB_8888 CV_8UC2 刚好匹配bitmap中的RGB_565
//1.获取bitmap信息
AndroidBitmapInfo info;
void *pixels;
AndroidBitmap_getInfo(env,bitmap,&amp;info);

//锁定bitmap画布
AndroidBitmap_lockPixels(env,bitmap,&amp;pixels);
//指定mat的宽高和type BGRA
mat.create(info.height,info.width,CV_8UC4);

if(info.format==ANDROID_BITMAP_FORMAT_RGBA_8888){
//对应的mat应该是CV_8UC4
Mat temp(info.height,info.width,CV_8UC4,pixels);
//把数据temp复制到mat里面
temp.copyTo(mat);

}else if(info.format==ANDROID_BITMAP_FORMAT_RGB_565){
    //对应的mat应该是CV_8UC2
    Mat temp(info.height,info.width,CV_8UC2,pixels);
    //上面mat创建的是CV_8UC4 要改为CV_8UC2  CV_8UC2数据拷贝到CV_8UC4
    cvtColor(temp,mat,COLOR_BGR5652BGRA);
}
//其他需要自己去转
//解锁画布
AndroidBitmap_unlockPixels(env,bitmap);
}

extern "C"
JNIEXPORT jint JNICALL
Java_com_suoer_ndk_opencvtestapplication_FaceDetection_faceDetectionSaveInfo(JNIEnv *env,
                                                                             jobject thiz,
                                                                             jobject face_bitmap) {
    // TODO: implement faceDetectionSaveInfo()
    //检测人脸 opencv有关键的类是Mat,opencv是c和c++写的，只会处理Mat,android里面是Bitmap
    //1.Bitmap转成opencv能操作的c++对象 Mat ,Mat是一个矩阵
    Mat mat;
    bitmap2Mat(env,mat,face_bitmap);
    //处理灰度opencv 处理灰度图 提高效率,一般所有的操作都会对齐进行处理
    Mat gray_mat;
    cvtColor(mat,gray_mat,COLOR_BGRA2GRAY);

    //再次处理直方均衡补偿
    Mat equalize_mat;
    equalizeHist(gray_mat,equalize_mat);
    //识别人脸 当然我们可以直接用彩色图去做，识别人脸要加载人脸分类器文件
    std::vector&lt;Rect&gt; faces;
    cascadeClassifier.detectMultiScale(equalize_mat,faces,1.1,5);
    LOGE("人脸个数:%d",faces.size());
    if(faces.size()!=1){
        return -1;
    }

        Rect faceRect=faces[0];
        //在人脸部分画个图
        rectangle(mat,faceRect,Scalar(255,155,155),8);
        //把mat 放到bitmap中 图片展示出来
        //mat2Bitmap(env,mat,face_bitmap);
        //保存人脸信息 Mat,图片
        Mat face_info_mat(equalize_mat,faceRect);
        //保存face_info_mat
        mat2Bitmap(env,face_info_mat,face_bitmap);
        //mat2Bitmap(env,equalize_mat,face_bitmap);







    //保存人脸信息
    return 0;
}

void mat2Bitmap(JNIEnv *env, Mat mat, jobject bitmap) {
//Mat里面有个type:CV_8UC4 刚好对上bitmap中的ARGB_8888 CV_8UC2 刚好匹配bitmap中的RGB_565
//1.获取bitmap信息
    AndroidBitmapInfo info;
    void *pixels;
    AndroidBitmap_getInfo(env,bitmap,&amp;info);

//锁定bitmap画布
    AndroidBitmap_lockPixels(env,bitmap,&amp;pixels);


    if(info.format==ANDROID_BITMAP_FORMAT_RGBA_8888){
//对应的mat应该是CV_8UC4
        Mat temp(info.height,info.width,CV_8UC4,pixels);
        if(mat.type()==CV_8UC4){
            mat.copyTo(temp);
        }else if(mat.type()==CV_8UC2){
            cvtColor(mat,temp,COLOR_BGR5652BGRA);
        }
        else if(mat.type()==CV_8UC1){//灰度mat
            cvtColor(mat,temp,COLOR_GRAY2BGRA);
        }
    }else if(info.format==ANDROID_BITMAP_FORMAT_RGB_565){
        //对应的mat应该是CV_8UC2
        Mat temp(info.height,info.width,CV_8UC2,pixels);
        if(mat.type()==CV_8UC4){
            cvtColor(mat,temp,COLOR_BGRA2BGR565);
        }else if(mat.type()==CV_8UC2){
            mat.copyTo(temp);
        }
        else if(mat.type()==CV_8UC1){//灰度mat
            cvtColor(mat,temp,COLOR_GRAY2BGR565);
        }

    }
//其他需要自己去转
//解锁画布
    AndroidBitmap_unlockPixels(env,bitmap);
}

extern "C"
JNIEXPORT jboolean JNICALL
Java_com_suoer_ndk_opencvtestapplication_FaceDetection_loadCascade(JNIEnv *env, jobject thiz,
                                                                   jstring file_path) {
    // TODO: implement loadCascade()
    const char *filePath=env-&gt;GetStringUTFChars(file_path,0);
    bool load=cascadeClassifier.load(filePath);
    env-&gt;ReleaseStringUTFChars(file_path,filePath);
    return load;
}</code></pre> 
<p>运行app至手机设备出现如下图所示错误</p> 
<p><img alt="" height="444" src="https://images2.imgbox.com/02/db/imgRLRoQ_o.png" width="1200"></p> 
<p>error: undefined reference to 'AndroidBitmap_getInfo'</p> 
<p> 解决方式修改CMakeLists.txt</p> 
<p><img alt="" height="380" src="https://images2.imgbox.com/8f/f4/8XCcwMec_o.png" width="971"></p> 
<p> </p> 
<pre><code class="language-bash">target_link_libraries( # Specifies the target library.
                       native-lib opencv-lib
                       #加入该依赖库
                       jnigraphics

                       # Links the target library to the log library
                       # included in the NDK.
                       ${log-lib} )</code></pre> 
<p>CMakeLists.txt内容如下：</p> 
<pre><code class="language-bash"># For more information about using CMake with Android Studio, read the
# documentation: https://d.android.com/studio/projects/add-native-code.html

# Sets the minimum version of CMake required to build the native library.

cmake_minimum_required(VERSION 3.10.2)

# Declares and names the project.

project("opencvtestapplication")
#需要引入我们头文件，以这个配置的目录为基准
include_directories(${CMAKE_SOURCE_DIR}/../jni/include)

# Creates and names a library, sets it as either STATIC
# or SHARED, and provides the relative paths to its source code.
# You can define multiple libraries, and CMake builds them for you.
# Gradle automatically packages shared libraries with your APK.

add_library( # Sets the name of the library.
             native-lib

             # Sets the library as a shared library.
             SHARED

             # Provides a relative path to your source file(s).
             native-lib.cpp )
# 添加opencv的库
add_library(
        opencv-lib
        SHARED
        IMPORTED)
set_target_properties(
        opencv-lib
        PROPERTIES IMPORTED_LOCATION
        ${CMAKE_SOURCE_DIR}/../jni/armeabi-v7a/libopencv_java4.so)

# Searches for a specified prebuilt library and stores the path as a
# variable. Because CMake includes system libraries in the search path by
# default, you only need to specify the name of the public NDK library
# you want to add. CMake verifies that the library exists before
# completing its build.

find_library( # Sets the name of the path variable.
              log-lib

              # Specifies the name of the NDK library that
              # you want CMake to locate.
              log )

# Specifies libraries CMake should link to your target library. You
# can link multiple libraries, such as libraries you define in this
# build script, prebuilt third-party libraries, or system libraries.

target_link_libraries( # Specifies the target library.
                       native-lib opencv-lib
                       #加入该依赖库
                       jnigraphics

                       # Links the target library to the log library
                       # included in the NDK.
                       ${log-lib} )</code></pre> 
<p>其他详细内容可见Demo。</p>
                </div>

		</div>
	</article>
</main>




			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程小白.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://www.w3counter.com/tracker.js?id=150625"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>
	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>