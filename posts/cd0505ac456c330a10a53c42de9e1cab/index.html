<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<title>强化学习笔记：马尔科夫链介绍及基于Python的蒙特卡洛仿真 - 编程小白</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程小白" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程小白</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">强化学习笔记：马尔科夫链介绍及基于Python的蒙特卡洛仿真</h1>
			
		</header>
		<div class="content post__content clearfix">
			


                <div id="content_views" class="htmledit_views">
                    <p id="main-toc"><strong>目录</strong></p> 
<p id="0.-前言-toc" style="margin-left:0px"><a href="#0.-%E5%89%8D%E8%A8%80">0. 前言</a></p> 
<p id="0.1-马尔可夫性-toc" style="margin-left:0px"><a href="#0.1-%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E6%80%A7">0.1 马尔可夫性</a></p> 
<p id="0.2-马尔科夫链-toc" style="margin-left:0px"><a href="#0.2-%E9%A9%AC%E5%B0%94%E7%A7%91%E5%A4%AB%E9%93%BE">0.2 马尔科夫链</a></p> 
<p id="0.3-马尔科夫链有什么用？-toc" style="margin-left:40px"><a href="#0.3-%E9%A9%AC%E5%B0%94%E7%A7%91%E5%A4%AB%E9%93%BE%E6%9C%89%E4%BB%80%E4%B9%88%E7%94%A8%EF%BC%9F">0.3 马尔科夫链有什么用？</a></p> 
<p id="3.-离散时间马尔科夫链(DTMC)-toc" style="margin-left:0px"><a href="#3.-%E7%A6%BB%E6%95%A3%E6%97%B6%E9%97%B4%E9%A9%AC%E5%B0%94%E7%A7%91%E5%A4%AB%E9%93%BE%28DTMC%29">3. 离散时间马尔科夫链(DTMC)</a></p> 
<p id="4.-马尔科夫链建模-toc" style="margin-left:0px"><a href="#4.-%E9%A9%AC%E5%B0%94%E7%A7%91%E5%A4%AB%E9%93%BE%E5%BB%BA%E6%A8%A1">4. 马尔科夫链建模</a></p> 
<p id="4.1-转移概率矩阵-toc" style="margin-left:40px"><a href="#4.1-%E8%BD%AC%E7%A7%BB%E6%A6%82%E7%8E%87%E7%9F%A9%E9%98%B5">4.1 转移概率矩阵</a></p> 
<p id="4.2-有向图表示-toc" style="margin-left:40px"><a href="#4.2-%E6%9C%89%E5%90%91%E5%9B%BE%E8%A1%A8%E7%A4%BA">4.2 有向图表示</a></p> 
<p id="4.3-一个实例-toc" style="margin-left:40px"><a href="#4.3-%E4%B8%80%E4%B8%AA%E5%AE%9E%E4%BE%8B">4.3 一个实例</a></p> 
<p id="4.4-矩阵运算例-toc" style="margin-left:40px"><a href="#4.4-%E7%9F%A9%E9%98%B5%E8%BF%90%E7%AE%97%E4%BE%8B">4.4 矩阵运算例</a></p> 
<p id="5.-马尔科夫链蒙特卡洛仿真-toc" style="margin-left:0px"><a href="#5.-%E9%A9%AC%E5%B0%94%E7%A7%91%E5%A4%AB%E9%93%BE%E8%92%99%E7%89%B9%E5%8D%A1%E6%B4%9B%E4%BB%BF%E7%9C%9F">5. 马尔科夫链蒙特卡洛仿真</a></p> 
<p id="5.1%20Python%20modelling-toc" style="margin-left:40px"><a href="#5.1%20Python%20modelling">5.1 Python modelling</a></p> 
<p id="5.2%20The%20first%20trial-toc" style="margin-left:40px"><a href="#5.2%20The%20first%20trial">5.2 The first trial</a></p> 
<p id="5.3%20%E8%92%99%E7%89%B9%E5%8D%A1%E6%B4%9B%E4%BB%BF%E7%9C%9F-toc" style="margin-left:40px"><a href="#5.3%20%E8%92%99%E7%89%B9%E5%8D%A1%E6%B4%9B%E4%BB%BF%E7%9C%9F">5.3 蒙特卡洛仿真</a></p> 
<hr id="hr-toc">
<h1>0. 前言</h1> 
<h1 id="0.1-马尔可夫性">0.1 马尔可夫性</h1> 
<p>        简而言之，所谓马尔可夫性(Markov Property)是指系统的下一个状态<img alt="s_{t+1}" class="mathcode" src="https://latex.codecogs.com/gif.latex?s_%7Bt&amp;plus;1%7D">仅与当前状态<img alt="s_t" class="mathcode" src="https://images2.imgbox.com/6e/e8/yrWevUtM_o.gif">有关，而与以前的状态无关。</p> 
<p>        马尔可夫性的一个更通俗的说法是无记忆性(memorylessness)，即系统不记得当前状态以前的状态，仅仅基于当前状态来决定下一个时刻转移到什么状态。</p> 
<h1 id="0.2-马尔科夫链">0.2 马尔科夫链</h1> 
<p>        马尔可夫链（Markov Chain, MC）是具有马尔可夫性（Markov property）的随机过程（stochastic process）,又称马尔可夫(随机)过程。</p> 
<p>        如果指标集(index set)是连续的，则称为连续时间马尔可夫链（Continuous-Time MC, CTMC）；如果指标集是离散的，则称为离散时间马尔可夫链（Discrete-Time MC, DTMC）。注意，这里‘时间’应该以广义的方式理解。时间是指标(index)的一种，但是的确是最常用的一种。因此，人们通常以时间作为广义的index的代名词。</p> 
<p>        通常情况下，我们碰到的都是DTMC，并且常常就简称为马尔科夫链。所以，当没有特别指明的情况，说起马尔科夫链的话通常就是指DTMC。</p> 
<p>        马尔可夫链可通过转移矩阵和转移图定义，除马尔可夫性外，马尔可夫链可能具有不可约性、常返性、周期性和遍历性。一个不可约和正常返的马尔可夫链是严格平稳的马尔可夫链，拥有唯一的平稳分布。遍历马尔可夫链（ergodic MC）的极限分布收敛于其平稳分布。</p> 
<h2 id="0.3-马尔科夫链有什么用？">0.3 马尔科夫链有什么用？</h2> 
<p>马尔可夫链可被应用于蒙特卡罗方法中，形成马尔可夫链蒙特卡罗（Markov Chain Monte Carlo, MCMC），也被用于经济学、博弈论、通信理论、金融、动力系统、化学反应、排队论、市场行为和信息检索的数学建模。此外作为结构最简单的马尔可夫模型（Markov model），一些机器学习算法，例如隐马尔可夫模型（Hidden Markov Model, HMM）、马尔可夫随机场（Markov Random Field, MRF）和马尔可夫决策过程（Markov decision process, MDP）以马尔可夫链为理论基础。</p> 
<p>Markov Chains have prolific usage in mathematics. They are widely employed in economics, game theory, communication theory, genetics and finance. They arise broadly in statistical specially Bayesian statistics and information-theoretical contexts. When it comes real-world problems, they are used to postulate solutions to study cruise control systems in motor vehicles, queues or lines of customers arriving at an airport, exchange rates of currencies, etc. The algorithm known as PageRank, which was originally proposed for the internet search engine Google, is based on a Markov process. Reddit's Subreddit Simulator is a fully-automated subreddit that generates random submissions and comments using markov chains, so cool!</p> 
<p>        马尔可夫链的命名来自俄国数学家安德雷·马尔可夫（Андрей Андреевич Марков）以纪念其首次提出马尔可夫链和对其收敛性质所做的研究[2]。</p> 
<p></p> 
<h1 id="3.-离散时间马尔科夫链(DTMC)">3. 离散时间马尔科夫链(DTMC)</h1> 
<p>如前所述，DTMC是指其指标为离散时间，称为time step（时间步，时刻），系统状态在每个time step随机变化。每个time step的状态相当于一个随机变量。因此DTMC可以看作是一个离散随机变量序列。当然，把time step换成任意其它的离散指标，比如说距离啊什么，也完全可以。总之，把离散时间广义地理解为离散指标就没有错。</p> 
<p>记时刻t的状态随机变量为??∈?Xt∈S，后者称为该马尔科夫链的状态空间，状态空间可以为任意事物，比如说，字母、数字、篮球比赛计分、天气状况等等。对于DTMC，虽然指标(时间)为离散的，但是对于状态空间没有什么离散或者连续的约束。当然需要实际应用中的DTMC都采用有限的或者可数的状态空间，因为这样更容易进行统计分析。</p> 
<p>从时刻t的状态??Xt转移到时刻(t+1)的状态??+1Xt+1遵循一定的概率规则，再加上马尔科夫性的约束，这个概率性的状态转移关系可以表示为：</p> 
<p>        <img alt="Pr(X_{t+1}=x | X_1=x_1,X_2=x_2,...,X_t=x_t) = Pr(X_{t+1}=x | X_t=x_t)" class="mathcode" src="https://latex.codecogs.com/gif.latex?Pr%28X_%7Bt&amp;plus;1%7D%3Dx%20%7C%20X_1%3Dx_1%2CX_2%3Dx_2%2C...%2CX_t%3Dx_t%29%20%3D%20Pr%28X_%7Bt&amp;plus;1%7D%3Dx%20%7C%20X_t%3Dx_t%29"></p> 
<p>        如上所示，系统不记得当前状态以前的状态，仅仅基于当前状态来决定下一个时刻转移到什么状态。</p> 
<h1 id="4.-马尔科夫链建模">4. 马尔科夫链建模</h1> 
<p>马尔科夫链的模型由一个状态空间和一个状态转移矩阵，以及一个初始状态分布完全刻画。</p> 
<h2 id="4.1-转移概率矩阵">4.1 转移概率矩阵</h2> 
<p>        一个马尔科夫链可以用一个概率性自动机(probabilistic automaton)来表示。状态之间转移的概率称为转移概率(transition probabilities),在状态空间有限或者可数的条件，所有各状态两两之间的转移概率可以用转移概率矩阵(transition probability matrix)表示。考虑系统有N个状态，则转移概率矩阵为?multiply?NmultiplyN方阵，如下所示：</p> 
<p>        <img alt="P_{ntimes n} = left[ {begin{array}{cccc} p_{11} &amp; p_{12} &amp; cdots &amp; p_{1n}\ p_{21} &amp; p_{22} &amp; cdots &amp; p_{2n}\ vdots &amp; vdots &amp; ddots &amp; vdots\ p_{n1} &amp; p_{n2} &amp; cdots &amp; p_{nn}\ end{array} } right]" class="mathcode" src="https://images2.imgbox.com/40/0d/gCgbA6TA_o.gif"></p> 
<p>        其中??,?pi,j表示从状态i向状态j转移的概率。很显然，转移概率矩阵是一个右随机矩阵(stochastic matrix),它的每一行的和为1，因为每一行就表示某个状态的概率分布（向包括它自己在内的所有各状态转移的概率）.</p> 
<p>        当然，转移概率矩阵有时候也以表格的方式表达。</p> 
<h2 id="4.2-有向图表示">4.2 有向图表示</h2> 
<p>        马尔科夫链的状态转移也可以用一个有向图(directed graph)来表示。其中的节点表示状态，边(edge)的箭头方向表示状态转移的方向，而edge上的数值则表示对应状态转移的概率。参见下面的例子。</p> 
<h2 id="4.3-一个实例">4.3 一个实例</h2> 
<p>        假定小A每天功课虽然很紧张，但是每天下午有一个放松时段，她有三个选择：要么出去跑步，要么吃冰淇淋，要么睡一觉。</p> 
<p>        从历史数据来看，如果某一天小A在放松时段睡了一觉的话，那么第二天她有60%的概率会去跑步，有20%的概率会选择睡觉，还有20%的概率选择吃冰淇淋。</p> 
<p>        如果某一天小A在放松时段跑步的话，那么第二天她仍有60%的概率会去跑步，有10%的概率会选择睡觉，还有30%的概率选择吃冰淇淋。</p> 
<p>        如果某一天小A在放松时段是吃冰淇淋的话，那么第二天她仍有10%的概率会选择吃冰淇淋，有70%的概率去跑步，有20%的概率会选择睡觉。</p> 
<p>        小A的每天在下午放松时段的选择其实就构成一个马尔科夫链，可以用有向图表示如下，这个图通常称为状态转移图(state transition diagram)：</p> 
<p><img alt="" height="311" src="https://images2.imgbox.com/05/9c/5519Gw33_o.png" width="421"></p> 
<p>        而概率转移矩阵以表格的方式表示的话如下所示： </p> 
<p><img alt="" height="279" src="https://images2.imgbox.com/4b/54/y7GoPPjA_o.png" width="931"></p> 
<p>        接下来的问题是，我们用了这么花哨的方式来表示这么个事情，有什么用呢？的确会有一些用。虽然在我们这个简单的例子中，看起来有点金弹子打鸟了。</p> 
<p>        比如说，在以上这个例子中，基于马尔科夫链的理论，你现在可以回答这样的问题：</p> 
<p>        假定已知小A今天选择了跑步，在两天后（即后天）小A会去跑步的概率有多大？让我们来手动计算一下（手动计算永远都是彻底理解一个概念的必要步骤）。</p> 
<p>        因为小A今天选择了跑步，到达后天小A选择跑步的状态转移的路径一共有三条，如下图所示。</p> 
<p><img alt="" height="283" src="https://images2.imgbox.com/eb/fb/wXgt1S1o_o.png" width="513"></p> 
<p> </p> 
<p>        这个图是将状态转移图随着time step展开而得，称为trellis diagram. 这三条路径分别为：</p> 
<p>        (1) RUN--&gt;RUN--&gt;RUN;</p> 
<p>        (2) RUN--&gt;ICECREAM--&gt;RUN;</p> 
<p>        (3) RUN--&gt;SLEEP--&gt;RUN.</p> 
<p>        根据条件概率我们可以得到：</p> 
<p>        ??(后天=???|明天=???,今天=???) =</p> 
<p>                ??(后天=???|明天=???)⋅??(明天=???|今天=???)=0.6∗0.6=0.36</p> 
<p></p> 
<p>        ??(后天=???|明天=????????,今天=???) =</p> 
<p>                ??(后天=???|明天=????????)⋅??(明天=????????|今天=???)=0.3∗0.7=0.21</p> 
<p></p> 
<p>        ??(后天=???|明天=?????,今天=???) =</p> 
<p>                ??(后天=???|明天=?????)⋅??(明天=?????|今天=???)=0.1∗0.6=0.06</p> 
<p></p> 
<p>        因此，我们可以得到：</p> 
<p>        ??(后天=???|今天=???) = ??(后天=???|明天=???,今天=???)</p> 
<p>                                        + ??(后天=???|明天=???,今天=???)</p> 
<p>                                        + ??(后天=???|明天=???,今天=???)</p> 
<p>                                        =0.36+0.21+0.06=0.63</p> 
<p>        因此，我们得出，如果今天小A选择了跑步的话，那么在后天她仍然有63%的概率会选择跑步。同理，我们在已知今天小A的选择的前提条件下，可以推算在其后任意一天小A的任意选择的概率。当然，如果以以上这种方式计算的话会显得非常繁琐且容易出错。幸好数学家们给我们准备了强有力的矩阵运算工具。</p> 
<h2 id="4.4-矩阵运算例">4.4 矩阵运算例</h2> 
<p>        由于今天小A选择了RUN，所以今天的状态可以用向量表示为(参考上面的转移表，第一行表示SLEEP, 第二行表示RUN, 第三行表示ICECREAM)：</p> 
<p>        <img alt="S_0 = [s_{00}, s_{01}, s_{02}]^T = [0, 1, 0]^T" class="mathcode" src="https://images2.imgbox.com/27/07/Tlym5A88_o.gif"></p> 
<p>        注意，T放在左上标表示转置，下面我们用P表示转置矩阵。</p> 
<p>        明天的状态向量可以由状态转移矩阵的转置左乘今天的状态向量运算而得，如下所示(我们状态向量是列向量，要注意以下矩阵运算中的形状匹配)：</p> 
<p>        <img alt="S_1 = left[ {begin{array}{c} s_{11}\ s_{12}\ s_{13}\ end{array} } right] = left[ {begin{array}{ccc} p_{11} &amp; p_{12} &amp; p_{13}\ p_{21} &amp; p_{22} &amp; p_{23}\ p_{31} &amp; p_{32} &amp; p_{33}\ end{array} } right]^T cdot left[ {begin{array}{c} s_{01} \ s_{02} \ s_{03}\ end{array} } right] = P^T cdot S_0" class="mathcode" src="https://images2.imgbox.com/15/05/gGA7qSOR_o.gif"></p> 
<p></p> 
<p>        同理，我们可得，后天的状态向量可以如下计算而得：</p> 
<p>        <img alt="S_2 = P^T cdot S_1 = (P^T)^2 cdot S_0" class="mathcode" src="https://images2.imgbox.com/c7/66/olNh9CQZ_o.gif"></p> 
<p>        将转移概率矩阵和今天的初始向量代入则可以得到后天的状态向量为：</p> 
<p>        <img alt="S_2 = left[ {begin{array}{ccc} 0.2 &amp; 0.6 &amp; 0.2\ 0.1 &amp; 0.6 &amp; 0.3\ 0.2 &amp; 0.7 &amp; 0.1\ end{array} } right]^2 cdot left[ {begin{array}{c} 0\ 1\ 0\ end{array} } right]" class="mathcode" src="https://images2.imgbox.com/1c/34/faUgVgoV_o.gif"></p> 
<p>        看上去这个运算比上面的手算还要可怕得多，是不是？如果继续手动计算的话，确实，这样用矩阵的方式计算未必有什么好处。幸运的是，计算机程序非常擅长于这种矩阵运算。比如说，上面的这个计算我们可以调用python中专司矩阵运算的numpy库用以下一小段代码来实现（注意，矩阵的乘法用@，而不是*!）.</p> 
<pre><code class="language-python">import numpy as np

P = np.array([[0.2,0.6,0.2],[0.1,0.6,0.3],[0.2,0.7,0.1]])
S0 = np.array([[0],[1],[0]])
S2 = P.T@P.T@S0
S2</code></pre> 
<pre>array([[0.14],
       [0.63],
       [0.23]])</pre> 
<p>        由计算结果可得，S2的第2个元素值为0.63，它就是表示在后天小A选择RUN的概率，与上面手算的结果一致。这个运算还顺便把后天选择ICECRAM和SLEEP的概率也一并计算了！当我们要进行更多的计算，甚至进行理论的推演时，矩阵形式的运算就不仅仅是提高效率，而是必须的了。</p> 
<p>        注意，以上由于我们把状态转移概率矩阵表达成右随机矩阵（即每行之和为1），所以运算中要使用它的转置。事实上我们也可以一开始就将状态转移概率矩阵表达成左随机矩阵（即每列之和为1），这样的话，就不必用转置符号了.但是这些都只是表达形式的细节差异而已，只是convention的问题，只要保持前后一致即可。</p> 
<p>        本节我们只是用python numpy小试牛刀地做了个马尔科夫链的状态变化的计算，下一章我们将基于python做一个完整的马尔科夫链的实现例，并基于程序实验探索马尔科夫链的更多性质。</p> 
<p> </p> 
<h1 id="5.-马尔科夫链蒙特卡洛仿真">5. 马尔科夫链蒙特卡洛仿真</h1> 
<p>        已经有很多非常棒的开源马尔可夫链实现库，所以如果你是在做一个开发项目的话那你应该去选择一个好用的开源库。但是，自己动手代码实现毫无疑问是你获得对马尔科夫链的直观理解的必要的一个步骤。</p> 
<h2 id="5.1%20Python%20modelling">5.1 Python modelling</h2> 
<p>        首先，定义状态states以及他们的转移概率矩阵。由于我们有3个状态，所以状态转移矩阵transitionMatrix为3乘以3的方阵。transitionName表示状态转移路径，对应于状态转移图中的有向edge，比如说，SS表示从SLEEP状态到SLEEP状态的转移，IR表示从ICECREAM到RUN的转移。</p> 
<p>        最后一条语句用于检查transitionMatrix是否是一个有效的状态转移矩阵（右随机矩阵，各行之和等于1）</p> 
<pre><code class="language-python">import numpy as np
import random as rm

# The statespace
states = ["Sleep","Icecream","Run"]

# Possible sequences of events
transitionName = [["SS","SR","SI"],["RS","RR","RI"],["IS","IR","II"]]

# Probabilities matrix (transition matrix)
transitionMatrix = [[0.2,0.6,0.2],[0.1,0.6,0.3],[0.2,0.7,0.1]]

# make sure the probabilities sum up to 1.
if sum(transitionMatrix[0])+sum(transitionMatrix[1])+sum(transitionMatrix[1]) != 3:
    print("Somewhere, something went wrong. Transition matrix, perhaps?")
else: print("All is gonna be okay, you should move on!! ;)")</code></pre> 
<p>        以下我们定义一个函数，用于从指定的初始状态，经过指定的若干天，计算某一个可能的状态转移序列，并相应地给出它所对应的概率。在以下实现中，在每一步（每一天），基于今天的状态(今天所选择的activity)以及状态转移概率矩阵通过随机采样的方式决定明天的选择。这个随机采样是通过调用np.random.choice()函数来实现的，该函数第一个参数指定可选择项列表，第三个参数指定对应各个选项的选择概率。</p> 
<p>        这个函数其实就是对我们所定义的马尔科夫链的蒙特卡洛仿真的一个engine。</p> 
<pre><code class="language-python"># A function that implements the Markov model to forecast the state/mood.
def activity_sequence_forecast(activityToday, days):
    #print("Start state: " + activityToday)
    # Shall store the sequence of states taken. So, this only has the starting state for now.
    activityList = [activityToday]
    i = 0
    # To calculate the probability of the activityList
    prob = 1
    while i != days:
        if activityToday == "Sleep":
            change = np.random.choice(transitionName[0],replace=True,p=transitionMatrix[0])
            if change == "SS":
                prob = prob * transitionMatrix[0][0]
                activityList.append("Sleep")
                pass
            elif change == "SR":
                prob = prob * transitionMatrix[0][1]
                activityToday = "Run"
                activityList.append("Run")
            else:
                prob = prob * transitionMatrix[0][2]
                activityToday = "Icecream"
                activityList.append("Icecream")
        elif activityToday == "Run":
            change = np.random.choice(transitionName[1],replace=True,p=transitionMatrix[1])
            if change == "RR":
                prob = prob * transitionMatrix[1][1]
                activityList.append("Run")
                pass
            elif change == "RS":
                prob = prob * transitionMatrix[1][0]
                activityToday = "Sleep"
                activityList.append("Sleep")
            else:
                prob = prob * transitionMatrix[1][2]
                activityToday = "Icecream"
                activityList.append("Icecream")
        elif activityToday == "Icecream":
            change = np.random.choice(transitionName[2],replace=True,p=transitionMatrix[2])
            if change == "II":
                prob = prob * transitionMatrix[2][2]
                activityList.append("Icecream")
                pass
            elif change == "IS":
                prob = prob * transitionMatrix[2][0]
                activityToday = "Sleep"
                activityList.append("Sleep")
            else:
                prob = prob * transitionMatrix[0][1]
                activityToday = "Run"
                activityList.append("Run")
        i += 1  
    return activityList, prob</code></pre> 
<h2 id="5.2%20The%20first%20trial">5.2 The first trial</h2> 
<p>        先做一个试运行：</p> 
<pre><code class="language-python"># First trial simulation.
# 由于是蒙特卡洛仿真，每次调用函数所返回的结果并不是确定性的。
startState = "Run"
activityList, prob = activity_sequence_forecast(startState,2)
print("One possible state transition sequence: {0}, with probability = {1:2.2f}".format(str(activityList),prob))
activityList, prob = activity_sequence_forecast(startState,2)
print("One possible state transition sequence: {0}, with probability = {1:2.2f}".format(str(activityList),prob))
activityList, prob = activity_sequence_forecast(startState,2)
print("One possible state transition sequence: {0}, with probability = {1:2.2f}".format(str(activityList),prob))
activityList, prob = activity_sequence_forecast(startState,2)
print("One possible state transition sequence: {0}, with probability = {1:2.2f}".format(str(activityList),prob))</code></pre> 
<p><img alt="" height="115" src="https://images2.imgbox.com/5e/39/w7vK0wwi_o.png" width="1146"></p> 
<p>         如上所示，以上每次调用产生一个可能的序列及其相应的概率，并没有直接给出比如说从今天的RUN出发两天后选择RUN的概率。但是通过调用足够多次然后进行统计就可以得到一个足够好的统计近似值，其中，每次调用相当于是一次采样。</p> 
<h2 id="5.3%20%E8%92%99%E7%89%B9%E5%8D%A1%E6%B4%9B%E4%BB%BF%E7%9C%9F">5.3 蒙特卡洛仿真</h2> 
<pre><code class="language-python"># To save every activityList
list_activity = []

# iterate for many times to perform the sampling
for iterations in range(1,10000):
    initState = np.random.choice(states,replace=True,p=[1/3,1/3,1/3]) # Select the init state with equal probability
    list_activity.append(activity_sequence_forecast(initState,2))

# Check out all the `activityList` we collected    
#print(list_activity)

# Iterate through the list to get a count of all activities ending in state:'Run'
cnt_start_from_RUN = 0
cnt_start_from_RUN_and_end_at_RUN= 0
for (activityList, prob) in list_activity:
    if activityList[0] == "Run":
        cnt_start_from_RUN += 1
        if activityList[2] == "Run":
            cnt_start_from_RUN_and_end_at_RUN += 1

# Calculate the probability of starting from state:'Sleep' and ending at state:'Run'
percentage = (cnt_start_from_RUN_and_end_at_RUN/cnt_start_from_RUN) * 100
print("The probability of starting at state:'Run' and ending at state:'Run'= " + str(percentage) + "%")</code></pre> 
<pre>The probability of starting at state:'Run' and ending at state:'Run'= 63.175074183976264%</pre> 
<p>        基于蒙特卡洛仿真我们得到从RUN出发经过2步（天）到达RUN状态的概率约为63%，与上一章我们的理论推算值基本一致。如果仿真的次数继续增加，仿真估计值与真实值的差异会进一步减小。这是大数定律发挥威力的地方。</p> 
<p>        当然，以上仿真中事实上不仅仅计算了从RUN出发经过2步（天）到达RUN状态的概率，而是从任意状态S0出发经过2天到达任意状态S2的概率。进一步，我们可以把步数也参数，这样我们就可以通过蒙特卡洛仿真得出“从任意状态S0出发经过K天到达任意状态Sk”的概率。在此基础上我们还可以做更多的有趣的实验。这些就留给感兴趣的小伙伴自行实验。</p> 
<p></p> 
<p>Reference</p> 
<p>[1] <a href="https://www.datacamp.com/community/tutorials/markov-chains-python-tutorial" title="https://www.datacamp.com/community/tutorials/markov-chains-python-tutorial">https://www.datacamp.com/community/tutorials/markov-chains-python-tutorial</a></p> 
<p>[2] <a href="https://baike.baidu.com/item/%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E9%93%BE/6171383" title="马尔可夫链_百度百科">马尔可夫链_百度百科</a></p>
                </div>

		</div>
	</article>
</main>




			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程小白.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://www.w3counter.com/tracker.js?id=150625"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>
	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>