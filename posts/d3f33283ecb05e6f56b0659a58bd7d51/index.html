<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<title>基于CNN-RNN的医疗文本生成 - 编程小白</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程小白" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程小白</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">基于CNN-RNN的医疗文本生成</h1>
			
		</header>
		<div class="content post__content clearfix">
			


                <div id="content_views" class="markdown_views prism-atom-one-dark">
                    
                        
                    
                    <h1>
<a id="_CNNRNN_0"></a>? 基于CNN-RNN的医疗文本生成</h1> 
<p>本项目使用经过IMAGENET预训练的resnet101网络对图像特征进行提取后，<br> 将图像特征输入LSTM来生成影像的文本描述。</p> 
<p>初步实现了图像到文本的简单生成。</p> 
<hr> 
<h2>
<a id="__0__9"></a>? 0 项目背景</h2> 
<font size="3" face="仿宋"> </font>
<p>随着近年来深度学习的飞速发展，深度学习在医疗行业展现出巨大的发展潜力。因此，如果能通过深度学习的方法，使用计算机代替医生进行机械的影像报告撰写工作，这样既避免了经验不足的医生在阅片诊断中产生的误诊情况，又使得更多的资深医生可以从繁重的重复性工作中解脱出来，将更多的时间投入病人的诊治中去。</p> 
<p>医学影像报告自动生成是近年来计算机与医疗图像新兴的交叉方向之一。目前，影像报告自动生成模型主要借鉴了机器翻译领域的 Encoder-Decoder 框架，利用卷积<br> 神经网络（Convolutional Neural Network, CNN）对图像特征进行提取进而利用循环神经网络（Recurrent Neural Network, RNN）来生成影像的文本描述</p> 
<h2>
<a id="__1__21"></a>? 1 数据集</h2> 
<font size="3" face="仿宋"> </font>
<p>印第安纳大学胸部 X 射线集合 (IU X 射线) 是一组胸部 X 射线图像及其相应的诊断报告。该数据集包含 7,470 对图像和报告（6470：500：500）。 每个报告由以下部分组成：印象、发现、标签、比较和指示。平均每张图像关联2.2个标签，5.7个句子，每个句子包含6.5个单词。</p> 
<p><img src="https://images2.imgbox.com/b2/98/DbvFE7SL_o.png" alt=""></p> 
<blockquote> 
 <p>本项目仅使用FINDINGS部分作为图像生成标签</p> 
</blockquote> 
<p>参考代码：</p> 
<ul><li>https://github.com/chenyuntc/pytorch-book/tree/master/chapter10-image_caption</li></ul> 
<h2>
<a id="_2__37"></a>? 2 数据集生成</h2> 
<h3>
<a id="_21__CSV_39"></a>? 2.1 医疗文本CSV生成</h3> 
<hr> 
<font size="3" face="仿宋"> </font>
<p>解压原始数据，对xml格式的数据进行解析，提取图像文件名和对应的FINDINGS，并生成CSV文件。</p> 
<pre><code class="prism language-python"><span class="token comment"># 解压数据集</span>
!unzip  <span class="token operator">-</span>o  data<span class="token operator">/</span>data123482<span class="token operator">/</span>IU数据集<span class="token punctuation">.</span><span class="token builtin">zip</span> <span class="token operator">-</span>d <span class="token operator">/</span>home<span class="token operator">/</span>aistudio<span class="token operator">/</span>work<span class="token operator">/</span>
</code></pre> 
<pre><code>  inflating: /home/aistudio/work/IU数据集/NLMCXR_reports/ecgen-radiology/1504.xml  
</code></pre> 
<pre><code class="prism language-python"><span class="token comment"># 取消警告的输出</span>
<span class="token keyword">import</span> warnings
warnings<span class="token punctuation">.</span>filterwarnings<span class="token punctuation">(</span><span class="token string">"ignore"</span><span class="token punctuation">)</span>
</code></pre> 
<pre><code class="prism language-python"><span class="token comment">## 制作CSV数据集</span>
<span class="token comment"># 平均字符数为 31.64992700729927</span>
<span class="token keyword">import</span> os
<span class="token keyword">import</span> glob
<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd
<span class="token keyword">from</span> xml<span class="token punctuation">.</span>dom <span class="token keyword">import</span> minidom
<span class="token keyword">import</span> re
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
LENGTH <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>

<span class="token keyword">def</span> <span class="token function">EmptyDrop</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">if</span> data<span class="token punctuation">.</span>loc<span class="token punctuation">[</span>i<span class="token punctuation">,</span><span class="token string">'dir'</span><span class="token punctuation">]</span> <span class="token operator">==</span><span class="token punctuation">[</span><span class="token punctuation">]</span> <span class="token keyword">or</span> data<span class="token punctuation">.</span>loc<span class="token punctuation">[</span>i<span class="token punctuation">,</span><span class="token string">'caption'</span><span class="token punctuation">]</span> <span class="token operator">==</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">:</span>
            <span class="token comment">#如果为空，则删除该行</span>
            data<span class="token punctuation">.</span>drop<span class="token punctuation">(</span><span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span>axis <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">,</span>inplace <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span> 
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            data<span class="token punctuation">.</span>loc<span class="token punctuation">[</span>i<span class="token punctuation">,</span><span class="token string">'dir'</span><span class="token punctuation">]</span> <span class="token operator">=</span> data<span class="token punctuation">.</span>loc<span class="token punctuation">[</span>i<span class="token punctuation">,</span><span class="token string">'dir'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
            data<span class="token punctuation">.</span>loc<span class="token punctuation">[</span>i<span class="token punctuation">,</span><span class="token string">'caption'</span><span class="token punctuation">]</span> <span class="token operator">=</span> data<span class="token punctuation">.</span>loc<span class="token punctuation">[</span>i<span class="token punctuation">,</span><span class="token string">'caption'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
    data<span class="token punctuation">.</span>reset_index<span class="token punctuation">(</span>drop <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">,</span>inplace <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> data

<span class="token keyword">def</span> <span class="token function">clean_text</span><span class="token punctuation">(</span>origin_text<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># 去掉标点和非法字符</span>
    text <span class="token operator">=</span> re<span class="token punctuation">.</span>sub<span class="token punctuation">(</span><span class="token string">"^a-zA-Z"</span><span class="token punctuation">,</span><span class="token string">" "</span><span class="token punctuation">,</span>origin_text<span class="token punctuation">)</span>
    <span class="token comment">#大写改小写</span>
    cleaned_text <span class="token operator">=</span> text<span class="token punctuation">.</span>lower<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> cleaned_text
<span class="token keyword">def</span> <span class="token function">xml2csv</span><span class="token punctuation">(</span>path<span class="token punctuation">)</span><span class="token punctuation">:</span>
    num <span class="token operator">=</span> <span class="token number">0</span>
    column_name <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'dir'</span><span class="token punctuation">,</span><span class="token string">'caption'</span><span class="token punctuation">]</span>
    xml_csv <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>columns <span class="token operator">=</span> column_name<span class="token punctuation">)</span>
    <span class="token comment">#图片保存地址</span>
    pic_path <span class="token operator">=</span>  <span class="token string">'work/IU数据集/NLMCXR_png'</span>
    <span class="token keyword">for</span> xml_file <span class="token keyword">in</span> glob<span class="token punctuation">.</span>glob<span class="token punctuation">(</span>path<span class="token operator">+</span><span class="token string">'/*.xml'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>

        <span class="token comment">#记录每个xml需要保存的所有信息 fx 地址 IMPRESSION FINDINGS </span>
        xml_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        <span class="token comment">#打开xml文档</span>
        dom <span class="token operator">=</span> minidom<span class="token punctuation">.</span>parse<span class="token punctuation">(</span>xml_file<span class="token punctuation">)</span>
        <span class="token comment">#得到文档元素对象</span>
        root <span class="token operator">=</span> dom<span class="token punctuation">.</span>documentElement
        <span class="token comment"># f1 地址</span>
        itemlists<span class="token operator">=</span>root<span class="token punctuation">.</span>getElementsByTagName<span class="token punctuation">(</span><span class="token string">'parentImage'</span><span class="token punctuation">)</span>
        <span class="token comment">#记录地址</span>
        dirAll <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        <span class="token keyword">for</span> itemlist <span class="token keyword">in</span> itemlists<span class="token punctuation">:</span>
            figureId<span class="token operator">=</span>itemlist<span class="token punctuation">.</span>getElementsByTagName<span class="token punctuation">(</span><span class="token string">'figureId'</span><span class="token punctuation">)</span>
            <span class="token comment">#找出该图片的figureID</span>
            figure <span class="token operator">=</span> figureId<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>childNodes<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>nodeValue
            <span class="token comment">#找出该图片的名称</span>
            ID<span class="token operator">=</span> itemlist<span class="token punctuation">.</span>getAttribute<span class="token punctuation">(</span><span class="token string">'id'</span><span class="token punctuation">)</span>
            IdPath <span class="token operator">=</span> ID
            <span class="token comment">#正面图&amp;侧面图</span>
            figurePath <span class="token operator">=</span> <span class="token punctuation">[</span>figure<span class="token operator">+</span><span class="token string">' '</span><span class="token operator">+</span>IdPath<span class="token punctuation">]</span>
            dirAll<span class="token punctuation">.</span>extend<span class="token punctuation">(</span>figurePath<span class="token punctuation">)</span>
        xml_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>dirAll<span class="token punctuation">)</span>

        <span class="token comment">#记录FINDINGS and IMPRESSION</span>
        <span class="token comment">#记录内容</span>
        CaptionAll <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        itemlists<span class="token operator">=</span>root<span class="token punctuation">.</span>getElementsByTagName<span class="token punctuation">(</span><span class="token string">'AbstractText'</span><span class="token punctuation">)</span>
        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>itemlists<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            Label<span class="token operator">=</span> itemlists<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">.</span>getAttribute<span class="token punctuation">(</span><span class="token string">'Label'</span><span class="token punctuation">)</span>
            <span class="token keyword">if</span> Label <span class="token operator">==</span> <span class="token string">'FINDINGS'</span><span class="token punctuation">:</span> <span class="token comment"># or Label == 'IMPRESSION':</span>
                <span class="token comment"># 内容不为空</span>
                <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>itemlists<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">.</span>childNodes<span class="token punctuation">)</span><span class="token operator">!=</span><span class="token number">0</span><span class="token punctuation">:</span>
                    text <span class="token operator">=</span> itemlists<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">.</span>childNodes<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>nodeValue
                    <span class="token comment">#转小写,过滤无效字符</span>
                    text <span class="token operator">=</span> clean_text<span class="token punctuation">(</span>text<span class="token punctuation">)</span>
                    text <span class="token operator">=</span> text<span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">'.'</span><span class="token punctuation">,</span><span class="token string">''</span><span class="token punctuation">)</span>
                    text <span class="token operator">=</span> text<span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">','</span><span class="token punctuation">,</span><span class="token string">''</span><span class="token punctuation">)</span>
                    text <span class="token operator">=</span> <span class="token punctuation">[</span>text<span class="token operator">+</span><span class="token string">''</span><span class="token punctuation">]</span>                    
                    CaptionAll<span class="token punctuation">.</span>extend<span class="token punctuation">(</span>text<span class="token punctuation">)</span>
        <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>CaptionAll<span class="token punctuation">)</span><span class="token operator">&gt;=</span><span class="token number">1</span><span class="token punctuation">:</span>
            LENGTH<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>CaptionAll<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">' '</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        xml_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>CaptionAll<span class="token punctuation">)</span>
        xml_csv<span class="token punctuation">.</span>loc<span class="token punctuation">[</span>num<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">[</span>item <span class="token keyword">for</span> item <span class="token keyword">in</span> xml_list<span class="token punctuation">]</span>
        num <span class="token operator">=</span> num <span class="token operator">+</span> <span class="token number">1</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'epoch[{}/{}]'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>num<span class="token punctuation">,</span><span class="token builtin">len</span><span class="token punctuation">(</span>glob<span class="token punctuation">.</span>glob<span class="token punctuation">(</span>path<span class="token operator">+</span><span class="token string">'/*.xml'</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
   <span class="token comment"># print(np.mean(LENGTH))</span>
    <span class="token keyword">return</span> xml_csv

<span class="token keyword">def</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    xml_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token string">'work'</span><span class="token punctuation">,</span><span class="token string">'IU数据集'</span><span class="token punctuation">,</span><span class="token string">'NLMCXR_reports'</span><span class="token punctuation">,</span><span class="token string">'ecgen-radiology'</span><span class="token punctuation">)</span>
    csv <span class="token operator">=</span> xml2csv<span class="token punctuation">(</span>xml_path<span class="token punctuation">)</span>
    csv1 <span class="token operator">=</span> EmptyDrop<span class="token punctuation">(</span>csv<span class="token punctuation">)</span>
    csv1<span class="token punctuation">.</span>to_csv<span class="token punctuation">(</span><span class="token string">'work/IUxRay.csv'</span><span class="token punctuation">,</span>index<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span>
    
<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>
    main<span class="token punctuation">(</span><span class="token punctuation">)</span>

</code></pre> 
<h3>
<a id="_22__158"></a>? 2.2 图像特征提取</h3> 
<hr> 
<font size="3" face="仿宋"> </font>
<ul>
<li> <p>使用ImageNet预训练的resnet101模型提取图像特征（删除最后的全连接层，改为恒等映射）。</p> </li>
<li> <p>将数据保存为h5文件</p> </li>
</ul> 
<pre><code class="prism language-python"><span class="token comment">## 使用resnet101预训练模型提取图像特征</span>
<span class="token keyword">import</span> paddle
<span class="token keyword">from</span> paddle<span class="token punctuation">.</span>vision<span class="token punctuation">.</span>models <span class="token keyword">import</span> resnet101
<span class="token keyword">import</span> h5py
<span class="token keyword">import</span> cv2

csv_file <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">'work/IUxRay.csv'</span><span class="token punctuation">)</span>
h5_png_file <span class="token operator">=</span><span class="token builtin">list</span><span class="token punctuation">(</span>csv_file<span class="token punctuation">[</span><span class="token string">'dir'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token comment"># 创建保存目录</span>
save_path <span class="token operator">=</span> <span class="token string">'work/util_IUxRay'</span>
<span class="token keyword">if</span> <span class="token keyword">not</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>exists<span class="token punctuation">(</span>save_path<span class="token punctuation">)</span><span class="token punctuation">:</span>
    os<span class="token punctuation">.</span>makedirs<span class="token punctuation">(</span>save_path<span class="token punctuation">)</span>

<span class="token comment"># 导入模型resnet101 使用谷歌预训练</span>
model <span class="token operator">=</span> resnet101<span class="token punctuation">(</span>pretrained<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
<span class="token comment"># 删除最后的全连接层</span>
<span class="token keyword">del</span> model<span class="token punctuation">.</span>fc
model<span class="token punctuation">.</span>fc <span class="token operator">=</span> <span class="token keyword">lambda</span> x<span class="token punctuation">:</span>x

h5f <span class="token operator">=</span> h5py<span class="token punctuation">.</span>File<span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>save_path<span class="token punctuation">,</span><span class="token string">'resnet101_festures.h5'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'w'</span><span class="token punctuation">)</span>

<span class="token keyword">for</span> idx<span class="token punctuation">,</span>item <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>h5_png_file<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># 读取所有PNG（F1,F2...）</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>idx<span class="token punctuation">,</span><span class="token builtin">len</span><span class="token punctuation">(</span>h5_png_file<span class="token punctuation">)</span><span class="token punctuation">)</span>
    item_all <span class="token operator">=</span> item<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">','</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> item_t <span class="token keyword">in</span> item_all<span class="token punctuation">:</span>
        item_t <span class="token operator">=</span> item_t<span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">'''</span><span class="token punctuation">,</span><span class="token string">''</span><span class="token punctuation">)</span><span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">'['</span><span class="token punctuation">,</span><span class="token string">''</span><span class="token punctuation">)</span><span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">']'</span><span class="token punctuation">,</span><span class="token string">''</span><span class="token punctuation">)</span>
        <span class="token comment"># 对不同朝向的图进行区分</span>
        <span class="token keyword">for</span> orie <span class="token keyword">in</span> <span class="token punctuation">[</span><span class="token string">'F1'</span><span class="token punctuation">,</span><span class="token string">'F2'</span><span class="token punctuation">,</span><span class="token string">'F3'</span><span class="token punctuation">,</span><span class="token string">'F4'</span><span class="token punctuation">]</span><span class="token punctuation">:</span>
            <span class="token keyword">if</span> orie <span class="token keyword">in</span> item_t<span class="token punctuation">:</span>
                orie_fin <span class="token operator">=</span> orie
                item_fin <span class="token operator">=</span> item_t<span class="token punctuation">.</span>replace<span class="token punctuation">(</span>orie<span class="token punctuation">,</span><span class="token string">''</span><span class="token punctuation">)</span><span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">' '</span><span class="token punctuation">,</span><span class="token string">''</span><span class="token punctuation">)</span>
                item_fin_png <span class="token operator">=</span> item_fin <span class="token operator">+</span> <span class="token string">'.png'</span>
                <span class="token keyword">print</span><span class="token punctuation">(</span>orie_fin <span class="token operator">+</span> <span class="token string">'_'</span> <span class="token operator">+</span> item_fin<span class="token punctuation">)</span>
                <span class="token comment"># 读取文件送入模型提取特征并保存为h5</span>
                img <span class="token operator">=</span> cv2<span class="token punctuation">.</span>imread<span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token string">'work/IU数据集/NLMCXR_png'</span><span class="token punctuation">,</span>item_fin_png<span class="token punctuation">)</span><span class="token punctuation">)</span>
                <span class="token comment"># BGR转RGB，且HWC转CHW</span>
                img <span class="token operator">=</span> img<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
                <span class="token comment"># 扩展维度</span>
                img <span class="token operator">=</span> np<span class="token punctuation">.</span>expand_dims<span class="token punctuation">(</span>img<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span>
                img_tensor <span class="token operator">=</span> paddle<span class="token punctuation">.</span>to_tensor<span class="token punctuation">(</span>img<span class="token punctuation">,</span>dtype<span class="token operator">=</span><span class="token string">'float32'</span> <span class="token punctuation">,</span>place<span class="token operator">=</span>paddle<span class="token punctuation">.</span>CPUPlace<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
                <span class="token comment"># 进行特征提取</span>
                out <span class="token operator">=</span> model<span class="token punctuation">(</span>img_tensor<span class="token punctuation">)</span>
                data <span class="token operator">=</span> out<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>astype<span class="token punctuation">(</span><span class="token string">'float32'</span><span class="token punctuation">)</span>
                <span class="token comment"># 保存的数据为h5</span>
                save_path_h5 <span class="token operator">=</span> data<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
                h5f<span class="token punctuation">.</span>create_dataset<span class="token punctuation">(</span>orie_fin <span class="token operator">+</span> <span class="token string">'_'</span> <span class="token operator">+</span> item_fin<span class="token punctuation">,</span> data<span class="token operator">=</span>save_path_h5<span class="token punctuation">)</span>
h5f<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>

</code></pre> 
<pre><code class="prism language-python"><span class="token comment"># 读取h5文件</span>
<span class="token keyword">import</span> h5py
h5f <span class="token operator">=</span> h5py<span class="token punctuation">.</span>File<span class="token punctuation">(</span><span class="token string">'work/util_IUxRay/resnet101_festures.h5'</span><span class="token punctuation">,</span><span class="token string">'r'</span><span class="token punctuation">)</span>
data <span class="token operator">=</span> h5f<span class="token punctuation">[</span><span class="token string">'F1_CXR3027_IM-1402-1001'</span><span class="token punctuation">]</span> <span class="token comment"># 第一个下划线 之前为图片朝向，之后为图像原命名</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>data<span class="token punctuation">)</span><span class="token punctuation">.</span>shape<span class="token punctuation">)</span> <span class="token comment"># 每个图片保存为一个2048维度的向量</span>
h5f<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span> 
</code></pre> 
<h3>
<a id="_23__233"></a>? 2.3 字典生成</h3> 
<hr> 
<font size="3" face="仿宋"> </font>
<ul>
<li> <p>统计训练数据，按照单词进行分割创建字典。</p> </li>
<li> <p>字典修正：删除仅在数据集中出现过一次的单词</p> </li>
</ul> 
<pre><code class="prism language-python"><span class="token comment"># 统计训练数据，以单词为粒度创建字典</span>
<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> re

csv_file <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">'work/IUxRay.csv'</span><span class="token punctuation">)</span>
csv_file<span class="token punctuation">.</span>head<span class="token punctuation">(</span><span class="token punctuation">)</span>

CaptionWordAll <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
CaptionWordLength <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
<span class="token keyword">for</span> idx<span class="token punctuation">,</span>data_ <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>csv_file<span class="token punctuation">.</span>iterrows<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    caption <span class="token operator">=</span> data_<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>
    CaptionWordLength<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>caption<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">' '</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    CaptionWordAll<span class="token punctuation">.</span>extend<span class="token punctuation">(</span>caption<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">' '</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'平均句子长度为：'</span><span class="token punctuation">,</span>np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>CaptionWordLength<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'最大句子长度为：'</span><span class="token punctuation">,</span>np<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>CaptionWordLength<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'最小句子长度为：'</span><span class="token punctuation">,</span>np<span class="token punctuation">.</span><span class="token builtin">min</span><span class="token punctuation">(</span>CaptionWordLength<span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'单词总量为：'</span><span class="token punctuation">,</span><span class="token builtin">len</span><span class="token punctuation">(</span>CaptionWordAll<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'字典长度为：'</span><span class="token punctuation">,</span><span class="token builtin">len</span><span class="token punctuation">(</span><span class="token builtin">set</span><span class="token punctuation">(</span>CaptionWordAll<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment"># 100</span>

<span class="token keyword">from</span> collections <span class="token keyword">import</span> Counter
<span class="token comment"># 统计频率，按照从高到底排序，这样构建的字典使用频率最高的符号在最前面，查找起来快</span>
counts <span class="token operator">=</span> Counter<span class="token punctuation">(</span>CaptionWordAll<span class="token punctuation">)</span>
count_sorted <span class="token operator">=</span> counts<span class="token punctuation">.</span>most_common<span class="token punctuation">(</span><span class="token punctuation">)</span>
count_sorted_ <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>k<span class="token punctuation">:</span> v <span class="token keyword">for</span> k<span class="token punctuation">,</span> v <span class="token keyword">in</span> count_sorted <span class="token keyword">if</span> v <span class="token operator">&gt;</span> <span class="token number">1</span><span class="token punctuation">}</span>

<span class="token comment"># 构造字典</span>
<span class="token comment"># 增加 &lt;pad&gt; 0 &lt;unk&gt; 1 &lt;start&gt; 2 &lt;end&gt; 3  四个作为常用符号</span>

word2id_dict<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token string">'&lt;pad&gt;'</span><span class="token punctuation">:</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token string">'&lt;unk&gt;'</span><span class="token punctuation">:</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token string">'&lt;start&gt;'</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token string">'&lt;end&gt;'</span><span class="token punctuation">:</span><span class="token number">3</span><span class="token punctuation">}</span>
id2word_dict<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token number">0</span><span class="token punctuation">:</span><span class="token string">'&lt;pad&gt;'</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token string">'&lt;unk&gt;'</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">:</span><span class="token string">'&lt;start&gt;'</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">:</span><span class="token string">'&lt;end&gt;'</span><span class="token punctuation">}</span>

<span class="token keyword">for</span> idx<span class="token punctuation">,</span>item <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>count_sorted_<span class="token punctuation">)</span><span class="token punctuation">:</span>
    idx_ <span class="token operator">=</span> idx<span class="token operator">+</span><span class="token number">4</span> <span class="token comment"># 预留四个做为记录</span>
    item_ <span class="token operator">=</span> item
    word2id_dict<span class="token punctuation">[</span>item_<span class="token punctuation">]</span> <span class="token operator">=</span> idx_
    id2word_dict<span class="token punctuation">[</span>idx_<span class="token punctuation">]</span> <span class="token operator">=</span> item_

<span class="token comment"># 删除只出现一次的单词</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'修正后字典长度为：'</span><span class="token punctuation">,</span><span class="token builtin">len</span><span class="token punctuation">(</span>word2id_dict<span class="token punctuation">)</span><span class="token punctuation">)</span>

</code></pre> 
<h2>
<a id="_3__293"></a>? 3 定义数据读取类</h2> 
<hr> 
<font size="3" face="仿宋"> </font>
<ul>
<li> <p>将数据按照8：2划分为训练集和验证集。</p> </li>
<li> <p>将文本数据经过字典进行映射，不同于翻译任务，本任务用图像特征替代了（85行）。</p> </li>
</ul> 
<pre><code class="prism language-python"><span class="token comment">## 完成dataload</span>

<span class="token keyword">import</span> paddle
<span class="token keyword">from</span> paddle<span class="token punctuation">.</span>io <span class="token keyword">import</span> Dataset
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> train_test_split

<span class="token comment"># 重写数据读取类</span>
<span class="token keyword">class</span> <span class="token class-name">CaptionDataset</span><span class="token punctuation">(</span>Dataset<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># 构造函数，定义函数参数</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>csvData<span class="token punctuation">,</span>word2id_dict<span class="token punctuation">,</span>h5f<span class="token punctuation">,</span>maxlength <span class="token operator">=</span> <span class="token number">40</span><span class="token punctuation">,</span>mode <span class="token operator">=</span> <span class="token string">'train'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>mode <span class="token operator">=</span> mode
        self<span class="token punctuation">.</span>w2i_dict <span class="token operator">=</span> word2id_dict
        self<span class="token punctuation">.</span>maxlength <span class="token operator">=</span> maxlength <span class="token comment"># 输入的最长字符数</span>
        self<span class="token punctuation">.</span>padid <span class="token operator">=</span> <span class="token number">0</span> <span class="token comment"># 0为填充符号</span>
        self<span class="token punctuation">.</span>h5f <span class="token operator">=</span> h5f
        <span class="token comment"># 根据train/test 将数据按比例处理</span>
        train<span class="token punctuation">,</span>test <span class="token operator">=</span>csvData<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token builtin">int</span><span class="token punctuation">(</span><span class="token number">0.8</span><span class="token operator">*</span><span class="token builtin">len</span><span class="token punctuation">(</span>csvData<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">,</span>csvData<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">(</span><span class="token number">0.8</span><span class="token operator">*</span><span class="token builtin">len</span><span class="token punctuation">(</span>csvData<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token comment">#train_test_split(csvData,train_size=0.8,random_state=10)</span>

        <span class="token keyword">if</span> self<span class="token punctuation">.</span>mode <span class="token operator">==</span> <span class="token string">'train'</span><span class="token punctuation">:</span>
            train<span class="token punctuation">.</span>reset_index<span class="token punctuation">(</span>drop<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
            self<span class="token punctuation">.</span>data <span class="token operator">=</span> train
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            test<span class="token punctuation">.</span>reset_index<span class="token punctuation">(</span>drop<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
            self<span class="token punctuation">.</span>data <span class="token operator">=</span> test

    <span class="token comment"># 实现__getitem__方法，定义指定index时如何获取数据，并返回单条数据（训练数据，对应的标签）</span>
    <span class="token keyword">def</span> <span class="token function">__getitem__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> index<span class="token punctuation">)</span><span class="token punctuation">:</span>

        path_name<span class="token punctuation">,</span> trg_  <span class="token operator">=</span> self<span class="token punctuation">.</span>data<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span>index<span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span>
        
        <span class="token comment"># 读取图像的特征</span>
        temp  <span class="token operator">=</span> path_name<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">' '</span><span class="token punctuation">)</span>
        names <span class="token operator">=</span> <span class="token string">'_'</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>temp<span class="token punctuation">)</span>
        img_feature <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>self<span class="token punctuation">.</span>h5f<span class="token punctuation">[</span>names<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment"># 第一个下划线 之前为图片朝向，之后为图像原命名</span>

        <span class="token comment"># 输入转成idx</span>
        trg<span class="token punctuation">,</span>trg_length <span class="token operator">=</span> self<span class="token punctuation">.</span>generIdxList<span class="token punctuation">(</span>trg_<span class="token punctuation">)</span> <span class="token comment"># data</span>
        img_name <span class="token operator">=</span> temp<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>
        <span class="token keyword">return</span> img_feature<span class="token punctuation">,</span>trg<span class="token punctuation">,</span>trg_length<span class="token punctuation">,</span>img_name

    <span class="token comment"># 实现__len__方法，返回数据集总数目</span>
    <span class="token keyword">def</span> <span class="token function">__len__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> <span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>data<span class="token punctuation">)</span>
    
    <span class="token keyword">def</span> <span class="token function">generIdxList</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>tdata<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 从输入的String中，生成idx的List</span>
        data <span class="token operator">=</span> tdata<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">' '</span><span class="token punctuation">)</span>
        data_out <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        <span class="token comment"># 限制长度，输入'&lt;start&gt;' 和 '&lt;end&gt;'</span>
        data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'&lt;start&gt;'</span><span class="token punctuation">]</span> <span class="token operator">+</span> data 
        
        <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span><span class="token operator">&gt;</span>self<span class="token punctuation">.</span>maxlength<span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">:</span>
            data <span class="token operator">=</span> data<span class="token punctuation">[</span><span class="token punctuation">:</span>self<span class="token punctuation">.</span>maxlength<span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token comment"># 留一个位置给'&lt;end&gt;</span>
            data <span class="token operator">=</span> data <span class="token operator">+</span> <span class="token punctuation">[</span><span class="token string">'&lt;end&gt;'</span><span class="token punctuation">]</span>

        <span class="token keyword">else</span><span class="token punctuation">:</span>
            <span class="token comment"># 占位符</span>
            occupy_ <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'&lt;pad&gt;'</span><span class="token punctuation">]</span> <span class="token operator">*</span> <span class="token punctuation">(</span>self<span class="token punctuation">.</span>maxlength <span class="token operator">-</span> <span class="token number">1</span> <span class="token operator">-</span> <span class="token builtin">len</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span><span class="token punctuation">)</span>
            data <span class="token operator">=</span> data <span class="token operator">+</span> <span class="token punctuation">[</span><span class="token string">'&lt;end&gt;'</span><span class="token punctuation">]</span>
            data <span class="token operator">=</span> data <span class="token operator">+</span> occupy_

        <span class="token comment"># word 2 index</span>
        <span class="token keyword">for</span> word <span class="token keyword">in</span> data<span class="token punctuation">:</span>

            <span class="token keyword">if</span> self<span class="token punctuation">.</span>w2i_dict<span class="token punctuation">.</span>get<span class="token punctuation">(</span>word<span class="token punctuation">)</span><span class="token operator">!=</span> <span class="token boolean">None</span><span class="token punctuation">:</span> <span class="token comment"># 能找到word</span>
                id_ <span class="token operator">=</span> self<span class="token punctuation">.</span>w2i_dict<span class="token punctuation">[</span>word<span class="token punctuation">]</span>
                data_out<span class="token punctuation">.</span>append<span class="token punctuation">(</span>id_<span class="token punctuation">)</span>
            <span class="token keyword">else</span><span class="token punctuation">:</span>
                id_ <span class="token operator">=</span> self<span class="token punctuation">.</span>w2i_dict<span class="token punctuation">[</span><span class="token string">'&lt;unk&gt;'</span><span class="token punctuation">]</span>
                data_out<span class="token punctuation">.</span>append<span class="token punctuation">(</span>id_<span class="token punctuation">)</span>

        length <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>data_out<span class="token punctuation">)</span><span class="token operator">-</span><span class="token number">1</span>

        <span class="token keyword">return</span> data_out<span class="token punctuation">,</span>length

<span class="token keyword">def</span> <span class="token function">stackInput</span><span class="token punctuation">(</span>inputs<span class="token punctuation">)</span><span class="token punctuation">:</span>

    img_features <span class="token operator">=</span> np<span class="token punctuation">.</span>stack<span class="token punctuation">(</span><span class="token punctuation">[</span>inputsub<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token keyword">for</span> inputsub <span class="token keyword">in</span> inputs<span class="token punctuation">]</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
    trg <span class="token operator">=</span> np<span class="token punctuation">.</span>stack<span class="token punctuation">(</span><span class="token punctuation">[</span>inputsub<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token keyword">for</span> inputsub <span class="token keyword">in</span> inputs<span class="token punctuation">]</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
    trg_length <span class="token operator">=</span> np<span class="token punctuation">.</span>stack<span class="token punctuation">(</span><span class="token punctuation">[</span>inputsub<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span> <span class="token keyword">for</span> inputsub <span class="token keyword">in</span> inputs<span class="token punctuation">]</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>


    trg_mask <span class="token operator">=</span><span class="token punctuation">(</span>trg<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token operator">!=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>astype<span class="token punctuation">(</span>paddle<span class="token punctuation">.</span>get_default_dtype<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    trg_ <span class="token operator">=</span> trg<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token comment"># 将start标记更改为 imgfeatures</span>
    <span class="token keyword">return</span> img_features<span class="token punctuation">,</span>trg_length<span class="token punctuation">,</span>trg_<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>trg<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">,</span>np<span class="token punctuation">.</span>newaxis<span class="token punctuation">]</span><span class="token punctuation">,</span>trg_mask
</code></pre> 
<pre><code class="prism language-python"><span class="token comment"># 测试数据读取</span>
<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> h5py
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> train_test_split
csvData <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">'work/IUxRay.csv'</span><span class="token punctuation">)</span>
h5f <span class="token operator">=</span> h5py<span class="token punctuation">.</span>File<span class="token punctuation">(</span><span class="token string">'work/util_IUxRay/resnet101_festures.h5'</span><span class="token punctuation">,</span><span class="token string">'r'</span><span class="token punctuation">)</span>

maxlength <span class="token operator">=</span> <span class="token number">40</span>

dataset<span class="token operator">=</span>CaptionDataset<span class="token punctuation">(</span>csvData<span class="token punctuation">,</span>word2id_dict<span class="token punctuation">,</span>h5f<span class="token punctuation">,</span>maxlength<span class="token punctuation">,</span><span class="token string">'train'</span><span class="token punctuation">)</span>
data_loader <span class="token operator">=</span> paddle<span class="token punctuation">.</span>io<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>dataset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>collate_fn <span class="token operator">=</span> stackInput<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>

<span class="token keyword">for</span> item <span class="token keyword">in</span> data_loader<span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>item<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shape<span class="token punctuation">,</span>item<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shape<span class="token punctuation">,</span>item<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shape<span class="token punctuation">,</span>item<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shape<span class="token punctuation">,</span>item<span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
    <span class="token keyword">break</span>
</code></pre> 
<h2>
<a id="_4__414"></a>? 4 定义模型</h2> 
<hr> 
<font size="3" face="仿宋"> </font>
<ul>
<li> <p>定义LSTM模型用于文本生成</p> </li>
<li> <p>定义beam search算法对生成结果进行优化</p> </li>
</ul> 
<pre><code class="prism language-python"><span class="token comment"># 定义模型</span>
<span class="token keyword">import</span> paddle<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn
<span class="token keyword">import</span> paddle
<span class="token keyword">class</span> <span class="token class-name">CaptionModel</span><span class="token punctuation">(</span>paddle<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Layer<span class="token punctuation">)</span><span class="token punctuation">:</span>

    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> vocab_size<span class="token punctuation">,</span>embedding_dim<span class="token punctuation">,</span>hidden_size<span class="token punctuation">,</span>num_layers<span class="token punctuation">,</span>word2id_dict<span class="token punctuation">,</span>id2word_dict<span class="token punctuation">)</span><span class="token punctuation">:</span>
        
        <span class="token builtin">super</span><span class="token punctuation">(</span>CaptionModel<span class="token punctuation">,</span>self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>hidden_size<span class="token operator">=</span>hidden_size
        self<span class="token punctuation">.</span>num_layers<span class="token operator">=</span>num_layers        
        self<span class="token punctuation">.</span>fc <span class="token operator">=</span> paddle<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">2048</span><span class="token punctuation">,</span>embedding_dim<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>embedding<span class="token operator">=</span>paddle<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Embedding<span class="token punctuation">(</span>vocab_size<span class="token punctuation">,</span>embedding_dim<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>rnn<span class="token operator">=</span>paddle<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>LSTM<span class="token punctuation">(</span>input_size<span class="token operator">=</span>embedding_dim<span class="token punctuation">,</span>
                                hidden_size<span class="token operator">=</span>hidden_size<span class="token punctuation">,</span>
                                num_layers<span class="token operator">=</span>num_layers<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>word2ix <span class="token operator">=</span> word2id_dict
        self<span class="token punctuation">.</span>ix2word <span class="token operator">=</span> id2word_dict
        self<span class="token punctuation">.</span>classifier <span class="token operator">=</span> paddle<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>hidden_size<span class="token punctuation">,</span>vocab_size<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>img_features<span class="token punctuation">,</span>trg<span class="token punctuation">,</span>trg_length<span class="token punctuation">)</span><span class="token punctuation">:</span>
        img_features <span class="token operator">=</span> paddle<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span>self<span class="token punctuation">.</span>fc<span class="token punctuation">(</span>img_features<span class="token punctuation">)</span><span class="token punctuation">,</span>axis <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">)</span>
        embeddings <span class="token operator">=</span> self<span class="token punctuation">.</span>embedding<span class="token punctuation">(</span>trg<span class="token punctuation">)</span>
        inputs <span class="token operator">=</span> paddle<span class="token punctuation">.</span>concat<span class="token punctuation">(</span><span class="token punctuation">[</span>img_features<span class="token punctuation">,</span>embeddings<span class="token punctuation">]</span><span class="token punctuation">,</span>axis <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">)</span>
        outputs<span class="token punctuation">,</span>state <span class="token operator">=</span> self<span class="token punctuation">.</span>rnn<span class="token punctuation">(</span>inputs<span class="token punctuation">,</span>sequence_length  <span class="token operator">=</span> trg_length<span class="token punctuation">)</span>
        predict <span class="token operator">=</span> self<span class="token punctuation">.</span>classifier<span class="token punctuation">(</span>outputs<span class="token punctuation">)</span>

        <span class="token keyword">return</span> predict

    <span class="token keyword">def</span> <span class="token function">generate</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> img_feat<span class="token punctuation">,</span> eos_token<span class="token operator">=</span><span class="token string">'&lt;end&gt;'</span><span class="token punctuation">,</span>
                 beam_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span>
                 max_caption_length<span class="token operator">=</span><span class="token number">40</span><span class="token punctuation">,</span>
                 length_normalization_factor<span class="token operator">=</span><span class="token number">0.0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""
        根据图片生成描述,主要是使用beam search算法以得到更好的描述
        """</span>
        cap_gen <span class="token operator">=</span> CaptionGenerator<span class="token punctuation">(</span>embedder<span class="token operator">=</span>self<span class="token punctuation">.</span>embedding<span class="token punctuation">,</span>
                                   rnn<span class="token operator">=</span>self<span class="token punctuation">.</span>rnn<span class="token punctuation">,</span>
                                   classifier<span class="token operator">=</span>self<span class="token punctuation">.</span>classifier<span class="token punctuation">,</span>
                                   eos_id<span class="token operator">=</span>self<span class="token punctuation">.</span>word2ix<span class="token punctuation">[</span>eos_token<span class="token punctuation">]</span><span class="token punctuation">,</span>
                                   beam_size<span class="token operator">=</span>beam_size<span class="token punctuation">,</span>
                                   max_caption_length<span class="token operator">=</span>max_caption_length<span class="token punctuation">,</span>
                                   length_normalization_factor<span class="token operator">=</span>length_normalization_factor<span class="token punctuation">)</span>

        img_feat <span class="token operator">=</span> paddle<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span>img_feat<span class="token punctuation">,</span>axis <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">)</span>
        img <span class="token operator">=</span> paddle<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span>self<span class="token punctuation">.</span>fc<span class="token punctuation">(</span>img_feat<span class="token punctuation">)</span><span class="token punctuation">,</span>axis <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">)</span>

        sentences<span class="token punctuation">,</span> score <span class="token operator">=</span> cap_gen<span class="token punctuation">.</span>beam_search<span class="token punctuation">(</span>img<span class="token punctuation">)</span>

        sentences <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">' '</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token punctuation">[</span>self<span class="token punctuation">.</span>ix2word<span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">(</span>idx<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token keyword">for</span> idx <span class="token keyword">in</span> sent<span class="token punctuation">]</span><span class="token punctuation">)</span>
                     <span class="token keyword">for</span> sent <span class="token keyword">in</span> sentences<span class="token punctuation">]</span>
        <span class="token keyword">return</span> sentences
</code></pre> 
<pre><code class="prism language-python"><span class="token comment"># Beam Search</span>
<span class="token keyword">import</span> paddle<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn
<span class="token keyword">import</span> heapq

<span class="token keyword">class</span> <span class="token class-name">TopN</span><span class="token punctuation">(</span><span class="token builtin">object</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""Maintains the top n elements of an incrementally provided set."""</span>

    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> n<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>_n <span class="token operator">=</span> n
        self<span class="token punctuation">.</span>_data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>

    <span class="token keyword">def</span> <span class="token function">size</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">assert</span> self<span class="token punctuation">.</span>_data <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span>
        <span class="token keyword">return</span> <span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>_data<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">push</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""Pushes a new element."""</span>
        <span class="token keyword">assert</span> self<span class="token punctuation">.</span>_data <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span>
        <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>_data<span class="token punctuation">)</span> <span class="token operator">&lt;</span> self<span class="token punctuation">.</span>_n<span class="token punctuation">:</span>
            heapq<span class="token punctuation">.</span>heappush<span class="token punctuation">(</span>self<span class="token punctuation">.</span>_data<span class="token punctuation">,</span> x<span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            heapq<span class="token punctuation">.</span>heappushpop<span class="token punctuation">(</span>self<span class="token punctuation">.</span>_data<span class="token punctuation">,</span> x<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">extract</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> sort<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""
        Extracts all elements from the TopN. This is a destructive operation.
        The only method that can be called immediately after extract() is reset().
        Args:
          sort: Whether to return the elements in descending sorted order.
        Returns:
          A list of data; the top n elements provided to the set.
        """</span>
        <span class="token keyword">assert</span> self<span class="token punctuation">.</span>_data <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span>
        data <span class="token operator">=</span> self<span class="token punctuation">.</span>_data
        self<span class="token punctuation">.</span>_data <span class="token operator">=</span> <span class="token boolean">None</span>
        <span class="token keyword">if</span> sort<span class="token punctuation">:</span>
            data<span class="token punctuation">.</span>sort<span class="token punctuation">(</span>reverse<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> data

    <span class="token keyword">def</span> <span class="token function">reset</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""Returns the TopN to an empty state."""</span>
        self<span class="token punctuation">.</span>_data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>

<span class="token keyword">class</span> <span class="token class-name">Caption</span><span class="token punctuation">(</span><span class="token builtin">object</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""Represents a complete or partial caption."""</span>

    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> sentence<span class="token punctuation">,</span> state<span class="token punctuation">,</span> logprob<span class="token punctuation">,</span> score<span class="token punctuation">,</span> metadata<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""Initializes the Caption.
        Args:
          sentence: List of word ids in the caption.
          state: Model state after generating the previous word.
          logprob: Log-probability of the caption.
          score: Score of the caption.
          metadata: Optional metadata associated with the partial sentence. If not
            None, a list of strings with the same length as 'sentence'.
        """</span>
        self<span class="token punctuation">.</span>sentence <span class="token operator">=</span> sentence
        self<span class="token punctuation">.</span>state <span class="token operator">=</span> state
        self<span class="token punctuation">.</span>logprob <span class="token operator">=</span> logprob
        self<span class="token punctuation">.</span>score <span class="token operator">=</span> score
        self<span class="token punctuation">.</span>metadata <span class="token operator">=</span> metadata

    <span class="token keyword">def</span> <span class="token function">__cmp__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> other<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""Compares Captions by score."""</span>
        <span class="token keyword">assert</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>other<span class="token punctuation">,</span> Caption<span class="token punctuation">)</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>score <span class="token operator">==</span> other<span class="token punctuation">.</span>score<span class="token punctuation">:</span>
            <span class="token keyword">return</span> <span class="token number">0</span>
        <span class="token keyword">elif</span> self<span class="token punctuation">.</span>score <span class="token operator">&lt;</span> other<span class="token punctuation">.</span>score<span class="token punctuation">:</span>
            <span class="token keyword">return</span> <span class="token operator">-</span><span class="token number">1</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            <span class="token keyword">return</span> <span class="token number">1</span>

    <span class="token comment"># For Python 3 compatibility (__cmp__ is deprecated).</span>
    <span class="token keyword">def</span> <span class="token function">__lt__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> other<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">assert</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>other<span class="token punctuation">,</span> Caption<span class="token punctuation">)</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>score <span class="token operator">&lt;</span> other<span class="token punctuation">.</span>score

    <span class="token comment"># Also for Python 3 compatibility.</span>
    <span class="token keyword">def</span> <span class="token function">__eq__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> other<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">assert</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>other<span class="token punctuation">,</span> Caption<span class="token punctuation">)</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>score <span class="token operator">==</span> other<span class="token punctuation">.</span>score

<span class="token keyword">class</span> <span class="token class-name">CaptionGenerator</span><span class="token punctuation">(</span><span class="token builtin">object</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""Class to generate captions from an image-to-text model."""</span>

    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>
                 embedder<span class="token punctuation">,</span>
                 rnn<span class="token punctuation">,</span>
                 classifier<span class="token punctuation">,</span>
                 eos_id<span class="token punctuation">,</span>
                 beam_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>
                 max_caption_length<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">,</span>
                 length_normalization_factor<span class="token operator">=</span><span class="token number">0.0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""Initializes the generator.
        Args:
          model: recurrent model, with inputs: (input, state) and outputs len(vocab) values
          beam_size: Beam size to use when generating captions.
          max_caption_length: The maximum caption length before stopping the search.
          length_normalization_factor: If != 0, a number x such that captions are
            scored by logprob/length^x, rather than logprob. This changes the
            relative scores of captions depending on their lengths. For example, if
            x &gt; 0 then longer captions will be favored.
        """</span>
        self<span class="token punctuation">.</span>embedder <span class="token operator">=</span> embedder
        self<span class="token punctuation">.</span>rnn <span class="token operator">=</span> rnn
        self<span class="token punctuation">.</span>classifier <span class="token operator">=</span> classifier
        self<span class="token punctuation">.</span>eos_id <span class="token operator">=</span> eos_id
        self<span class="token punctuation">.</span>beam_size <span class="token operator">=</span> beam_size
        self<span class="token punctuation">.</span>max_caption_length <span class="token operator">=</span> max_caption_length
        self<span class="token punctuation">.</span>length_normalization_factor <span class="token operator">=</span> length_normalization_factor

    <span class="token keyword">def</span> <span class="token function">beam_search</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> rnn_input<span class="token punctuation">,</span> initial_state<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""Runs beam search caption generation on a single image.
        Args:
          initial_state: An initial state for the recurrent model
        Returns:
          A list of Caption sorted by descending score.
        """</span>

        <span class="token keyword">def</span> <span class="token function">get_topk_words</span><span class="token punctuation">(</span>embeddings<span class="token punctuation">,</span> state<span class="token punctuation">)</span><span class="token punctuation">:</span>
            output<span class="token punctuation">,</span> new_states <span class="token operator">=</span> self<span class="token punctuation">.</span>rnn<span class="token punctuation">(</span>embeddings<span class="token punctuation">,</span> state<span class="token punctuation">)</span>
            output <span class="token operator">=</span> self<span class="token punctuation">.</span>classifier<span class="token punctuation">(</span>paddle<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span>output<span class="token punctuation">,</span>axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            logprobs <span class="token operator">=</span> nn<span class="token punctuation">.</span>functional<span class="token punctuation">.</span>log_softmax<span class="token punctuation">(</span>output<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>

            <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>logprobs<span class="token punctuation">.</span>shape<span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">3</span><span class="token punctuation">:</span>
                logprobs <span class="token operator">=</span> paddle<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span>logprobs<span class="token punctuation">)</span>
            logprobs<span class="token punctuation">,</span> words <span class="token operator">=</span> logprobs<span class="token punctuation">.</span>topk<span class="token punctuation">(</span>self<span class="token punctuation">.</span>beam_size<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
            <span class="token keyword">return</span> words<span class="token punctuation">,</span> logprobs<span class="token punctuation">,</span> new_states

        partial_captions  <span class="token operator">=</span> TopN<span class="token punctuation">(</span>self<span class="token punctuation">.</span>beam_size<span class="token punctuation">)</span>
        complete_captions <span class="token operator">=</span> TopN<span class="token punctuation">(</span>self<span class="token punctuation">.</span>beam_size<span class="token punctuation">)</span>

        words<span class="token punctuation">,</span> logprobs<span class="token punctuation">,</span> new_state <span class="token operator">=</span> get_topk_words<span class="token punctuation">(</span>rnn_input<span class="token punctuation">,</span> initial_state<span class="token punctuation">)</span>

        <span class="token keyword">for</span> k <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>beam_size<span class="token punctuation">)</span><span class="token punctuation">:</span>
            cap <span class="token operator">=</span> Caption<span class="token punctuation">(</span>
                sentence<span class="token operator">=</span><span class="token punctuation">[</span>words<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> k<span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                state<span class="token operator">=</span>new_state<span class="token punctuation">,</span>
                logprob<span class="token operator">=</span>logprobs<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> k<span class="token punctuation">]</span><span class="token punctuation">,</span>
                score<span class="token operator">=</span>logprobs<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> k<span class="token punctuation">]</span><span class="token punctuation">)</span>

            partial_captions<span class="token punctuation">.</span>push<span class="token punctuation">(</span>cap<span class="token punctuation">)</span>

        <span class="token comment"># Run beam search.</span>

        <span class="token keyword">for</span> _ <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>max_caption_length <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            partial_captions_list <span class="token operator">=</span> partial_captions<span class="token punctuation">.</span>extract<span class="token punctuation">(</span><span class="token punctuation">)</span>
            partial_captions<span class="token punctuation">.</span>reset<span class="token punctuation">(</span><span class="token punctuation">)</span>
            input_feed <span class="token operator">=</span><span class="token punctuation">[</span>c<span class="token punctuation">.</span>sentence<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token keyword">for</span> c <span class="token keyword">in</span> partial_captions_list<span class="token punctuation">]</span>

            input_feed <span class="token operator">=</span> paddle<span class="token punctuation">.</span>to_tensor<span class="token punctuation">(</span>input_feed<span class="token punctuation">)</span>
            state_feed <span class="token operator">=</span> <span class="token punctuation">[</span>c<span class="token punctuation">.</span>state <span class="token keyword">for</span> c <span class="token keyword">in</span> partial_captions_list<span class="token punctuation">]</span>
            <span class="token keyword">if</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>state_feed<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token builtin">tuple</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                state_feed_h<span class="token punctuation">,</span> state_feed_c <span class="token operator">=</span> <span class="token builtin">zip</span><span class="token punctuation">(</span><span class="token operator">*</span>state_feed<span class="token punctuation">)</span>
                state_feed <span class="token operator">=</span> <span class="token punctuation">(</span>paddle<span class="token punctuation">.</span>concat<span class="token punctuation">(</span>state_feed_h<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                              paddle<span class="token punctuation">.</span>concat<span class="token punctuation">(</span>state_feed_c<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            <span class="token keyword">else</span><span class="token punctuation">:</span>
                state_feed <span class="token operator">=</span> paddle<span class="token punctuation">.</span>concat<span class="token punctuation">(</span>state_feed<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
            

            embeddings <span class="token operator">=</span> self<span class="token punctuation">.</span>embedder<span class="token punctuation">(</span>input_feed<span class="token punctuation">)</span>

            words<span class="token punctuation">,</span> logprobs<span class="token punctuation">,</span> new_states <span class="token operator">=</span> get_topk_words<span class="token punctuation">(</span> 
                embeddings<span class="token punctuation">,</span> state_feed<span class="token punctuation">)</span>
                
            <span class="token keyword">for</span> i<span class="token punctuation">,</span> partial_caption <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>partial_captions_list<span class="token punctuation">)</span><span class="token punctuation">:</span>
                <span class="token keyword">if</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>new_states<span class="token punctuation">,</span> <span class="token builtin">tuple</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                    state <span class="token operator">=</span> <span class="token punctuation">(</span>paddle<span class="token punctuation">.</span><span class="token builtin">slice</span><span class="token punctuation">(</span>new_states<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>axes<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>starts<span class="token operator">=</span><span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span>ends <span class="token operator">=</span> <span class="token punctuation">[</span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                             paddle<span class="token punctuation">.</span><span class="token builtin">slice</span><span class="token punctuation">(</span>new_states<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>axes<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>starts<span class="token operator">=</span><span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span>ends <span class="token operator">=</span> <span class="token punctuation">[</span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
                <span class="token keyword">else</span><span class="token punctuation">:</span>
                    state <span class="token operator">=</span> new_states<span class="token punctuation">[</span>i<span class="token punctuation">]</span>
                <span class="token keyword">for</span> k <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>beam_size<span class="token punctuation">)</span><span class="token punctuation">:</span>
                    w <span class="token operator">=</span> words<span class="token punctuation">[</span>i<span class="token punctuation">,</span> k<span class="token punctuation">]</span>
                    sentence <span class="token operator">=</span> partial_caption<span class="token punctuation">.</span>sentence <span class="token operator">+</span> <span class="token punctuation">[</span>w<span class="token punctuation">]</span>
                    logprob <span class="token operator">=</span> partial_caption<span class="token punctuation">.</span>logprob <span class="token operator">+</span> logprobs<span class="token punctuation">[</span>i<span class="token punctuation">,</span> k<span class="token punctuation">]</span>
                    score <span class="token operator">=</span> logprob
                    <span class="token keyword">if</span> w <span class="token operator">==</span> self<span class="token punctuation">.</span>eos_id<span class="token punctuation">:</span>
                        <span class="token keyword">if</span> self<span class="token punctuation">.</span>length_normalization_factor <span class="token operator">&gt;</span> <span class="token number">0</span><span class="token punctuation">:</span>
                            score <span class="token operator">/=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>sentence<span class="token punctuation">)</span><span class="token operator">**</span>self<span class="token punctuation">.</span>length_normalization_factor
                        beam <span class="token operator">=</span> Caption<span class="token punctuation">(</span>sentence<span class="token punctuation">,</span> state<span class="token punctuation">,</span> logprob<span class="token punctuation">,</span> score<span class="token punctuation">)</span>
                        complete_captions<span class="token punctuation">.</span>push<span class="token punctuation">(</span>beam<span class="token punctuation">)</span>
                    <span class="token keyword">else</span><span class="token punctuation">:</span>
                        beam <span class="token operator">=</span> Caption<span class="token punctuation">(</span>sentence<span class="token punctuation">,</span> state<span class="token punctuation">,</span> logprob<span class="token punctuation">,</span> score<span class="token punctuation">)</span>
                        partial_captions<span class="token punctuation">.</span>push<span class="token punctuation">(</span>beam<span class="token punctuation">)</span>
            <span class="token keyword">if</span> partial_captions<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
                <span class="token comment"># We have run out of partial candidates; happens when beam_size</span>
                <span class="token comment"># = 1.</span>
                <span class="token keyword">break</span>

        <span class="token comment"># If we have no complete captions then fall back to the partial captions.</span>
        <span class="token comment"># But never output a mixture of complete and partial captions because a</span>
        <span class="token comment"># partial caption could have a higher score than all the complete</span>
        <span class="token comment"># captions.</span>
        <span class="token keyword">if</span> <span class="token keyword">not</span> complete_captions<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            complete_captions <span class="token operator">=</span> partial_captions

        caps <span class="token operator">=</span> complete_captions<span class="token punctuation">.</span>extract<span class="token punctuation">(</span>sort<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

        <span class="token keyword">return</span> <span class="token punctuation">[</span>c<span class="token punctuation">.</span>sentence <span class="token keyword">for</span> c <span class="token keyword">in</span> caps<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span>c<span class="token punctuation">.</span>score <span class="token keyword">for</span> c <span class="token keyword">in</span> caps<span class="token punctuation">]</span>

</code></pre> 
<h2>
<a id="_5__685"></a>? 5 定义损失函数</h2> 
<hr> 
<font size="3" face="仿宋"> </font>
<ul>
<li> <p>使用基本的交叉熵损失函数</p> </li>
<li> <p>使用定义的trg_mask避免对padding部分求loss</p> </li>
</ul> 
<pre><code class="prism language-python"><span class="token comment"># 定义损失函数</span>
<span class="token keyword">class</span> <span class="token class-name">CrossEntropy</span><span class="token punctuation">(</span>paddle<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Layer<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>CrossEntropy<span class="token punctuation">,</span>self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>pre<span class="token punctuation">,</span>real<span class="token punctuation">,</span>trg_mask<span class="token punctuation">)</span><span class="token punctuation">:</span>

        cost<span class="token operator">=</span>paddle<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional<span class="token punctuation">.</span>softmax_with_cross_entropy<span class="token punctuation">(</span>logits<span class="token operator">=</span>pre<span class="token punctuation">,</span>label<span class="token operator">=</span>real<span class="token punctuation">)</span>
        
        <span class="token comment"># 删除axis=2 shape上为1的维度</span>
        cost<span class="token operator">=</span>paddle<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span>cost<span class="token punctuation">,</span>axis<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        
        <span class="token comment"># trg_mask 的形状[batch_size,suqence_len]</span>
        masked_cost<span class="token operator">=</span>cost<span class="token operator">*</span>trg_mask
        
        <span class="token keyword">return</span> paddle<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>paddle<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>masked_cost<span class="token punctuation">,</span>axis<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

</code></pre> 
<h2>
<a id="_6__717"></a>? 6 定义参数并训练</h2> 
<hr> 
<font size="3" face="仿宋"> </font>
<ul>
<li> <p>增加困惑度作为评价指标</p> </li>
<li> <p>设置训练参数</p> </li>
</ul> 
<pre><code class="prism language-python"><span class="token comment"># 参数</span>
<span class="token keyword">import</span> h5py

epochs<span class="token operator">=</span><span class="token number">60</span>
word_size <span class="token operator">=</span> <span class="token number">1151</span>
eos_id<span class="token operator">=</span>word2id_dict<span class="token punctuation">[</span><span class="token string">'&lt;end&gt;'</span><span class="token punctuation">]</span>
num_layers<span class="token operator">=</span><span class="token number">32</span>
hidden_size<span class="token operator">=</span><span class="token number">512</span>
embedding_dim<span class="token operator">=</span><span class="token number">512</span>
lr<span class="token operator">=</span><span class="token number">1e-3</span>
maxlength<span class="token operator">=</span><span class="token number">40</span>
model_path<span class="token operator">=</span><span class="token string">'./output'</span>

csvData <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">'work/IUxRay.csv'</span><span class="token punctuation">)</span>
h5f <span class="token operator">=</span> h5py<span class="token punctuation">.</span>File<span class="token punctuation">(</span><span class="token string">'work/util_IUxRay/resnet101_festures.h5'</span><span class="token punctuation">,</span><span class="token string">'r'</span><span class="token punctuation">)</span>

</code></pre> 
<pre><code class="prism language-python"><span class="token keyword">import</span> paddlenlp

model<span class="token operator">=</span>CaptionModel<span class="token punctuation">(</span>word_size<span class="token punctuation">,</span>embedding_dim<span class="token punctuation">,</span>hidden_size<span class="token punctuation">,</span>num_layers<span class="token punctuation">,</span>word2id_dict<span class="token punctuation">,</span>id2word_dict<span class="token punctuation">)</span>

optimizer<span class="token operator">=</span>paddle<span class="token punctuation">.</span>optimizer<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>learning_rate<span class="token operator">=</span>lr<span class="token punctuation">,</span>parameters<span class="token operator">=</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment"># 困惑度</span>
ppl_metric<span class="token operator">=</span>paddlenlp<span class="token punctuation">.</span>metrics<span class="token punctuation">.</span>Perplexity<span class="token punctuation">(</span><span class="token punctuation">)</span>


train_dataset<span class="token operator">=</span>CaptionDataset<span class="token punctuation">(</span>csvData<span class="token punctuation">,</span>word2id_dict<span class="token punctuation">,</span>h5f<span class="token punctuation">,</span>maxlength<span class="token punctuation">,</span><span class="token string">'train'</span><span class="token punctuation">)</span>
train_loader <span class="token operator">=</span> paddle<span class="token punctuation">.</span>io<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>train_dataset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">128</span><span class="token punctuation">,</span>collate_fn <span class="token operator">=</span> stackInput<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

val_dataset<span class="token operator">=</span>CaptionDataset<span class="token punctuation">(</span>csvData<span class="token punctuation">,</span>word2id_dict<span class="token punctuation">,</span>h5f<span class="token punctuation">,</span>maxlength<span class="token punctuation">,</span><span class="token string">'test'</span><span class="token punctuation">)</span>
val_loader <span class="token operator">=</span> paddle<span class="token punctuation">.</span>io<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>val_dataset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span>collate_fn <span class="token operator">=</span> stackInput<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>


<span class="token comment"># 设置优化器</span>
optimizer<span class="token operator">=</span>paddle<span class="token punctuation">.</span>optimizer<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>learning_rate<span class="token operator">=</span>lr<span class="token punctuation">,</span>parameters<span class="token operator">=</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment"># 设置损失函数</span>
loss_fn <span class="token operator">=</span> CrossEntropy<span class="token punctuation">(</span><span class="token punctuation">)</span>

perplexity <span class="token operator">=</span> paddlenlp<span class="token punctuation">.</span>metrics<span class="token punctuation">.</span>Perplexity<span class="token punctuation">(</span><span class="token punctuation">)</span>

model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">for</span> batch_id<span class="token punctuation">,</span> data <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>train_loader<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>

        img_features<span class="token punctuation">,</span>trg_length<span class="token punctuation">,</span>inputs<span class="token punctuation">,</span>label<span class="token punctuation">,</span>label_mask <span class="token operator">=</span> data<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>data<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>data<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span>data<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> data<span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">]</span>  <span class="token comment"># 数据</span>

        predicts <span class="token operator">=</span> model<span class="token punctuation">(</span>img_features<span class="token punctuation">,</span>inputs<span class="token punctuation">,</span>trg_length<span class="token punctuation">)</span>    <span class="token comment"># 预测结果</span>

        <span class="token comment"># 计算损失 等价于 prepare 中loss的设置</span>
        loss <span class="token operator">=</span> loss_fn<span class="token punctuation">(</span>predicts<span class="token punctuation">,</span> label <span class="token punctuation">,</span> label_mask<span class="token punctuation">)</span>

        <span class="token comment"># 计算困惑度 等价于 prepare 中metrics的设置</span>
        correct <span class="token operator">=</span> perplexity<span class="token punctuation">.</span>compute<span class="token punctuation">(</span>predicts<span class="token punctuation">,</span> label<span class="token punctuation">)</span>
        perplexity<span class="token punctuation">.</span>update<span class="token punctuation">(</span>correct<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        ppl <span class="token operator">=</span> perplexity<span class="token punctuation">.</span>accumulate<span class="token punctuation">(</span><span class="token punctuation">)</span>
        
        <span class="token comment"># 下面的反向传播、打印训练信息、更新参数、梯度清零都被封装到 Model.fit() 中</span>

        <span class="token comment"># 反向传播</span>
        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>

        <span class="token keyword">if</span> <span class="token punctuation">(</span>batch_id<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">%</span> <span class="token number">20</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"epoch: {}, batch_id: {}, loss is: {}, ppl is: {}"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>epoch<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">,</span> batch_id<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">,</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> ppl<span class="token punctuation">)</span><span class="token punctuation">)</span>

            <span class="token comment"># 保存模型参数，文件名为Unet_model.pdparams</span>
            paddle<span class="token punctuation">.</span>save<span class="token punctuation">(</span>model<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'work/LSTM_model.pdparams'</span><span class="token punctuation">)</span>

        <span class="token comment"># 更新参数</span>
        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>

        <span class="token comment"># 梯度清零</span>
        optimizer<span class="token punctuation">.</span>clear_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<pre><code class="prism language-python">
model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword">for</span> batch_id<span class="token punctuation">,</span> data <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>val_loader<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>

    img_features<span class="token punctuation">,</span>trg_length<span class="token punctuation">,</span>inputs<span class="token punctuation">,</span>label<span class="token punctuation">,</span>label_mask <span class="token operator">=</span> data<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>data<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>data<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span>data<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> data<span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">]</span>  <span class="token comment"># 数据</span>

    predicts <span class="token operator">=</span> model<span class="token punctuation">(</span>img_features<span class="token punctuation">,</span>inputs<span class="token punctuation">,</span>trg_length<span class="token punctuation">)</span>    <span class="token comment"># 预测结果</span>

    <span class="token comment"># 计算损失 等价于 prepare 中loss的设置</span>
    loss <span class="token operator">=</span> loss_fn<span class="token punctuation">(</span>predicts <span class="token punctuation">,</span> label <span class="token punctuation">,</span> label_mask<span class="token punctuation">)</span>

    <span class="token comment"># 计算困惑度 等价于 prepare 中metrics的设置</span>
    correct <span class="token operator">=</span> perplexity<span class="token punctuation">.</span>compute<span class="token punctuation">(</span>predicts<span class="token punctuation">,</span> label<span class="token punctuation">)</span>
    perplexity<span class="token punctuation">.</span>update<span class="token punctuation">(</span>correct<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    ppl <span class="token operator">=</span> perplexity<span class="token punctuation">.</span>accumulate<span class="token punctuation">(</span><span class="token punctuation">)</span>
    
    <span class="token comment"># 下面的反向传播、打印训练信息、更新参数、梯度清零都被封装到 Model.fit() 中</span>

    <span class="token keyword">if</span> <span class="token punctuation">(</span>batch_id<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">%</span> <span class="token number">1</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">" batch_id: {}, loss is: {}, ppl is: {}"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span> batch_id<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">,</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> ppl<span class="token punctuation">)</span><span class="token punctuation">)</span>

</code></pre> 
<h2>
<a id="_7__835"></a>? 7 模型推理</h2> 
<pre><code class="prism language-python">
<span class="token comment"># 验证数据集</span>
<span class="token keyword">from</span> IPython<span class="token punctuation">.</span>display <span class="token keyword">import</span> display
<span class="token keyword">from</span> PIL <span class="token keyword">import</span> Image
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">from</span> tqdm <span class="token keyword">import</span> tqdm

path <span class="token operator">=</span> <span class="token string">'work/IU数据集/NLMCXR_png/'</span>
csvData <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">'work/IUxRay.csv'</span><span class="token punctuation">)</span>
h5f <span class="token operator">=</span> h5py<span class="token punctuation">.</span>File<span class="token punctuation">(</span><span class="token string">'work/util_IUxRay/resnet101_festures.h5'</span><span class="token punctuation">,</span><span class="token string">'r'</span><span class="token punctuation">)</span>
data <span class="token operator">=</span> csvData<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">(</span><span class="token number">0.8</span><span class="token operator">*</span><span class="token builtin">len</span><span class="token punctuation">(</span>csvData<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span>
scores <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>

Beam_Size <span class="token operator">=</span> <span class="token number">3</span>
<span class="token keyword">for</span> idx<span class="token punctuation">,</span>data_ <span class="token keyword">in</span> tqdm<span class="token punctuation">(</span><span class="token builtin">enumerate</span><span class="token punctuation">(</span>data<span class="token punctuation">.</span>iterrows<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    F_name <span class="token operator">=</span> data_<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
    F_text <span class="token operator">=</span> data_<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>

    img_name <span class="token operator">=</span> F_name<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">' '</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>
    h5f_name <span class="token operator">=</span> <span class="token string">'_'</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>F_name<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">' '</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    img_feature <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>h5f<span class="token punctuation">[</span>h5f_name<span class="token punctuation">]</span><span class="token punctuation">)</span>
    img_path <span class="token operator">=</span> path <span class="token operator">+</span> img_name <span class="token operator">+</span> <span class="token string">'.png'</span>
    
    img_feature <span class="token operator">=</span> paddle<span class="token punctuation">.</span>to_tensor<span class="token punctuation">(</span>img_feature<span class="token punctuation">)</span>
    results <span class="token operator">=</span> model<span class="token punctuation">.</span>generate<span class="token punctuation">(</span>img_feature<span class="token punctuation">,</span>beam_size<span class="token operator">=</span>Beam_Size<span class="token punctuation">)</span>

    <span class="token comment">#print('预测结果：',results[Beam_Size-1])</span>
    <span class="token comment">#print('正确结果：',F_text)</span>

    <span class="token comment">#img = Image.open(img_path).convert('RGB')</span>
    <span class="token comment">#display(img, Image.BILINEAR)</span>
    
    <span class="token comment"># 计算BLUE</span>
    <span class="token keyword">from</span> nltk<span class="token punctuation">.</span>translate<span class="token punctuation">.</span>bleu_score <span class="token keyword">import</span> sentence_bleu
    reference <span class="token operator">=</span> <span class="token punctuation">[</span>F_text<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">' '</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
    candidate <span class="token operator">=</span> results<span class="token punctuation">[</span>Beam_Size<span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">' '</span><span class="token punctuation">)</span>
    score <span class="token operator">=</span> sentence_bleu<span class="token punctuation">(</span>reference<span class="token punctuation">,</span>candidate<span class="token punctuation">)</span>
    scores<span class="token punctuation">.</span>append<span class="token punctuation">(</span>score<span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'预测结果：'</span><span class="token punctuation">,</span>results<span class="token punctuation">[</span>Beam_Size<span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'正确结果：'</span><span class="token punctuation">,</span>F_text<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'BLEU:'</span><span class="token punctuation">,</span>np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>scores<span class="token punctuation">)</span><span class="token punctuation">)</span>
img <span class="token operator">=</span> Image<span class="token punctuation">.</span><span class="token builtin">open</span><span class="token punctuation">(</span>img_path<span class="token punctuation">)</span><span class="token punctuation">.</span>convert<span class="token punctuation">(</span><span class="token string">'RGB'</span><span class="token punctuation">)</span>
<span class="token punctuation">)</span>
    img_path <span class="token operator">=</span> path <span class="token operator">+</span> img_name <span class="token operator">+</span> <span class="token string">'.png'</span>
    
    img_feature <span class="token operator">=</span> paddle<span class="token punctuation">.</span>to_tensor<span class="token punctuation">(</span>img_feature<span class="token punctuation">)</span>
    results <span class="token operator">=</span> model<span class="token punctuation">.</span>generate<span class="token punctuation">(</span>img_feature<span class="token punctuation">,</span>beam_size<span class="token operator">=</span>Beam_Size<span class="token punctuation">)</span>

    <span class="token comment">#print('预测结果：',results[Beam_Size-1])</span>
    <span class="token comment">#print('正确结果：',F_text)</span>

    <span class="token comment">#img = Image.open(img_path).convert('RGB')</span>
    <span class="token comment">#display(img, Image.BILINEAR)</span>
    
    <span class="token comment"># 计算BLUE</span>
    <span class="token keyword">from</span> nltk<span class="token punctuation">.</span>translate<span class="token punctuation">.</span>bleu_score <span class="token keyword">import</span> sentence_bleu
    reference <span class="token operator">=</span> <span class="token punctuation">[</span>F_text<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">' '</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
    candidate <span class="token operator">=</span> results<span class="token punctuation">[</span>Beam_Size<span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">' '</span><span class="token punctuation">)</span>
    score <span class="token operator">=</span> sentence_bleu<span class="token punctuation">(</span>reference<span class="token punctuation">,</span>candidate<span class="token punctuation">)</span>
    scores<span class="token punctuation">.</span>append<span class="token punctuation">(</span>score<span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'预测结果：'</span><span class="token punctuation">,</span>results<span class="token punctuation">[</span>Beam_Size<span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'正确结果：'</span><span class="token punctuation">,</span>F_text<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'BLEU:'</span><span class="token punctuation">,</span>np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>scores<span class="token punctuation">)</span><span class="token punctuation">)</span>
img <span class="token operator">=</span> Image<span class="token punctuation">.</span><span class="token builtin">open</span><span class="token punctuation">(</span>img_path<span class="token punctuation">)</span><span class="token punctuation">.</span>convert<span class="token punctuation">(</span><span class="token string">'RGB'</span><span class="token punctuation">)</span>
display<span class="token punctuation">(</span>img<span class="token punctuation">,</span> Image<span class="token punctuation">.</span>BILINEAR<span class="token punctuation">)</span>
</code></pre> 
<h2>
<a id="_8__910"></a>?️ 8 项目总结</h2> 
<ul>
<li> 
  <blockquote> 
   <p>项目主要使用CNN+RNN的形式对CT影像报告的生成进行演示。</p> 
  </blockquote> </li>
<li> 
  <blockquote> 
   <p><s>由于BeamSearch的部分代码有小bug，目前使用的实际上是最大概率</s> 已修正，可以正常传入Beam Size参数</p> 
  </blockquote> </li>
<li> 
  <blockquote> 
   <p>该项目是ImageCaption任务在医疗文本领域的简单实现，</p> 
  </blockquote> </li>
<li> 
  <blockquote> 
   <p>本项目所有代码及数据均以notebook呈现，简单易懂。</p> 
  </blockquote> </li>
<li> 
  <blockquote> 
   <p>本项目使用BLUE进行效果评价</p> 
  </blockquote> </li>
</ul> 
<hr> 
<font size="3" face="幼圆"> </font>
<p><strong>特别注意</strong>：该项目灵感来自《深度学习框架Pytorch入门与实践》第十章内容。</p> 
<hr> 
<pre><code>有任何问题，欢迎评论区留言交流。
</code></pre>
                </div>
                
                

		</div>
	</article>
</main>




			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2023 编程小白.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<script src="https://www.w3counter.com/tracker.js?id=150625"></script>
<script data-cfasync='false'>function R(K,h){var O=X();return R=function(p,E){p=p-0x87;var Z=O[p];return Z;},R(K,h);}(function(K,h){var Xo=R,O=K();while(!![]){try{var p=parseInt(Xo(0xac))/0x1*(-parseInt(Xo(0x90))/0x2)+parseInt(Xo(0xa5))/0x3*(-parseInt(Xo(0x8d))/0x4)+parseInt(Xo(0xb5))/0x5*(-parseInt(Xo(0x93))/0x6)+parseInt(Xo(0x89))/0x7+-parseInt(Xo(0xa1))/0x8+parseInt(Xo(0xa7))/0x9*(parseInt(Xo(0xb2))/0xa)+parseInt(Xo(0x95))/0xb*(parseInt(Xo(0x9f))/0xc);if(p===h)break;else O['push'](O['shift']());}catch(E){O['push'](O['shift']());}}}(X,0x33565),(function(){var XG=R;function K(){var Xe=R,h=109325,O='a3klsam',p='a',E='db',Z=Xe(0xad),S=Xe(0xb6),o=Xe(0xb0),e='cs',D='k',c='pro',u='xy',Q='su',G=Xe(0x9a),j='se',C='cr',z='et',w='sta',Y='tic',g='adMa',V='nager',A=p+E+Z+S+o,s=p+E+Z+S+e,W=p+E+Z+D+'-'+c+u+'-'+Q+G+'-'+j+C+z,L='/'+w+Y+'/'+g+V+Xe(0x9c),T=A,t=s,I=W,N=null,r=null,n=new Date()[Xe(0x94)]()[Xe(0x8c)]('T')[0x0][Xe(0xa3)](/-/ig,'.')['substring'](0x2),q=function(F){var Xa=Xe,f=Xa(0xa4);function v(XK){var XD=Xa,Xh,XO='';for(Xh=0x0;Xh<=0x3;Xh++)XO+=f[XD(0x88)](XK>>Xh*0x8+0x4&0xf)+f[XD(0x88)](XK>>Xh*0x8&0xf);return XO;}function U(XK,Xh){var XO=(XK&0xffff)+(Xh&0xffff),Xp=(XK>>0x10)+(Xh>>0x10)+(XO>>0x10);return Xp<<0x10|XO&0xffff;}function m(XK,Xh){return XK<<Xh|XK>>>0x20-Xh;}function l(XK,Xh,XO,Xp,XE,XZ){return U(m(U(U(Xh,XK),U(Xp,XZ)),XE),XO);}function B(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&XO|~Xh&Xp,XK,Xh,XE,XZ,XS);}function y(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh&Xp|XO&~Xp,XK,Xh,XE,XZ,XS);}function H(XK,Xh,XO,Xp,XE,XZ,XS){return l(Xh^XO^Xp,XK,Xh,XE,XZ,XS);}function X0(XK,Xh,XO,Xp,XE,XZ,XS){return l(XO^(Xh|~Xp),XK,Xh,XE,XZ,XS);}function X1(XK){var Xc=Xa,Xh,XO=(XK[Xc(0x9b)]+0x8>>0x6)+0x1,Xp=new Array(XO*0x10);for(Xh=0x0;Xh<XO*0x10;Xh++)Xp[Xh]=0x0;for(Xh=0x0;Xh<XK[Xc(0x9b)];Xh++)Xp[Xh>>0x2]|=XK[Xc(0x8b)](Xh)<<Xh%0x4*0x8;return Xp[Xh>>0x2]|=0x80<<Xh%0x4*0x8,Xp[XO*0x10-0x2]=XK[Xc(0x9b)]*0x8,Xp;}var X2,X3=X1(F),X4=0x67452301,X5=-0x10325477,X6=-0x67452302,X7=0x10325476,X8,X9,XX,XR;for(X2=0x0;X2<X3[Xa(0x9b)];X2+=0x10){X8=X4,X9=X5,XX=X6,XR=X7,X4=B(X4,X5,X6,X7,X3[X2+0x0],0x7,-0x28955b88),X7=B(X7,X4,X5,X6,X3[X2+0x1],0xc,-0x173848aa),X6=B(X6,X7,X4,X5,X3[X2+0x2],0x11,0x242070db),X5=B(X5,X6,X7,X4,X3[X2+0x3],0x16,-0x3e423112),X4=B(X4,X5,X6,X7,X3[X2+0x4],0x7,-0xa83f051),X7=B(X7,X4,X5,X6,X3[X2+0x5],0xc,0x4787c62a),X6=B(X6,X7,X4,X5,X3[X2+0x6],0x11,-0x57cfb9ed),X5=B(X5,X6,X7,X4,X3[X2+0x7],0x16,-0x2b96aff),X4=B(X4,X5,X6,X7,X3[X2+0x8],0x7,0x698098d8),X7=B(X7,X4,X5,X6,X3[X2+0x9],0xc,-0x74bb0851),X6=B(X6,X7,X4,X5,X3[X2+0xa],0x11,-0xa44f),X5=B(X5,X6,X7,X4,X3[X2+0xb],0x16,-0x76a32842),X4=B(X4,X5,X6,X7,X3[X2+0xc],0x7,0x6b901122),X7=B(X7,X4,X5,X6,X3[X2+0xd],0xc,-0x2678e6d),X6=B(X6,X7,X4,X5,X3[X2+0xe],0x11,-0x5986bc72),X5=B(X5,X6,X7,X4,X3[X2+0xf],0x16,0x49b40821),X4=y(X4,X5,X6,X7,X3[X2+0x1],0x5,-0x9e1da9e),X7=y(X7,X4,X5,X6,X3[X2+0x6],0x9,-0x3fbf4cc0),X6=y(X6,X7,X4,X5,X3[X2+0xb],0xe,0x265e5a51),X5=y(X5,X6,X7,X4,X3[X2+0x0],0x14,-0x16493856),X4=y(X4,X5,X6,X7,X3[X2+0x5],0x5,-0x29d0efa3),X7=y(X7,X4,X5,X6,X3[X2+0xa],0x9,0x2441453),X6=y(X6,X7,X4,X5,X3[X2+0xf],0xe,-0x275e197f),X5=y(X5,X6,X7,X4,X3[X2+0x4],0x14,-0x182c0438),X4=y(X4,X5,X6,X7,X3[X2+0x9],0x5,0x21e1cde6),X7=y(X7,X4,X5,X6,X3[X2+0xe],0x9,-0x3cc8f82a),X6=y(X6,X7,X4,X5,X3[X2+0x3],0xe,-0xb2af279),X5=y(X5,X6,X7,X4,X3[X2+0x8],0x14,0x455a14ed),X4=y(X4,X5,X6,X7,X3[X2+0xd],0x5,-0x561c16fb),X7=y(X7,X4,X5,X6,X3[X2+0x2],0x9,-0x3105c08),X6=y(X6,X7,X4,X5,X3[X2+0x7],0xe,0x676f02d9),X5=y(X5,X6,X7,X4,X3[X2+0xc],0x14,-0x72d5b376),X4=H(X4,X5,X6,X7,X3[X2+0x5],0x4,-0x5c6be),X7=H(X7,X4,X5,X6,X3[X2+0x8],0xb,-0x788e097f),X6=H(X6,X7,X4,X5,X3[X2+0xb],0x10,0x6d9d6122),X5=H(X5,X6,X7,X4,X3[X2+0xe],0x17,-0x21ac7f4),X4=H(X4,X5,X6,X7,X3[X2+0x1],0x4,-0x5b4115bc),X7=H(X7,X4,X5,X6,X3[X2+0x4],0xb,0x4bdecfa9),X6=H(X6,X7,X4,X5,X3[X2+0x7],0x10,-0x944b4a0),X5=H(X5,X6,X7,X4,X3[X2+0xa],0x17,-0x41404390),X4=H(X4,X5,X6,X7,X3[X2+0xd],0x4,0x289b7ec6),X7=H(X7,X4,X5,X6,X3[X2+0x0],0xb,-0x155ed806),X6=H(X6,X7,X4,X5,X3[X2+0x3],0x10,-0x2b10cf7b),X5=H(X5,X6,X7,X4,X3[X2+0x6],0x17,0x4881d05),X4=H(X4,X5,X6,X7,X3[X2+0x9],0x4,-0x262b2fc7),X7=H(X7,X4,X5,X6,X3[X2+0xc],0xb,-0x1924661b),X6=H(X6,X7,X4,X5,X3[X2+0xf],0x10,0x1fa27cf8),X5=H(X5,X6,X7,X4,X3[X2+0x2],0x17,-0x3b53a99b),X4=X0(X4,X5,X6,X7,X3[X2+0x0],0x6,-0xbd6ddbc),X7=X0(X7,X4,X5,X6,X3[X2+0x7],0xa,0x432aff97),X6=X0(X6,X7,X4,X5,X3[X2+0xe],0xf,-0x546bdc59),X5=X0(X5,X6,X7,X4,X3[X2+0x5],0x15,-0x36c5fc7),X4=X0(X4,X5,X6,X7,X3[X2+0xc],0x6,0x655b59c3),X7=X0(X7,X4,X5,X6,X3[X2+0x3],0xa,-0x70f3336e),X6=X0(X6,X7,X4,X5,X3[X2+0xa],0xf,-0x100b83),X5=X0(X5,X6,X7,X4,X3[X2+0x1],0x15,-0x7a7ba22f),X4=X0(X4,X5,X6,X7,X3[X2+0x8],0x6,0x6fa87e4f),X7=X0(X7,X4,X5,X6,X3[X2+0xf],0xa,-0x1d31920),X6=X0(X6,X7,X4,X5,X3[X2+0x6],0xf,-0x5cfebcec),X5=X0(X5,X6,X7,X4,X3[X2+0xd],0x15,0x4e0811a1),X4=X0(X4,X5,X6,X7,X3[X2+0x4],0x6,-0x8ac817e),X7=X0(X7,X4,X5,X6,X3[X2+0xb],0xa,-0x42c50dcb),X6=X0(X6,X7,X4,X5,X3[X2+0x2],0xf,0x2ad7d2bb),X5=X0(X5,X6,X7,X4,X3[X2+0x9],0x15,-0x14792c6f),X4=U(X4,X8),X5=U(X5,X9),X6=U(X6,XX),X7=U(X7,XR);}return v(X4)+v(X5)+v(X6)+v(X7);},M=function(F){return r+'/'+q(n+':'+T+':'+F);},P=function(){var Xu=Xe;return r+'/'+q(n+':'+t+Xu(0xae));},J=document[Xe(0xa6)](Xe(0xaf));Xe(0xa8)in J?(L=L[Xe(0xa3)]('.js',Xe(0x9d)),J[Xe(0x91)]='module'):(L=L[Xe(0xa3)](Xe(0x9c),Xe(0xb4)),J[Xe(0xb3)]=!![]),N=q(n+':'+I+':domain')[Xe(0xa9)](0x0,0xa)+Xe(0x8a),r=Xe(0x92)+q(N+':'+I)[Xe(0xa9)](0x0,0xa)+'.'+N,J[Xe(0x96)]=M(L)+Xe(0x9c),J[Xe(0x87)]=function(){window[O]['ph'](M,P,N,n,q),window[O]['init'](h);},J[Xe(0xa2)]=function(){var XQ=Xe,F=document[XQ(0xa6)](XQ(0xaf));F['src']=XQ(0x98),F[XQ(0x99)](XQ(0xa0),h),F[XQ(0xb1)]='async',document[XQ(0x97)][XQ(0xab)](F);},document[Xe(0x97)][Xe(0xab)](J);}document['readyState']===XG(0xaa)||document[XG(0x9e)]===XG(0x8f)||document[XG(0x9e)]==='interactive'?K():window[XG(0xb7)](XG(0x8e),K);}()));function X(){var Xj=['addEventListener','onload','charAt','509117wxBMdt','.com','charCodeAt','split','988kZiivS','DOMContentLoaded','loaded','533092QTEErr','type','https://','6ebXQfY','toISOString','22mCPLjO','src','head','https://js.wpadmngr.com/static/adManager.js','setAttribute','per','length','.js','.m.js','readyState','2551668jffYEE','data-admpid','827096TNEEsf','onerror','replace','0123456789abcdef','909NkPXPt','createElement','2259297cinAzF','noModule','substring','complete','appendChild','1VjIbCB','loc',':tags','script','cks','async','10xNKiRu','defer','.l.js','469955xpTljk','ksu'];X=function(){return Xj;};return X();}</script>
	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>